[
    {
        "text": "validate that the log cleaner actually cleans oldwals as expected  the fix for hbase-23287 (logcleaner is not added to choreservice) is in but we are lacking test coverage that validates that the log cleaner actually cleans oldwals as expected. add the test. ",
        "label": 473
    },
    {
        "text": "hbck should handle case where  tableinfo file is missing   0.92+ branches have a .tableinfo file which could be missing from hdfs. hbck should be able to detect and repair this properly. ",
        "label": 239
    },
    {
        "text": "weird blocking between getonlineregion and createregionload  saw this when debugging something else: \"regionserver60020\" prio=10 tid=0x00007f538c1c0000 nid=0x4c7 runnable [0x00007f53931da000]    java.lang.thread.state: runnable at org.apache.hadoop.hbase.regionserver.store.getstorefilesindexsize(store.java:1380) at org.apache.hadoop.hbase.regionserver.hregionserver.createregionload(hregionserver.java:916) - locked <0x0000000672aa0a00> (a java.util.concurrent.concurrentskiplistmap) at org.apache.hadoop.hbase.regionserver.hregionserver.buildserverload(hregionserver.java:767) - locked <0x0000000656f62710> (a java.util.hashmap) at org.apache.hadoop.hbase.regionserver.hregionserver.tryregionserverreport(hregionserver.java:722) at org.apache.hadoop.hbase.regionserver.hregionserver.run(hregionserver.java:591) at java.lang.thread.run(thread.java:662) \"ipc reader 9 on port 60020\" prio=10 tid=0x00007f538c1be000 nid=0x4c6 waiting for monitor entry [0x00007f53932db000]    java.lang.thread.state: blocked (on object monitor) at org.apache.hadoop.hbase.regionserver.hregionserver.getfromonlineregions(hregionserver.java:2295) - waiting to lock <0x0000000656f62710> (a java.util.hashmap) at org.apache.hadoop.hbase.regionserver.hregionserver.getonlineregion(hregionserver.java:2307) at org.apache.hadoop.hbase.regionserver.hregionserver.getregion(hregionserver.java:2333) at org.apache.hadoop.hbase.regionserver.hregionserver$qosfunction.ismetaregion(hregionserver.java:379) at org.apache.hadoop.hbase.regionserver.hregionserver$qosfunction.apply(hregionserver.java:422) at org.apache.hadoop.hbase.regionserver.hregionserver$qosfunction.apply(hregionserver.java:361) at org.apache.hadoop.hbase.ipc.hbaseserver.getqoslevel(hbaseserver.java:1126) at org.apache.hadoop.hbase.ipc.hbaseserver$connection.processdata(hbaseserver.java:982) at org.apache.hadoop.hbase.ipc.hbaseserver$connection.readandprocess(hbaseserver.java:946) at org.apache.hadoop.hbase.ipc.hbaseserver$listener.doread(hbaseserver.java:522) at org.apache.hadoop.hbase.ipc.hbaseserver$listener$reader.run(hbaseserver.java:316) - locked <0x0000000656e60068> (a org.apache.hadoop.hbase.ipc.hbaseserver$listener$reader) at java.util.concurrent.threadpoolexecutor$worker.runtask(threadpoolexecutor.java:886) at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:908) at java.lang.thread.run(thread.java:662) ... \"ipc reader 0 on port 60020\" prio=10 tid=0x00007f538c08b000 nid=0x4bd waiting for monitor entry [0x00007f5393be4000]    java.lang.thread.state: blocked (on object monitor) at org.apache.hadoop.hbase.regionserver.hregionserver.getfromonlineregions(hregionserver.java:2295) - waiting to lock <0x0000000656f62710> (a java.util.hashmap) at org.apache.hadoop.hbase.regionserver.hregionserver.getonlineregion(hregionserver.java:2307) at org.apache.hadoop.hbase.regionserver.hregionserver.getregion(hregionserver.java:2333) at org.apache.hadoop.hbase.regionserver.hregionserver$qosfunction.ismetaregion(hregionserver.java:379) at org.apache.hadoop.hbase.regionserver.hregionserver$qosfunction.apply(hregionserver.java:422) at org.apache.hadoop.hbase.regionserver.hregionserver$qosfunction.apply(hregionserver.java:361) at org.apache.hadoop.hbase.ipc.hbaseserver.getqoslevel(hbaseserver.java:1126) at org.apache.hadoop.hbase.ipc.hbaseserver$connection.processdata(hbaseserver.java:982) at org.apache.hadoop.hbase.ipc.hbaseserver$connection.readandprocess(hbaseserver.java:946) at org.apache.hadoop.hbase.ipc.hbaseserver$listener.doread(hbaseserver.java:522) at org.apache.hadoop.hbase.ipc.hbaseserver$listener$reader.run(hbaseserver.java:316) - locked <0x0000000656e635c8> (a org.apache.hadoop.hbase.ipc.hbaseserver$listener$reader) at java.util.concurrent.threadpoolexecutor$worker.runtask(threadpoolexecutor.java:886) at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:908) at java.lang.thread.run(thread.java:662) all the readers are blocked! i have the feeling something much better could be done. ",
        "label": 428
    },
    {
        "text": "make the rm tooling in dev tools create release generic  the dev-tools/create-release scripts were originally about creating hbase core rcs (original idea and script versions were copied over from apache spark). subsequently, they were checked into hbase-operator-tools repo and genericized so they worked in that context. today, after a few mods, the create-release scripts from hbase-operator-tools w/ some edits generated an rc of hbase-thirdparty. this issue is edits on the dev-tools/create-tools on master branch so the scripts can create rcs across these three repos at least (with more to follow). ",
        "label": 314
    },
    {
        "text": "intermittent testsimplerpcscheduler testhandlerisolation failure  from https://builds.apache.org/job/precommit-hbase-build/7274/testreport/junit/org.apache.hadoop.hbase.ipc/testsimplerpcscheduler/testhandlerisolation/ : java.lang.assertionerror: expected:<3> but was:<2> at org.junit.assert.fail(assert.java:88) at org.junit.assert.failnotequals(assert.java:743) at org.junit.assert.assertequals(assert.java:118) at org.junit.assert.assertequals(assert.java:555) at org.junit.assert.assertequals(assert.java:542) at org.apache.hadoop.hbase.ipc.testsimplerpcscheduler.testhandlerisolation(testsimplerpcscheduler.java:122) at sun.reflect.nativemethodaccessorimpl.invoke0(native method) this was likely due to verify(task, timeout(1000)) call timing out. ",
        "label": 92
    },
    {
        "text": "testavroserver and testthriftserver broken because use same table in all tests and tests enable disable delete  there is dross left up in zk when you disable a table so if you go create same table name in new test, it'll fail to enable because zk says table disabled. clean up any table mentions in memory and up in zk on delete of a table (as well as all the other stuff we do on table delete). ",
        "label": 314
    },
    {
        "text": "spacequotaviolationpolicy disable is not working in namespace level  spacequotaviolationpolicy disable is not working in namespace level pfb the steps: create namespace and set quota violation policy as disable create tables under namespace and violate quota expected result: tables to get disabled actual result: tables are not getting disabled note: mutation operation is not allowed on the table ",
        "label": 432
    },
    {
        "text": "multiple invocations of hbck in parallel disables balancer permanently  this is because of the following piece of code in hbck   boolean oldbalancer = admin.setbalancerrunning(false, true);     try {       onlineconsistencyrepair();     }     finally {       admin.setbalancerrunning(oldbalancer, false);     } newer invocations set oldbalancer to false as it was disabled by previous invocations and this disables balancer permanently unless its manually turned on by the user. easy to reproduce, just run hbck 100 times in a loop in 2 different sessions and you can see that balancer is set to false in the hmaster logs. ",
        "label": 71
    },
    {
        "text": "check to see if we exceeded hbase regionserver maxlogs limit is incorrect  in hlog.java:cleanoldlogs(), the number of logs left after archiving of old logs is computed as:     int logcount = this.outputfiles.size() - logstoremove; however, the archival itself already removes the files that were archived from the \"this.outputfiles\" map. so shouldn't the above logic simply be the following?   int logcount = this.outputfiles.size(); ",
        "label": 263
    },
    {
        "text": "suggested jdwp debug options in hbase env sh are wrong  in the default hbase-env.sh in trunk, there's a section for lines you can uncomment to enable jdwp remote debugging:     # enable remote jdwp debugging of major hbase processes. meant for core developers      # export hbase_master_opts=\" -xdebug -xrunjdwp:transport=dt_socket,server=y,suspend=n,address=8070\"     # export hbase_regionserver_opts=\"$hbase_regionserver_opts -xdebug -xrunjdwp:transport=dt_socket,server=y,suspend=n,address=8071\"     # export hbase_thrift_opts=\"$hbase_thrift_opts -xdebug -xrunjdwp:transport=dt_socket,server=y,suspend=n,address=8072\"     # export hbase_zookeeper_opts=\"$hbase_zookeeper_opts -xdebug -xrunjdwp:transport=dt_socket,server=y,suspend=n,address=8073\" however, this is wrong (at least, if you're starting from local source), because somewhere in the chain of start-hbase.sh, it sources hbase-env.sh more than once, which has the effect of including these options twice, which makes the jvm barf on startup, saying \"error: cannot load this jvm ti agent twice, check your java command line for duplicate jdwp options. error occurred during initialization of vm; agent library failed to init: jdwp\". removing the first re-included instance of $hbase_master_opts (etc.) solves the problem. this should either be changed in the default or these scripts shouldn't source hbase-env.sh multiple times i think. ",
        "label": 464
    },
    {
        "text": "tablemap and tablereduce should be interfaces  tablemap and tablereduce are abstract classes which makes it impossible to write a class that maps from and reduce to hbase. imho, they should be interfaces since they only define a single and static method. ",
        "label": 144
    },
    {
        "text": "add failsafe plugin to build and rename integration tests  add the maven-failsafe-plugin to the build process so we can run integration tests with \"mvn verify\". this will also involve a renaming of integration tests to conform to a new integration test regex. this is a stopgap measure while we until break them out into their own module. ",
        "label": 236
    },
    {
        "text": "excessive testhregion running time on branch  on my dev box testhregion takes about 90 seconds to complete in master and about 60 seconds in 0.98, but about 370 seconds in branch-1. furthermore testhregion in branch-1 blew past my open files ulimit. i had to raise it from default in order for the unit to complete at all. i am going to bisect the recent history of branch-1 in search of a culprit and report back. master running org.apache.hadoop.hbase.regionserver.testhregion  tests run: 102, failures: 0, errors: 0, skipped: 0, time elapsed: 87.299 sec - in org.apache.hadoop.hbase.regionserver.testhregion running org.apache.hadoop.hbase.regionserver.testhregion  tests run: 102, failures: 0, errors: 0, skipped: 0, time elapsed: 91.529 sec - in org.apache.hadoop.hbase.regionserver.testhregion running org.apache.hadoop.hbase.regionserver.testhregion  tests run: 102, failures: 0, errors: 0, skipped: 0, time elapsed: 89.23 sec - in org.apache.hadoop.hbase.regionserver.testhregion branch-1 running org.apache.hadoop.hbase.regionserver.testhregion  tests run: 102, failures: 0, errors: 0, skipped: 0, time elapsed: 368.868 sec - in org.apache.hadoop.hbase.regionserver.testhregion running org.apache.hadoop.hbase.regionserver.testhregion  tests run: 102, failures: 0, errors: 0, skipped: 0, time elapsed: 366.203 sec - in org.apache.hadoop.hbase.regionserver.testhregion running org.apache.hadoop.hbase.regionserver.testhregion  tests run: 102, failures: 0, errors: 0, skipped: 0, time elapsed: 345.806 sec - in org.apache.hadoop.hbase.regionserver.testhregion 0.98 running org.apache.hadoop.hbase.regionserver.testhregion  tests run: 90, failures: 0, errors: 0, skipped: 0, time elapsed: 61.038 sec - in org.apache.hadoop.hbase.regionserver.testhregion running org.apache.hadoop.hbase.regionserver.testhregion  tests run: 90, failures: 0, errors: 0, skipped: 0, time elapsed: 56.382 sec - in org.apache.hadoop.hbase.regionserver.testhregion running org.apache.hadoop.hbase.regionserver.testhregion  tests run: 90, failures: 0, errors: 0, skipped: 0, time elapsed: 63.509 sec - in org.apache.hadoop.hbase.regionserver.testhregion ",
        "label": 544
    },
    {
        "text": "stripestoreflusher causes nullpointerexception  storeflusher.flushsnapshot() mustn't return null value.  but stripestoreflusher.flushsnapshot() does. it cause nullpointerexception at org.apache.hadoop.hbase.regionserver.hstore.flushcache(hstore.java:802)  and this makes regions dead after exhaustive retries and no recovery available from it. the code (stripestoreflusher:64) has to be changed   ===============  from  list<path> result = null   to  list<path> result = new arraylist<path>();  ===============  to return a empty list not null value. ",
        "label": 533
    },
    {
        "text": "documentation javadoc error in singlecolumnvaluefilter constructor  the behaviour when the column is not found is documented differently in the constructor and in the setter. the constructor is actually wrong: by default, when the column is not found, the row is emitted (may be the opposite would be better, but it's another question) singlecolumnvaluefilter  public singlecolumnvaluefilter(byte[] family,  byte[] qualifier,  comparefilter.compareop compareop,  byte[] value) constructor for binary compare of the value of a single column. if the column is found and the condition passes, all columns of the row will be emitted. if the column is not found or the condition fails, the row will not be emitted. setfilterifmissing  public void setfilterifmissing(boolean filterifmissing)  set whether entire row should be filtered if column is not found.  if true, the entire row will be skipped if the column is not found.  if false, the row will pass if the column is not found. this is default. possible correction for the constructor documentation:  if the column is found and the condition passes, all columns of the row will be emitted. if the condition fails, the row will not be emitted. the behavior when the column is not found is defined by setfilterifmissing. ",
        "label": 146
    },
    {
        "text": "fix hbase common findbugs complaints  ",
        "label": 424
    },
    {
        "text": "incorrect timeout in recommended zookeeper configuration  the recommended configuration section for zookeeper states that the default zookeeper.session.timeout is 3 minutes, however, the default configuration is 90 seconds(   /** default value for zookeeper session timeout */ public static final int default_zk_session_timeout = 90 * 1000; ).   this section in the documentation should be modified to reflect the default configuration.   ",
        "label": 538
    },
    {
        "text": "remove 'indexed' contrib  the 'indexed' contrib is moving to github. remove it in time for 0.20.4 release. ",
        "label": 502
    },
    {
        "text": "style the web ui to use twitter's bootstrap   our web ui has lagged a little bit behind. while it's not a huge deal, it is one of the first things that new people see. as such styling it a little bit better would put a good foot forward. ",
        "label": 154
    },
    {
        "text": " hbase  unexpected exits corrupt dfs  when a regionserver exits unexpectedly, it often leaves its dfs files open. in the case of the redo log, this can result in a zero-length file, which a newly started regionserver will be unable to read, causing it to exit again. it also causes dfs corruption, requiring the admin to run a dfs fsck -delete before hbase can be restarted. ",
        "label": 241
    },
    {
        "text": " unit tests  testreplication queuefailover occasionally fails  part   have seen it twice in the recent past: http://bit.ly/mpcykb & http://bit.ly/o79dq7 .. looking briefly at the logs hints at a pattern - in both the failed test instances, there was an rs crash while the test was running. ",
        "label": 139
    },
    {
        "text": "new config property for user table only regionobservers   it turns out that a regionobserver can interfere with - root - and .meta. that seems weird and should be prevented. (the one use case for this that i could come up with is access control by region by intercepting actions on .meta., and i don't think that's a particularly strong use case). i'll attach a patch as soon as i get to it. ",
        "label": 286
    },
    {
        "text": "print row locks at the debug dump page  we had to debug cases where some handlers are holding row locks for an extended time (and maybe leak) and other handlers are getting timeouts for obtaining row locks. we should add row lock information at the debug page at the rs ui to be able to live-debug such cases. ",
        "label": 198
    },
    {
        "text": "disable table doesn't work reliably  when creating a couple of tables like this:  1) create an empty table  2) disable table, add new column family, enable table  3) put 100 small documents into newly created column  around once in 10 tries the disable doesn't happen. i have no clue as to why the table isn't disabled in the first place, but if this occurs, two things in hbaseadmin.disabletable() strike me as odd: after numretries tries to wait for disabling we exit the loop; there is no exception or error message:  ...  2008-05-14 16:19:47,903 info org.apache.hadoop.hbase.client.hbaseadmin: disabled table table31  2008-05-14 16:19:47,910 info org.apache.hadoop.ipc.server: ipc server handler 3 on 60000, call addcolumn(table31, {name: document, max versions: 3, compression: none, in memory: false, block cache enabled: false, max length: 2147483647, time to live: forever, bloom filter: none} ) from xxx.xx.40.36:47116: error: org.apache.hadoop.hbase.tablenotdisabledexception: table31  ... the scanner iterates over hregioninfos of several tables. if any one of those is disabled, we also leave the loop as if the requested table had been disabled. i've had this disabling problem occur quite reliably over the last days - today i couldn't reproduce it, though hbase version hasn't changed. ??? ",
        "label": 241
    },
    {
        "text": "fix new javadoc warnings    [javadoc] building tree for all the packages and classes...   [javadoc] /home/stack/checkouts/hbase/trunk/src/java/org/apache/hadoop/hbase/hcolumndescriptor.java:65: warning - tag @link: reference not found: compression.algorithm   [javadoc] /home/stack/checkouts/hbase/trunk/src/java/org/apache/hadoop/hbase/hcolumndescriptor.java:65: warning - tag @link: reference not found: compression.algorithm   [javadoc] /home/stack/checkouts/hbase/trunk/src/java/org/apache/hadoop/hbase/keyvalue.java:50: warning - tag @link: reference not found: hfile   [javadoc] /home/stack/checkouts/hbase/trunk/src/java/org/apache/hadoop/hbase/keyvalue.java:235: warning - tag @return cannot be used in constructor documentation.  it can only be used in the following types of documentation: method.   [javadoc] /home/stack/checkouts/hbase/trunk/src/java/org/apache/hadoop/hbase/keyvalue.java:245: warning - tag @return cannot be used in constructor documentation.  it can only be used in the following types of documentation: method.   [javadoc] /home/stack/checkouts/hbase/trunk/src/java/org/apache/hadoop/hbase/keyvalue.java:255: warning - tag @return cannot be used in constructor documentation.  it can only be used in the following types of documentation: method.   [javadoc] /home/stack/checkouts/hbase/trunk/src/java/org/apache/hadoop/hbase/keyvalue.java:265: warning - tag @return cannot be used in constructor documentation.  it can only be used in the following types of documentation: method.   [javadoc] /home/stack/checkouts/hbase/trunk/src/java/org/apache/hadoop/hbase/keyvalue.java:276: warning - tag @return cannot be used in constructor documentation.  it can only be used in the following types of documentation: method.   [javadoc] /home/stack/checkouts/hbase/trunk/src/java/org/apache/hadoop/hbase/keyvalue.java:287: warning - tag @return cannot be used in constructor documentation.  it can only be used in the following types of documentation: method.   [javadoc] /home/stack/checkouts/hbase/trunk/src/java/org/apache/hadoop/hbase/keyvalue.java:299: warning - tag @return cannot be used in constructor documentation.  it can only be used in the following types of documentation: method.   [javadoc] /home/stack/checkouts/hbase/trunk/src/java/org/apache/hadoop/hbase/keyvalue.java:310: warning - tag @return cannot be used in constructor documentation.  it can only be used in the following types of documentation: method.   [javadoc] /home/stack/checkouts/hbase/trunk/src/java/org/apache/hadoop/hbase/keyvalue.java:322: warning - tag @return cannot be used in constructor documentation.  it can only be used in the following types of documentation: method.   [javadoc] /home/stack/checkouts/hbase/trunk/src/java/org/apache/hadoop/hbase/keyvalue.java:337: warning - tag @return cannot be used in constructor documentation.  it can only be used in the following types of documentation: method.   [javadoc] /home/stack/checkouts/hbase/trunk/src/java/org/apache/hadoop/hbase/keyvalue.java:351: warning - tag @return cannot be used in constructor documentation.  it can only be used in the following types of documentation: method.   [javadoc] /home/stack/checkouts/hbase/trunk/src/java/org/apache/hadoop/hbase/keyvalue.java:365: warning - tag @return cannot be used in constructor documentation.  it can only be used in the following types of documentation: method.   [javadoc] /home/stack/checkouts/hbase/trunk/src/java/org/apache/hadoop/hbase/keyvalue.java:380: warning - tag @return cannot be used in constructor documentation.  it can only be used in the following types of documentation: method.   [javadoc] /home/stack/checkouts/hbase/trunk/src/java/org/apache/hadoop/hbase/keyvalue.java:401: warning - tag @return cannot be used in constructor documentation.  it can only be used in the following types of documentation: method.   [javadoc] /home/stack/checkouts/hbase/trunk/src/java/org/apache/hadoop/hbase/keyvalue.java:547: warning - @param argument \"b\" is not a parameter name.   [javadoc] /home/stack/checkouts/hbase/trunk/src/java/org/apache/hadoop/hbase/keyvalue.java:1037: warning - @return tag has no arguments.   [javadoc] /home/stack/checkouts/hbase/trunk/src/java/org/apache/hadoop/hbase/filter/rowfilterinterface.java:124: warning - @param argument \"colunmname\" is not a parameter name.   [javadoc] /home/stack/checkouts/hbase/trunk/src/java/org/apache/hadoop/hbase/io/rowresult.java:276: warning - @param argument \"r\" is not a parameter name.   [javadoc] /home/stack/checkouts/hbase/trunk/src/java/org/apache/hadoop/hbase/io/sequencefile.java:1793: warning - @return tag has no arguments.   [javadoc] /home/stack/checkouts/hbase/trunk/src/java/org/apache/hadoop/hbase/io/hfile/hfile.java:277: warning - parameter \"c\" is documented more than once.   [javadoc] /home/stack/checkouts/hbase/trunk/src/java/org/apache/hadoop/hbase/mapred/tableinputformatbase.java:75: warning - tag @link: reference not found: text   [javadoc] /home/stack/checkouts/hbase/trunk/src/java/org/apache/hadoop/hbase/regionserver/habstractscanner.java:90: warning - @param argument \"family/store\" is not a parameter name.   [javadoc] /home/stack/checkouts/hbase/trunk/src/java/org/apache/hadoop/hbase/regionserver/lruhashmap.java:348: warning - @param argument \"o\" is not a parameter name.   [javadoc] /home/stack/checkouts/hbase/trunk/src/java/org/apache/hadoop/hbase/regionserver/store.java:1020: warning - @param argument \"origin\" is not a parameter name.   [javadoc] /home/stack/checkouts/hbase/trunk/src/java/org/apache/hadoop/hbase/rest/filter/rowfiltersetfactory.java:91: warning - @return tag has no arguments.   [javadoc] /home/stack/checkouts/hbase/trunk/src/java/org/apache/hadoop/hbase/util/bytes.java:692: warning - @return tag has no arguments.   [javadoc] /home/stack/checkouts/hbase/trunk/src/java/org/apache/hadoop/hbase/util/bytes.java:169: warning - @param argument \"bytes\" is not a parameter name.   [javadoc] /home/stack/checkouts/hbase/trunk/src/java/org/apache/hadoop/hbase/util/bytes.java:169: warning - @param argument \"offset\" is not a parameter name.   [javadoc] /home/stack/checkouts/hbase/trunk/src/java/org/apache/hadoop/hbase/util/bytes.java:169: warning - @param argument \"b\" is not a parameter name.   [javadoc] /home/stack/checkouts/hbase/trunk/src/java/org/apache/hadoop/hbase/hcolumndescriptor.java:65: warning - tag @link: reference not found: compression.algorithm   [javadoc] /home/stack/checkouts/hbase/trunk/src/java/org/apache/hadoop/hbase/hcolumndescriptor.java:65: warning - tag @link: reference not found: compression.algorithm   [javadoc] building index for all the packages and classes...   [javadoc] /home/stack/checkouts/hbase/trunk/src/java/org/apache/hadoop/hbase/hcolumndescriptor.java:65: warning - tag @link: reference not found: compression.algorithm   [javadoc] /home/stack/checkouts/hbase/trunk/src/java/org/apache/hadoop/hbase/hcolumndescriptor.java:65: warning - tag @link: reference not found: compression.algorithm   [javadoc] building index for all classes...   [javadoc] generating /home/stack/checkouts/hbase/trunk/build/docs/api/stylesheet.css... ",
        "label": 167
    },
    {
        "text": "hbaseadmin createtable  using old htabledescription doesn't work  the following test case (see below) illustrate what used to work in branch 0.1 and that doesn't anymore. testtruncateintrunk() shows how i got it to work again. i get this error now when trying the old code but using trunk: java.lang.reflect.invocationtargetexception  at sun.reflect.nativemethodaccessorimpl.invoke0(native method)  at sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:39)  at sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:25)  at java.lang.reflect.method.invoke(method.java:597)  at com.openplaces.test.fixture.fixtureloader.truncatehbasetable(fixtureloader.java:105)  at com.openplaces.test.fixture.fixtureloader.loadhbasefixtures(fixtureloader.java:63)  at com.openplaces.test.fixture.testcasewithfixtures.hbasefixtures(testcasewithfixtures.java:34)  at com.openplaces.test.isolated.testsearchsrfief.setup(testsearchsrfief.java:37)  at junit.framework.testcase.runbare(testcase.java:125)  at junit.framework.testresult$1.protect(testresult.java:106)  at junit.framework.testresult.runprotected(testresult.java:124)  at junit.framework.testresult.run(testresult.java:109)  at junit.framework.testcase.run(testcase.java:118)  at junit.framework.testsuite.runtest(testsuite.java:208)  at junit.framework.testsuite.run(testsuite.java:203)  at org.eclipse.jdt.internal.junit.runner.junit3.junit3testreference.run(junit3testreference.java:130)  at org.eclipse.jdt.internal.junit.runner.testexecution.run(testexecution.java:38)  at org.eclipse.jdt.internal.junit.runner.remotetestrunner.runtests(remotetestrunner.java:460)  at org.eclipse.jdt.internal.junit.runner.remotetestrunner.runtests(remotetestrunner.java:673)  at org.eclipse.jdt.internal.junit.runner.remotetestrunner.run(remotetestrunner.java:386)  at org.eclipse.jdt.internal.junit.runner.remotetestrunner.main(remotetestrunner.java:196)  caused by: java.net.sockettimeoutexception: timed out waiting for rpc response  at org.apache.hadoop.ipc.client.call(client.java:559)  at org.apache.hadoop.hbase.ipc.hbaserpc$invoker.invoke(hbaserpc.java:211)  at $proxy5.createtable(unknown source)  at org.apache.hadoop.hbase.client.hbaseadmin.createtableasync(hbaseadmin.java:184)  at org.apache.hadoop.hbase.client.hbaseadmin.createtable(hbaseadmin.java:144)  at com.openplaces.util.hbaserecord.connectionadapters.hbaseadapter.truncatetable(hbaseadapter.java:502)  at com.openplaces.util.hbaserecord.base$singleton.truncate(base.java:609)  ... 21 more import java.io.ioexception;  import java.util.collection; import org.apache.hadoop.hbase.hbaseconfiguration;  import org.apache.hadoop.hbase.hcolumndescriptor;  import org.apache.hadoop.hbase.htabledescriptor;  import org.apache.hadoop.hbase.client.hbaseadmin;  import org.apache.hadoop.hbase.client.htable; import junit.framework.testcase; @suppresswarnings(\"deprecation\")  public class testtruncate extends testcase {  public void testtruncateinbranch_0_1() throws ioexception { htable table = new htable(\"mytable\"); hbaseadmin admin = new hbaseadmin(new hbaseconfiguration()); htabledescriptor tabledesc = table.getmetadata(); admin.deletetable(table.gettablename()); admin.createtable(tabledesc); } public void testtruncateintrunk() throws ioexception{  htable table = new htable(\"mytable\");  hbaseadmin admin = new hbaseadmin(new hbaseconfiguration());  collection<hcolumndescriptor> families = table.getmetadata().getfamilies();  htabledescriptor tabledesc = new htabledescriptor(table.gettablename());  for(hcolumndescriptor family : families) { tabledesc.addfamily(family); } admin.deletetable(table.gettablename());  admin.createtable(tabledesc);  }  } ",
        "label": 218
    },
    {
        "text": "hlog should roll periodically to allow dn decommission to eventually complete   we encountered a situation where we had an esseitially read only table and attempted to do a clean hdfs dn decommission. dn's cannot decomission if there are open blocks being written to currently on it. because the hbase hlog file was open, had some data (hlog header), the dn could not decommission itself. since no new data is ever written, the existing periodic check is not activated. after discussing with aaron myers, it seems that although an hdfs semantics change would be ideal (e.g. hbase doesn't have to be aware of hdfs decommission and the client would roll over) this would take much more effort than having hbase periodically force a log roll. this would enable the hdfs dn con complete. ",
        "label": 309
    },
    {
        "text": "bytes tostringbinary escapes printable chars  bytes.tostringbinary hex-escapes printable chars such as '@', '$', '#', '%', '&', '*', '(', ')', ' {', '} ', '[', ']', ';', ',', '~', '|'. why? ",
        "label": 38
    },
    {
        "text": "provide consistent and clear logging about disabling chores  right now if you want to disable any of our chores you can set the period to be <= 0. sometimes, if you do this you get a nice message: 2019-09-16 22:10:16,756 info  [master-1:16000.activemastermanager] master.hmaster: the period is 0 seconds, mobcompactionchore is disabled and sometimes you get an opaque message: 2019-09-16 22:09:45,333 info  [master-1:16000.activemastermanager] hbase.choreservice: could not successfully schedule chore: logscleaner 2019-09-16 22:09:45,340 info  [master-1:16000.activemastermanager] hbase.choreservice: could not successfully schedule chore: hfilecleaner this is because sometimes we just blindly submit to choreservice which submits to a java scheduledexecutorservice and then catches the illegalargumentexception. we should remove the one-offs and make it so choreservice checks the period before accepting a submittal and produces a consistent \"foo is disabled\" message. ",
        "label": 395
    },
    {
        "text": "gettabledirs is missing directories to skip  the gettabledirs() is missing extra checks:   public static list<path> gettabledirs(final filesystem fs, final path rootdir)   throws ioexception {     // presumes any directory under hbase.rootdir is a table     filestatus [] dirs = fs.liststatus(rootdir, new dirfilter(fs));     list<path> tabledirs = new arraylist<path>(dirs.length);     for (filestatus dir: dirs) {       path p = dir.getpath();       string tablename = p.getname();       if (tablename.equals(hconstants.hregion_logdir_name) ||           tablename.equals(bytes.tostring(hconstants.root_table_name)) ||           tablename.equals(bytes.tostring(hconstants.meta_table_name)) ||           tablename.equals(hconstants.hregion_oldlogdir_name) ) {         continue;       }       tabledirs.add(p);     }     return tabledirs;   } it needs to also skip .tmp .corrupt splitlog a broader check should be performed to make sure it is all covered. the missing .corrupt check causes for example: 2011-07-05 11:34:33,364 warn org.apache.hadoop.hbase.master.hmaster: failed getting all descriptors java.io.filenotfoundexception: no status for hdfs://localhost:8020/hbase/.corrupt         at org.apache.hadoop.hbase.util.fsutils.gettableinfomodtime(fsutils.java:888)         at org.apache.hadoop.hbase.util.fstabledescriptors.get(fstabledescriptors.java:122)         at org.apache.hadoop.hbase.util.fstabledescriptors.getall(fstabledescriptors.java:149)         at org.apache.hadoop.hbase.master.hmaster.gethtabledescriptors(hmaster.java:1429)         at sun.reflect.nativemethodaccessorimpl.invoke0(native method)         at sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:39)         at sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:25)         at java.lang.reflect.method.invoke(method.java:597)         at org.apache.hadoop.hbase.ipc.writablerpcengine$server.call(writablerpcengine.java:312)         at org.apache.hadoop.hbase.ipc.hbaseserver$handler.run(hbaseserver.java:1065) not sure yet why others do not have this issue, could be me being on trunk and fiddling? ",
        "label": 441
    },
    {
        "text": " hbck2  fixmeta method and server side support  add a fixmeta method to hbck service. hbck2 tool in hbase-operator-tools will use this if it is available otherwise it will do its own client-side version. making these server-side versions so can copy/exploit code/findings doing hbase-operator-tools hbck2 tool version. this does pure meta fixup.... plug holes and fix overlaps. ",
        "label": 314
    },
    {
        "text": "fix unit tests  fixing the following unit tests:  testcompaction ",
        "label": 154
    },
    {
        "text": "rat check fails in nightlies  fails on  old  test data files   the nightly runs where we check rm steps fails in branch-2.1 because the rat test complains about old test data files not having licenses. see hbase-22022 for how we turned up this issue. this jira adds exclusions for these files that cause failure. ",
        "label": 314
    },
    {
        "text": "graceful stop sh syntax error  when i was trying to run graceful_stop.sh i got error: ./graceful_stop.sh: line 59: syntax error near unexpected token `;' ./graceful_stop.sh: line 59: `    --failfast) ;&' after looking at script i notice that this lines are causing error:     --failfast) ;&     -e)  failfast=true; shift;;     --debug)  ;&     -d)  debug=\"--debug\"; shift;; they sholud be changed to this:  --failfast | -e)  failfast=true; shift;;  --debug | -d)  debug=\"--debug\"; shift;; i will attach patch today. ",
        "label": 393
    },
    {
        "text": "rest server ignores start row and end row arguments in scanner request  when issuing a command like:  post /api/users/scanner?column=habbit:football&start_row=alice&end_row=bob the resultant scanner appears to ignore the start_row and end_row constraints, so that a command like:  post /api/users/scanner/1?limit=1000 returns results outside of the specified range e.g. the row for \"william\" will be returned. ",
        "label": 549
    },
    {
        "text": "test to prove bytes tobytesbinary and bytes tostringbinary  is reversible  bytes.tostringbinary() doesn't escape \\. otherwise the transformation isn't reversible byte[] a = {'\\', 'x' , '0', '0'} bytes.tobytesbinary(bytes.tostringbinary(a)) won't be equal to a ",
        "label": 273
    },
    {
        "text": "convert rs  shutdown  and table dir content to pb  ",
        "label": 314
    },
    {
        "text": "testupgradefromhfilev1toencoding testupgrade hangs  i'm having a look. here is the stack i got locally: \"pool-1-thread-1\" prio=10 tid=0x00007f27c8406000 nid=0xf908 in object.wait() [0x00007f27cec5b000]    java.lang.thread.state: waiting (on object monitor)         at java.lang.object.wait(native method)         - waiting on <0x00000000e88b19b0> (a org.apache.hadoop.hbase.util.jvmclusterutil$regionserverthread)         at java.lang.thread.join(thread.java:1186)         - locked <0x00000000e88b19b0> (a org.apache.hadoop.hbase.util.jvmclusterutil$regionserverthread)         at java.lang.thread.join(thread.java:1239)         at org.apache.hadoop.hbase.util.jvmclusterutil.shutdown(jvmclusterutil.java:245)         at org.apache.hadoop.hbase.localhbasecluster.shutdown(localhbasecluster.java:430)         at org.apache.hadoop.hbase.minihbasecluster.shutdown(minihbasecluster.java:501)         at org.apache.hadoop.hbase.hbasetestingutility.shutdownminihbasecluster(hbasetestingutility.java:856)         at org.apache.hadoop.hbase.io.encoding.testupgradefromhfilev1toencoding.testupgrade(testupgradefromhfilev1toencoding.java:83) \"regionserver:0;localhost,35592,1357148534219-splits-1357148554209\" daemon prio=10 tid=0x0000000040ed1000 nid=0x1178 waiting on condition [0x00007f27b3d3c000]    java.lang.thread.state: timed_waiting (sleeping)         at java.lang.thread.sleep(native method)         at org.apache.hadoop.hbase.client.hconnectionmanager$hconnectionimplementation.locateregioninmeta(hconnectionmanager.java:1164)         at org.apache.hadoop.hbase.client.hconnectionmanager$hconnectionimplementation.locateregion(hconnectionmanager.java:966)         at org.apache.hadoop.hbase.client.hconnectionmanager$hconnectionimplementation.locateregion(hconnectionmanager.java:919)         at org.apache.hadoop.hbase.client.htable.finishsetup(htable.java:246)         at org.apache.hadoop.hbase.client.htable.<init>(htable.java:187)         at org.apache.hadoop.hbase.catalog.metareader.gethtable(metareader.java:198)         at org.apache.hadoop.hbase.catalog.metareader.getmetahtable(metareader.java:224)         at org.apache.hadoop.hbase.catalog.metaeditor.offlineparentinmeta(metaeditor.java:229)         at org.apache.hadoop.hbase.regionserver.splittransaction.createdaughters(splittransaction.java:341)         at org.apache.hadoop.hbase.regionserver.splittransaction.execute(splittransaction.java:471)         at org.apache.hadoop.hbase.regionserver.splitrequest.run(splitrequest.java:68)         at java.util.concurrent.threadpoolexecutor$worker.runtask(threadpoolexecutor.java:886)         at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:908)         at java.lang.thread.run(thread.java:662) \"regionserver:0;localhost,35592,1357148534219\" prio=10 tid=0x00007f27c0929000 nid=0x5a7 waiting on condition [0x00007f27be5e3000]    java.lang.thread.state: timed_waiting (parking)         at sun.misc.unsafe.park(native method)         - parking to wait for  <0x00000000e88b1978> (a java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject)         at java.util.concurrent.locks.locksupport.parknanos(locksupport.java:196)         at java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject.awaitnanos(abstractqueuedsynchronizer.java:2025)         at java.util.concurrent.threadpoolexecutor.awaittermination(threadpoolexecutor.java:1253)         at org.apache.hadoop.hbase.regionserver.compactsplitthread.waitfor(compactsplitthread.java:252)         at org.apache.hadoop.hbase.regionserver.compactsplitthread.join(compactsplitthread.java:261)         at org.apache.hadoop.hbase.regionserver.hregionserver.run(hregionserver.java:948)         at org.apache.hadoop.hbase.minihbasecluster$minihbaseclusterregionserver.runregionserver(minihbasecluster.java:151)         at org.apache.hadoop.hbase.minihbasecluster$minihbaseclusterregionserver.access$000(minihbasecluster.java:103)         at org.apache.hadoop.hbase.minihbasecluster$minihbaseclusterregionserver$1.run(minihbasecluster.java:135) ",
        "label": 340
    },
    {
        "text": "filterlist reports false positives  when filterlist is set to operator.must_pass_all, if a child filter returns returncode.seek_next_using_hint, that return code gets swallowed and returncode.include gets returned instead. this causes false positives with columnprefixfilter. ",
        "label": 489
    },
    {
        "text": "snapshot of table  havening an option to take a snapshot of a table would be vary useful in production. what i would like to see this option do is do a merge of all the data into one or more files stored in the same folder on the dfs. this way we could save data in case of a software bug in hadoop or user code. the other advantage would be to be able to export a table to multi locations. say i had a read_only table that must be online. i could take a snapshot of it when needed and export it to a separate data center and have it loaded there and then i would have it online at multi data centers for load balancing and failover. i understand that hadoop takes the need out of havening backup to protect from failed servers, but this does not protect use from software bugs that might delete or alter data in ways we did not plan. we should have a way we can roll back a dataset. ",
        "label": 288
    },
    {
        "text": "provide a fast mechanism for shutting down mini cluster  the current mechanism of shutting down a mini cluster through hbasetestingutility.shutdownminicluster can take a lot of time when the mini cluster almost has a lot of tables. a lot of this time is spent in closing all the user regions. it would be nice to have a mechanism where this shutdown can happen quickly without having to worry about closing these user regions. at the same time, this mechanism would need to make sure that all the critical system resources like file handles and network ports are still released so that subsequently initialized mini clusters on the same jvm or system won't run into resource issues. this would make testing using hbase mini clusters much faster and immensely help out test frameworks of dependent projects like phoenix. ",
        "label": 51
    },
    {
        "text": "rowcounter does not return the correct number of rows in certain circumstances  when you run hadoop jar hbase.jar rowcounter <table> the org.apache.hadoop.hbase.mapreduce.rowcounter class is run.  the rowcountermapper class in the rowcounter mapreduce job contains the following:     @override     public void map(immutablebyteswritable row, result values,       context context)     throws ioexception {       for (keyvalue value: values.list()) {         if (value.getvalue().length > 0) {           context.getcounter(counters.rows).increment(1);           break;         }       }     } the intention is to go through the column values in the row, and increment the rows counter if some value is non-empty. however, values.list() always has size 1. this is because the createsubmittablejob static method uses a scan as follows:     scan scan = new scan();     scan.setfilter(new firstkeyonlyfilter()); so the input map splits always contain just the first kv. if the column corresponding to that first kv is empty, even though other columns are non-empty, that row is skipped.  this way, rowcounter can return an incorrect result. one way to reproduce this is to create an hbase table with two columns, say f1:q1 and f2:q2. create some (say 2) rows with empty f1:q1 but non-empty f2:q2, and some (say 3) rows with empty f2:q2 and non-empty f1:q1.  then run rowcounter (specifying only the table but not any columns). the count will be either 2 short or 3 short. ",
        "label": 126
    },
    {
        "text": "make flush decisions per column family  today, the flush decision is made using the aggregate size of all column families. when large and small column families co-exist, this causes many small flushes of the smaller cf. we need to make per-cf flush decisions. ",
        "label": 181
    },
    {
        "text": "testrsgroupsbase has some always false checks  discovered via error-prone analysis: [error] failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.6.1:testcompile (default-testcompile) on project hbase-rsgroup: compilation failure: compilation failure: [error] /users/mdrob/ideaprojects/hbase/hbase-rsgroup/src/test/java/org/apache/hadoop/hbase/rsgroup/testrsgroupsbase.java:[421,40] [collectionincompatibletype] argument 'region' should not be passed to this method; its type regioninfo is not compatible with its collection's type argument string [error]     (see http://errorprone.info/bugpattern/collectionincompatibletype) [error] /users/mdrob/ideaprojects/hbase/hbase-rsgroup/src/test/java/org/apache/hadoop/hbase/rsgroup/testrsgroupsbase.java:[531,65] [collectionincompatibletype] argument 'targetregion' should not be passed to this method; its type string is not compatible with its collection's type argument regioninfo [error]     (see http://errorprone.info/bugpattern/collectionincompatibletype) both of these are checks to list<t>.contains with an element of the wrong type so they will always return false. the first is an optimization that we can probably live without (or short circuit on the master, at least) the second is an assertion that will never fail, rendering the test ineffective. ",
        "label": 38
    },
    {
        "text": "high load import of data into single table family never triggers split  importing a heavy amount of data into a single table and family. one column in that family (the same fam:col for every row) contains a frequently large amount of utf-8 data. this column grows and grows but never causes a region split. currently there is a single mapfile containing nearly 10gb. eventually this has caused regions to crash with oome, as described in hbase-706 table in question: hql > describe items;  ----------------------------------------------------------------------------- column family descriptor ----------------------------------------------------------------------------- name: cfrecs, max versions: 2, compression: none, in memory: false, max leng th: 2147483647, bloom filter: none ----------------------------------------------------------------------------- name: clusters, max versions: 2, compression: none, in memory: false, max le ngth: 2147483647, bloom filter: none ----------------------------------------------------------------------------- name: content, max versions: 2, compression: none, in memory: false, max len gth: 2147483647, bloom filter: none ----------------------------------------------------------------------------- name: readby, max versions: 2, compression: none, in memory: false, max leng th: 2147483647, bloom filter: none ----------------------------------------------------------------------------- name: receivedby, max versions: 2, compression: none, in memory: false, max length: 2147483647, bloom filter: none ----------------------------------------------------------------------------- name: savedby, max versions: 2, compression: none, in memory: false, max len gth: 2147483647, bloom filter: none ----------------------------------------------------------------------------- name: sentby, max versions: 2, compression: none, in memory: false, max leng th: 2147483647, bloom filter: none -----------------------------------------------------------------------------  7 columnfamily(s) in set. (0.34 sec) ",
        "label": 314
    },
    {
        "text": "ensure proper ordering for shutdown hooks  ",
        "label": 154
    },
    {
        "text": " amv2  fix test hbase coprocessor testcoprocessormetrics testregionobserverafterregionclosed  when executeproceduresremotecall in remoteproceduredispatcher is enabled the test hbase.coprocessor.testcoprocessormetrics#testregionobserverafterregionclosed fails as it uses not supported call admin.closeregion() to close a region. disabling table later throws exception as one of the region is not online (already closed). org.apache.hadoop.hbase.notservingregionexception: the region d8c770379823cbe6cdc517327024b128 is not online, and is not opening.   at org.apache.hadoop.hbase.regionserver.hregionserver.closeregion(hregionserver.java:3111)   at org.apache.hadoop.hbase.regionserver.rsrpcservices.closeregion(rsrpcservices.java:1485)   at org.apache.hadoop.hbase.regionserver.rsrpcservices.executeprocedures(rsrpcservices.java:3430)   at org.apache.hadoop.hbase.shaded.protobuf.generated.adminprotos$adminservice$2.callblockingmethod(adminprotos.java:28757)   at org.apache.hadoop.hbase.ipc.rpcserver.call(rpcserver.java:406)   at org.apache.hadoop.hbase.ipc.callrunner.run(callrunner.java:133)   at org.apache.hadoop.hbase.ipc.rpcexecutor$handler.run(rpcexecutor.java:278)   at org.apache.hadoop.hbase.ipc.rpcexecutor$handler.run(rpcexecutor.java:258) 2017-06-16 11:25:02,177 warn  [rsproceduredispatcher-pool4-t6] procedure.rsproceduredispatcher$abstractrsremotecall(200): the request should be tried elsewhere instead; server=172.21.2.192,53652,1497637493318 try=0 org.apache.hadoop.hbase.notservingregionexception: org.apache.hadoop.hbase.notservingregionexception: the region d8c770379823cbe6cdc517327024b128 is not online, and is not opening.   at org.apache.hadoop.hbase.regionserver.hregionserver.closeregion(hregionserver.java:3111)   at org.apache.hadoop.hbase.regionserver.rsrpcservices.closeregion(rsrpcservices.java:1485)   at org.apache.hadoop.hbase.regionserver.rsrpcservices.executeprocedures(rsrpcservices.java:3430)   at org.apache.hadoop.hbase.shaded.protobuf.generated.adminprotos$adminservice$2.callblockingmethod(adminprotos.java:28757)   at org.apache.hadoop.hbase.ipc.rpcserver.call(rpcserver.java:406)   at org.apache.hadoop.hbase.ipc.callrunner.run(callrunner.java:133)   at org.apache.hadoop.hbase.ipc.rpcexecutor$handler.run(rpcexecutor.java:278)   at org.apache.hadoop.hbase.ipc.rpcexecutor$handler.run(rpcexecutor.java:258)   at sun.reflect.nativeconstructoraccessorimpl.newinstance0(native method)   at sun.reflect.nativeconstructoraccessorimpl.newinstance(nativeconstructoraccessorimpl.java:62)   at sun.reflect.delegatingconstructoraccessorimpl.newinstance(delegatingconstructoraccessorimpl.java:45)   at java.lang.reflect.constructor.newinstance(constructor.java:423)   at org.apache.hadoop.hbase.ipc.remotewithextrasexception.instantiateexception(remotewithextrasexception.java:93)   at org.apache.hadoop.hbase.ipc.remotewithextrasexception.unwrapremoteexception(remotewithextrasexception.java:83)   at org.apache.hadoop.hbase.shaded.protobuf.protobufutil.makeioexceptionofexception(protobufutil.java:370)   at org.apache.hadoop.hbase.shaded.protobuf.protobufutil.getremoteexception(protobufutil.java:347)   at org.apache.hadoop.hbase.master.procedure.rsproceduredispatcher$executeproceduresremotecall.sendrequest(rsproceduredispatcher.java:295)   at org.apache.hadoop.hbase.master.procedure.rsproceduredispatcher$executeproceduresremotecall.call(rsproceduredispatcher.java:265)   at org.apache.hadoop.hbase.master.procedure.rsproceduredispatcher$executeproceduresremotecall.call(rsproceduredispatcher.java:246)   at java.util.concurrent.futuretask.run(futuretask.java:266)   at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1142)   at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:617)   at java.lang.thread.run(thread.java:745) caused by: org.apache.hadoop.hbase.ipc.remotewithextrasexception(org.apache.hadoop.hbase.notservingregionexception): org.apache.hadoop.hbase.notservingregionexception: the region d8c770379823cbe6cdc517327024b128 is not online, and is not opening.   at org.apache.hadoop.hbase.regionserver.hregionserver.closeregion(hregionserver.java:3111)   at org.apache.hadoop.hbase.regionserver.rsrpcservices.closeregion(rsrpcservices.java:1485)   at org.apache.hadoop.hbase.regionserver.rsrpcservices.executeprocedures(rsrpcservices.java:3430)   at org.apache.hadoop.hbase.shaded.protobuf.generated.adminprotos$adminservice$2.callblockingmethod(adminprotos.java:28757)   at org.apache.hadoop.hbase.ipc.rpcserver.call(rpcserver.java:406)   at org.apache.hadoop.hbase.ipc.callrunner.run(callrunner.java:133)   at org.apache.hadoop.hbase.ipc.rpcexecutor$handler.run(rpcexecutor.java:278)   at org.apache.hadoop.hbase.ipc.rpcexecutor$handler.run(rpcexecutor.java:258) ",
        "label": 459
    },
    {
        "text": "update website with info on how to report security bugs  the hbase website should be updated with information on how to report potential security vulnerabilities. in hadoop land we have a private security list that anyone case post to that we point to on our list page: hadoop example http://hadoop.apache.org/general_lists.html#security. ",
        "label": 330
    },
    {
        "text": "before release verify all object sizes using ryans' instrumented jvm trick  ",
        "label": 161
    },
    {
        "text": "use hstorefile instead of storefile in our own code base and remove unnecessary methods in storefile interface  use generic types to avoid too many casts. ",
        "label": 149
    },
    {
        "text": "possible null pointer dereference of regionlocation in reversedscannercallable  if regionlocation is null in reversedscannercallable.locateregionsinrange then the else branch will attempt to dereference it. ",
        "label": 320
    },
    {
        "text": "stackoverflow in explicitcolumntracker when row has many columns  when doing a \"get\" on a row with many columns and where the \"get\" also contains many columns to get a stack overflow is thrown in the explicitcolumntracker: java.io.ioexception: java.io.ioexception: java.lang.stackoverflowerror  at org.apache.hadoop.hbase.regionserver.hregionserver.convertthrowabletoioe(hregionserver.java:872)  at org.apache.hadoop.hbase.regionserver.hregionserver.convertthrowabletoioe(hregionserver.java:862)  at org.apache.hadoop.hbase.regionserver.hregionserver.get(hregionserver.java:1733)  at sun.reflect.generatedmethodaccessor6.invoke(unknown source)  at sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:25)  at java.lang.reflect.method.invoke(method.java:597)  at org.apache.hadoop.hbase.ipc.hbaserpc$server.call(hbaserpc.java:657)  at org.apache.hadoop.hbase.ipc.hbaseserver$handler.run(hbaseserver.java:915)  caused by: java.lang.stackoverflowerror  at org.apache.hadoop.hbase.regionserver.explicitcolumntracker.checkcolumn(explicitcolumntracker.java:122)  at org.apache.hadoop.hbase.regionserver.explicitcolumntracker.checkcolumn(explicitcolumntracker.java:123)  at org.apache.hadoop.hbase.regionserver.explicitcolumntracker.checkcolumn(explicitcolumntracker.java:123)  [... repeats many times ...]  at org.apache.hadoop.hbase.regionserver.explicitcolumntracker.checkcolumn(explicitcolumntracker.java:123)  at org.apache.hadoop.hbase.regionserver.explicitcolumntracker.checkcolumn(explicitcolumntracker.java:123)  at org.apache.hadoop.hbase.client.hconnectionmanager$tableservers.getregionserverwithretries(hconnectionmanager.java:1048)  at org.apache.hadoop.hbase.client.htable.get(htable.java:417) ",
        "label": 229
    },
    {
        "text": "method replication decoratemasterconfiguration can fail with npe in case that property hbase master logcleaner plugins is not defined  while upgrading hbase dependency on pig via pig-3529, i've noticed that method replication.decoratemasterconfiguration() can throw nullpointerexception (code) in case when property hbase_master_logcleaner_plugins won't be defined. the issue was more on a pig side where we weren't propagating default hbase configuration resources (such as hbase-default.xml), but i was curious if it's expected that this property will be always defined? we might want to tweak the code a bit if this property can be null. ",
        "label": 230
    },
    {
        "text": "htable deleteall documentation is ambiguous  \"delete all values for a column\" should be \"delete all versions of a column\". ",
        "label": 314
    },
    {
        "text": "master stuck in loop wanting to assign but regions are closing  from streamy logs. 2008-11-19 10:36:58,933 info org.apache.hadoop.hbase.master.regionmanager: skipping region streamitems,\ufffd,1225411057556 because it is already closing. 2008-11-19 10:37:01,315 debug org.apache.hadoop.hbase.master.servermanager: total load: 138, num servers: 9, avg load: 16.0 2008-11-19 10:37:01,935 debug org.apache.hadoop.hbase.master.regionmanager: server xx.xx.xx.212:60020 is overloaded. server load: 21 avg: 16.0, slop: 0.1 2008-11-19 10:37:01,935 debug org.apache.hadoop.hbase.master.regionmanager: choosing to reassign 5 regions. mostloadedregions has 10 regions in it. 2008-11-19 10:37:01,935 info org.apache.hadoop.hbase.master.regionmanager: skipping region streams,'6,1226967394935 because it is already closing. 2008-11-19 10:37:01,935 info org.apache.hadoop.hbase.master.regionmanager: skipping region streamitems,'\ufffd,1226078595896 because it is already closing. 2008-11-19 10:37:01,935 info org.apache.hadoop.hbase.master.regionmanager: skipping region streamitems,\ufffd\ufffd\ufffd,1225472287315 because it is already closing. 2008-11-19 10:37:01,935 info org.apache.hadoop.hbase.master.regionmanager: skipping region streamitems,x$\ufffd,1225411877996 because it is already closing. 2008-11-19 10:37:01,935 info org.apache.hadoop.hbase.master.regionmanager: skipping region streamitems,\ufffd},1225411050812 because it is already closing. 2008-11-19 10:37:01,935 info org.apache.hadoop.hbase.master.regionmanager: skipping region api,,1222913694225 because it is already closing. 2008-11-19 10:37:01,935 info org.apache.hadoop.hbase.master.regionmanager: skipping region streamitems,0\ufffd\ufffd,1226459423496 because it is already closing. 2008-11-19 10:37:01,935 info org.apache.hadoop.hbase.master.regionmanager: skipping region items,r\ufffd,1223906859795 because it is already closing. 2008-11-19 10:37:01,935 info org.apache.hadoop.hbase.master.regionmanager: skipping region authentication,,1222913700431 because it is already closing. 2008-11-19 10:37:01,935 info org.apache.hadoop.hbase.master.regionmanager: skipping region streamitems,\ufffd,1225411057556 because it is already closing. 2008-11-19 10:37:04,939 debug org.apache.hadoop.hbase.master.regionmanager: server  xx.xx.xx.212:60020 is overloaded. server load: 21 avg: 16.0, slop: 0.1 2008-11-19 10:37:04,939 debug org.apache.hadoop.hbase.master.regionmanager: choosing to reassign 5 regions. mostloadedregions has 10 regions in it. 2008-11-19 10:37:04,939 info org.apache.hadoop.hbase.master.regionmanager: skipping region streams,'6,1226967394935 because it is already closing. 2008-11-19 10:37:04,939 info org.apache.hadoop.hbase.master.regionmanager: skipping region streamitems,'\ufffd,1226078595896 because it is already closing. 2008-11-19 10:37:04,939 info org.apache.hadoop.hbase.master.regionmanager: skipping region streamitems,\ufffd\ufffd\ufffd,1225472287315 because it is already closing. 2008-11-19 10:37:04,939 info org.apache.hadoop.hbase.master.regionmanager: skipping region streamitems,x$\ufffd,1225411877996 because it is already closing. 2008-11-19 10:37:04,939 info org.apache.hadoop.hbase.master.regionmanager: skipping region streamitems,\ufffd},1225411050812 because it is already closing. 2008-11-19 10:37:04,939 info org.apache.hadoop.hbase.master.regionmanager: skipping region api,,1222913694225 because it is already closing. 2008-11-19 10:37:04,939 info org.apache.hadoop.hbase.master.regionmanager: skipping region streamitems,0\ufffd\ufffd,1226459423496 because it is already closing. 2008-11-19 10:37:04,939 info org.apache.hadoop.hbase.master.regionmanager: skipping region items,r\ufffd,1223906859795 because it is already closing. 2008-11-19 10:37:04,939 info org.apache.hadoop.hbase.master.regionmanager: skipping region authentication,,1222913700431 because it is already closing. 2008-11-19 10:37:04,939 info org.apache.hadoop.hbase.master.regionmanager: skipping region streamitems,\ufffd,1225411057556 because it is already closing. 2008-11-19 10:37:07,941 debug org.apache.hadoop.hbase.master.regionmanager: server  xx.xx.xx.212:60020 is overloaded. server load: 21 avg: 16.0, slop: 0.1 2008-11-19 10:37:07,941 debug org.apache.hadoop.hbase.master.regionmanager: choosing to reassign 5 regions. mostloadedregions has 10 regions in it. 2008-11-19 10:37:07,941 info org.apache.hadoop.hbase.master.regionmanager: skipping region streams,'6,1226967394935 because it is already closing. 2008-11-19 10:37:07,941 info org.apache.hadoop.hbase.master.regionmanager: skipping region streamitems,'\ufffd,1226078595896 because it is already closing. 2008-11-19 10:37:07,942 info org.apache.hadoop.hbase.master.regionmanager: skipping region streamitems,\ufffd\ufffd\ufffd,1225472287315 because it is already closing. 2008-11-19 10:37:07,942 info org.apache.hadoop.hbase.master.regionmanager: skipping region streamitems,x$\ufffd,1225411877996 because it is already closing. 2008-11-19 10:37:07,942 info org.apache.hadoop.hbase.master.regionmanager: skipping region streamitems,\ufffd},1225411050812 because it is already closing. 2008-11-19 10:37:07,942 info org.apache.hadoop.hbase.master.regionmanager: skipping region api,,1222913694225 because it is already closing. 2008-11-19 10:37:07,942 info org.apache.hadoop.hbase.master.regionmanager: skipping region streamitems,0\ufffd\ufffd,1226459423496 because it is already closing. 2008-11-19 10:37:07,942 info org.apache.hadoop.hbase.master.regionmanager: skipping region items,r\ufffd,1223906859795 because it is already closing. 2008-11-19 10:37:07,942 info org.apache.hadoop.hbase.master.regionmanager: skipping region authentication,,1222913700431 because it is already closing. 2008-11-19 10:37:07,942 info org.apache.hadoop.hbase.master.regionmanager: skipping region streamitems,\ufffd,1225411057556 because it is already closing. ",
        "label": 314
    },
    {
        "text": "vc listlabels  erroneously closes any connection  in hbase-13358 the visibilityclient.listlabels() was amended to take in a connection from the caller, which totally makes sense. but the patch forgot to remove the unconditional call to connection.close() in the finally block:     finally {       if (table != null) {         table.close();       }       if (connection != null) {         connection.close();       }     } remove the second if completely. ",
        "label": 46
    },
    {
        "text": "add documentation for hbtop  we already have readme for hbtop, so we can make the refguide refer to this:  https://github.com/apache/hbase/blob/master/hbase-hbtop/readme.md ",
        "label": 455
    },
    {
        "text": "mitigate compatibility concerns between branch and branch  ",
        "label": 38
    },
    {
        "text": "handle large edits for asynchronous wal  first, fanoutoneblockasyncdfsoutput can not work if the buffered data is larger than packetreceiver.max_packet_size(16mb). second, since we only allow one block here, we need to make sure we do not exceed the block size after writing a large chunk of data. ",
        "label": 149
    },
    {
        "text": "make in memory table scanning faster  this issue is about profiling hbase to see if i can make hbase scans run faster when all is up in memory. talking to some users, they are seeing about 1/4 million rows a second. it should be able to go faster than this (scanning an array of objects, they can do about 4-5x this). ",
        "label": 340
    },
    {
        "text": "zookeeper test failing on hudson  we're failing here because .meta. moved: retrying after sleep of 5000 because: connection refused 2010-10-02 00:50:49,728 debug [main] client.hconnectionmanager$hconnectionimplementation(717): locateregioninmeta attempt 2 of 4 failed; retrying after sleep of 5000 because: connection refused 2010-10-02 00:50:59,730 debug [main] client.hconnectionmanager$hconnectionimplementation(717): locateregioninmeta attempt 0 of 4 failed; retrying after sleep of 5000 because: connection refused 2010-10-02 00:51:04,731 debug [main] client.hconnectionmanager$hconnectionimplementation(717): locateregioninmeta attempt 1 of 4 failed; retrying after sleep of 5000 because: connection refused 2010-10-02 00:51:09,732 debug [main] client.hconnectionmanager$hconnectionimplementation(717): locateregioninmeta attempt 2 of 4 failed; retrying after sleep of 5000 because: connection refused 2010-10-02 00:51:14,734 warn  [main] client.hconnectionmanager$hconnectionimplementation(597): encounted problems when prefetch meta table:  org.apache.hadoop.hbase.client.retriesexhaustedexception: trying to contact region server vesta.apache.org:54172 for region .meta.,,1, row 'test1285980613475,,99999999999999', but failed after 4 attempts. exceptions: java.net.connectexception: connection refused java.net.connectexception: connection refused java.net.connectexception: connection refused java.net.connectexception: connection refused at org.apache.hadoop.hbase.client.hconnectionmanager$hconnectionimplementation.getregionserverwithretries(hconnectionmanager.java:946) at org.apache.hadoop.hbase.client.htable.getroworbefore(htable.java:500) at org.apache.hadoop.hbase.client.metascanner.metascan(metascanner.java:104) at org.apache.hadoop.hbase.client.hconnectionmanager$hconnectionimplementation.prefetchregioncache(hconnectionmanager.java:594) at org.apache.hadoop.hbase.client.hconnectionmanager$hconnectionimplementation.locateregioninmeta(hconnectionmanager.java:645) at org.apache.hadoop.hbase.client.hconnectionmanager$hconnectionimplementation.locateregion(hconnectionmanager.java:539) at org.apache.hadoop.hbase.client.hconnectionmanager$hconnectionimplementation.locateregion(hconnectionmanager.java:507) at org.apache.hadoop.hbase.client.hbaseadmin.createtable(hbaseadmin.java:287) at org.apache.hadoop.hbase.client.hbaseadmin.createtable(hbaseadmin.java:207) at org.apache.hadoop.hbase.testzookeeper.testsanity(testzookeeper.java:140) ... i'm not sure why we're not picking up new locations. ",
        "label": 314
    },
    {
        "text": "multirowrangefilter returns records whose rowkeys are out of allowed ranges  i haven't found a way to attach test program to jira issue, so put it below : public class multirowrangefiltertest {       byte[] key1start = new byte[] {-3};     byte[] key1end  = new byte[] {-2};     byte[] key2start = new byte[] {5};     byte[] key2end  = new byte[] {6};     byte[] badkey = new byte[] {-10};     @test     public void testranges() throws ioexception {         multirowrangefilter filter = new multirowrangefilter(arrays.aslist(                 new multirowrangefilter.rowrange(key1start, true, key1end, false),                 new multirowrangefilter.rowrange(key2start, true, key2end, false)         ));         filter.filterrowkey(badkey, 0, 1);         /*         * fails -- includes bad key!         * expected :seek_next_using_hint         * actual   :include         * */         assertequals(filter.returncode.seek_next_using_hint, filter.filterkeyvalue(null));     } } it seems to happen on 2.0.0-snapshot too, but i wasn't able to link one with included class. i have played some time with algorithm, and found that quick fix may be applied to \"getnextrangeindex(byte[] rowkey)\" method (hbase-client:1.1.0) : if (insertionposition == 0 && !rangelist.get(insertionposition).contains(rowkey)) {         return row_before_first_range; } // fix start if(!this.initialized) {     this.initialized = true; } // fix end return insertionposition; thanks, hope it will help. ",
        "label": 47
    },
    {
        "text": "testsplitlogmanager testunassignedtimeout is flaky  this is the most frequently failing test in the recent 0.94 jenkins builds.  looking at the code it seem the timeouts are a bit too aggressive (there's only a 500ms window for the test to detect that a zk was removed). i think we should just double the timeouts. ",
        "label": 286
    },
    {
        "text": "hmaster getprotocolversion  ignores hmasterregioninterface version  the recent split of rpc protocol version numbers doesn't work quite as expected with hmasterregioninterface. since hmaster implements both hmasterinterface and hmasterregioninterface, its getprotocolversion() implementation needs to check the requested protocol name and return either the hmasterinterface.version value or hmasterregioninterface.version value as appropriate. ",
        "label": 180
    },
    {
        "text": "fix potential bugs in exception handlers  hi hbase developers,  we are a group of researchers on software reliability. recently we did a study and found that majority of the most severe failures in hbase are caused by bugs in exception handling logic \u2013 that it is hard to anticipate all the possible real-world error scenarios. therefore we built a simple checking tool that automatically detects some bug patterns that have caused some very severe real-world failures. i am reporting some of the results here. any feedback is much appreciated! ding =========================  case 1:  line: 134, file: \"org/apache/hadoop/hbase/regionserver/regionmergerequest.java\"   protected void releasetablelock() {     if (this.tablelock != null) {       try {         this.tablelock.release();       } catch (ioexception ex) {         log.warn(\"could not release the table lock\", ex);         //todo: if we get here, and not abort rs, this lock will never be released       }     } the lock is not released if the exception occurs, causing potential deadlock or starvation. similar code pattern can be found at:  line: 135, file: \"org/apache/hadoop/hbase/regionserver/splitrequest.java\"  ========================================== =========================  case 2:  line: 252, file: \"org/apache/hadoop/hbase/regionserver/wal/sequencefilelogreader.java\"     try {       field fend = sequencefile.reader.class.getdeclaredfield(\"end\");       fend.setaccessible(true);       end = fend.getlong(this.reader);     } catch(exception e) { /* reflection fail. keep going */ } the caught exception seems to be too general.  while reflection-related errors might be harmless, the try block can throw  other exceptions including \"securityexception\", \"illegalaccessexception\", etc. currently  all those exceptions are ignored. maybe  the safe way is to ignore the specific reflection-related errors while logging and  handling other types of unexpected exceptions.  ==========================================  =========================  case 3:  line: 148, file: \"org/apache/hadoop/hbase/hbaseconfiguration.java\"     try {       if (class.forname(\"org.apache.hadoop.conf.confservlet\") != null) {         isshowconf = true;       }     } catch (exception e) {     } similar to the previous case, the exception handling is too general. while classnotfound error might be the normal case and ignored, class.forname can also throw other exceptions (e.g., linkageerror) under some unexpected and rare error cases. if that happens, the error will be lost. so maybe change it to below:     try {       if (class.forname(\"org.apache.hadoop.conf.confservlet\") != null) {         isshowconf = true;       }     } catch (linkageerror e) {       log.warn(\"..\");       // handle linkage error     } catch (exceptionininitializererror e) {       log.warn(\"..\");       // handle initializer error     } catch (classnotfoundexception e) {      log.debug(\"..\");      // ignore     } ==========================================  =========================  case 4:  line: 163, file: \"org/apache/hadoop/hbase/client/get.java\"   public get settimestamp(long timestamp) {     try {       tr = new timerange(timestamp, timestamp+1);     } catch(ioexception e) {       // will never happen     }     return this;   } even if the ioexception never happens right now, is it possible to happen in the future due to code change?  at least there should be a log message. the current behavior is dangerous since if the exception ever happens  in any unexpected scenario, it will be silently swallowed. similar code pattern can be found at:  line: 300, file: \"org/apache/hadoop/hbase/client/scan.java\"  ========================================== =========================  case 5:  line: 207, file: \"org/apache/hadoop/hbase/util/jvm.java\"    if (input != null){         try {           input.close();         } catch (ioexception ignored) {         }       } any exception encountered in close is completely ignored, not even logged.  in particular, the same exception scenario was handled differently in other methods in the same file:  line: 154, same file        if (in != null){          try {            in.close();          } catch (ioexception e) {            log.warn(\"not able to close the inputstream\", e);          }        } line: 248, same file       if (in != null){         try {           in.close();         } catch (ioexception e) {           log.warn(\"not able to close the inputstream\", e);         }       } ========================================== =========================  case 6: empty handler for exception: java.io.ioexception  line: 312, file: \"org/apache/hadoop/hbase/rest/rowresource.java\"     } finally {       if (table != null) try {         table.close();       } catch (ioexception ioe) { }     } ioexception is completely ignored. this behavior is inconsistent with the same  code snippet at line 249 in the same file, where the ioexceptions was logged:    } finally {       if (table != null) try {         table.close();       } catch (ioexception ioe) {         log.debug(\"exception received while closing the table\", ioe);       }     } ==========================================  =========================  case 7:  line: 95, file: \"org/apache/hadoop/hbase/master/handler/enabletablehandler.java\"         try {           this.assignmentmanager.getzktable().removeenablingtable(tablename, true);         } catch (keeperexception e) {           // todo : use hbck to clear such nodes           log.warn(\"failed to delete the enabling node for the table \" + tablename               + \".  the table will remain unusable. run hbck to manually fix the problem.\");         } the log message in the exception handler and the comment seem to suggest that such nodes should be cleared using hbck.  ========================================== =========================  case 8:  line: 463, file: \"org/apache/hadoop/hbase/client/clientscanner.java\"         try {           this.caller.callwithretries(callable);         } catch (ioexception e) {           // we used to catch this error, interpret, and rethrow. however, we           // have since decided that it's not nice for a scanner's close to           // throw exceptions. chances are it was just an unknownscanner           // exception due to lease time out.         } currently the handler is empty because it may be caused by \"just an unknownscanner exception\".  but what if it has other causes? maybe the catch block can differentiate the exception into  different causes, ignoring the ones caused by unknownscanner while handle others differently?  ========================================== ",
        "label": 142
    },
    {
        "text": "row keys should be array of bytes  i have heard from several people that row keys in hbase should be less restricted than hadoop.io.text. what do you think? at the very least, a row key has to be a writablecomparable. this would lead to the most general case being either hadoop.io.byteswritable or hbase.io.immutablebyteswritable. the primary difference between these two classes is that hadoop.io.byteswritable by default allocates 100 bytes and if you do not pay attention to the length, (byteswritable.getsize()), converting a string to a byteswritable and vice versa can become problematic. hbase.io.immutablebyteswritable, in contrast only allocates as many bytes as you pass in and then does not allow the size to be changed. if we were to change from text to a non-text key, my preference would be for immutablebyteswritable, because it has a fixed size once set, and operations like get, etc do not have to something like system.arraycopy where you specify the number of bytes to copy. your comments, questions are welcome on this issue. if we receive enough feedback that text is too restrictive, we are willing to change it, but we need to hear what would be the most useful thing to change it to as well. ",
        "label": 314
    },
    {
        "text": "change htable class doc so it sends people to hcm getting instances  the htable class doc does not reflect the new regime where you are meant to go via cluster connection to get an instance. getting an htable otherwise also makes for some strange issues: see \"occasional gssexception that brings down region server\" on mailing list. ",
        "label": 314
    },
    {
        "text": "deletes with and without visibility expression do not delete the matching mutation  this is from the user list as reported by anoop sharma  running into an issue related to visibility expressions and delete. example run from hbase shell is listed below. will appreciate any help on this issue. thanks. in the example below, user running queries has \u2018manager\u2019 authorization. *first example:*   add a column with visib expr \u2018manager\u2019   delete it by passing in visibility of \u2018manager\u2019   this works and scan doesn\u2019t return anything. *second example:*   add a column with visib expr \u2018manager\u2019   delete it by not passing in any visibility.   this doesn\u2019t delete the column.   scan doesn\u2019t return the row but raw scan shows the column   marked as deletecolumn.   now if delete is done again with visibility of \u2018manager\u2019,   it still doesn\u2019t delete it and scan returns the original column. *example 1:* hbase(main):096:0> create 'hbt1', 'cf' hbase(main):098:0* *put 'hbt1', 'john', 'cf:a', 'ca', {visibility=>'manager'}* hbase(main):099:0> *scan 'hbt1'* row column+cell  john                 column=cf:a, timestamp=1446154722055, value=ca 1 row(s) in 0.0030 seconds hbase(main):100:0> *delete 'hbt1', 'john', 'cf:a', {visibility=>'manager'}* 0 row(s) in 0.0030 seconds hbase(main):101:0> *scan 'hbt1'* row column+cell 0 row(s) in 0.0030 seconds *example 2:* hbase(main):010:0* *put 'hbt1', 'john', 'cf:a', 'ca', {visibility=>'manager'}* 0 row(s) in 0.0040 seconds hbase(main):011:0> *scan 'hbt1'* row column+cell  john                 column=cf:a, timestamp=1446155346473, value=ca 1 row(s) in 0.0060 seconds hbase(main):012:0> *delete 'hbt1', 'john', 'cf:a'* 0 row(s) in 0.0090 seconds hbase(main):013:0> *scan 'hbt1'* row column+cell  john                 column=cf:a, timestamp=1446155346473, value=ca 1 row(s) in 0.0050 seconds hbase(main):014:0> *scan 'hbt1', {raw => true}* row column+cell  john                 column=cf:a, timestamp=1446155346519, type=deletecolumn 1 row(s) in 0.0060 seconds hbase(main):015:0> *delete 'hbt1', 'john', 'cf:a', {visibility=>'manager'}* 0 row(s) in 0.0030 seconds hbase(main):016:0> *scan 'hbt1'* row column+cell  john                 column=cf:a, timestamp=1446155346473, value=ca 1 row(s) in 0.0040 seconds hbase(main):017:0> *scan 'hbt1', {raw => true}* row column+cell  john                 column=cf:a, timestamp=1446155346601, type=deletecolumn 1 row(s) in 0.0060 seconds ",
        "label": 544
    },
    {
        "text": "testdistributedlogsplitting testrecoverededits fails  https://builds.apache.org/job/hbase-0.95/342/testreport/org.apache.hadoop.hbase.master/testdistributedlogsplitting/testrecoverededits/ java.lang.assertionerror: expected:<1000> but was:<0> at org.junit.assert.fail(assert.java:88) at org.junit.assert.failnotequals(assert.java:743) at org.junit.assert.assertequals(assert.java:118) at org.junit.assert.assertequals(assert.java:555) at org.junit.assert.assertequals(assert.java:542) at org.apache.hadoop.hbase.master.testdistributedlogsplitting.testrecoverededits(testdistributedlogsplitting.java:209) at sun.reflect.nativemethodaccessorimpl.invoke0(native method) at sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:57) at sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43) at java.lang.reflect.method.invoke(method.java:601) at org.junit.runners.model.frameworkmethod$1.runreflectivecall(frameworkmethod.java:47) at org.junit.internal.runners.model.reflectivecallable.run(reflectivecallable.java:12) at org.junit.runners.model.frameworkmethod.invokeexplosively(frameworkmethod.java:44) at org.junit.internal.runners.statements.invokemethod.evaluate(invokemethod.java:17) at org.junit.internal.runners.statements.failontimeout$statementthread.run(failontimeout.java:74) jimmy xiang or jeffrey zhong want to take a look at this one? ",
        "label": 233
    },
    {
        "text": "closing socket connection can't be removed from secureclient  we found many ioexceptions naming \"call # not added as the connection # is closing\" when using secureclient to access hbase. from the source code of secureclient, we found there may be bug in close() method of secureclient. the following is the current logic in close() method of secureclient\uff1a       // release the resources       // first thing to do;take the connection out of the connection list       synchronized (connections) {         if (connections.get(remoteid) == this) {           connections.remove(remoteid);         }       } however, connections are managed by poolmap\uff1b therefore, if more than one connection are created for the same remoteid, the 'if condition' may not be satisfied because the default pooltype is roundrobin. this could be cause a closing state connection can't be removed from connections, making new calls which use such connections will always throws ioexception naming \"connection is closing\".  we can use logic from close() method of hbaseclient to resolve the problem:       // release the resources       // first thing to do;take the connection out of the connection list       synchronized (connections) {         connections.remove(remoteid, this);       } ",
        "label": 238
    },
    {
        "text": "if we timeout pending close and send another closeregion rpc  need to handle nsre from rs  comes as a remoteexception   when we send a closeregion rpc to an rs, we are catching nsre but when the rs is the one throwing the nsre, then it comes back as a remoteexception (then an nsre) and we aren't unwrapping it properly. we need to catch this and then deal with it appropriately. still tracking how this happened in the first place. ",
        "label": 247
    },
    {
        "text": "clarify that ttl in hcolumndescriptor is seconds  ",
        "label": 314
    },
    {
        "text": "hregionserver won't go down since we added in new lrublockcache  new lrublockcache uses thread excecutor scheduling stats dumping. the scheduled excecutor needs to be cancelled else it just stays running stopping the hrs going down. ",
        "label": 314
    },
    {
        "text": "forward port fixes that are in branch but not in trunk  part of the merge of old into trunk task   list of issues to forward port is up here: http://gist.github.com/398246 many no longer apply because they are for contribs since removed or the issue was a backport from here. others seem to be just missing mention in changes.txt. i'm going through them one by one. ",
        "label": 314
    },
    {
        "text": "readme txt should contain basic information like how to run or build hbase  currently if you download hbase you need to visit the wiki and figure out how to start it or build it. that information should be available in the local documents like readme.txt ",
        "label": 314
    },
    {
        "text": "add ability to start rs as root and call mlockall  a common issue we've seen in practice is that users oversubscribe their region servers with too many mr tasks, etc. as soon as the machine starts swapping, the rs grinds to a halt, loses zk session, aborts, etc. this can be combatted by starting the rs as root, calling mlockall(), and then setuid down to the hbase user. we should not require this, but we should provide it as an option. ",
        "label": 309
    },
    {
        "text": "rolling restart sh shouldn't rely on zoo cfg  i tried the rolling-restart script on our dev environment, which is configured with zoo.cfg for zookeeper, and it worked pretty well. then i tried it on our mr cluster, which doesn't have a zoo.cfg, and we suffered some downtime (no biggie tho, nothing critical was running). when the script calls this line: bin/hbase zkcli stat $zmaster it directly runs a zookeepermain which isn't modified to read from the hbase configuration files. what happens next if zk isn't running on the master node is that it receives a connectionrefused, ignores it, procedes to restart the master (which waits on the znode), and the starts restarting the region servers. they can't shutdown properly under 60 seconds, since they need a master, so they get killed. what follows is pretty ugly and pretty much requires a whole restart. ",
        "label": 314
    },
    {
        "text": "testtablesnapshotinputformatscan fails frequently on  not entirely sure why.  interestingly it always fails before the tests even start: error message no server address listed in .meta. for region scantest,lll,1397560084603.a2e754fa8f9b4ce82bd6fa3f8c678e53. containing row lll stacktrace org.apache.hadoop.hbase.client.noserverforregionexception: no server address listed in .meta. for region scantest,lll,1397560084603.a2e754fa8f9b4ce82bd6fa3f8c678e53. containing row lll at org.apache.hadoop.hbase.client.hconnectionmanager$hconnectionimplementation.locateregioninmeta(hconnectionmanager.java:1175) at org.apache.hadoop.hbase.client.hconnectionmanager$hconnectionimplementation.locateregion(hconnectionmanager.java:1001) at org.apache.hadoop.hbase.client.hconnectionmanager$hconnectionimplementation.locateregion(hconnectionmanager.java:958) at org.apache.hadoop.hbase.client.hconnectionmanager$hconnectionimplementation.processbatchcallback(hconnectionmanager.java:1675) at org.apache.hadoop.hbase.client.hconnectionmanager$hconnectionimplementation.processbatch(hconnectionmanager.java:1560) at org.apache.hadoop.hbase.client.htable.flushcommits(htable.java:994) at org.apache.hadoop.hbase.client.htable.doput(htable.java:850) at org.apache.hadoop.hbase.client.htable.put(htable.java:826) at org.apache.hadoop.hbase.hbasetestingutility.loadtable(hbasetestingutility.java:1031) at org.apache.hadoop.hbase.mapreduce.testtablesnapshotinputformatscan.setupbeforeclass(testtablesnapshotinputformatscan.java:85) ",
        "label": 286
    },
    {
        "text": "additional jar dependencies needed for mapreduce performanceevaluation  i have a unit test that runs a simple performanceevaluation test to make sure things are basically working bin/hbase org.apache.hadoop.hbase.performanceevaluation --rows=50000 sequentialwrite 1 this test runs against hadoop 2.7.0 and works against all past versions 0.99.0 and up. it broke with 1.4.0 with the following error. 2017-12-21 13:49:40,974 info  [main] mapreduce.job: task id : attempt_1513892752187_0002_m_000004_2, status : failed error: java.io.ioexception: java.lang.reflect.invocationtargetexception at org.apache.hadoop.hbase.client.connectionfactory.createconnection(connectionfactory.java:240) at org.apache.hadoop.hbase.client.connectionfactory.createconnection(connectionfactory.java:218) at org.apache.hadoop.hbase.client.connectionfactory.createconnection(connectionfactory.java:119) at org.apache.hadoop.hbase.performanceevaluation$evaluationmaptask.map(performanceevaluation.java:297) at org.apache.hadoop.hbase.performanceevaluation$evaluationmaptask.map(performanceevaluation.java:250) at org.apache.hadoop.mapreduce.mapper.run(mapper.java:146) at org.apache.hadoop.mapred.maptask.runnewmapper(maptask.java:787) at org.apache.hadoop.mapred.maptask.run(maptask.java:341) at org.apache.hadoop.mapred.yarnchild$2.run(yarnchild.java:163) at java.security.accesscontroller.doprivileged(native method) at javax.security.auth.subject.doas(subject.java:415) at org.apache.hadoop.security.usergroupinformation.doas(usergroupinformation.java:1657) at org.apache.hadoop.mapred.yarnchild.main(yarnchild.java:158) caused by: java.lang.reflect.invocationtargetexception at sun.reflect.nativeconstructoraccessorimpl.newinstance0(native method) at sun.reflect.nativeconstructoraccessorimpl.newinstance(nativeconstructoraccessorimpl.java:57) at sun.reflect.delegatingconstructoraccessorimpl.newinstance(delegatingconstructoraccessorimpl.java:45) at java.lang.reflect.constructor.newinstance(constructor.java:526) at org.apache.hadoop.hbase.client.connectionfactory.createconnection(connectionfactory.java:238) ... 12 more caused by: java.lang.runtimeexception: could not create  interface org.apache.hadoop.hbase.zookeeper.metricszookeepersource is the hadoop compatibility jar on the classpath? at org.apache.hadoop.hbase.compatibilitysingletonfactory.getinstance(compatibilitysingletonfactory.java:75) at org.apache.hadoop.hbase.zookeeper.metricszookeeper.<init>(metricszookeeper.java:38) at org.apache.hadoop.hbase.zookeeper.recoverablezookeeper.<init>(recoverablezookeeper.java:130) at org.apache.hadoop.hbase.zookeeper.zkutil.connect(zkutil.java:143) at org.apache.hadoop.hbase.zookeeper.zookeeperwatcher.<init>(zookeeperwatcher.java:181) at org.apache.hadoop.hbase.zookeeper.zookeeperwatcher.<init>(zookeeperwatcher.java:155) at org.apache.hadoop.hbase.client.zookeeperkeepaliveconnection.<init>(zookeeperkeepaliveconnection.java:43) at org.apache.hadoop.hbase.client.connectionmanager$hconnectionimplementation.getkeepalivezookeeperwatcher(connectionmanager.java:1737) at org.apache.hadoop.hbase.client.zookeeperregistry.getclusterid(zookeeperregistry.java:104) at org.apache.hadoop.hbase.client.connectionmanager$hconnectionimplementation.retrieveclusterid(connectionmanager.java:945) at org.apache.hadoop.hbase.client.connectionmanager$hconnectionimplementation.<init>(connectionmanager.java:721) ... 17 more caused by: java.util.serviceconfigurationerror: org.apache.hadoop.hbase.zookeeper.metricszookeepersource: provider org.apache.hadoop.hbase.zookeeper.metricszookeepersourceimpl could not be instantiated at java.util.serviceloader.fail(serviceloader.java:224) at java.util.serviceloader.access$100(serviceloader.java:181) at java.util.serviceloader$lazyiterator.next(serviceloader.java:377) at java.util.serviceloader$1.next(serviceloader.java:445) at org.apache.hadoop.hbase.compatibilitysingletonfactory.getinstance(compatibilitysingletonfactory.java:59) ... 27 more caused by: java.lang.noclassdeffounderror: lorg/apache/hadoop/hbase/metrics/metricregistry; at java.lang.class.getdeclaredfields0(native method) at java.lang.class.privategetdeclaredfields(class.java:2509) at java.lang.class.getdeclaredfields(class.java:1819) at org.apache.hadoop.util.reflectionutils.getdeclaredfieldsincludinginherited(reflectionutils.java:323) at org.apache.hadoop.metrics2.lib.metricssourcebuilder.initregistry(metricssourcebuilder.java:92) at org.apache.hadoop.metrics2.lib.metricssourcebuilder.<init>(metricssourcebuilder.java:56) at org.apache.hadoop.metrics2.lib.metricsannotations.newsourcebuilder(metricsannotations.java:42) at org.apache.hadoop.metrics2.impl.metricssystemimpl.register(metricssystemimpl.java:224) at org.apache.hadoop.hbase.metrics.basesourceimpl.<init>(basesourceimpl.java:115) at org.apache.hadoop.hbase.zookeeper.metricszookeepersourceimpl.<init>(metricszookeepersourceimpl.java:56) at org.apache.hadoop.hbase.zookeeper.metricszookeepersourceimpl.<init>(metricszookeepersourceimpl.java:51) at sun.reflect.nativeconstructoraccessorimpl.newinstance0(native method) at sun.reflect.nativeconstructoraccessorimpl.newinstance(nativeconstructoraccessorimpl.java:57) at sun.reflect.delegatingconstructoraccessorimpl.newinstance(delegatingconstructoraccessorimpl.java:45) at java.lang.reflect.constructor.newinstance(constructor.java:526) at java.lang.class.newinstance(class.java:383) at java.util.serviceloader$lazyiterator.next(serviceloader.java:373) ... 29 more caused by: java.lang.classnotfoundexception: org.apache.hadoop.hbase.metrics.metricregistry at java.net.urlclassloader$1.run(urlclassloader.java:366) at java.net.urlclassloader$1.run(urlclassloader.java:355) at java.security.accesscontroller.doprivileged(native method) at java.net.urlclassloader.findclass(urlclassloader.java:354) at java.lang.classloader.loadclass(classloader.java:425) at sun.misc.launcher$appclassloader.loadclass(launcher.java:312) at java.lang.classloader.loadclass(classloader.java:358) ... 46 more the errors are coming from within the map tasks. suggesting that they are missing some jar/class dependency. i know there are several new jars created in hbase 1.4.0. are they missing/should be included in performanceevaluation. ",
        "label": 13
    },
    {
        "text": "major compact  and other admin commands  broken for  meta   table admin commands seem to be broken against meta. implementation is new in master rewrite branch so should wait until that goes in to see if this bug still exists. ",
        "label": 314
    },
    {
        "text": "hbase bin hbase cleanup sh has wrong usage string  looks like hbase-cleanup,sh has wrong usage string.  https://github.com/apache/hbase/blob/trunk/bin/hbase-cleanup.sh#l34 current usage string: [systest@search-testing-c5-ncm-1 ~]$ echo `/usr/lib/hbase/bin/hbase-cleanup.sh` usage: hbase-cleanup.sh (zk|hdfs|all) but ideally digging into the logic of hbase-cleanup.sh, it should be modified to [systest@search-testing-c5-ncm-1 ~]$ echo `/usr/lib/hbase/bin/hbase-cleanup.sh` usage: hbase-cleanup.sh (--cleanzk|--cleanhdfs|--cleanall) ",
        "label": 461
    },
    {
        "text": "move hbaserpc metrics to metrics2  hbase rpc is the last thing still publishing through metrics1. we should move this into metrics2. ",
        "label": 154
    },
    {
        "text": "releasing l2 cache hfileblocks before shipped  when switching from pread to stream causes result corruption  in hbase-17917 tries to switch from pread to stream read when a specific size of bytes are read. so in order to switch over, it closes the existing scanners and creates a new scanners with pread=false.  when we close the exisitng scanners - if the blocks are served from offheap cache we will decrement the ref count on those blocks and if it becomes zero we make the block ready for eviction. then there is a chance that the result could be corrupted if new blocks occupy the cache. so the expectation was that till the rpc call completes the response we will hold on to the blocks that are referred by the scan. (except the last one). so trying to switch over to stream read will break this expectation and hence testblockevictionfromclient fails. ",
        "label": 149
    },
    {
        "text": "method regionserver memstore updatecolumnvalue  the check for qualifier and family is missing             [...]             while (it.hasnext()) {                 keyvalue kv = it.next();                 // if this isnt the row we are interested in, then bail:                 if (!firstkv.matchingcolumn(family, qualifier) || !firstkv.matchingrow(kv)) {                     break; // rows dont match, bail.                 }                 [...]             } should be replaced by:                 // if this isnt the row we are interested in, then bail:                 if (!kv.matchingcolumn(family, qualifier) || !firstkv.matchingrow(kv)) {                     break; // rows dont match, bail.                 } ",
        "label": 340
    },
    {
        "text": "testshell failing on branch and branch  here's a failed run from branch-1.4   https://builds.apache.org/job/hbase-flaky-tests/job/branch-1.4/3958/testreport/junit/org.apache.hadoop.hbase.client/testshell/testrunshelltests/ ",
        "label": 473
    },
    {
        "text": "hbase mapreduce job launch documentation misplaced  documentation on steps to properly launch a mapreduce job on an hbase + hadoop cluster is misplaced and is located in javadocs: http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/mapreduce/package-summary.html#classpath this must be extracted and placed in a separate page with rest of hbase mr guide. ",
        "label": 330
    },
    {
        "text": "improve unit test coverage of package org apache hadoop hbase mapreduce hadoopbackport  the patch is for branch 0.94 only. the class inputsampler is modified because need to fix bug there: in method \"run(string[] args)\" should be \"totalorderpartitioner.setpartitionfile(job.getconfiguration(), outf);\" instead of \"totalorderpartitioner.setpartitionfile(getconf(), outf);\". otherwise it is impossible to set output file correctly. ",
        "label": 217
    },
    {
        "text": " dataloss  bulk loading with seqids can prevent some log entries from being replayed  we found an issue with bulk loads causing data loss when assigning sequence ids (hbase-6630) that is triggered when replaying recovered edits. we're nicknaming this issue blindspot. the problem is that the sequence id given to a bulk loaded file is higher than those of the edits in the region's memstore. when replaying recovered edits, the rule to skip some of them is that they have to be lower than the highest sequence id. in other words, the edits that have a sequence id lower than the highest one in the store files should have also been flushed. this is not the case with bulk loaded files since we now have an hfile with a sequence id higher than unflushed edits. the log recovery code takes this into account by simply skipping the bulk loaded files, but this \"bulk loaded status\" is lost on compaction. the edits in the logs that have a sequence id lower than the bulk loaded file that got compacted are put in a blind spot and are skipped during replay. here's the easiest way to recreate this issue: create an empty table put one row in it (let's say it gets seqid 1) bulk load one file (it gets seqid 2). i used importsv and set hbase.mapreduce.bulkload.assign.sequencenumbers. bulk load a second file the same way (it gets seqid 3). major compact the table (the new file has seqid 3 and isn't considered bulk loaded). kill the region server that holds the table's region. scan the table once the region is made available again. the first row, at seqid 1, will be missing since the hfile with seqid 3 makes us believe that everything that came before it was flushed. ",
        "label": 229
    },
    {
        "text": "major compact keeps deletes with future timestamps  hello! during migration from hbase 0.90.6 to 0.94.6 we found changed behaviour in how major compact handles delete markers with timestamps in the future. before hbase-4721 major compact purged deletes regardless of their timestamp. newer versions keep them in hfile until timestamp not reached. i guess this happened due to new check in scanquerymatcher environmentedgemanager.currenttimemillis() - timestamp) <= timetopurgedeletes. this can be worked around by specifying large negative value in hbase.hstore.time.to.purge.deletes option, but, unfortunately, negative values are pulled up to zero by math.max in hstore.java. maybe, we are trying to do something weird by specifing delete timestamp in future, but hbase-4721 definitely breaks old behaviour we rely on. steps to reproduce this: put 'test', 'delmerow', 'delme:something', 'hello' flush 'test' delete 'test', 'delmerow', 'delme:something', 1394161431061 flush 'test' major_compact 'test' before major_compact we have two hfiles with the following: first: k: delmerow/delme:something/1384161431061/put/vlen=5/ts=0 second: k: delmerow/delme:something/1394161431061/deletecolumn/vlen=0/ts=0 after major compact we get the following: k: delmerow/delme:something/1394161431061/deletecolumn/vlen=0/ts=0 in our installation, we resolved this by removing math.max and setting hbase.hstore.time.to.purge.deletes to integer.min_value, which purges delete markers, and it looks like a solution. but, maybe, there are better approach. ",
        "label": 411
    },
    {
        "text": "distinguish read and write request count in region  distinguishing read and write request counts, on top of hbase-3507, would benefit load balancer.  the action for balancing read vs. write load should be different. for read load, region movement should be low (to keep scanner happy). for write load, region movement is allowed.  now that we have cheap(er) counters, it should not be too burdensome keeping up the extra count. ",
        "label": 441
    },
    {
        "text": "add table based replication peers queues storage back  we removed them after hbase-19397. so open a issue to track this thing. ",
        "label": 514
    },
    {
        "text": "direct api calls from embedded thrift server to regionserver  when handling thrift calls in the regionserver we should not go through rpc to talk to the local regionserver. ",
        "label": 324
    },
    {
        "text": "add hbase ref card pointer to ref guide  the hbase refcard is at http://refcardz.dzone.com/refcardz/hbase  maybe it belongs to appendix f? doug meil? ",
        "label": 146
    },
    {
        "text": "the clusters can't provide services because region can't flush   hbase version 0.90.4 + patches my analysis is as follows: //started splitting region b24d8ccb852ff742f2a27d01b7f5853e and closed region. 2011-12-10 17:32:48,653 info org.apache.hadoop.hbase.regionserver.splittransaction: starting split of region htable_ufdr_004,09781,1323508582833.b24d8ccb852ff742f2a27d01b7f5853e.  2011-12-10 17:32:49,759 debug org.apache.hadoop.hbase.regionserver.hregion: closing htable_ufdr_004,09781,1323508582833.b24d8ccb852ff742f2a27d01b7f5853e.: disabling compactions & flushes  2011-12-10 17:32:49,759 info org.apache.hadoop.hbase.regionserver.hregion: running close preflush of htable_ufdr_004,09781,1323508582833.b24d8ccb852ff742f2a27d01b7f5853e. //processed a flush request and skipped , but flushrequested had set to true  2011-12-10 17:33:06,963 debug org.apache.hadoop.hbase.regionserver.hregion: started memstore flush for htable_ufdr_004,09781,1323508582833.b24d8ccb852ff742f2a27d01b7f5853e., current region memstore size 12.6m  2011-12-10 17:33:17,277 debug org.apache.hadoop.hbase.regionserver.hregion: skipping flush on htable_ufdr_004,09781,1323508582833.b24d8ccb852ff742f2a27d01b7f5853e. because closing //split region b24d8ccb852ff742f2a27d01b7f5853 failed and rolled back, flushrequested flag was true, so all handle was blocked 2011-12-10 17:34:01,293 info org.apache.hadoop.hbase.regionserver.splittransaction: cleaned up old failed split transaction detritus: hdfs://193.195.18.121:9000/hbase/htable_ufdr_004/b24d8ccb852ff742f2a27d01b7f5853e/splits  2011-12-10 17:34:01,294 info org.apache.hadoop.hbase.regionserver.hregion: onlined htable_ufdr_004,09781,1323508582833.b24d8ccb852ff742f2a27d01b7f5853e.; next sequenceid=15494173  2011-12-10 17:34:01,295 info org.apache.hadoop.hbase.regionserver.compactsplitthread: successful rollback of failed split of htable_ufdr_004,09781,1323508582833.b24d8ccb852ff742f2a27d01b7f5853e.  2011-12-10 17:43:10,147 info org.apache.hadoop.hbase.regionserver.hregion: blocking updates for 'ipc server handler 19 on 20020' on region   htable_ufdr_004,09781,1323508582833.b24d8ccb852ff742f2a27d01b7f5853e.: memstore size 384.0m is >= than blocking 384.0m size // all handles had been blocked. the clusters could not provide services 2011-12-10 17:34:01,295 info org.apache.hadoop.hbase.regionserver.compactsplitthread: successful rollback of failed split of htable_ufdr_004,09781,1323508582833.b24d8ccb852ff742f2a27d01b7f5853e.  2011-12-10 17:43:10,147 info org.apache.hadoop.hbase.regionserver.hregion: blocking updates for 'ipc server handler 19 on 20020' on region htable_ufdr_004,09781,1323508582833.b24d8ccb852ff742f2a27d01b7f5853e.: memstore size 384.0m is >= than blocking 384.0m size  2011-12-10 17:43:10,192 info org.apache.hadoop.hbase.regionserver.hregion: blocking updates for 'ipc server handler 34 on 20020' on region htable_ufdr_004,09781,1323508582833.b24d8ccb852ff742f2a27d01b7f5853e.: memstore size 384.0m is >= than blocking 384.0m size  2011-12-10 17:43:10,193 info org.apache.hadoop.hbase.regionserver.hregion: blocking updates for 'ipc server handler 51 on 20020' on region htable_ufdr_004,09781,1323508582833.b24d8ccb852ff742f2a27d01b7f5853e.: memstore size 384.0m is >= than blocking 384.0m size  2011-12-10 17:43:10,196 info org.apache.hadoop.hbase.regionserver.hregion: blocking updates for 'ipc server handler 85 on 20020' on region htable_ufdr_004,09781,1323508582833.b24d8ccb852ff742f2a27d01b7f5853e.: memstore size 384.0m is >= than blocking 384.0m size  2011-12-10 17:43:10,199 info org.apache.hadoop.hbase.regionserver.hregion: blocking updates for 'ipc server handler 88 on 20020' on region htable_ufdr_004,09781,1323508582833.b24d8ccb852ff742f2a27d01b7f5853e.: memstore size 384.0m is >= than blocking 384.0m size  2011-12-10 17:43:10,202 info org.apache.hadoop.hbase.regionserver.hregion: blocking updates for 'ipc server handler 44 on 20020' on region htable_ufdr_004,09781,1323508582833.b24d8ccb852ff742f2a27d01b7f5853e.: memstore size 384.0m is >= than blocking 384.0m size  2011-12-10 17:43:11,663 info org.apache.hadoop.hbase.regionserver.hregion: blocking updates for 'ipc server handler 2 on 20020' on region htable_ufdr_004,09781,1323508582833.b24d8ccb852ff742f2a27d01b7f5853e.: memstore size 384.0m is >= than blocking 384.0m size  2011-12-10 17:43:11,665 info org.apache.hadoop.hbase.regionserver.hregion: blocking updates for 'ipc server handler 10 on 20020' on region htable_ufdr_004,09781,1323508582833.b24d8ccb852ff742f2a27d01b7f5853e.: memstore size 384.0m is >= than blocking 384.0m size  2011-12-10 17:43:11,670 info org.apache.hadoop.hbase.regionserver.hregion: blocking updates for 'ipc server handler 75 on 20020' on region htable_ufdr_004,09781,1323508582833.b24d8ccb852ff742f2a27d01b7f5853e.: memstore size 384.0m is >= than blocking 384.0m size  2011-12-10 17:43:11,671 info org.apache.hadoop.hbase.regionserver.hregion: blocking updates for 'ipc server handler 98 on 20020' on region htable_ufdr_004,09781,1323508582833.b24d8ccb852ff742f2a27d01b7f5853e.: memstore size 384.0m is >= than blocking 384.0m size  2011-12-10 17:43:11,680 info org.apache.hadoop.hbase.regionserver.hregion: blocking updates for 'ipc server handler 11 on 20020' on region ",
        "label": 529
    },
    {
        "text": "release build fails in checkstyle phase of site target  branch   running these commands: export maven_opts=\"-xmx4g -xx:maxpermsize=256m\" mvn clean org.codehaus.mojo:versions-maven-plugin:2.5:set -dnewversion=1.4.0 git clean -xdf mvn clean install -dskiptests -prelease mvn install -dskiptests site assembly:single -prelease fails on that last maven invocation in the checkstyle phase of the site target with [error] failed to execute goal org.apache.maven.plugins:maven-site-plugin:3.4:site (default-site) on project hbase-annotations: error generating maven-checkstyle-plugin:2.17:checkstyle: failed during checkstyle execution: unable to process suppressions file location: hbase/checkstyle-suppressions.xml: cannot create file-based resource:invalid block type ",
        "label": 38
    },
    {
        "text": "hbase removed an important edge case  in hbase-2553 an important edge case whereby a kv with the same ts in snapshot was lost, tests have been failing (but flakly so) indicating it as well. ",
        "label": 547
    },
    {
        "text": "max seq id in flushed file can be larger than its correct value causing data loss during recovery  [while doing some cluster kill tests, i noticed some missing data after log recovery. upon investigating further, and pretty printing contents of hfiles and recovered logs, this is my analysis of the situation/bug. please confirm the theory and pitch in with suggestions.] when memstores are flushed, the max sequence id recorded in the hfile should be the max sequence id of all kvs in the memstore. however, we seem to simply obtain the current sequence id from the hregion, and stamp the hfile's max_seq_id with it. from hregion.java:     sequenceid = (wal == null)? myseqid: wal.startcacheflush(); where, startcacheflush() is: public long startcacheflush() {     this.cacheflushlock.lock();     return obtainseqnum();  } where, obtainseqnum() is simply: private long obtainseqnum() {     return this.logseqnum.incrementandget();   } so let's say a memstore contains edits with sequence number 1..10. meanwhile, say more puts come along, and are going through this flow (in pseudo-code) 1. hlog.append();        1.1  obtainseqnum()        1.2 writetowal() 2 updatememstore() so it is possible that the sequence number has already been incremented to say 15 if there are 5 more outstanding puts. say the writetowal() is still in progress for these puts. in this case, none of these edits (11..15) would have been written to memstore yet. at this point if a cache flush of the memstore happens, then we'll record its max_seq_id as 16 in the store file instead of 10 (because that's what obtainseqnum() would return as the next sequence number to use, right?). assume that the edits 11..15 eventually complete. and so hlogs do contain the data for edits 11..15. now, at this point if the region server were to crash, and we run log recovery, the splits all go through correctly, and a correct recovered.edits file is generated with the edits 11..15. next, when the region is opened, the hregion notes that one of the store file says max_seq_id is 16. so, when it replays the recovered.edits file, it skips replaying edits 11..15. or in other words, data loss. ",
        "label": 547
    },
    {
        "text": "regionserver confused about empty row keys  i'm no longer sure about the expected behavior when using an empty row key (e.g. a 0-byte long byte array). i assumed that this was a legitimate row key, just like having an empty column qualifier is allowed. but it seems that the regionserver considers the empty row key to be whatever the first row key is. version: 0.89.20100830, r0da2890b242584a8a5648d83532742ca7243346b, sat sep 18 15:30:09 pdt 2010 hbase(main):001:0> scan 'tsdb-uid', {limit => 1} row                           column+cell                                                                            \\x00                         column=id:metrics, timestamp=1288375187699, value=foo        \\x00                         column=id:tagk, timestamp=1287522021046, value=bar           \\x00                         column=id:tagv, timestamp=1288111387685, value=qux       1 row(s) in 0.4610 seconds hbase(main):002:0> get 'tsdb-uid', '' column                        cell                                                                                   id:metrics                   timestamp=1288375187699, value=foo                           id:tagk                      timestamp=1287522021046, value=bar                           id:tagv                      timestamp=1288111387685, value=qux                       3 row(s) in 0.0910 seconds hbase(main):003:0> get 'tsdb-uid', \"\\000\" column                        cell                                                                                   id:metrics                   timestamp=1288375187699, value=foo                           id:tagk                      timestamp=1287522021046, value=bar                           id:tagv                      timestamp=1288111387685, value=qux                       3 row(s) in 0.0550 seconds this isn't a parsing problem with the command-line of the shell. i can reproduce this behavior both with plain java code and with my asynchbase client. since i don't actually have a row with an empty row key, i expected that the first get would return nothing. ",
        "label": 139
    },
    {
        "text": "coprocessors  client side support  \"high-level call interface for clients. unlike rpc, calls addressed to rows or ranges of rows. coprocessor client library resolves to actual locations. calls across multiple rows automatically split into multiple parallelized rpcs\" generic multicall rpc facility which incorporates this and multiget/multiput/multidelete and parallel scanners. group and batch rpcs by region server. track and retry outstanding rpcs. ride over region relocations. support addressing by explicit region identifier or by row key or row key range. include a facility for merging results client side. ",
        "label": 180
    },
    {
        "text": "write up fixversion policy from dev discussion in refguide  useful discussion up on dev list \"fix version maintenance for 1.4.0\" where we state fixversion in jira policy we all seem to be following but have never written down anywhere. this issue is about synopsizing what came of the discussion in the refguide dev/rm section. ",
        "label": 334
    },
    {
        "text": "unload script displays wrong counts  off by one  when unloading regions  upon running an unload command, such as:  hbase org.jruby.main /usr/lib/hbase/bin/region_mover.rb unload `hostname`, the region counter is indexed at 0 and hence, when the regions are being moved, regions are being counted from 0 instead of 1. ",
        "label": 423
    },
    {
        "text": "enable rolling averages in stochasticloadbalancer  now that all of the serverload transitions into pb are done. the load balancer should get more updates about the current state of the cluster. this should be used to allow stochasticloadbalancer to get rolling averages. ",
        "label": 154
    },
    {
        "text": "expose catalogjanitor controls  when doing surgery or other operational tasks, it's nice to be able to have the .meta. table quickly cleaned of split parents. the catalogjanitor already has controls baked in (currently used in unit tests), i think we should expose this the same way we do with the balancer, that is: start stop request a run a client would need to go through hbaseadmin, and shell commands need to be created. ",
        "label": 139
    },
    {
        "text": "some more api cleanup for  parent jira to keep track of some more api cleanup that did not happen in 1.x timeframe. ",
        "label": 155
    },
    {
        "text": "co locate meta and master  i was thinking simplifying/improving the region assignments. the first step is to co-locate the meta and the master as many people agreed on hbase-5487. ",
        "label": 242
    },
    {
        "text": "use nextgen hadoop to deploy hbase  currently (circa 2011), with due respect, it's not practical to run shared, multi-tenant hbase clusters on the largest hadoop installs (of 4000+ nodes). as an interim, i'd like to brainstorm using nextgen hadoop (mapreduce-279) to deploy hbase for focussed sets of applications/users/organizations. thus, one could deploy a smaller instance of hbase (100s of nodes) in a large hadoop cluster and use it for a set of applications. the other advantage is that the resource usage of hbase (master, region-server etc.) is accounted for in the overall utilization of the cluster and, conceivably, aid in resource tracking, capacity planning etc. thoughts? ",
        "label": 139
    },
    {
        "text": "testhlogsplit testlogrollaftersplitstart not working due to hbase  java.lang.illegalstateexception: can't overwrite cause  at java.lang.throwable.initcause(throwable.java:320)  at org.apache.hadoop.hbase.regionserver.wal.hlog.createwriter(hlog.java:624)  at org.apache.hadoop.hbase.regionserver.wal.hlog.createwriterinstance(hlog.java:570)  at org.apache.hadoop.hbase.regionserver.wal.hlog.rollwriter(hlog.java:504)  at org.apache.hadoop.hbase.regionserver.wal.testhlogsplit.testlogrollaftersplitstart(testhlogsplit.java:880) ",
        "label": 242
    },
    {
        "text": "the newly split testreplicationstatus  tests are flaky  they are introduced by hbase-22455, from the original testreplicationstatus tests. need to dig more. ",
        "label": 149
    },
    {
        "text": "deprecated admin deletesnapshot byte   we should use string as snapshotname. all other related methods has been marked as deprecated in 2.2.0+ and removed in 3.0.0. we should do the same for this method. ",
        "label": 257
    },
    {
        "text": "zksplitlogworkercoordination doesn't allow a regionserver to pick up all of the split work it is capable of  a region hosted by a crashed regionserver cannot be reassigned until the crashed regionserver's write-ahead logs have been processed and split into per-region recovered edits files. reassignment of a region from a crashed server will be held up by the distributed split work backlog. every regionserver runs a background daemon thread that manages the acquisition and execution of distributed log split tasks. this thread registers a watcher on a znode managed by the master. when the master is processing a server shutdown or crash or cluster restart when it detects the presence of unprocessed wal files it will register the wal files for processing under the znode. one or more live regionservers will attempt to get an exclusive lock on an entry. one of them wins, splits the wal file, deletes the entry, then will acquire more work or go back to sleep if the worklist is empty. a regionserver can acquire at most a fixed number of log split tasks determined by configuration, hbase.regionserver.wal.max.splitters (default 2). if the number of entries/logs to process exceeds the number of available split workers in the cluster, perhaps due to the correlated failure of a significant subset of the fleet, then splitting work will fall behind. regions may remain in rit until the backlog is cleared. however, the regionserver side coordination logic - zksplitlogworkercoordination - only allows a regionserver to grab one task one at a time. nearby javadoc says \"this policy puts an upper-limit on the number of simultaneous log splitting that could be happening in a cluster.\" that upper limit will be the number of currently live regionservers. i don't feel i understand exactly why this is necessary or appropriate because a regionserver can handle more than one task at once and in fact the max number of concurrent split tasks it can accept is configurable.   /**    * this function calculates how many splitters it could create based on expected average tasks per    * rs and the hard limit upper bound(maxconcurrenttasks) set by configuration. <br>    * at any given time, a rs allows spawn min(expected tasks/rs, hard upper bound)    * @param numtasks current total number of available tasks    */   private int calculateavailablesplitters(int numtasks) {     // at lease one rs(itself) available     int availablerss = 1;     try {       list<string> regionservers =           zkutil.listchildrennowatch(watcher, watcher.rsznode);       availablerss = math.max(availablerss, (regionservers == null) ? 0 : regionservers.size());     } catch (keeperexception e) {       // do nothing       log.debug(\"getavailableregionservers got zookeeper exception\", e);     }     int expectedtasksperrs = (numtasks / availablerss) + ((numtasks % availablerss == 0) ? 0 : 1);     expectedtasksperrs = math.max(1, expectedtasksperrs); // at least be one     // calculate how many more splitters we could spawn     return math.min(expectedtasksperrs, maxconcurrenttasks)         - this.tasksinprogress.get();    shouldn't this simply be:   private int calculateavailablesplitters() {     return maxconcurrenttasks - tasksinprogress.get();   } ? this is branch-1. ",
        "label": 38
    },
    {
        "text": "getting started for standalone still references hadoop version specific binary artifacts  as of hbase 1.0 we no longer have binary artifacts that are tied to a particular hadoop release. the current section of the ref guide for getting started with standalone mode still refers to them: choose a download site from this list of apache download mirrors. click on the suggested top link. this will take you to a mirror of hbase releases. click on the folder named stable and then download the binary file that ends in .tar.gz to your local filesystem. be sure to choose the version that corresponds with the version of hadoop you are likely to use later. in most cases, you should choose the file for hadoop 2, which will be called something like hbase-0.98.3-hadoop2-bin.tar.gz. do not download the file ending in src.tar.gz for now. either remove the reference or turn it into a note call-out for versions 0.98 and earlier. ",
        "label": 177
    },
    {
        "text": "counter class should always be added as dependencyjar  this is an ergonomic thing. tablemapreduceutil.inittablesnapshotmapjob adds high-scale-lib.jar to the \"tmpjars\" for the job but tablemapreduceutil.adddependencyjars does not include it. this means that hbase mapredcp doesn't pick it up. we should include this jar so that it's picked up by mapredcp. branch-1 and onward has done away with our dependency on high-scale-lib, so this only applies to 0.98. ",
        "label": 339
    },
    {
        "text": "region server dynamic metrics can cause high cpu usage   when regions are getting added and removed lots of cpu time can be used by jmx. this is caused by sending jmx messages for every new metric that is added or removed. seeing jstacks like this: \"rmi tcp connection(3)-10.4.19.33\" daemon prio=10 tid=0x00007f9d64b1d000 nid=0x353 runnable [0x00007f9d598d6000]  java.lang.thread.state: runnable  at java.util.hashmap.put(hashmap.java:374)  at org.apache.hadoop.metrics.util.metricsdynamicmbeanbase.creatembeaninfo(metricsdynamicmbeanbase.java:103)  at org.apache.hadoop.metrics.util.metricsdynamicmbeanbase.updatembeaninfoifmetricslistchanged(metricsdynamicmbeanbase.java:75)  at org.apache.hadoop.metrics.util.metricsdynamicmbeanbase.getattribute(metricsdynamicmbeanbase.java:133)  at com.sun.jmx.interceptor.defaultmbeanserverinterceptor.getattribute(defaultmbeanserverinterceptor.java:666)  at com.sun.jmx.mbeanserver.jmxmbeanserver.getattribute(jmxmbeanserver.java:638)  at javax.management.remote.rmi.rmiconnectionimpl.dooperation(rmiconnectionimpl.java:1404)  \u2013  at java.util.timerthread.run(timer.java:462) \"timer thread for monitoring hbase\" daemon prio=10 tid=0x00007f9d648fe000 nid=0x2b5 runnable [0x00007f9d624c7000]  java.lang.thread.state: runnable  at java.util.hashmap.put(hashmap.java:374)  at org.apache.hadoop.metrics.util.metricsdynamicmbeanbase.creatembeaninfo(metricsdynamicmbeanbase.java:103)  at org.apache.hadoop.metrics.util.metricsdynamicmbeanbase.updatembeaninfoifmetricslistchanged(metricsdynamicmbeanbase.java:75)  at sun.reflect.generatedmethodaccessor29.invoke(unknown source)  at sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:25)  at java.lang.reflect.method.invoke(method.java:597)  at org.apache.hadoop.hbase.regionserver.metrics.regionserverdynamicmetrics.setnumericmetric(regionserverdynamicmetrics.java:105) ",
        "label": 154
    },
    {
        "text": "upgrade to latest error prone  there's some trouble with lambda expressions in our current version as reported in https://github.com/google/error-prone/issues/768 also, error-prone 2.1.x has a bunch of nice upgrades that would be good to get. https://groups.google.com/forum/#!topic/error-prone-announce/ixllhsi_n5u ",
        "label": 320
    },
    {
        "text": "undo workarounds in integrationtestddlmasterfailover for client double submit  now that nonce support for dealing with double-submits from client in hbase-13415 is committed, we should undo the workarounds done in hbase-13470 for this part. we needed these workarounds for 1.1.1, but we should not do that anymore for proper testing for 1.2+. stephen yuan jiang, sophia feng, matteo bertozzi fyi. ",
        "label": 426
    },
    {
        "text": "fix flaky testsimplerpcscheduler  there were several flaky tests added there as part of hbase-15306 and likely hbase-15136. ",
        "label": 149
    },
    {
        "text": "aggregationclient fails validation for open stoprow scan  aggregationclient.validateparameters throws an exception when the scan has a valid startrow but an unset endrow. ",
        "label": 333
    },
    {
        "text": "clean up coprocessor loading failure handling  when registering a coprocessor with a missing dependency, the regionserver gets stuck in an infinite fail loop. restarting the regionserver and/or master has no affect. e.g., load coprocessor from my-coproc.jar, that uses an external dependency (kafka) that is not included with hbase. 12/09/24 13:13:15 info handler.openregionhandler: opening of region {name => 'documents,,1348505987177.6d1e1b7bb93486f096173bd401e8ef6b.', startkey => '', endkey => '', encoded => 6d1e1b7bb93486f096173bd401e8ef6b,} failed, marking as failed_open in zk 12/09/24 13:13:15 debug zookeeper.zkassign: regionserver:60020-0x139f43af2a70043 attempting to transition node 6d1e1b7bb93486f096173bd401e8ef6b from rs_zk_region_opening to rs_zk_region_failed_open 12/09/24 13:13:15 debug zookeeper.zkassign: regionserver:60020-0x139f43af2a70043 successfully transitioned node 6d1e1b7bb93486f096173bd401e8ef6b from rs_zk_region_opening to rs_zk_region_failed_open 12/09/24 13:13:15 info regionserver.hregionserver: received request to open region: documents,,1348505987177.6d1e1b7bb93486f096173bd401e8ef6b. 12/09/24 13:13:15 debug zookeeper.zkassign: regionserver:60020-0x139f43af2a70043 attempting to transition node 6d1e1b7bb93486f096173bd401e8ef6b from m_zk_region_offline to rs_zk_region_opening 12/09/24 13:13:15 debug zookeeper.zkassign: regionserver:60020-0x139f43af2a70043 successfully transitioned node 6d1e1b7bb93486f096173bd401e8ef6b from m_zk_region_offline to rs_zk_region_opening 12/09/24 13:13:15 debug regionserver.hregion: opening region: {name => 'documents,,1348505987177.6d1e1b7bb93486f096173bd401e8ef6b.', startkey => '', endkey => '', encoded => 6d1e1b7bb93486f096173bd401e8ef6b,} 12/09/24 13:13:15 info regionserver.hregion: setting up tabledescriptor config now ... 12/09/24 13:13:15 info coprocessor.coprocessorhost: class com.mycompany.hbase.documents.documentobservercoprocessor needs to be loaded from a file - file:/path/to/my-coproc.jar. 12/09/24 13:13:16 error handler.openregionhandler: failed open of region=documents,,1348505987177.6d1e1b7bb93486f096173bd401e8ef6b., starting to roll back the global memstore size. java.lang.illegalstateexception: could not instantiate a region instance. at org.apache.hadoop.hbase.regionserver.hregion.newhregion(hregion.java:3595) at org.apache.hadoop.hbase.regionserver.hregion.openhregion(hregion.java:3733) at org.apache.hadoop.hbase.regionserver.handler.openregionhandler.openregion(openregionhandler.java:332) at org.apache.hadoop.hbase.regionserver.handler.openregionhandler.process(openregionhandler.java:108) at org.apache.hadoop.hbase.executor.eventhandler.run(eventhandler.java:169) at java.util.concurrent.threadpoolexecutor$worker.runtask(threadpoolexecutor.java:886) at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:908) at java.lang.thread.run(thread.java:680) caused by: java.lang.reflect.invocationtargetexception at sun.reflect.generatedconstructoraccessor15.newinstance(unknown source) at sun.reflect.delegatingconstructoraccessorimpl.newinstance(delegatingconstructoraccessorimpl.java:27) at java.lang.reflect.constructor.newinstance(constructor.java:513) at org.apache.hadoop.hbase.regionserver.hregion.newhregion(hregion.java:3592) ... 7 more caused by: java.lang.noclassdeffounderror: kafka/common/nobrokersforpartitionexception at java.lang.class.getdeclaredconstructors0(native method) at java.lang.class.privategetdeclaredconstructors(class.java:2389) at java.lang.class.getconstructor0(class.java:2699) at java.lang.class.newinstance0(class.java:326) at java.lang.class.newinstance(class.java:308) at org.apache.hadoop.hbase.coprocessor.coprocessorhost.loadinstance(coprocessorhost.java:254) at org.apache.hadoop.hbase.coprocessor.coprocessorhost.load(coprocessorhost.java:227) at org.apache.hadoop.hbase.regionserver.regioncoprocessorhost.loadtablecoprocessors(regioncoprocessorhost.java:162) at org.apache.hadoop.hbase.regionserver.regioncoprocessorhost.<init>(regioncoprocessorhost.java:126) at org.apache.hadoop.hbase.regionserver.hregion.<init>(hregion.java:417) ... 11 more caused by: java.lang.classnotfoundexception: kafka.common.nobrokersforpartitionexception at java.net.urlclassloader$1.run(urlclassloader.java:202) at java.security.accesscontroller.doprivileged(native method) at java.net.urlclassloader.findclass(urlclassloader.java:190) at java.lang.classloader.loadclass(classloader.java:306) at java.lang.classloader.loadclass(classloader.java:247) ... 21 more 12/09/24 13:13:16 info handler.openregionhandler: opening of region {name => 'documents,,1348505987177.6d1e1b7bb93486f096173bd401e8ef6b.', startkey => '', endkey => '', encoded => 6d1e1b7bb93486f096173bd401e8ef6b,} failed, marking as failed_open in zk 12/09/24 13:13:16 debug zookeeper.zkassign: regionserver:60020-0x139f43af2a70043 attempting to transition node 6d1e1b7bb93486f096173bd401e8ef6b from rs_zk_region_opening to rs_zk_region_failed_open 12/09/24 13:13:16 debug zookeeper.zkassign: regionserver:60020-0x139f43af2a70043 successfully transitioned node 6d1e1b7bb93486f096173bd401e8ef6b from rs_zk_region_opening to rs_zk_region_failed_open 12/09/24 13:13:16 info regionserver.hregionserver: received request to open region: documents,,1348505987177.6d1e1b7bb93486f096173bd401e8ef6b. 12/09/24 13:13:16 debug zookeeper.zkassign: regionserver:60020-0x139f43af2a70043 attempting to transition node 6d1e1b7bb93486f096173bd401e8ef6b from m_zk_region_offline to rs_zk_region_opening 12/09/24 13:13:16 debug zookeeper.zkassign: regionserver:60020-0x139f43af2a70043 successfully transitioned node 6d1e1b7bb93486f096173bd401e8ef6b from m_zk_region_offline to rs_zk_region_opening 12/09/24 13:13:16 debug regionserver.hregion: opening region: {name => 'documents,,1348505987177.6d1e1b7bb93486f096173bd401e8ef6b.', startkey => '', endkey => '', encoded => 6d1e1b7bb93486f096173bd401e8ef6b,} 12/09/24 13:13:16 info regionserver.hregion: setting up tabledescriptor config now ... 12/09/24 13:13:16 info coprocessor.coprocessorhost: class com.mycompany.hbase.documents.documentobservercoprocessor needs to be loaded from a file - file:/path/to/my-coproc.jar. 12/09/24 13:13:17 error handler.openregionhandler: failed open of region=documents,,1348505987177.6d1e1b7bb93486f096173bd401e8ef6b., starting to roll back the global memstore size. java.lang.illegalstateexception: could not instantiate a region instance. at org.apache.hadoop.hbase.regionserver.hregion.newhregion(hregion.java:3595) at org.apache.hadoop.hbase.regionserver.hregion.openhregion(hregion.java:3733) at org.apache.hadoop.hbase.regionserver.handler.openregionhandler.openregion(openregionhandler.java:332) at org.apache.hadoop.hbase.regionserver.handler.openregionhandler.process(openregionhandler.java:108) at org.apache.hadoop.hbase.executor.eventhandler.run(eventhandler.java:169) at java.util.concurrent.threadpoolexecutor$worker.runtask(threadpoolexecutor.java:886) at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:908) at java.lang.thread.run(thread.java:680) caused by: java.lang.reflect.invocationtargetexception at sun.reflect.generatedconstructoraccessor15.newinstance(unknown source) at sun.reflect.delegatingconstructoraccessorimpl.newinstance(delegatingconstructoraccessorimpl.java:27) at java.lang.reflect.constructor.newinstance(constructor.java:513) at org.apache.hadoop.hbase.regionserver.hregion.newhregion(hregion.java:3592) ... 7 more caused by: java.lang.noclassdeffounderror: kafka/common/nobrokersforpartitionexception at java.lang.class.getdeclaredconstructors0(native method) at java.lang.class.privategetdeclaredconstructors(class.java:2389) at java.lang.class.getconstructor0(class.java:2699) at java.lang.class.newinstance0(class.java:326) at java.lang.class.newinstance(class.java:308) at org.apache.hadoop.hbase.coprocessor.coprocessorhost.loadinstance(coprocessorhost.java:254) at org.apache.hadoop.hbase.coprocessor.coprocessorhost.load(coprocessorhost.java:227) at org.apache.hadoop.hbase.regionserver.regioncoprocessorhost.loadtablecoprocessors(regioncoprocessorhost.java:162) at org.apache.hadoop.hbase.regionserver.regioncoprocessorhost.<init>(regioncoprocessorhost.java:126) at org.apache.hadoop.hbase.regionserver.hregion.<init>(hregion.java:417) ... 11 more caused by: java.lang.classnotfoundexception: kafka.common.nobrokersforpartitionexception at java.net.urlclassloader$1.run(urlclassloader.java:202) at java.security.accesscontroller.doprivileged(native method) at java.net.urlclassloader.findclass(urlclassloader.java:190) at java.lang.classloader.loadclass(classloader.java:306) at java.lang.classloader.loadclass(classloader.java:247) ... 21 more ad infinitum. it seems that upon failing to open a region after adding a coprocessor, that coprocessor should be unregister or at least disabled/blacklisted. ",
        "label": 38
    },
    {
        "text": "improve detection of secure zookeeper  hbase client code assumes zookeeper is secured, as long as there is a java.security.auth.login.config property being set. when hbase client is embedded in other java program with other security configuration, it can produce wrong assumption that zookeeper is secured. ideally, issecurezookeeper method should detect jaas configuration specifically for zookeeper to ensure that client program doesn't have a false positive detection. ",
        "label": 160
    },
    {
        "text": "allow test patch sh to detect treemap keyed by byte  which doesn't use proper comparator  there were two recent bug fixes (hbase-9285 and hbase-9238) for the case where the treemap keyed by byte[] doesn't use proper comparator: new treemap<byte[], ...>() test-patch.sh should be able to detect this situation and report accordingly. ",
        "label": 441
    },
    {
        "text": "document how to re run github pr checks  our peter somogyi has a trick for re-running github pr checks that is not force-push of original patch. lets get it into the refguide. ",
        "label": 314
    },
    {
        "text": "fix link to svn repository on hbase website  we currently point to http://svn.apache.org/repos/asf/hadoop/hbase on the website, when we should point to http://svn.apache.org/repos/asf/hbase (and similar). ",
        "label": 231
    },
    {
        "text": "catch zk's connectionlossexception and augment error message with more help  0.90 has a different behavior regarding zk connections, it tends to create too many of them and it's not obvious to users what they should do to fix. i think i've helped at least 5 different users this week with this error. by catching connectionlossexception and augmenting its message, we could say something like \"it's possible that the zookeeper server has too many connections from this ip, see doc at blah\" since the zk server isn't nice enough to let us know what's going on. ",
        "label": 229
    },
    {
        "text": "build fails on branch using maven  with maven 3.5.2 the build fails on branch-1-2, branch-1.3, branch-1.4 and branch-1. on branch-1.1, branch-2 and master the build succeeds. with older maven versions the build finishes. maven version $ mvn -v java hotspot(tm) 64-bit server vm warning: ignoring option permsize=1024m; support was removed in 8.0 apache maven 3.5.2 (138edd61fd100ec658bfa2d307c43b76940a5d7d; 2017-10-18t09:58:13+02:00) maven home: /users/peter.somogyi/bin/apache-maven-3.5.2 java version: 1.8.0_141, vendor: oracle corporation java home: /library/java/javavirtualmachines/jdk1.8.0_141.jdk/contents/home/jre default locale: en_us, platform encoding: utf-8 os name: \"mac os x\", version: \"10.12.6\", arch: \"x86_64\", family: \"mac\" $ mvn clean install -dskiptests ... [info] --- jamon-maven-plugin:2.4.1:translate (default) @ hbase-server --- [info]  [info] --- maven-antrun-plugin:1.6:run (generate) @ hbase-server --- [info] executing tasks main: log4j:warn no appenders could be found for logger (org.apache.jasper.jspc). log4j:warn please initialize the log4j system properly. log4j:warn see http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info. [info] logging to org.slf4j.impl.mavensimplelogger(org.mortbay.log) via org.mortbay.log.slf4jlog java.util.missingresourceexception: can't find bundle for base name org.apache.jasper.resources.localstrings, locale en_us at java.util.resourcebundle.throwmissingresourceexception(resourcebundle.java:1564) at java.util.resourcebundle.getbundleimpl(resourcebundle.java:1387) at java.util.resourcebundle.getbundle(resourcebundle.java:773) at org.apache.jasper.compiler.localizer.<clinit>(localizer.java:36) at org.apache.jasper.compiler.jspruntimecontext.<init>(jspruntimecontext.java:103) at org.apache.jasper.jspc.initservletcontext(jspc.java:1242) at org.apache.jasper.jspc.execute(jspc.java:1103) at sun.reflect.nativemethodaccessorimpl.invoke0(native method) at sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:62) at sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43) at java.lang.reflect.method.invoke(method.java:498) at org.apache.tools.ant.dispatch.dispatchutils.execute(dispatchutils.java:106) at org.apache.tools.ant.taskadapter.execute(taskadapter.java:154) at org.apache.tools.ant.unknownelement.execute(unknownelement.java:291) at sun.reflect.generatedmethodaccessor122.invoke(unknown source) at sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43) at java.lang.reflect.method.invoke(method.java:498) at org.apache.tools.ant.dispatch.dispatchutils.execute(dispatchutils.java:106) at org.apache.tools.ant.task.perform(task.java:348) at org.apache.tools.ant.target.execute(target.java:390) at org.apache.tools.ant.target.performtasks(target.java:411) at org.apache.tools.ant.project.executesortedtargets(project.java:1397) at org.apache.tools.ant.project.executetarget(project.java:1366) at org.apache.maven.plugin.antrun.antrunmojo.execute(antrunmojo.java:270) at org.apache.maven.plugin.defaultbuildpluginmanager.executemojo(defaultbuildpluginmanager.java:134) at org.apache.maven.lifecycle.internal.mojoexecutor.execute(mojoexecutor.java:208) at org.apache.maven.lifecycle.internal.mojoexecutor.execute(mojoexecutor.java:154) at org.apache.maven.lifecycle.internal.mojoexecutor.execute(mojoexecutor.java:146) at org.apache.maven.lifecycle.internal.mojoexecutor.executeforkedexecutions(mojoexecutor.java:353) at org.apache.maven.lifecycle.internal.mojoexecutor.execute(mojoexecutor.java:198) at org.apache.maven.lifecycle.internal.mojoexecutor.execute(mojoexecutor.java:154) at org.apache.maven.lifecycle.internal.mojoexecutor.execute(mojoexecutor.java:146) at org.apache.maven.lifecycle.internal.lifecyclemodulebuilder.buildproject(lifecyclemodulebuilder.java:117) at org.apache.maven.lifecycle.internal.lifecyclemodulebuilder.buildproject(lifecyclemodulebuilder.java:81) at org.apache.maven.lifecycle.internal.builder.singlethreaded.singlethreadedbuilder.build(singlethreadedbuilder.java:51) at org.apache.maven.lifecycle.internal.lifecyclestarter.execute(lifecyclestarter.java:128) at org.apache.maven.defaultmaven.doexecute(defaultmaven.java:309) at org.apache.maven.defaultmaven.doexecute(defaultmaven.java:194) at org.apache.maven.defaultmaven.execute(defaultmaven.java:107) at org.apache.maven.cli.mavencli.execute(mavencli.java:955) at org.apache.maven.cli.mavencli.domain(mavencli.java:290) at org.apache.maven.cli.mavencli.main(mavencli.java:194) at sun.reflect.nativemethodaccessorimpl.invoke0(native method) at sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:62) at sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43) at java.lang.reflect.method.invoke(method.java:498) at org.codehaus.plexus.classworlds.launcher.launcher.launchenhanced(launcher.java:289) at org.codehaus.plexus.classworlds.launcher.launcher.launch(launcher.java:229) at org.codehaus.plexus.classworlds.launcher.launcher.mainwithexitcode(launcher.java:415) at org.codehaus.plexus.classworlds.launcher.launcher.main(launcher.java:356) [info] ------------------------------------------------------------------------ [info] reactor summary: [info]  [info] apache hbase ....................................... success [  1.952 s] [info] apache hbase - checkstyle .......................... success [  0.499 s] [info] apache hbase - resource bundle ..................... success [  0.164 s] [info] apache hbase - annotations ......................... success [  0.798 s] [info] apache hbase - protocol ............................ success [  8.456 s] [info] apache hbase - common .............................. success [  4.961 s] [info] apache hbase - procedure ........................... success [  1.242 s] [info] apache hbase - metrics api ......................... success [  0.599 s] [info] apache hbase - hadoop compatibility ................ success [  0.748 s] [info] apache hbase - metrics implementation .............. success [  0.687 s] [info] apache hbase - hadoop two compatibility ............ success [  1.217 s] [info] apache hbase - client .............................. success [  3.575 s] [info] apache hbase - prefix tree ......................... success [  0.990 s] [info] apache hbase - server .............................. failure [ 16.050 s] [info] apache hbase - testing util ........................ skipped [info] apache hbase - thrift .............................. skipped [info] apache hbase - rest ................................ skipped [info] apache hbase - rsgroup ............................. skipped [info] apache hbase - shell ............................... skipped [info] apache hbase - integration tests ................... skipped [info] apache hbase - examples ............................ skipped [info] apache hbase - external block cache ................ skipped [info] apache hbase - assembly ............................ skipped [info] apache hbase - shaded .............................. skipped [info] apache hbase - shaded - client ..................... skipped [info] apache hbase - shaded - server ..................... skipped [info] apache hbase shaded packaging invariants ........... skipped [info] apache hbase - archetypes .......................... skipped [info] apache hbase - exemplar for hbase-client archetype . skipped [info] apache hbase - exemplar for hbase-shaded-client archetype skipped [info] apache hbase - archetype builder ................... skipped [info] ------------------------------------------------------------------------ [info] build failure [info] ------------------------------------------------------------------------ [info] total time: 42.875 s [info] finished at: 2017-11-06t14:00:15+01:00 [info] final memory: 123m/1802m [info] ------------------------------------------------------------------------ [error] failed to execute goal org.apache.maven.plugins:maven-antrun-plugin:1.6:run (generate) on project hbase-server: an ant buildexception has occured: java.lang.nullpointerexception -> [help 1] [error]  [error] to see the full stack trace of the errors, re-run maven with the -e switch. [error] re-run maven using the -x switch to enable full debug logging. [error]  [error] for more information about the errors and possible solutions, please read the following articles: [error] [help 1] http://cwiki.apache.org/confluence/display/maven/mojoexecutionexception [error]  [error] after correcting the problems, you can resume the build with the command [error]   mvn <goals> -rf :hbase-server ",
        "label": 352
    },
    {
        "text": "cellchunkmap benchmarking and user interface  we have made some experiments how working with cellchunkmap (ccm) influences the performance when running on-heap and off-heap. based on those results it is suggested to tie the mslab usage (off-heap or on-heap) with ccm index usage. ",
        "label": 35
    },
    {
        "text": "testinterfaceaudienceannotations should hadoop compt module resources  over on hbase-12911, buildbot tells me i'm missing some interface audience annotations. indeed, from test log, my patch is not the only one missing annotations. 2015-09-08 12:05:31,071 debug [main] hbase.classfinder(147): looking in /users/ndimiduk/repos/hbase/hbase-client/target/classes/org/apache/hadoop/hbase; isjar=false 2015-09-08 12:05:31,071 debug [main] hbase.classfinder(147): looking in /users/ndimiduk/repos/hbase/hbase-annotations/target/classes/org/apache/hadoop/hbase; isjar=false 2015-09-08 12:05:31,071 debug [main] hbase.classfinder(147): looking in /users/ndimiduk/repos/hbase/hbase-common/target/classes/org/apache/hadoop/hbase; isjar=false 2015-09-08 12:05:31,072 debug [main] hbase.classfinder(147): looking in /users/ndimiduk/repos/hbase/hbase-hadoop-compat/target/classes/org/apache/hadoop/hbase; isjar=false 2015-09-08 12:05:31,072 debug [main] hbase.classfinder(147): looking in /users/ndimiduk/repos/hbase/hbase-hadoop2-compat/target/classes/org/apache/hadoop/hbase; isjar=false 2015-09-08 12:05:31,072 debug [main] hbase.classfinder(147): looking in /users/ndimiduk/repos/hbase/hbase-protocol/target/classes/org/apache/hadoop/hbase; isjar=false 2015-09-08 12:05:31,158 info  [main] hbase.testinterfaceaudienceannotations(252): these are the classes that do not have @interfaceaudience annotation: 2015-09-08 12:05:31,158 info  [main] hbase.testinterfaceaudienceannotations(254): interface org.apache.hadoop.hbase.client.metricsregionclientwrapper 2015-09-08 12:05:31,158 info  [main] hbase.testinterfaceaudienceannotations(254): interface org.apache.hadoop.hbase.client.metricsconnectionwrapper 2015-09-08 12:05:31,160 info  [main] hbase.testinterfaceaudienceannotations(254): interface org.apache.hadoop.hbase.client.metricsconnectionsourcefactory 2015-09-08 12:05:31,160 info  [main] hbase.testinterfaceaudienceannotations(254): interface org.apache.hadoop.hbase.client.metricsconnectionhostsource 2015-09-08 12:05:31,160 info  [main] hbase.testinterfaceaudienceannotations(254): class org.apache.hadoop.hbase.replication.regionserver.metricsreplicationsourcesourceimpl 2015-09-08 12:05:31,160 info  [main] hbase.testinterfaceaudienceannotations(254): interface org.apache.hadoop.hbase.replication.regionserver.metricsreplicationsourcefactory 2015-09-08 12:05:31,160 info  [main] hbase.testinterfaceaudienceannotations(254): interface org.apache.hadoop.hbase.thrift.metricsthriftserversource 2015-09-08 12:05:31,160 info  [main] hbase.testinterfaceaudienceannotations(254): interface org.apache.hadoop.hbase.master.balancer.metricsstochasticbalancersource 2015-09-08 12:05:31,161 info  [main] hbase.testinterfaceaudienceannotations(254): interface org.apache.hadoop.hbase.regionserver.wal.metricseditsreplaysource 2015-09-08 12:05:31,161 info  [main] hbase.testinterfaceaudienceannotations(254): interface org.apache.hadoop.hbase.thrift.metricsthriftserversourcefactory 2015-09-08 12:05:31,161 info  [main] hbase.testinterfaceaudienceannotations(254): class org.apache.hadoop.hbase.replication.regionserver.metricsreplicationsinksourceimpl 2015-09-08 12:05:31,161 info  [main] hbase.testinterfaceaudienceannotations(254): interface org.apache.hadoop.hbase.client.metricsconnectionsource 2015-09-08 12:05:31,161 info  [main] hbase.testinterfaceaudienceannotations(254): interface org.apache.hadoop.hbase.regionserver.metricsregionserverwrapper 2015-09-08 12:05:31,161 info  [main] hbase.testinterfaceaudienceannotations(254): interface org.apache.hadoop.hbase.regionserver.metricsregionserversource 2015-09-08 12:05:31,161 info  [main] hbase.testinterfaceaudienceannotations(254): class org.apache.hadoop.hbase.replication.regionserver.metricsreplicationglobalsourcesource 2015-09-08 12:05:31,162 info  [main] hbase.testinterfaceaudienceannotations(254): class org.apache.hadoop.hbase.replication.regionserver.metricsreplicationsourcefactoryimpl 2015-09-08 12:05:31,162 info  [main] hbase.testinterfaceaudienceannotations(254): interface org.apache.hadoop.hbase.regionserver.metricsregionsource 2015-09-08 12:05:31,162 info  [main] hbase.testinterfaceaudienceannotations(254): interface org.apache.hadoop.hbase.master.metricsmasterwrapper 2015-09-08 12:05:31,162 info  [main] hbase.testinterfaceaudienceannotations(254): interface org.apache.hadoop.hbase.metrics.basesource 2015-09-08 12:05:31,162 info  [main] hbase.testinterfaceaudienceannotations(254): interface org.apache.hadoop.hbase.rest.metricsrestsource 2015-09-08 12:05:31,162 info  [main] hbase.testinterfaceaudienceannotations(254): interface org.apache.hadoop.hbase.replication.regionserver.metricsreplicationsource 2015-09-08 12:05:31,162 info  [main] hbase.testinterfaceaudienceannotations(254): class org.apache.hadoop.hbase.compatibilityfactory 2015-09-08 12:05:31,162 info  [main] hbase.testinterfaceaudienceannotations(254): interface org.apache.hadoop.hbase.regionserver.metricsregionaggregatesource 2015-09-08 12:05:31,163 info  [main] hbase.testinterfaceaudienceannotations(254): interface org.apache.hadoop.hbase.regionserver.metricsregionwrapper 2015-09-08 12:05:31,163 info  [main] hbase.testinterfaceaudienceannotations(254): class org.apache.hadoop.hbase.compatibilitysingletonfactory$singletonstorage 2015-09-08 12:05:31,163 info  [main] hbase.testinterfaceaudienceannotations(254): interface org.apache.hadoop.hbase.ipc.metricshbaseserverwrapper 2015-09-08 12:05:31,163 info  [main] hbase.testinterfaceaudienceannotations(254): interface org.apache.hadoop.hbase.regionserver.wal.metricswalsource 2015-09-08 12:05:31,163 info  [main] hbase.testinterfaceaudienceannotations(254): interface org.apache.hadoop.hbase.master.metricsmastersource 2015-09-08 12:05:31,163 info  [main] hbase.testinterfaceaudienceannotations(254): interface org.apache.hadoop.hbase.metrics.mbeansource 2015-09-08 12:05:31,163 info  [main] hbase.testinterfaceaudienceannotations(254): interface org.apache.hadoop.hbase.master.metricsassignmentmanagersource 2015-09-08 12:05:31,163 info  [main] hbase.testinterfaceaudienceannotations(254): interface org.apache.hadoop.hbase.ipc.metricshbaseserversource 2015-09-08 12:05:31,164 info  [main] hbase.testinterfaceaudienceannotations(254): interface org.apache.hadoop.hbase.master.metricsmasterfilesystemsource 2015-09-08 12:05:31,164 info  [main] hbase.testinterfaceaudienceannotations(254): interface org.apache.hadoop.hbase.master.balancer.metricsbalancersource 2015-09-08 12:05:31,164 info  [main] hbase.testinterfaceaudienceannotations(254): class org.apache.hadoop.hbase.compatibilitysingletonfactory 2015-09-08 12:05:31,164 info  [main] hbase.testinterfaceaudienceannotations(254): interface org.apache.hadoop.hbase.regionserver.metricsregionserversourcefactory 2015-09-08 12:05:31,164 info  [main] hbase.testinterfaceaudienceannotations(254): interface org.apache.hadoop.hbase.master.metricssnapshotsource 2015-09-08 12:05:31,164 info  [main] hbase.testinterfaceaudienceannotations(254): interface org.apache.hadoop.hbase.master.metricsmastersourcefactory 2015-09-08 12:05:31,164 info  [main] hbase.testinterfaceaudienceannotations(254): interface org.apache.hadoop.hbase.replication.regionserver.metricsreplicationsourcesource 2015-09-08 12:05:31,165 info  [main] hbase.testinterfaceaudienceannotations(254): interface org.apache.hadoop.hbase.replication.regionserver.metricsreplicationsinksource 2015-09-08 12:05:31,165 info  [main] hbase.testinterfaceaudienceannotations(254): class org.apache.hadoop.hbase.ipc.metricshbaseserversourcefactory ",
        "label": 339
    },
    {
        "text": "set state splitting  merging  merging new  splitting new properly in regionstatesnode  in current code, we did not set above states to a region node at all, but we still have statements like below to check if node have above states. else if (!regionnode.isinstate(state.closing, state.splitting)) { .... } we need to set above states in a correct place. ",
        "label": 499
    },
    {
        "text": "testreplicationsyncuptool fails because failover takes too long  new issue to keep track of this. ",
        "label": 229
    },
    {
        "text": "mark single parameter htable constructors as deprecated in and  hbase-4746 removed 2 constructors from htable for 0.94.0 but we never marked them as deprecated. it's not too late to fix it in 0.90 and 0.92 point releases. ",
        "label": 441
    },
    {
        "text": "remove hfilev1 code  hfilev1 should be removed from the regionserver because it is somewhat of a drag on development for working on the lower level read paths. it's an impediment to cleaning up the store code. v1 hfiles ceased to be written in 0.92, but the v1 reader was left in place so users could upgrade from 0.90 to 0.92. once all hfiles are compacted in 0.92, then the v1 code is no longer needed. we then decided to leave the v1 code in place in 0.94 so users could upgrade directly from 0.90 to 0.94. the code is still there in trunk but should probably be shown the door. i see a few options: 1) just delete the code and tell people to make sure they compact everything using 0.92 or 0.94  2) create a standalone script that people can run on their 0.92 or 0.94 cluster that iterates the filesystem and prints out any v1 files with a message that the user should run a major compaction  3) add functionality to 0.96.0 (first release, maybe in hbck) that proactively kills v1 files, so that we can be sure there are none when upgrading from 0.96 to 0.98  4) punt to 0.98 and probably do one of the above options in a year i would vote for #1 or #2 which will allow us to have a v1-free 0.96.0. hfilev1 has already survived 2 major release upgrades which i think many would agree is more than enough for a pre-1.0, free product. if we can remove it in 0.96.0 it will be out of the way to introduce some nice performance improvements in subsequent 0.96.x releases. ",
        "label": 441
    },
    {
        "text": " shell  add means of custom formatting output by column  see jacques suggestion toward end of this thread for how we should allow adding a custom formatter per column to use outputting column content in shell: http://search-hadoop.com/m/2wxub1fuxl11/printing+integers+in+the+hbase+shell&subj=printing+integers+in+the+hbase+shell ",
        "label": 239
    },
    {
        "text": "testscanner testfilters failing  i'm getting this on a pristine checkout of 0.20 branch: testcase: teststoprow took 8.382 sec testcase: testfilters took 5.16 sec failed expected:<98> but was:<97> junit.framework.assertionfailederror: expected:<98> but was:<97> at org.apache.hadoop.hbase.regionserver.testscanner.rowprefixfilter(testscanner.java:157) at org.apache.hadoop.hbase.regionserver.testscanner.testfilters(testscanner.java:191) testcase: testscanner took 4.7 sec testcase: testscanandsyncflush took 3.527 sec testcase: testscanandrealconcurrentflush took 2.647 sec ",
        "label": 314
    },
    {
        "text": "minihbasecluster shutdown  doesn't work if no active master  running tests over in hbase-4014 brought up this issue. if the active master in a minihbasecluster has aborted, then calling minihbasecluster.shutdown() will just hang in jvmclusterutil.shutdown(), waiting to join each of the region server threads. seems like we should explicitly stop each region server instead of just relying on an active master instance deleting the cluster status znode? ",
        "label": 180
    },
    {
        "text": "merge group admin apis into admin  the initial implementation strategy proposed for group based assignment was coprocessor based, but we went a different route. support for the group admin apis will be universal with it in core, so consider merging these apis into admin. when doing so, consider where existing apis can be overloaded to hold down the number of methods in admin. ",
        "label": 174
    },
    {
        "text": "regionscannerimpl next  is inefficient   we just came across a special scenario. for our phoenix project (sql runtime for hbase), we push a lot of work into hbase via coprocessors. one method is to wrap regionscanner in coprocessor hooks and then do processing in the hook to avoid returning a lot of data to the client unnecessarily. in this specific case this is pretty bad. since the wrapped regionscanner's next() does not \"know\" that it is called this way is still does all of this on each invocation: 1. starts a regionoperation 2. increments the request count 3. set the current read point on a thread local (because generally each call could come from a different thread) 4. finally does the next on its storescanner(s) 5. ends the regionoperation when this is done in a tight loop millions of times (as is the case for us) it starts to become significant. not sure what to do about this, really. opening this issue for discussion. one way is to extend the regionscanner with an \"internal\" next() method of sorts, so that all this overhead can be avoided. the coprocessor could call the regular next() methods once and then just call the cheaper internal version. are there better/cleaner ways? ",
        "label": 286
    },
    {
        "text": "rig our build to support our new contribs   stargate and thbase ithbase  jigger our build so it will pass targets across all in the contrib. subdirectories. will model it on hadoop parent way of calling into contrib dirs (did work on that making it work for hbase when it was a hadoop contrib). ",
        "label": 314
    },
    {
        "text": "fix possible npe in hconnectionmanager  i was running ycsb against a 0.92 branch and encountered this error message: 11/11/29 08:47:16 warn client.hconnectionmanager$hconnectionimplementation: failed all from region=usertable,user3917479014967760871,1322555655231.f78d161e5724495a9723bcd972f97f41., hostname=c0316.hal.cloudera.com, port=57020 java.util.concurrent.executionexception: java.lang.runtimeexception: java.lang.nullpointerexception         at java.util.concurrent.futuretask$sync.innerget(futuretask.java:222)         at java.util.concurrent.futuretask.get(futuretask.java:83)         at org.apache.hadoop.hbase.client.hconnectionmanager$hconnectionimplementation.processbatchcallback(hconnectionmanager.java:1501)         at org.apache.hadoop.hbase.client.hconnectionmanager$hconnectionimplementation.processbatch(hconnectionmanager.java:1353)         at org.apache.hadoop.hbase.client.htable.flushcommits(htable.java:898)         at org.apache.hadoop.hbase.client.htable.doput(htable.java:775)         at org.apache.hadoop.hbase.client.htable.put(htable.java:750)         at com.yahoo.ycsb.db.hbaseclient.update(unknown source)         at com.yahoo.ycsb.dbwrapper.update(unknown source)         at com.yahoo.ycsb.workloads.coreworkload.dotransactionupdate(unknown source)         at com.yahoo.ycsb.workloads.coreworkload.dotransaction(unknown source)         at com.yahoo.ycsb.clientthread.run(unknown source) caused by: java.lang.runtimeexception: java.lang.nullpointerexception         at org.apache.hadoop.hbase.client.hconnectionmanager$hconnectionimplementation.getregionserverwithoutretries(hconnectionmanager.java:1315)         at org.apache.hadoop.hbase.client.hconnectionmanager$hconnectionimplementation$3.call(hconnectionmanager.java:1327)         at org.apache.hadoop.hbase.client.hconnectionmanager$hconnectionimplementation$3.call(hconnectionmanager.java:1325)         at java.util.concurrent.futuretask$sync.innerrun(futuretask.java:303)         at java.util.concurrent.futuretask.run(futuretask.java:138)         at java.util.concurrent.threadpoolexecutor$worker.runtask(threadpoolexecutor.java:886)         at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:908)         at java.lang.thread.run(thread.java:619) caused by: java.lang.nullpointerexception         at org.apache.hadoop.hbase.ipc.writablerpcengine$invoker.invoke(writablerpcengine.java:158)         at $proxy4.multi(unknown source)         at org.apache.hadoop.hbase.client.hconnectionmanager$hconnectionimplementation$3$1.call(hconnectionmanager.java:1330)         at org.apache.hadoop.hbase.client.hconnectionmanager$hconnectionimplementation$3$1.call(hconnectionmanager.java:1328)         at org.apache.hadoop.hbase.client.hconnectionmanager$hconnectionimplementation.getregionserverwithoutretries(hconnectionmanager.java:1309)         ... 7 more it looks like the npe is caused by server being null in the multirespone call() method.      public multiresponse call() throws ioexception {          return getregionserverwithoutretries(              new servercallable<multiresponse>(connection, tablename, null) {                public multiresponse call() throws ioexception {                  return server.multi(multi);                }                @override                public void connect(boolean reload) throws ioexception {                  server =                    connection.gethregionconnection(loc.gethostname(), loc.getport());                }              }          ); ",
        "label": 314
    },
    {
        "text": "enable rs to query a secondary datanode in parallel  if the primary takes too long  ",
        "label": 34
    },
    {
        "text": "fshdfsutils recoverfilelease tries to rethrow interruptedexception but actually shallows it  coding error is:       try {         thread.sleep(1000);       } catch (interruptedexception ex) {         new interruptedioexception().initcause(ex);       } the exception is created but not thrown... ",
        "label": 340
    },
    {
        "text": "reflection fails to access a private nested class  hmaster crashes at org/apache/hadoop/hbase/regionserver/hregionserver.java:1044  a private static nested class can not be instantiated via reflection. code snippet     try { aborttimeouttask = class.forname(conf.get(abort_timeout_task, systemexitwhenaborttimeout.class.getname())) .assubclass(timertask.class).getdeclaredconstructor().newinstance(); } catch (exception e) { log.warn(\"initialize abort timeout task failed\", e); }     log in product environtment 2019-08-16 18:01:40,737 [warn ] hregionserver:1046 initialize abort timeout task failed  java.lang.illegalaccessexception: class org.apache.hadoop.hbase.regionserver.hregionserver can not access a member of class org.apache.hadoop.hbase.regionss  erver.hregionserver$systemexitwhenaborttimeout with modifiers \"private\"  at sun.reflect.reflection.ensurememberaccess(reflection.java:102)  at java.lang.reflect.accessibleobject.slowcheckmemberaccess(accessibleobject.java:296)  at java.lang.reflect.accessibleobject.checkaccess(accessibleobject.java:288)  at java.lang.reflect.constructor.newinstance(constructor.java:413)  at org.apache.hadoop.hbase.regionserver.hregionserver.run(hregionserver.java:1044)  at org.apache.hadoop.hbase.master.hmaster.run(hmaster.java:598) ",
        "label": 545
    },
    {
        "text": "deprecate htable istableenabled  methods in favor of hbaseadmin methods  the static methods on htable.istableenabled() can lead to unintended consequences if used naively without understanding potential side-effects. suggest deprecating these methods and pointing at the hbaseadmin methods to accomplish same task instead. ",
        "label": 128
    },
    {
        "text": "scan get put delete etc setters should consistently return this  while addressing review comments on hbase-10818, i noticed that our scan class is inconsistent with it's setter methods. some of them return this, other's don't. they should be consistent. i suggest making them all return this, to support chained invocation. ",
        "label": 155
    },
    {
        "text": "splitlogmanger async delete node hangs log splitting when zk connection is lost  1. one rs died, the servershutdownhandler found it out and started the distributed log splitting;  2. all tasks are failed due to zk connection lost, so the all the tasks were deleted asynchronously;  3. servershutdownhandler retried the log splitting;  4. the asynchronously deletion in step 2 finally happened for new task  5. this made the splitlogmanger in hanging state. this leads to .meta. region not assigened for long time hbase-root-master-host-192-168-47-204.log.2012-03-14\"(55413,79):2012-03-14 19:28:47,932 debug org.apache.hadoop.hbase.master.splitlogmanager: put up splitlog task at znode /hbase/splitlog/hdfs%3a%2f%2f192.168.47.205%3a9000%2fhbase%2f.logs%2flinux-114.site%2c60020%2c1331720381665-splitting%2flinux-114.site%252c60020%252c1331720381665.1331752316170 hbase-root-master-host-192-168-47-204.log.2012-03-14\"(89303,79):2012-03-14 19:34:32,387 debug org.apache.hadoop.hbase.master.splitlogmanager: put up splitlog task at znode /hbase/splitlog/hdfs%3a%2f%2f192.168.47.205%3a9000%2fhbase%2f.logs%2flinux-114.site%2c60020%2c1331720381665-splitting%2flinux-114.site%252c60020%252c1331720381665.1331752316170 hbase-root-master-host-192-168-47-204.log.2012-03-14\"(80417,99):2012-03-14 19:34:31,196 debug org.apache.hadoop.hbase.master.splitlogmanager$deleteasynccallback: deleted /hbase/splitlog/hdfs%3a%2f%2f192.168.47.205%3a9000%2fhbase%2f.logs%2flinux-114.site%2c60020%2c1331720381665-splitting%2flinux-114.site%252c60020%252c1331720381665.1331752316170 hbase-root-master-host-192-168-47-204.log.2012-03-14\"(89456,99):2012-03-14 19:34:32,497 debug org.apache.hadoop.hbase.master.splitlogmanager$deleteasynccallback: deleted /hbase/splitlog/hdfs%3a%2f%2f192.168.47.205%3a9000%2fhbase%2f.logs%2flinux-114.site%2c60020%2c1331720381665-splitting%2flinux-114.site%252c60020%252c1331720381665.1331752316170 ",
        "label": 356
    },
    {
        "text": "hbase metrics filecontext not working  figure why it ain't writing to file though it does to ganglia. ",
        "label": 314
    },
    {
        "text": "separate the old wals into different regionserver directories  currently all old wals of regionservers are achieved into the single directory of oldwals. in big clusters, because of long ttl of wal or disabled replications, the number of files under oldwals may reach the max-directory-items limit of hdfs, which will make the hbase cluster crashed. caused by: org.apache.hadoop.ipc.remoteexception(org.apache.hadoop.hdfs.protocol.fslimitexception$maxdirectoryitemsexceededexception): the directory item limit of /hbase/lgprc-xiaomi/.oldlogs is exceeded: limit=1048576 items=1048576 a simple solution is to separate the old wals into different directories according to the server name of the wal. suggestions are welcomed~ thanks ",
        "label": 187
    },
    {
        "text": "use hstore instead of store in our own code base and remove unnecessary methods in store interface  ",
        "label": 149
    },
    {
        "text": "long running scans lose benefit of bloomfilters and timerange hints  when you have a long running scan due to say an mr job, you can lose the benefit of timerange hints & bloom filters midway if your scanner gets reset. [note: the scanners can get reset say due to a flush or compaction]. in one of our workloads, we periodically want to do rollups on recent 15 minutes of data in a column family... but the timerange hint benefit is lost midway when this resetscannerstack (shown below) happens. and end result-- we end up reading all the old hfiles rather than just the recent hfiles.  private void resetscannerstack(keyvalue lasttopkey) throws ioexception {     if (heap != null) {       throw new runtimeexception(\"storescanner.reseek run on an existing heap!\");     }     /* when we have the scan object, should we not pass it to getscanners()      * to get a limited set of scanners? we did so in the constructor and we      * could have done it now by storing the scan object from the constructor */     list<keyvaluescanner> scanners = getscanners(); the comment in the code seems to be aware of this issue and even has the suggested fix! ",
        "label": 34
    },
    {
        "text": "shell command list shows something not meaningful  here is a sample output: hbase(main):004:0> list table                                                                                                                                                                                                                usertable                                                                                                                                                                                                            1 row(s) in 0.3240 seconds => #<#<class:0x2026c088>:0x5eb8f6d> ",
        "label": 248
    },
    {
        "text": "implement fuzzyrowfilter with ranges support  apart from current ability to specify fuzzy row filter e.g. for <userid_actionid> format as ????_0004 (where 0004 - actionid) it would be great to also have ability to specify the \"fuzzy range\" , e.g. ????_0004, ..., ????_0099. see initial discussion here: http://search-hadoop.com/m/wvljdx0z65 note: currently it is possible to provide multiple fuzzy row rules to existing fuzzyrowfilter, but in case when the range is big (contains thousands of values) it is not efficient. filter should perform efficient fast-forwarding during the scan (this is what distinguishes it from regex row filter). while such functionality may seem like a proper fit for custom filter (i.e. not including into standard filter set) it looks like the filter may be very re-useable. we may judge based on the implementation that will hopefully be added. ",
        "label": 18
    },
    {
        "text": "release hbase beta  the  finish line  release  apis done, but external facing and coprocessors. done w/ features. bug fixes only from here on out. there'll be a beta-2 but that is about rolling upgrade and bug fixes only. then our first 2.0.0 release candidate. ",
        "label": 314
    },
    {
        "text": "add snapshot information to hbase master webui  similarly to how tables are listed in the web interface, snapshots should be listed as well. ",
        "label": 309
    },
    {
        "text": "update hbase trunk to use released hadoop  hbase-839 put trunk on 0.19.0rc0. this issue is about updating to the released version of 0.19.0. ",
        "label": 314
    },
    {
        "text": "treat java net sockettimeoutexception same as connectexception assigning unassigning regions   i saw java.net.sockettimeoutexception on my cluster this evening. ",
        "label": 314
    },
    {
        "text": "cme in hstore notifychangedreadersobservers  running latest trunk plus jimk's patch for hbase-543: 2008-12-21 12:47:31,741 debug org.apache.hadoop.hbase.regionserver.hstorescanner  : added a storefilescanner to outstanding hstorescanner  2008-12-21 12:47:31,741 fatal org.apache.hadoop.hbase.regionserver.memcacheflusher: replay of hlog required. forcing server shutdown  org.apache.hadoop.hbase.droppedsnapshotexception: region: urls,http|playvideogame.net|,1229725620550  at org.apache.hadoop.hbase.regionserver.hregion.internalflushcache(hregion.java:880)  at org.apache.hadoop.hbase.regionserver.hregion.flushcache(hregion.java:773)  at org.apache.hadoop.hbase.regionserver.memcacheflusher.flushregion(memcacheflusher.java:228)  at org.apache.hadoop.hbase.regionserver.memcacheflusher.flushsomeregions(memcacheflusher.java:292)  at org.apache.hadoop.hbase.regionserver.memcacheflusher.reclaimmemcachememory(memcacheflusher.java:262)  at org.apache.hadoop.hbase.regionserver.hregionserver.batchupdates(hregionserver.java:1594)  at sun.reflect.generatedmethodaccessor12.invoke(unknown source)  at sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:25)  at java.lang.reflect.method.invoke(method.java:597)  at org.apache.hadoop.hbase.ipc.hbaserpc$server.call(hbaserpc.java:632)  at org.apache.hadoop.hbase.ipc.hbaseserver$handler.run(hbaseserver.java:894)  caused by: java.util.concurrentmodificationexception  at java.util.hashmap$hashiterator.nextentry(hashmap.java:793)  at java.util.hashmap$keyiterator.next(hashmap.java:828)  at org.apache.hadoop.hbase.regionserver.hstore.notifychangedreadersobservers(hstore.java:736)  at org.apache.hadoop.hbase.regionserver.hstore.updatereaders(hstore.java:724)  at org.apache.hadoop.hbase.regionserver.hstore.internalflushcache(hstore.java:693)  at org.apache.hadoop.hbase.regionserver.hstore.flushcache(hstore.java:629)  at org.apache.hadoop.hbase.regionserver.hregion.internalflushcache(hregion.java:865)  ... 10 more ",
        "label": 314
    },
    {
        "text": "testdistributedlogsplitting testthreersabort fails against hadoop  from https://builds.apache.org/job/hbase-trunk-on-hadoop-2.0.0/364/testreport/org.apache.hadoop.hbase.master/testdistributedlogsplitting/testthreersabort/ : 2013-01-21 11:49:34,276 debug [master_server_operations-juno.apache.org,57966,1358768818594-0] client.hconnectionmanager$hconnectionimplementation(956): looked up root region location, connection=hconnection 0x12f19fe; servername=juno.apache.org,55531,1358768819479 2013-01-21 11:49:34,278 info  [master_server_operations-juno.apache.org,57966,1358768818594-0] catalog.catalogtracker(576): failed verification of .meta.,,1 at address=juno.apache.org,57582,1358768819456; org.apache.hadoop.hbase.ipc.hbaseclient$failedserverexception: this server is in the failed servers list: juno.apache.org/67.195.138.61:57582 ",
        "label": 248
    },
    {
        "text": "allow secure zookeeper jaas configuration to be programmatically set  rather than only by reading jaas configuration file   in the currently proposed fix for hbase-2418, there must be a jaas file specified in system.setproperty(\"java.security.auth.login.config\"). however, it might be preferable to construct a jaas configuration programmatically, as is done with secure hadoop (see https://github.com/apache/hadoop-common/blob/a48eceb62c9b5c1a5d71ee2945d9eea2ed62527b/src/java/org/apache/hadoop/security/usergroupinformation.java#l175). this would have the benefit of avoiding a usage of a system property setting, and allow instead an hbase-local configuration setting. ",
        "label": 309
    },
    {
        "text": "nmapinputformat should use a different config param for number of maps  annoyingly, the mr local runner drops the mapred.map.tasks parameter before running a job. should use a different config parameter so we can specify it. ",
        "label": 453
    },
    {
        "text": "make procedure retry interval configurable in test  i think the problem is related to hbase-22193, where we add exponential backoff when failing to open a region. saw this in the output 2019-04-29 20:43:09,624 warn  [peworker-24] assignment.transitregionstateprocedure(351): failed transition, suspend 129secs pid=15, state=runnable:region_state_transition_get_assign_candidate, haslock=true;  and the wait time is 180 seconds, so we time out... maybe we should introduce a max wait time config, and set it to a small value in this test... ",
        "label": 149
    },
    {
        "text": "document date tiered compaction in the book  we have two new compaction algorithms fifo and date tiered that are for time series data. we should document how to use them in the book. ",
        "label": 108
    },
    {
        "text": "unify synchronous and asynchronous methods in admin and cleanup  admin has a bunch of methods, some are asnyc, some are sync. needs some unification in method naming, and method signatures. we use modify and alter interchangeably. pick one and stick with it (modifytable(), versus getalterstatus()). shell uses alter. remove getalterstatus(), should not be needed. remove already deprecated methods istableavailable(tablename tablename, byte[][] splitkeys) should be removed. consistently use aysnc as a prefix for all async methods. other ideas? ",
        "label": 60
    },
    {
        "text": "filtering by singlecolumnvaluefilter bug  see up in hbase-user mailing list under title 'filtering by singlecolumnvaluefilter'. adrian describes roughly how he fixed the issue (and what he wanted the filter to do). ",
        "label": 247
    },
    {
        "text": "display total uncompressed byte size of a region in web ui  the decision to split data blocks when flushing and compacting is made based on the uncompressed data size which can often lead to compressed disk blocks that are a fraction of the intended 64 kb (default). this often leads to a larger number of blocks and index entries than expected and can cause block indexes to take up gb of memory. there is already a \"long totaluncompressedbytes\" written to the hfiletrailer. it would be nice to expose this in the web ui to make it easier to calculate the compression ratio and then raise the block size appropriately (not necessarily to get it back to 64k). this should probably be added wherever the other hfile metrics are: regionload.createregions(..), and hserverload. hserverload is a writable, so it may break serialization. ",
        "label": 441
    },
    {
        "text": "update jruby to  jruby's 9.1.14.0 release is described as \"things generally work in jdk9\" https://twitter.com/headius/status/928405094407827457 ",
        "label": 352
    },
    {
        "text": "add a tool to dump procedure info in the wal file  ",
        "label": 149
    },
    {
        "text": "review  document  and fix up regions in transition timeout logic  in some of the testing stack and i have been doing, we've uncovered some issues with concurrent rs failure and when the master is under heavy load. it's led to situations where we handle zk events far after they actually occur and have uncovered some issues in our timeout logic. this jira is about reviewing the timeout semantics, especially around zk usage, and ensuring that we handle things appropriately. ",
        "label": 247
    },
    {
        "text": "remove sorted  methods from result now that gets are scans  with the old get codepath, we used to sometimes get results sent to the client that weren't fully sorted. now that gets are scans, results should always be sorted. confirm that we always get back sorted results and if so drop the result.sorted() method and update javadoc accordingly. ",
        "label": 547
    },
    {
        "text": "new regions should always be added with state closed  we shouldn't add regions with state null. in case of failures and recovery, it's not possible to determine what did it mean and things become uncertain.  all operations should add regions in a well defined state.  for now, we'll set the default to closed, since whatever ops are adding new regions, they would anyways be enabling them explicitly if needed.  fyi: michael stack ",
        "label": 48
    },
    {
        "text": "import generates huge log file while importing large amounts of data  import mapper has system.out.println statements for each key value if there is filter associated with the import. this is generating huge log file while importing large amounts of data. these statements must be changed to trace and log4j must be used for logging. ",
        "label": 464
    },
    {
        "text": "testtablelockmanager testreapalltablelocks is flakey  it comes from email list which michael stack post. this is the some relates qa information. https://builds.apache.org/view/h-l/view/hbase/job/hbase-trunk_matrix/512/jdk=latest1.8,label=hadoop/testreport/org.apache.hadoop.hbase.master/testtablelockmanager/testreapalltablelocks/ the reason is here.     writelocksobtained.await();     writelocksattempted.await(); writelocksattempted maybe count down to 0 before created node on zk, and main thread will go on to run lockmanager.reapwritelocks(), and after that node was created on zk, so relates lock acquire will timeout. i upload a patch which can reproduce this issue. ",
        "label": 198
    },
    {
        "text": "dependentcolumnfilter tostring  throws nullpointerexception  dependentcolumnfilter.tostring() accesses comparator which can be null. ",
        "label": 425
    },
    {
        "text": "use visitor pattern in metaregion to reduce code clones in htable and hconnectionmanager  htable and hconnectionmanager.tableservers both scan the meta region in the same way (but the later also retry one time if it fails). a visitor pattern should be used in a new scanning method in metaregion to accept visitors that gather information such as region names for a table or the list of all tables. ",
        "label": 229
    },
    {
        "text": "cluster confused about where  root  is  each node in cluster is doing below: 2009-01-11 20:52:22,739 [regionserver/0:0:0:0:0:0:0:0:60020.compactor] debug org.apache.hadoop.hbase.client.hconnectionmanager$tableservers: attempt 0 of 10 failed with <org.apache.hadoop.hbase.notservingregionexception: org.apache.hadoop.hbase.notservingregionexception: -root-,,0         at org.apache.hadoop.hbase.regionserver.hregionserver.getregion(hregionserver.java:2064)         at org.apache.hadoop.hbase.regionserver.hregionserver.getclosestrowbefore(hregionserver.java:1545)         at sun.reflect.generatedmethodaccessor17.invoke(unknown source)         at sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:25)         at java.lang.reflect.method.invoke(method.java:597)         at org.apache.hadoop.hbase.ipc.hbaserpc$server.call(hbaserpc.java:632)         at org.apache.hadoop.hbase.ipc.hbaseserver$handler.run(hbaseserver.java:894) >. retrying after sleep of 20002009-01-11 20:52:22,742 [regionserver/0:0:0:0:0:0:0:0:60020.compactor] debug org.apache.hadoop.hbase.client.hconnectionmanager$tableservers: found root region => {name => '-root-,,0', startkey => '', endkey => '', encoded => 70236052, table => {{name => '-root-', is_root => 'true', is_meta => 'true', families => [{name => 'info', bloomfilter => 'false', compression => 'none', versions => '10', length => '2147483647', ttl => '-1', in_memory => 'false', blockcache => 'true'}], indexes => []}}2009-01-11 20:52:24,759 [regionserver/0:0:0:0:0:0:0:0:60020.compactor] debug org.apache.hadoop.hbase.client.hconnectionmanager$tableservers: attempt 1 of 10 failed with <org.apache.hadoop.hbase.notservingregionexception: org.apache.hadoop.hbase.notservingregionexception: -root-,,0         at org.apache.hadoop.hbase.regionserver.hregionserver.getregion(hregionserver.java:2064)         at org.apache.hadoop.hbase.regionserver.hregionserver.getclosestrowbefore(hregionserver.java:1545)         at sun.reflect.generatedmethodaccessor17.invoke(unknown source)         at sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:25)         at java.lang.reflect.method.invoke(method.java:597)         at org.apache.hadoop.hbase.ipc.hbaserpc$server.call(hbaserpc.java:632)         at org.apache.hadoop.hbase.ipc.hbaseserver$handler.run(hbaseserver.java:894) i tried to close the root region and tripped over hbase-1120. so i killed the regionserver hosting root but weirdly had no effect as though the regionservers' internal cache of root location cannot be changed. ",
        "label": 241
    },
    {
        "text": "add a meta refresh tag to the web ui for master and region server  the hadoop job tracker includes an automatic page refresh in its web interface in the html header: <meta http-equiv=\"refresh\" content=\"30\"> it would be useful (and trivial) to add the same to the master and region server main pages. ",
        "label": 229
    },
    {
        "text": "fixing the testheapsizes   accounting for the extra references added. did an absolute count of non static variables and updated accordingly. ",
        "label": 302
    },
    {
        "text": "client should cache region locations in an lru structure  instead of keeping the region locations cached client side in a treemap, we should use an lru mechanism to help manage memory more dynamically. ",
        "label": 86
    },
    {
        "text": "hbase client doesn't handle master failover  a client on our beta tier was stuck in this exception loop when we issued a new hmaster after the old one died: exception while trying to connect hbase  java.lang.reflect.undeclaredthrowableexception  at $proxy1.getclusterstatus(unknown source)  at org.apache.hadoop.hbase.client.hbaseadmin.getclusterstatus(hbaseadmin.java:912)  at org.apache.hadoop.hbase.client.htable.getcurrentnrhrs(htable.java:170)  at org.apache.hadoop.hbase.client.htable.<init>(htable.java:143)  ...  at org.apache.thrift.server.tthreadpoolserver$workerprocess.run(tthreadpoolserver.java:253)  at java.util.concurrent.threadpoolexecutor$worker.runtask(threadpoolexecutor.java:885)  at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:907)  at java.lang.thread.run(thread.java:619)  caused by: java.net.sockettimeoutexception: 20000 millis timeout while waiting for channel to be ready for connect. ch : java.nio.channels.socketchannel[connection-pending remote=/10.18.34.212:60000]  at org.apache.hadoop.net.socketiowithtimeout.connect(socketiowithtimeout.java:213)  at org.apache.hadoop.net.netutils.connect(netutils.java:406)  at org.apache.hadoop.hbase.ipc.hbaseclient$connection.setupiostreams(hbaseclient.java:309)  at org.apache.hadoop.hbase.ipc.hbaseclient.getconnection(hbaseclient.java:856)  at org.apache.hadoop.hbase.ipc.hbaseclient.call(hbaseclient.java:724)  at org.apache.hadoop.hbase.ipc.hbaserpc$invoker.invoke(hbaserpc.java:252)  ... 20 more  12:52:55,863 [pool-4-thread-5182] info persistentutil:153 - retry after 1 second... looking at the client code, the hconnectionmanager does not watch zk for nodedeleted & nodecreated of /hbase/master ",
        "label": 247
    },
    {
        "text": "add snapshot verification admin tool  snapshots have a new file layout and there should be some admin command line tool to verify that they are not corrupt. this could potentially be added to hbck. ",
        "label": 309
    },
    {
        "text": "rest  stargate  tableregionmodel regions need to be updated to work w  new region naming convention from hbase  one reason testtableresource was failing was because comparing region names as strings was failing because the two below no longer matched. my guess is that the rest stuff is not using the new means of constructing region names. see hbase-2531 testtableresource,,1275503739792.30a45563321be3ec11841b0f1e79d687.  testtableresource,,1275503739792 ",
        "label": 314
    },
    {
        "text": "restartrsholdingroot action in org apache hadoop hbase util chaosmonkey restarting the server holding  meta  instead of  root   in chaosmonkey instead of restarting root holded regionserver it is restarting meta holded regionserver. public static class restartrsholdingroot extends restartrandomrs {     public restartrsholdingroot(long sleeptime) {       super(sleeptime);     }     @override     void perform() throws exception {       log.info(\"performing action: restart region server holding root\");       servername server = cluster.getserverholdingmeta();       if (server == null) {         log.warn(\"no server is holding -root- right now.\");         return;       }       restartrs(server, sleeptime);     }   } 13/07/23 17:03:54 info util.chaosmonkey: performing action: restart region server holding root 13/07/23 17:03:54 debug client.hconnectionmanager$hconnectionimplementation: looked up root region location, connection=org.apache.hadoop.hbase.client.hconnectionmanager$hconnectionimplementation@52b57e9a; servername=ocean06,60020,1374569995361 13/07/23 17:03:54 debug client.hconnectionmanager$hconnectionimplementation: removed .meta.,,1.1028785192 for tablename=.meta. from cache because of  13/07/23 17:03:54 debug client.hconnectionmanager$hconnectionimplementation: cached location for .meta.,,1.1028785192 is ocean06:60020 13/07/23 17:03:54 info util.chaosmonkey: killing region server:ocean06,60020,1374569995361 13/07/23 17:03:54 info hbase.hbasecluster: aborting rs: ocean06,60020,1374569995361 13/07/23 17:03:54 info hbase.clustermanager: executing remote command: ps ux | grep regionserver  | grep hbase | grep -v grep | tr -s ' ' | cut -d ' ' -f2 | xargs kill -s sigkill , hostname:ocean06 13/07/23 17:03:54 info util.shell: executing full command [/usr/bin/ssh  ocean06 \"ps ux | grep regionserver  | grep hbase | grep -v grep | tr -s ' ' | cut -d ' ' -f2 | xargs kill -s sigkill\"] 13/07/23 17:03:54 info hbase.clustermanager: executed remote command, exit code:0 , output: 13/07/23 17:03:54 info hbase.hbasecluster: waiting service:regionserver to stop: ocean06,60020,1374569995361 13/07/23 17:03:54 info hbase.clustermanager: executing remote command: ps ux | grep regionserver  | grep hbase | grep -v grep | tr -s ' ' | cut -d ' ' -f2 , hostname:ocean06 13/07/23 17:03:54 info util.shell: executing full command [/usr/bin/ssh  ocean06 \"ps ux | grep regionserver  | grep hbase | grep -v grep | tr -s ' ' | cut -d ' ' -f2\"] 13/07/23 17:03:55 info hbase.clustermanager: executed remote command, exit code:0 , output: 13/07/23 17:03:55 info util.chaosmonkey: killed region server:ocean06,60020,1374569995361. reported num of rs:2 this is only in 0.94.x ",
        "label": 496
    },
    {
        "text": "make compaction files cacheonwrite configurable based on threshold  as per comment from chenxu in the parent jira  https://issues.apache.org/jira/browse/hbase-23066?focusedcommentid=16937361&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-16937361  this is to introduce a config to identify if the resulting compacted file's blocks should be added to the cache - while writing. ",
        "label": 2
    },
    {
        "text": "deadlock in region metrics on shutdown  metricsregionsourceimpl vs metricsregionaggregatesourceimpl  looking into parent issue, got a hang locally of testdistributedlogreplay. we have region closes here: \"rs_close_meta-localhost:59610-0\" prio=5 tid=0x00007ff65c03f800 nid=0x54347 waiting on condition [0x000000011f7ac000]    java.lang.thread.state: waiting (parking) at sun.misc.unsafe.park(native method) - parking to wait for  <0x000000075636d8c0> (a java.util.concurrent.locks.reentrantreadwritelock$nonfairsync) at java.util.concurrent.locks.locksupport.park(locksupport.java:186) at java.util.concurrent.locks.abstractqueuedsynchronizer.parkandcheckinterrupt(abstractqueuedsynchronizer.java:834) at java.util.concurrent.locks.abstractqueuedsynchronizer.acquirequeued(abstractqueuedsynchronizer.java:867) at java.util.concurrent.locks.abstractqueuedsynchronizer.acquire(abstractqueuedsynchronizer.java:1197) at java.util.concurrent.locks.reentrantreadwritelock$writelock.lock(reentrantreadwritelock.java:945) at org.apache.hadoop.hbase.regionserver.metricsregionaggregatesourceimpl.deregister(metricsregionaggregatesourceimpl.java:78) at org.apache.hadoop.hbase.regionserver.metricsregionsourceimpl.close(metricsregionsourceimpl.java:120) at org.apache.hadoop.hbase.regionserver.metricsregion.close(metricsregion.java:41) at org.apache.hadoop.hbase.regionserver.hregion.doclose(hregion.java:1500) at org.apache.hadoop.hbase.regionserver.hregion.close(hregion.java:1344) - locked <0x00000007ff878190> (a java.lang.object) at org.apache.hadoop.hbase.regionserver.handler.closeregionhandler.process(closeregionhandler.java:102) at org.apache.hadoop.hbase.executor.eventhandler.run(eventhandler.java:103) at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1145) at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:615) at java.lang.thread.run(thread.java:744) they are trying to metricsregionaggregatesourceimpl.deregister. they want to get a write lock on this classes local reentrantreadwritelock while holding metricsregionsourceimpl's readwritelock write lock. then, elsewhere the jmxcachebuster is running trying to get metrics with above locks held in reverse: \"hbase-metrics2-1\" daemon prio=5 tid=0x00007ff65e14b000 nid=0x59a03 waiting on condition [0x0000000140ea5000]    java.lang.thread.state: waiting (parking) at sun.misc.unsafe.park(native method) - parking to wait for  <0x00000007cade1480> (a java.util.concurrent.locks.reentrantreadwritelock$nonfairsync) at java.util.concurrent.locks.locksupport.park(locksupport.java:186) at java.util.concurrent.locks.abstractqueuedsynchronizer.parkandcheckinterrupt(abstractqueuedsynchronizer.java:834) at java.util.concurrent.locks.abstractqueuedsynchronizer.doacquireshared(abstractqueuedsynchronizer.java:964) at java.util.concurrent.locks.abstractqueuedsynchronizer.acquireshared(abstractqueuedsynchronizer.java:1282) at java.util.concurrent.locks.reentrantreadwritelock$readlock.lock(reentrantreadwritelock.java:731) at org.apache.hadoop.hbase.regionserver.metricsregionsourceimpl.snapshot(metricsregionsourceimpl.java:193) at org.apache.hadoop.hbase.regionserver.metricsregionaggregatesourceimpl.getmetrics(metricsregionaggregatesourceimpl.java:115) at org.apache.hadoop.metrics2.impl.metricssourceadapter.getmetrics(metricssourceadapter.java:195) at org.apache.hadoop.metrics2.impl.metricssourceadapter.updatejmxcache(metricssourceadapter.java:172) at org.apache.hadoop.metrics2.impl.metricssourceadapter.getmbeaninfo(metricssourceadapter.java:151) at com.sun.jmx.interceptor.defaultmbeanserverinterceptor.getnewmbeanclassname(defaultmbeanserverinterceptor.java:333) at com.sun.jmx.interceptor.defaultmbeanserverinterceptor.registermbean(defaultmbeanserverinterceptor.java:319) at com.sun.jmx.mbeanserver.jmxmbeanserver.registermbean(jmxmbeanserver.java:522) at org.apache.hadoop.metrics2.util.mbeans.register(mbeans.java:57) at org.apache.hadoop.metrics2.impl.metricssourceadapter.startmbeans(metricssourceadapter.java:221) - locked <0x00000007e654bdc0> (a org.apache.hadoop.metrics2.impl.metricssourceadapter) at org.apache.hadoop.metrics2.impl.metricssourceadapter.start(metricssourceadapter.java:96) at org.apache.hadoop.metrics2.impl.metricssystemimpl.registersource(metricssystemimpl.java:245) - locked <0x0000000754302660> (a org.apache.hadoop.metrics2.impl.metricssystemimpl) at org.apache.hadoop.metrics2.impl.metricssystemimpl$1.poststart(metricssystemimpl.java:229) at sun.reflect.generatedmethodaccessor45.invoke(unknown source) at sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43) at java.lang.reflect.method.invoke(method.java:606) at org.apache.hadoop.metrics2.impl.metricssystemimpl$3.invoke(metricssystemimpl.java:290) at com.sun.proxy.$proxy13.poststart(unknown source) at org.apache.hadoop.metrics2.impl.metricssystemimpl.start(metricssystemimpl.java:185) - locked <0x0000000754302660> (a org.apache.hadoop.metrics2.impl.metricssystemimpl) at org.apache.hadoop.metrics2.impl.jmxcachebuster$jmxcachebusterrunnable.run(jmxcachebuster.java:81) ",
        "label": 154
    },
    {
        "text": "improve sync of hlog edits  hbase-5782 solved the correctness issue for the sync of hlog edits.  todd provided a patch that would achieve higher throughput. this jira is a continuation of todd's work submitted there. ",
        "label": 453
    },
    {
        "text": "improve zk node naming  hbase shutdown   right now the node /hbase/shutdown is used to indicate cluster status (cluster up, cluster down). however, upon a chat with lars george today, we feel that having a name /hbase/shutdown is possibly bad. the /hbase/shutdown zknode contains a date when the cluster was started. now that is difficult to understand and digest, given that a person may connect to zk and try to look at what it is about (they may think it 'shutdown' at that date.). i feel a better name may simply be: /hbase/running. thoughts? ",
        "label": 139
    },
    {
        "text": "packaging of trunk and does not create the dependent jars in the lib folder  after recent changes to trunk and 0.95 branch when i try to build and package, i do not find the dependent jars in the lib folder. prior to the changes, it was working fine.  am not a maven expert. will try to see what is going wrong here. ",
        "label": 340
    },
    {
        "text": "drop table drops all disabled tables  to reproduce in the shell: create 'a'  create 'b'  disable 'a'  disable 'b'  drop 'b'  enable 'a'  -> exception table 'a' not found ",
        "label": 314
    },
    {
        "text": "put  delete  increment  result  all all hbase m r classes still implement use writable  making blocker as suggested by stack. at least the following still use put/delete as writables. identitytablereduce.java multiput.java hregionserver.checkandmutate ",
        "label": 286
    },
    {
        "text": "master process can not be stopped when it is initializing  it is easy to reproduce by following step:  step1:start master process.(do not start regionserver process in the cluster).  the master will wait the regionserver to check in:  org.apache.hadoop.hbase.master.servermanager: waiting on regionserver(s) to checkin step2:stop the master by sh command bin/hbase master stop result:the master process will never die because catalogtracker.waitforroot() method will block unitl the root region assigned. ",
        "label": 544
    },
    {
        "text": "folder referred by thrift demo app instructions is outdated  due to the source tree module change for 0.96, the instructions in the thrift demo example don't match the folder structure any more. in the instruction, it is referring to: ../../../src/main/resources/org/apache/hadoop/hbase/thrift/hbase.thrift it should be ../../hbase-server/src/main/resources/org/apache/hadoop/hbase/thrift/hbase.thrift ",
        "label": 314
    },
    {
        "text": "multi writable can npe causing client hang  i have this backtrace: } org.apache.hadoop.hbase.notservingregionexception: usertable,,1284159178472.010c503fa9c9f12bd0fd9551ede360ec. is closed  at org.apache.hadoop.hbase.regionserver.hregion.startregionoperation(hregion.java:3068)  at org.apache.hadoop.hbase.regionserver.hregion.put(hregion.java:1248)  at org.apache.hadoop.hbase.regionserver.hregionserver.put(hregionserver.java:1709)  at org.apache.hadoop.hbase.regionserver.hregionserver.multi(hregionserver.java:2412)  at sun.reflect.generatedmethodaccessor13.invoke(unknown source)  at sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:25)  at java.lang.reflect.method.invoke(method.java:597)  at org.apache.hadoop.hbase.ipc.hbaserpc$server.call(hbaserpc.java:557)  at org.apache.hadoop.hbase.ipc.hbaseserver$handler.run(hbaseserver.java:1007) 2010-09-10 16:00:56,808 info org.apache.hadoop.ipc.hbaseserver: ipc server handler 15 on 60020 caught: java.lang.nullpointerexception  at org.apache.hadoop.hbase.client.multiresponse.write(multiresponse.java:92)  at org.apache.hadoop.hbase.io.hbaseobjectwritable.writeobject(hbaseobjectwritable.java:376)  at org.apache.hadoop.hbase.io.hbaseobjectwritable.write(hbaseobjectwritable.java:242)  at org.apache.hadoop.hbase.ipc.hbaseserver$handler.run(hbaseserver.java:1029) after this happened my client just sat there and didnt go anywhere. ",
        "label": 547
    },
    {
        "text": "clarify that simpleregionnormalizer does not merge empty  1mb  regions  simpleregionnormalizer does not merge empty region of a table steps to repro: create an empty table with few, say 5-6 regions without any data in any of them verify hbase:meta table to verify the regions for the table or check hmaster ui enable normalizer switch and normalization for this table run normalizer, by 'normalize' command from hbase shell verify the regions for table by scanning hbase:meta table or checking hmaster web ui the empty regions are not merged on running the region normalizer. this seems to be an edge case with completely empty regions since the normalizer checks for: smallestregion (in this case 0 size) + smallestneighborofsmallestregion (in this case 0 size) > avg region size (in this case 0 size)  thanks to josh elser for verifying this from the source code side ",
        "label": 252
    },
    {
        "text": "hbase book  section  has deficient list of client dependencies  the current text in section 2.6.4 of the hbase book says this about client dependencies: minimally, a client of hbase needs the hbase, hadoop, log4j, commons-logging, commons-lang, and zookeeper jars in its classpath connecting to a cluster. i tried that, and got an exception due to a class not being found. i fixed that by searching for that class in the jars in lib/, and tried again. got an exception, due to a different class not found. i iterated until it worked. when i was done, i found myself using the following jars: commons-configuration-1.6.jar hadoop-core-1.0.0.jar slf4j-api-1.5.8.jar  commons-lang-2.5.jar hbase-0.92.0.jar slf4j-log4j12-1.5.8.jar  commons-logging-1.1.1.jar log4j-1.2.16.jar zookeeper-3.4.2.jar ",
        "label": 209
    },
    {
        "text": "hlog may not be rolled in a long time if checklowreplication's request of logroll is blocked  some large hlog files(larger than 10g) appeared in our environment, and i got the reason why they got so huge: 1. the replicas is less than the expect number. so the method of checklowreplication will be called each sync. 2. the method checklowreplication request log-roll first, and set logrollrequested as true: private void checklowreplication() { // if the number of replicas in hdfs has fallen below the initial // value, then roll logs. try {   int numcurrentreplicas = getlogreplication();   if (numcurrentreplicas != 0 &&   numcurrentreplicas < this.initialreplication) { log.warn(\"hdfs pipeline error detected. \" + \"found \" + numcurrentreplicas + \" replicas but expecting \" + this.initialreplication + \" replicas. \" + \" requesting close of hlog.\"); requestlogroll(); logrollrequested = true;   } } catch (exception e) {   log.warn(\"unable to invoke dfsoutputstream.getnumcurrentreplicas\" + e +   \" still proceeding ahead...\"); } } 3.requestlogroll() just commit the roll request. it may not execute in time, for it must got the un-fair lock of cacheflushlock.  but the lock may be carried by the cacheflush threads. 4.logrollrequested was true until the log-roll executed. so during the time, each request of log-roll in sync() was skipped. here's the logs while the problem happened(please notice the file size of hlog \"193-195-5-111%3a20020.1309937386639\" in the last row): 2011-07-06 15:28:59,284 warn org.apache.hadoop.hbase.regionserver.wal.hlog: hdfs pipeline error detected. found 2 replicas but expecting 3 replicas. requesting close of hlog.  2011-07-06 15:29:46,714 info org.apache.hadoop.hbase.regionserver.wal.hlog: roll /hbase/.logs/193-195-5-111,20020,1309922880081/193-195-5-111%3a20020.1309937339119, entries=32434, filesize=239589754. new hlog /hbase/.logs/193-195-5-111,20020,1309922880081/193-195-5-111%3a20020.1309937386639  2011-07-06 15:29:56,929 warn org.apache.hadoop.hbase.regionserver.wal.hlog: hdfs pipeline error detected. found 2 replicas but expecting 3 replicas. requesting close of hlog.  2011-07-06 15:29:56,933 info org.apache.hadoop.hbase.regionserver.store: renaming flushed file at hdfs://193.195.5.112:9000/hbase/htable_ufdr_034/a3780cf0c909d8cf8f8ed618b290cc95/.tmp/4656903854447026847 to hdfs://193.195.5.112:9000/hbase/htable_ufdr_034/a3780cf0c909d8cf8f8ed618b290cc95/value/8603005630220380983  2011-07-06 15:29:57,391 info org.apache.hadoop.hbase.regionserver.store: added hdfs://193.195.5.112:9000/hbase/htable_ufdr_034/a3780cf0c909d8cf8f8ed618b290cc95/value/8603005630220380983, entries=445880, sequenceid=248900, memsize=207.5m, filesize=130.1m  2011-07-06 15:29:57,478 info org.apache.hadoop.hbase.regionserver.hregion: finished memstore flush of ~207.5m for region htable_ufdr_034,07664,1309936974158.a3780cf0c909d8cf8f8ed618b290cc95. in 10839ms, sequenceid=248900, compaction requested=false  2011-07-06 15:28:59,236 info org.apache.hadoop.hbase.regionserver.wal.hlog: roll /hbase/.logs/193-195-5-111,20020,1309922880081/193-195-5-111%3a20020.1309926531955, entries=216459, filesize=2370387468. new hlog /hbase/.logs/193-195-5-111,20020,1309922880081/193-195-5-111%3a20020.1309937339119  2011-07-06 15:29:46,714 info org.apache.hadoop.hbase.regionserver.wal.hlog: roll /hbase/.logs/193-195-5-111,20020,1309922880081/193-195-5-111%3a20020.1309937339119, entries=32434, filesize=239589754. new hlog /hbase/.logs/193-195-5-111,20020,1309922880081/193-195-5-111%3a20020.1309937386639  2011-07-06 16:29:58,775 debug org.apache.hadoop.hbase.regionserver.logroller: hlog roll period 3600000ms elapsed  2011-07-06 16:29:58,775 debug org.apache.hadoop.hbase.regionserver.logroller: hlog roll period 3600000ms elapsed  2011-07-06 16:30:01,978 info org.apache.hadoop.hbase.regionserver.wal.hlog: roll /hbase/.logs/193-195-5-111,20020,1309922880081/193-195-5-111%3a20020.1309937386639, entries=1135576, filesize=19220372830. new hlog /hbase/.logs/193-195-5-111,20020,1309922880081/193-195-5-111%3a20020.1309940998890 ",
        "label": 240
    },
    {
        "text": "simplify offheap cache configuration  the bucketcache (hbase-7404) is a very nice piece of functionality which is hidden behind complex configuration. enabling it currently requires manual calculation of l1 cache. it'd be nice to make this easier to use and conform better with the existing heap management tools we already have. turning it on currently requires explicitly setting lrublockcache (l1) instance size and ioengine (l2) size, making sure that l1 size isn't too big vs global memstore and total heap. this is further confused by hbase.bucketcache.size accepting a percentage of total heap or explicit size in mb. enabling slabcache is slightly easier in that it just accepts whatever lrublockcache is provided. turning on bucketcache using off-heap mode could look like: hbase-env.sh:  set hbase_regionserver_opts:  -xmx5000m  -xx:maxdirectmemorysize=15000m hbase-site.xml: hbase.regionserver.global.memstore.size = 0.7 hbase.regionserver.onheap.blockcache.size = 0.1 hbase.regionserver.blockcache.impl = bucketcache hbase.bucketcache.ioengine = offheap the result being a combinedcache instance with 500m lrublockcache + 15000m bytebufferioengine running in direct mode. this example does a couple things (mostly for the admin): knows not to enable slabcache s/hfile.block.cache.size/hbase.regionserver.onheap.blockcache.size/ maintains the validity of hbaseconfiguration's existing check that global memstore + lrublockcache == 0.8 maps \"bucketcache\" into meaning \"a combinedcache instance with these implementations for l1 and l2.\" figures out appropriate values for hbase.bucketcache.size and hbase.bucketcache.percentage.in.combinedcache ",
        "label": 339
    },
    {
        "text": "testreplicawithcluster turns zombie  happened a few times for me fixing unrelated findbugs. here is example: https://builds.apache.org/job/precommit-hbase-build/10065//consolefull see how it is hanging creating a table: \"pool-1-thread-1\" prio=10 tid=0x00007f1714657000 nid=0x4b7f waiting on condition [0x00007f16e9f80000]  java.lang.thread.state: timed_waiting (sleeping)  at java.lang.thread.sleep(native method)  at org.apache.hadoop.hbase.client.hbaseadmin.createtable(hbaseadmin.java:539)  at org.apache.hadoop.hbase.client.hbaseadmin.createtable(hbaseadmin.java:424)  at org.apache.hadoop.hbase.hbasetestingutility.createtable(hbasetestingutility.java:1185)  at org.apache.hadoop.hbase.client.testreplicawithcluster.testcreatedeletetable(testreplicawithcluster.java:138) ",
        "label": 323
    },
    {
        "text": "result compareresults is incorrect  a coworker of mine (james taylor) found a bug in result.compareresults(...).  this condition:       if (!ourkvs[i].equals(replicatedkvs[i]) &&           !bytes.equals(ourkvs[i].getvalue(), replicatedkvs[i].getvalue())) {         throw new exception(\"this result was different: \" should be       if (!ourkvs[i].equals(replicatedkvs[i]) ||           !bytes.equals(ourkvs[i].getvalue(), replicatedkvs[i].getvalue())) {         throw new exception(\"this result was different: \" just checked, this is wrong in all branches. ",
        "label": 286
    },
    {
        "text": "address issues found by error prone in hbase client  i thought this was something that we would already catch in findbugs, but maybe not? [error] failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.6.1:compile (default-compile) on project hbase-client: compilation failure [error] /users/mdrob/ideaprojects/hbase/hbase-client/src/main/java/org/apache/hadoop/hbase/shaded/protobuf/protobufutil.java:[2476,5] [missingcasesinenumswitch] non-exhaustive switch; either add a default or handle the remaining cases: global_bypass [error]     (see http://errorprone.info/bugpattern/missingcasesinenumswitch) cc: josh elser, this looks like it is part of quota code. i'm happy to add a trivial patch to error on the missing case, but want somebody with more contextual knowledge to look at it. ",
        "label": 320
    },
    {
        "text": "npe getting scanner  saw following in a 0.1.1 install: 2008-04-11 16:59:09,820 info org.apache.hadoop.ipc.server: ipc server handler 3 on 60020, call openscanner(enwiki_test10k,,1197341035929, null, k4xe4y6sk4dq7i2f2uhrn-==, 9223372036854775807, null) from 208.76.44.136:39230: error: java.io.ioexception: java.lang.nullpointerexception java.io.ioexception: java.lang.nullpointerexception         at org.apache.hadoop.hbase.hregion.getscanner(hregion.java:1195)         at org.apache.hadoop.hbase.hregionserver.openscanner(hregionserver.java:1449)         at sun.reflect.generatedmethodaccessor9.invoke(unknown source)         at sun.reflect.delegatingmethodaccessorimpl.invoke(unknown source)         at java.lang.reflect.method.invoke(unknown source)         at org.apache.hadoop.hbase.ipc.hbaserpc$server.call(hbaserpc.java:413)         at org.apache.hadoop.ipc.server$handler.run(server.java:910) ",
        "label": 241
    },
    {
        "text": "bin hbase zkcli cannot take arguments anymore  it used to be possible to do stuff like  bin/hbase zkcli stat  and we have this kind of stuff in the standard hbase scripts. this has been broken by hbase-8766 (reverting is an easy way to fix, it's unlikely to be the right thing to do. pinging enis soztutar) ",
        "label": 155
    },
    {
        "text": "testupgradefromhfilev1toencoding testupgrade fails in trunk  testupgradefromhfilev1toencoding started to fail since build #3242  build #3246 was more recent one where it failed. 2012-08-21 00:49:06,536 info  [splitlogworker-vesta.apache.org,40294,1345510146310] regionserver.splitlogworker(135): splitlogworker vesta.apache.org,40294,1345510146310 starting 2012-08-21 00:49:06,537 info  [regionserver:0;vesta.apache.org,40294,1345510146310] regionserver.hregionserver(2431): registered regionserver mxbean 2012-08-21 00:49:06,620 warn  [master:0;vesta.apache.org,60969,1345510146282] master.assignmentmanager(1606): failed assignment of -root-,,0.70236052 to vesta.apache.org,40294,1345510146310, trying to assign elsewhere instead; retry=0 org.apache.hadoop.hbase.ipc.servernotrunningyetexception: org.apache.hadoop.hbase.ipc.servernotrunningyetexception: server is not running yet at sun.reflect.nativeconstructoraccessorimpl.newinstance0(native method) at sun.reflect.nativeconstructoraccessorimpl.newinstance(nativeconstructoraccessorimpl.java:39) at sun.reflect.delegatingconstructoraccessorimpl.newinstance(delegatingconstructoraccessorimpl.java:27) at java.lang.reflect.constructor.newinstance(constructor.java:513) at org.apache.hadoop.ipc.remoteexception.instantiateexception(remoteexception.java:95) at org.apache.hadoop.ipc.remoteexception.unwrapremoteexception(remoteexception.java:79) at org.apache.hadoop.hbase.ipc.protobufrpcengine$invoker.invoke(protobufrpcengine.java:187) at $proxy15.openregion(unknown source) at org.apache.hadoop.hbase.master.servermanager.sendregionopen(servermanager.java:500) at org.apache.hadoop.hbase.master.assignmentmanager.assign(assignmentmanager.java:1587) at org.apache.hadoop.hbase.master.assignmentmanager.assign(assignmentmanager.java:1256) at org.apache.hadoop.hbase.master.assignmentmanager.assign(assignmentmanager.java:1226) at org.apache.hadoop.hbase.master.assignmentmanager.assign(assignmentmanager.java:1221) at org.apache.hadoop.hbase.master.assignmentmanager.assignroot(assignmentmanager.java:2103) at org.apache.hadoop.hbase.master.hmaster.assignrootandmeta(hmaster.java:785) at org.apache.hadoop.hbase.master.hmaster.finishinitialization(hmaster.java:665) at org.apache.hadoop.hbase.master.hmaster.run(hmaster.java:439) at java.lang.thread.run(thread.java:662) caused by: org.apache.hadoop.ipc.remoteexception: org.apache.hadoop.hbase.ipc.servernotrunningyetexception: server is not running yet at org.apache.hadoop.hbase.ipc.hbaseserver$handler.run(hbaseserver.java:1766) at org.apache.hadoop.hbase.ipc.hbaseclient.call(hbaseclient.java:1187) at org.apache.hadoop.hbase.ipc.protobufrpcengine$invoker.invoke(protobufrpcengine.java:178) ... 11 more 2012-08-21 00:49:06,621 info  [master:0;vesta.apache.org,60969,1345510146282] master.regionstates(250): region {name => '-root-,,0', startkey => '', endkey => '', encoded => 70236052,} transitioned from {-root-,,0.70236052 state=pending_open, ts=1345510146520, server=vesta.apache.org,40294,1345510146310} to {-root-,,0.70236052 state=offline, ts=1345510146621, server=null} 2012-08-21 00:49:06,621 warn  [master:0;vesta.apache.org,60969,1345510146282] master.assignmentmanager(1772): can't move the region 70236052, there is no destination server available. 2012-08-21 00:49:06,621 warn  [master:0;vesta.apache.org,60969,1345510146282] master.assignmentmanager(1618): unable to find a viable location to assign region -root-,,0.70236052 2012-08-21 00:50:06,406 debug [master:0;vesta.apache.org,60969,1345510146282.archivedhfilecleaner] cleaner.cleanerchore(145): checking directory: hdfs://localhost:56237/user/hudson/hbase/.archive/upgradetable looks like root region couldn't be assigned. ",
        "label": 441
    },
    {
        "text": "should use procedure store to persist the state in reportregionstatetransition  for now we will update the meta region directly. this may cause lots of problems and after a bunch of fixes, we still can not solve the problem in hbase-22060. so maybe the approach itself is not a good choice, let's try another way to see if it could work better. ",
        "label": 149
    },
    {
        "text": "change hbase storekey format  hbase-859 cleaned up keys removing the need of hregioninfo being in the context comparing keys. this issue is about changing the format. work done in hbase-859 means changes have been localized to hstorekey, in particular to comparators and parse routines. we should do this now since 0.20.0 will require rewriting all data. things to consider: <row> <columnfamily> <columnqualifier> <timestamp> <keytype> or leave off columnfamily altogether and just write it once into the hfile metadata (all key compares are done in the store context so columnfamily can be safely left out of the equation; its only when the key rises above store that the columnfamily needs appending). keytype is probably a byte. types are delete cell, delete row, delete family, delete column? what else? where should we put it? at the end? how should type sort? or should it not be part of sort so its just the order at which we encounter the key? how are we going to support keys that go in out of chronological order? ",
        "label": 314
    },
    {
        "text": "allow hbaserpcmetrics to register custom interface methods  opened from comments on hbase-2997. james kennedy notes: hbaserpcmetrics is now logging a warn message every time it encounters an unregistered rpc method. in my case i now get huge log files filled with these warnings because the hbase-trx transactional extension of hbase uses a subclass of hregionserver that adds new interface methods. it's easy enough to tell log4j to ignore hbaserpcmetrics output. however, it would be nice if the server/hregionserver hbaserpcmetrics mechanism was more extensible so i could pass down new interfaces or grab the hbaserpcmetrics object to add interfaces from up top... hbaserpcmetrics already has a public method createmetrics(class) to register method counters. we just need a way to expose the metrics class to allow the region server subclass to call it \u2013 add a getmetrics() method to rpcserver and hbaseserver. ",
        "label": 180
    },
    {
        "text": "failure in assigning root causes system hang  in looking into a testreplication failure, i found out sometimes assignroot could fail, for example, rs is not serving traffic yet. in this case, the master will keep waiting for root to be available, which could never happen. need to gracefully terminate master if root is not assigned properly. ",
        "label": 242
    },
    {
        "text": " replication  create an interface for replication peers  ",
        "label": 103
    },
    {
        "text": "unknownscanner happens too often   jean-daniel up on the list in an exchange with dru jensen solved an issue by recommending longer lease for client scanners in a mr job. lets make change to conf. this lessens the impact of andrew purtell added retry on use in hbase-816 in tablemap but will help in mr tasks that don't subclass tablemap. ",
        "label": 229
    },
    {
        "text": "hbase transitive dependencies not being pulled in when building apps like flume which depend on hbase  here is a snippet of the errors seen when building against hbase.... [warning] invalid pom for org.apache.hbase:hbase-common:jar:0.97.0-snapshot, transitive dependencies (if any) will not be available, enable debug logging for more details: some problems were encountered while processing the poms: [error] 'dependencymanagement.dependencies.dependency.artifactid' for org.apache.hbase:${compat.module}:jar with value '${compat.module}' does not match a valid id pattern. @ org.apache.hbase:hbase:0.97.0-snapshot, /users/rnaik/.m2/repository/org/apache/hbase/hbase/0.97.0-snapshot/hbase-0.97.0-snapshot.pom, line 982, column 21 [error] 'dependencymanagement.dependencies.dependency.artifactid' for org.apache.hbase:${compat.module}:test-jar with value '${compat.module}' does not match a valid id pattern. @ org.apache.hbase:hbase:0.97.0-snapshot, /users/rnaik/.m2/repository/org/apache/hbase/hbase/0.97.0-snapshot/hbase-0.97.0-snapshot.pom, line 987, column 21 ",
        "label": 314
    },
    {
        "text": "bytebuf leak error  we do failover test and throw a leak error, this is hard to reproduce. 2019-05-06 02:30:27,781 error [asyncfswal-0] util.resourceleakdetector: leak: bytebuf.release() was not called before it's garbage-collected. see http://netty.io/wiki/reference-counted-objects.html for more information. recent access records: created at:  org.apache.hbase.thirdparty.io.netty.buffer.pooledbytebufallocator.newdirectbuffer(pooledbytebufallocator.java:334)  org.apache.hbase.thirdparty.io.netty.buffer.abstractbytebufallocator.directbuffer(abstractbytebufallocator.java:187)  org.apache.hbase.thirdparty.io.netty.buffer.abstractbytebufallocator.directbuffer(abstractbytebufallocator.java:178)  org.apache.hadoop.hbase.io.asyncfs.fanoutoneblockasyncdfsoutput.flush0(fanoutoneblockasyncdfsoutput.java:494)  org.apache.hadoop.hbase.io.asyncfs.fanoutoneblockasyncdfsoutput.flush(fanoutoneblockasyncdfsoutput.java:513)  org.apache.hadoop.hbase.regionserver.wal.asyncprotobuflogwriter.sync(asyncprotobuflogwriter.java:144)  org.apache.hadoop.hbase.regionserver.wal.asyncfswal.sync(asyncfswal.java:353)  org.apache.hadoop.hbase.regionserver.wal.asyncfswal.consume(asyncfswal.java:536)  java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1149)  java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624)  java.lang.thread.run(thread.java:748) if fanoutoneblockasyncdfsoutput#endblock throw exception before call \"buf.release();\", this buf has not chance to release.  in callrunner if the call skipped or dropping timed out call, the call do not call cleanup. ",
        "label": 292
    },
    {
        "text": "testzkprocedurecontrollers testzkcoordinatorcontrollerwithsinglemembercohort is a flakey  tests fail in testzkprocedurecontrollers with some regularity. here is an example: https://builds.apache.org/view/h-l/view/hbase/job/hbase-1.3/309/jdk=latest1.8,label=hadoop/testreport/org.apache.hadoop.hbase.procedure/testzkprocedurecontrollers/testzkcoordinatorcontrollerwithsinglemembercohort/ org.mockito.exceptions.verification.toomanyactualinvocations:  proceduremember.submitsubprocedure(<any>); wanted 1 time: -> at org.apache.hadoop.hbase.procedure.testzkprocedurecontrollers.verifycohort(testzkprocedurecontrollers.java:364) but was 2 times. undesired invocation: -> at org.apache.hadoop.hbase.procedure.zkprocedurememberrpcs.startnewsubprocedure(zkprocedurememberrpcs.java:214) at org.apache.hadoop.hbase.procedure.testzkprocedurecontrollers.verifycohort(testzkprocedurecontrollers.java:364) at org.apache.hadoop.hbase.procedure.testzkprocedurecontrollers.runmockcommitwithorchestratedcontrollers(testzkprocedurecontrollers.java:235) at org.apache.hadoop.hbase.procedure.testzkprocedurecontrollers.testzkcoordinatorcontrollerwithsinglemembercohort(testzkprocedurecontrollers.java:158) tests in this suite fail always in this mockito verify step. always double the number of calls expected. strikes me as a mockito bug or mockito usage interesting behavior. unless someone intercedes, i'm just going to loosen this assert to be at least n rather than exactly n. lets see if it fails again soon... so i have another example to paste in here. ",
        "label": 314
    },
    {
        "text": "the hbase thrift service ignores xml configuration  i put the following configuration in my hbase-site.xml:   <property>     <name>hbase.regionserver.thrift.compact</name>     <value>true</value>   </property>   <property>     <name>hbase.regionserver.thrift.framed</name>     <value>true</value>   </property> but the configuration is ignored due to the following lines in thriftserver.java around lines 197:     conf.setboolean(         thriftserverrunner.compact_conf_key, cmd.hasoption(compact_option));     conf.setboolean(         thriftserverrunner.framed_conf_key, cmd.hasoption(framed_option)); the configuration values are being unconditionally set to the defaults programmatically. ",
        "label": 285
    },
    {
        "text": "backdoor coprocessorhconnection is no longer being used for local writes  there's a backdoor coprocessorhconnection used to ensure that a batched mutation does not go over the wire and back, but executes immediately locally. this is leveraged by phoenix during secondary index maintenance (for an ~20% perf improvement). it looks to me like it's no longer used, as the following function is never invoked:  public org.apache.hadoop.hbase.protobuf.generated.clientprotos.clientservice.blockinginterface  getclient(servername servername) throws ioexception { it'd be good if feasible to add an hbase unit test to prevent further regressions. for more info, see phoenix-1166. ",
        "label": 38
    },
    {
        "text": "hmaster fails to start with secure hadoop  in current trunk, hmaster will fail to start with secure hadoop if the user starting the process has not obtained a kerberos tgt. the user starting the process should not be required to have a tgt, as the hmaster process self logs in using the configured keytab and principal. this is due to a log line in the hmaster constructor executing prior to the user.login() step:     log.info(\"hbase.rootdir=\" + fsutils.getrootdir(this.conf) +         \", hbase.cluster.distributed=\" + this.conf.getboolean(\"hbase.cluster.distributed\", false)); here the fsutils.getrootdir() winds up hitting the namenode. the fix is trivial, moving the log line to follow user.login(). ",
        "label": 180
    },
    {
        "text": "fix the wrong reference to getreader survived in thefshlog javadoc  in fshlog, a wrong reference to getreader survived in the javadoc:  * to read an hlog, call {@link #getreader(org.apache.hadoop.fs.filesystem,  * org.apache.hadoop.fs.path, org.apache.hadoop.conf.configuration)}. ",
        "label": 191
    },
    {
        "text": "remove the adapter code in async fs implementation for hadoop x  ",
        "label": 149
    },
    {
        "text": "license notification misspells 'asciidoctor'  our license file contains 'asciidoctor' but with three \"i\" this project bundles a derivative of portions of the 'asciiidoctor' project  under the terms of the mit license. ",
        "label": 284
    },
    {
        "text": "regionsplitter incorrectly calculates splitcount  from discussion on hbase-11627: and i also find another bug about the caculation of the variable splitcount which is cause by the wrong caculation of variable splitcount. ",
        "label": 537
    },
    {
        "text": "add tag dictionary in wal compression  we can add tag dictionary like we have one for rowdictionary, familydictionary. but this has to be done after stabilizing hbase-7391. ",
        "label": 46
    },
    {
        "text": "bucketcache freeblock is too expensive  moving regions is unacceptably slow when using bucket cache, as it takes too long to free all the blocks. ",
        "label": 441
    },
    {
        "text": "ability to specify scanner caching on a per scan basis  i think that clients should have the ability to configure the scanner caching setting on a per-scan basis via the org.apache.hadoop.hbase.client.scan object. i propose adding a new caching property to the scan class which would override the htable.scannercaching property if set. this would turn the htable.scannercaching property into more of a default setting. the code inside clientscanner (an inner-class implementation of resultscanner) would look like this:       // use the caching from the scan.  if not set, use the default cache setting for this table.       if (this.scan.getcaching() > 0) {         this.caching = this.scan.getcaching();       } else {         this.caching = htable.this.scannercaching;       } note that currently the only option for per-scan scanner caching configuration is to modify the state of htable for each scan. this could lead to confusion when htables are pooled since the pool would potentially end up with many htables all configured differently. i will attach a patch. i'm looking forward to hearing your comments. ",
        "label": 274
    },
    {
        "text": "createtable blocks until all regions are out of transition  in hbase-3305, the behavior of createtable was changed and introduced this bug: createtable now blocks until all regions have been assigned, since it uses bulkstartupassigner. bulkstartupassigner.waituntildone calls assignmentmanager.waituntilnoregionsintransition, which waits across all regions, not just the regions of the table that has just been created. we saw an issue where one table had a region which was unable to be opened, so it was stuck in regionsintransition permanently (every open was failing). since this was the case, waituntildone would always block indefinitely even though the newly created table had been assigned. ",
        "label": 441
    },
    {
        "text": "document the leaseexception thrown in scanner next  in some situations clients that fetch data from a rs get a leaseexception instead of the usual scannertimeoutexception/unknownscannerexception. this particular case should be documented in the hbase guide. some key points the source of exception is: org.apache.hadoop.hbase.regionserver.leases.removelease(leases.java:230) it happens in the context of a slow/freezing rs#next it can be prevented by having hbase.rpc.timeout > hbase.regionserver.lease.period harsh j investigated the issue and has some conclusions, see http://mail-archives.apache.org/mod_mbox/hbase-user/201209.mbox/%3ccaocnvr3r-lqtkhfsk8bhrm-yw2i9o6j6fhjz2h7q6_sxvwd2yw%40mail.gmail.com%3e ",
        "label": 120
    },
    {
        "text": "hadoop unit test failures  an umbrella for all open issues for unit test failures specific to hadoop 2. ",
        "label": 248
    },
    {
        "text": "add metrics to keep track of region splits in rs  for write-heavy workload with region-size 1 gb, region-split is considerably high. we do normally grep the nn log (grep \"mkdir*.split\" nn.log | sort | uniq -c) to get the count. i would like to have a counter incremented each time region-split execution succeeds and this counter exposed via the metrics stuff in hbase. regionsplitsuccesscount regionsplitfailurecount (will help us to correlate the timestamp range in rs logs across all rs) ",
        "label": 309
    },
    {
        "text": "deprecate htable batch final list  extends row   this was brought up by amit's inquiry on mailing list, entitled 'batch returned value and exception handling' here is his sample code: object[] res = null; try {   res = table.batch(batch); } catch (retriesexhaustedwithdetailsexception retriesexhaustedwithdetailsexception) {   retriesexhaustedwithdetailsexception.printstacktrace(); } if (res == null) {   system.out.println(\"no results - returned null.\"); } when retriesexhaustedwithdetailsexception was thrown from batch() call, variable res carried value of null.  meaning user wouldn't get partial result along with the exception. we should deprecate htable#batch(final list<? extends row>) and refer to the following method: void batch(final list<?extends row> actions, final object[] results) throws ioexception, interruptedexception; ",
        "label": 230
    },
    {
        "text": "testservercustomprotocol is flaky  testservercustomprotocol has been showing some intermittent failures in jenkins due to what looks like region transitions. here is the most recent failure: results : failed tests:   testrowrange(org.apache.hadoop.hbase.regionserver.testservercustomprotocol): results should contain region test,bbb,1317332645939.aea9154349b9e0dc207e2e9476702763. for row 'bbb' ",
        "label": 180
    },
    {
        "text": "sequencefile reader keeps around buffer whose size is that of largest item read   results in lots of dead heap  andrew is oomeing again. looking at some of his heaps, i can count reader with dataoutputbuffers of ~600mb in a 2g heap. testing i see that the dataoutputbuffer allocated at head of mapfile.reader is reused when we call next, a reset is called. if i trace, the dataoutputbuffer has in it an internal buffer class which is based on bytearrayoutputstream. reset of the dob eventually goes through to the baos reset. this just sets the position. it keeps the buffer sized to whatever it grew to last time this baos was used (figuring this was a little complicated by the fact that dob does some fancy footwork in a reset override to avoid copies). ",
        "label": 314
    },
    {
        "text": "testaccesscontroller testglobalpermissionlist failed with indexoutofboundsexception  https://builds.apache.org/job/hbase-trunk/4246/testreport/junit/org.apache.hadoop.hbase.security.access/testaccesscontroller/testglobalpermissionlist/ java.lang.indexoutofboundsexception: index: 0, size: 0 at java.util.arraylist.rangecheck(arraylist.java:547) at java.util.arraylist.get(arraylist.java:322) at org.apache.hadoop.hbase.security.access.testaccesscontroller.setup(testaccesscontroller.java:188) ",
        "label": 314
    },
    {
        "text": "number of active threads in htable's threadpoolexecutor  using a threadpoolexecutor with corepoolsize = 0 and using linkedblockingqueue as the collection to hold incoming runnable tasks seems to be having the effect of running only 1 thread, irrespective of the maxpoolsize set by reading the property hbase.htable.threads.max (or number of rs). (this is what i infer from reading source code of threadpoolexecutor class in 1.6) on a 3 node ec2 cluster, a full table scan with approx 9m rows results in almost similar timing with a sequential scanner (240 secs) and scanning with a coprocessor (230 secs), that uses htable's pool to submit callable objects for each region.   i try to come up with a test class that creates a similar threadpool, and test that whether the pool size ever grows beyond 1. it also confirms that it remains 1 though it executed 100 requests. it seems the desired behavior was to release all resources when the client is done reading, but this can be achieved by setting allowcorethreadtimeout to true (after setting a +ve corepoolsize). ",
        "label": 199
    },
    {
        "text": "testhttpserverlifecycle teststartedserverisalive times out  running on my test rig, i see this test timeout from time to time. it just hangs after jetty setup. port clash? 2015-09-14 09:08:54,474 info  [main] hbase.resourcechecker(148): before: http.testhttpserverlifecycle#testcreatedserverisnotalive thread=4, openfiledescriptor=192, maxfiledescriptor=32768, systemloadaverage=122, processcount=507, availabl 2015-09-14 09:08:54,592 info  [time-limited test] log.slf4jlog(67): logging to org.slf4j.impl.log4jloggeradapter(org.mortbay.log) via org.mortbay.log.slf4jlog 2015-09-14 09:08:54,911 info  [time-limited test] http.httprequestlog(69): http request log for http.requests.test is not defined 2015-09-14 09:08:54,923 info  [time-limited test] http.httpserver(821): added global filter 'safety' (class=org.apache.hadoop.hbase.http.httpserver$quotinginputfilter) 2015-09-14 09:08:54,924 info  [time-limited test] http.httpserver(821): added global filter 'clickjackingprevention' (class=org.apache.hadoop.hbase.http.clickjackingpreventionfilter) 2015-09-14 09:08:54,985 info  [main] hbase.resourcechecker(172): after: http.testhttpserverlifecycle#testcreatedserverisnotalive thread=5 (was 4) potentially hanging thread: process reaper         sun.misc.unsafe.park(native method)         java.util.concurrent.locks.locksupport.parknanos(locksupport.java:226)         java.util.concurrent.synchronousqueue$transferstack.awaitfulfill(synchronousqueue.java:460)         java.util.concurrent.synchronousqueue$transferstack.transfer(synchronousqueue.java:359)         java.util.concurrent.synchronousqueue.poll(synchronousqueue.java:942)         java.util.concurrent.threadpoolexecutor.gettask(threadpoolexecutor.java:1068)         java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1130)         java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:615)         java.lang.thread.run(thread.java:745)  - thread leak? -, openfiledescriptor=192 (was 192), maxfiledescriptor=32768 (was 32768), systemloadaverage=122 (was 122), processcount=507 (was 507), availablememorymb=28014 (was 28054) 2015-09-14 09:08:55,013 info  [main] hbase.resourcechecker(148): before: http.testhttpserverlifecycle#testwepappcontextafterserverstop thread=5, openfiledescriptor=192, maxfiledescriptor=32768, systemloadaverage=122, processcount=507, ava 2015-09-14 09:08:55,088 info  [time-limited test] http.httprequestlog(69): http request log for http.requests.test is not defined 2015-09-14 09:08:55,089 info  [time-limited test] http.httpserver(821): added global filter 'safety' (class=org.apache.hadoop.hbase.http.httpserver$quotinginputfilter) 2015-09-14 09:08:55,090 info  [time-limited test] http.httpserver(821): added global filter 'clickjackingprevention' (class=org.apache.hadoop.hbase.http.clickjackingpreventionfilter) 2015-09-14 09:08:55,113 info  [time-limited test] http.httpserver(1013): jetty bound to port 60242 2015-09-14 09:08:55,113 info  [time-limited test] log.slf4jlog(67): jetty-6.1.26 2015-09-14 09:08:55,263 info  [time-limited test] log.slf4jlog(67): started selectchannelconnector@localhost:60242 2015-09-14 09:08:55,270 info  [time-limited test] log.slf4jlog(67): stopped selectchannelconnector@localhost:0 2015-09-14 09:08:55,401 info  [main] hbase.resourcechecker(172): after: http.testhttpserverlifecycle#testwepappcontextafterserverstop thread=5 (was 5), openfiledescriptor=197 (was 192) - openfiledescriptor leak? -, maxfiledescriptor=32768 2015-09-14 09:08:55,428 info  [main] hbase.resourcechecker(148): before: http.testhttpserverlifecycle#teststopunstartedserver thread=5, openfiledescriptor=197, maxfiledescriptor=32768, systemloadaverage=122, processcount=507, availablemem 2015-09-14 09:08:55,489 info  [time-limited test] http.httprequestlog(69): http request log for http.requests.test is not defined 2015-09-14 09:08:55,489 info  [time-limited test] http.httpserver(821): added global filter 'safety' (class=org.apache.hadoop.hbase.http.httpserver$quotinginputfilter) 2015-09-14 09:08:55,490 info  [time-limited test] http.httpserver(821): added global filter 'clickjackingprevention' (class=org.apache.hadoop.hbase.http.clickjackingpreventionfilter) 2015-09-14 09:08:55,521 info  [main] hbase.resourcechecker(172): after: http.testhttpserverlifecycle#teststopunstartedserver thread=5 (was 5), openfiledescriptor=197 (was 197), maxfiledescriptor=32768 (was 32768), systemloadaverage=122 (w 2015-09-14 09:08:55,548 info  [main] hbase.resourcechecker(148): before: http.testhttpserverlifecycle#teststartedserverisalive thread=5, openfiledescriptor=197, maxfiledescriptor=32768, systemloadaverage=122, processcount=507, availableme 2015-09-14 09:08:55,592 info  [time-limited test] http.httprequestlog(69): http request log for http.requests.test is not defined 2015-09-14 09:08:55,593 info  [time-limited test] http.httpserver(821): added global filter 'safety' (class=org.apache.hadoop.hbase.http.httpserver$quotinginputfilter) 2015-09-14 09:08:55,593 info  [time-limited test] http.httpserver(821): added global filter 'clickjackingprevention' (class=org.apache.hadoop.hbase.http.clickjackingpreventionfilter) 2015-09-14 09:08:55,596 info  [time-limited test] http.httpserver(1013): jetty bound to port 34027 2015-09-14 09:08:55,596 info  [time-limited test] log.slf4jlog(67): jetty-6.1.26 2015-09-14 09:08:55,620 info  [time-limited test] log.slf4jlog(67): started selectchannelconnector@localhost:34027 2015-09-14 09:09:55,589 info  [main] hbase.resourcechecker(172): after: http.testhttpserverlifecycle#teststartedserverisalive thread=8 (was 5) potentially hanging thread: 665017523@qtp-1303167268-1 - acceptor0 selectchannelconnector@localhost:34027         org.mortbay.io.nio.selectormanager$selectset.doselect(selectormanager.java:464)         org.mortbay.io.nio.selectormanager.doselect(selectormanager.java:192)         org.mortbay.jetty.nio.selectchannelconnector.accept(selectchannelconnector.java:124)         org.mortbay.jetty.abstractconnector$acceptor.run(abstractconnector.java:708)         org.mortbay.thread.queuedthreadpool$poolthread.run(queuedthreadpool.java:582) potentially hanging thread: time-limited test         org.mortbay.io.nio.selectormanager$selectset.stop(selectormanager.java:879)         org.mortbay.io.nio.selectormanager.dostop(selectormanager.java:240)         org.mortbay.component.abstractlifecycle.stop(abstractlifecycle.java:76)         org.mortbay.jetty.nio.selectchannelconnector.close(selectchannelconnector.java:136)         org.apache.hadoop.hbase.http.httpserver.stop(httpserver.java:1041)         org.apache.hadoop.hbase.http.httpserverfunctionaltest.stop(httpserverfunctionaltest.java:195)         org.apache.hadoop.hbase.http.testhttpserverlifecycle.teststartedserverisalive(testhttpserverlifecycle.java:73)         sun.reflect.nativemethodaccessorimpl.invoke0(native method)         sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:57)         sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43)         java.lang.reflect.method.invoke(method.java:606)         org.junit.runners.model.frameworkmethod$1.runreflectivecall(frameworkmethod.java:50)         org.junit.internal.runners.model.reflectivecallable.run(reflectivecallable.java:12)         org.junit.runners.model.frameworkmethod.invokeexplosively(frameworkmethod.java:47)         org.junit.internal.runners.statements.invokemethod.evaluate(invokemethod.java:17)         org.junit.internal.runners.statements.failontimeout$callablestatement.call(failontimeout.java:298)         org.junit.internal.runners.statements.failontimeout$callablestatement.call(failontimeout.java:292)         java.util.concurrent.futuretask.run(futuretask.java:262)         java.lang.thread.run(thread.java:745) potentially hanging thread: timer-1         java.lang.object.wait(native method)         java.util.timerthread.mainloop(timer.java:552)         java.util.timerthread.run(timer.java:505) potentially hanging thread: 1272155315@qtp-1303167268-0         java.lang.object.wait(native method)         org.mortbay.thread.queuedthreadpool$poolthread.run(queuedthreadpool.java:626)  - thread leak? -, openfiledescriptor=201 (was 197) - openfiledescriptor leak? -, maxfiledescriptor=32768 (was 32768), systemloadaverage=112 (was 122), processcount=507 (was 507), availablememorymb=27985 (was 27994) 2015-09-14 09:09:55,619 info  [main] hbase.resourcechecker(148): before: http.testhttpserverlifecycle#teststoppedserverisnotalive thread=9, openfiledescriptor=201, maxfiledescriptor=32768, systemloadaverage=112, processcount=507, availabl 2015-09-14 09:09:55,652 info  [time-limited test] http.httprequestlog(69): http request log for http.requests.test is not defined 2015-09-14 09:09:55,653 info  [time-limited test] http.httpserver(821): added global filter 'safety' (class=org.apache.hadoop.hbase.http.httpserver$quotinginputfilter) 2015-09-14 09:09:55,654 info  [time-limited test] http.httpserver(821): added global filter 'clickjackingprevention' (class=org.apache.hadoop.hbase.http.clickjackingpreventionfilter) 2015-09-14 09:09:55,657 info  [time-limited test] http.httpserver(1013): jetty bound to port 49253 2015-09-14 09:09:55,657 info  [time-limited test] log.slf4jlog(67): jetty-6.1.26 2015-09-14 09:09:55,681 info  [time-limited test] log.slf4jlog(67): started selectchannelconnector@localhost:49253 2015-09-14 09:09:55,684 info  [time-limited test] log.slf4jlog(67): stopped selectchannelconnector@localhost:0 2015-09-14 09:09:55,817 info  [main] hbase.resourcechecker(172): after: http.testhttpserverlifecycle#teststoppedserverisnotalive thread=9 (was 9), openfiledescriptor=201 (was 201), maxfiledescriptor=32768 (was 32768), systemloadaverage=11 2015-09-14 09:09:55,847 info  [main] hbase.resourcechecker(148): before: http.testhttpserverlifecycle#teststoppingtwiceserverisallowed thread=9, openfiledescriptor=201, maxfiledescriptor=32768, systemloadaverage=112, processcount=507, ava 2015-09-14 09:09:55,879 info  [time-limited test] http.httprequestlog(69): http request log for http.requests.test is not defined 2015-09-14 09:09:55,880 info  [time-limited test] http.httpserver(821): added global filter 'safety' (class=org.apache.hadoop.hbase.http.httpserver$quotinginputfilter) 2015-09-14 09:09:55,880 info  [time-limited test] http.httpserver(821): added global filter 'clickjackingprevention' (class=org.apache.hadoop.hbase.http.clickjackingpreventionfilter) 2015-09-14 09:09:55,883 info  [time-limited test] http.httpserver(1013): jetty bound to port 53449 2015-09-14 09:09:55,884 info  [time-limited test] log.slf4jlog(67): jetty-6.1.26 2015-09-14 09:09:55,906 info  [time-limited test] log.slf4jlog(67): started selectchannelconnector@localhost:53449 2015-09-14 09:09:55,910 info  [time-limited test] log.slf4jlog(67): stopped selectchannelconnector@localhost:0 2015-09-14 09:09:56,038 info  [main] hbase.resourcechecker(172): after: http.testhttpserverlifecycle#teststoppingtwiceserverisallowed thread=9 (was 9), openfiledescriptor=201 (was 201), maxfiledescriptor=32768 (was 32768), systemloadavera this test came over from hadoop. looking at history, it usually passes up on apache jenkins so not disabling for now. just noting this failure. https://builds.apache.org/view/h-l/view/hbase/job/precommit-hbase-build/15579/testreport/org.apache.hadoop.hbase.http/testhttpserverlifecycle/history/ ",
        "label": 314
    },
    {
        "text": "list regions command in hbase shell is broken  i faced the following error in the master branch: hbase(main):001:0> create \"test\", \"cf\" 2019-07-07 23:24:15,254 warn  [main] util.nativecodeloader: unable to load native-hadoop library for your platform... using builtin-java classes where applicable created table test took 6.5678 seconds => hbase::table - test hbase(main):002:0> list_regions \"test\" error: undefined method `getclusterstatus' for #<java::orgapachehadoophbaseclient::adminoverasyncadmin:0x4ffced4e> did you mean?  get_cluster_metrics for usage try 'help \"list_regions\"' took 0.1997 seconds i didn't check if the other branches have the same issue. ",
        "label": 149
    },
    {
        "text": "be able to get multiple rowresult at one time from client side  now from the region server side, we can get multiple rows at one time now. it's mostly used to cache the results in the client side. but we still can only get one row by row at one time. i think it's better to let users also be able to get multiple rows if they want. ",
        "label": 549
    },
    {
        "text": "rest sometimes returns incomplete xml json data  rest sometimes return incomplete xml/json data. we found these exceptions in rest server. 13/11/15 11:40:51 error mortbay.log:/log/1a:23:11:0c:06:22*  javax.ws.rs.webapplicationexception: javax.xml.bind.marshalexception with linked exception:  [org.mortbay.jetty.eofexception]  at com.sun.jersey.core.provider.jaxb.abstractrootelementprovider.writeto(abstractrootelementprovider.java:159)  at com.sun.jersey.spi.container.containerresponse.write(containerresponse.java:306)  at com.sun.jersey.server.impl.application.webapplicationimpl._handlerequest(webapplicationimpl.java:1437)  at com.sun.jersey.server.impl.application.webapplicationimpl.handlerequest(webapplicationimpl.java:1349)  at com.sun.jersey.server.impl.application.webapplicationimpl.handlerequest(webapplicationimpl.java:1339)  at com.sun.jersey.spi.container.servlet.webcomponent.service(webcomponent.java:416)  at com.sun.jersey.spi.container.servlet.servletcontainer.service(servletcontainer.java:537)  at com.sun.jersey.spi.container.servlet.servletcontainer.service(servletcontainer.java:699)  at javax.servlet.http.httpservlet.service(httpservlet.java:847)  at org.mortbay.jetty.servlet.servletholder.handle(servletholder.java:511)  at org.mortbay.jetty.servlet.servlethandler$cachedchain.dofilter(servlethandler.java:1221)  at org.apache.hadoop.hbase.rest.filter.gzipfilter.dofilter(gzipfilter.java:73)  at org.mortbay.jetty.servlet.servlethandler$cachedchain.dofilter(servlethandler.java:1212)  at org.mortbay.jetty.servlet.servlethandler.handle(servlethandler.java:399)  at org.mortbay.jetty.servlet.sessionhandler.handle(sessionhandler.java:182)  at org.mortbay.jetty.handler.contexthandler.handle(contexthandler.java:766)  at org.mortbay.jetty.handler.handlerwrapper.handle(handlerwrapper.java:152)  at org.mortbay.jetty.server.handle(server.java:322)  at org.mortbay.jetty.httpconnection.handlerequest(httpconnection.java:542)  at org.mortbay.jetty.httpconnection$requesthandler.headercomplete(httpconnection.java:928)  at org.mortbay.jetty.httpparser.parsenext(httpparser.java:549)  at org.mortbay.jetty.httpparser.parseavailable(httpparser.java:212)  at org.mortbay.jetty.httpconnection.handle(httpconnection.java:404)  at org.mortbay.io.nio.selectchannelendpoint.run(selectchannelendpoint.java:410)  at org.mortbay.thread.queuedthreadpool$poolthread.run(queuedthreadpool.java:582)  caused by: javax.xml.bind.marshalexception with linked exception:  [org.mortbay.jetty.eofexception]  at com.sun.xml.bind.v2.runtime.marshallerimpl.write(marshallerimpl.java:325)  at com.sun.xml.bind.v2.runtime.marshallerimpl.marshal(marshallerimpl.java:249)  at javax.xml.bind.helpers.abstractmarshallerimpl.marshal(abstractmarshallerimpl.java:75)  at com.sun.jersey.json.impl.jsonmarshallerimpl.marshal(jsonmarshallerimpl.java:74)  at com.sun.jersey.core.provider.jaxb.abstractrootelementprovider.writeto(abstractrootelementprovider.java:179)  at com.sun.jersey.core.provider.jaxb.abstractrootelementprovider.writeto(abstractrootelementprovider.java:157)  ... 24 more  caused by: org.mortbay.jetty.eofexception  at org.mortbay.jetty.httpgenerator.flush(httpgenerator.java:791)  at org.mortbay.jetty.abstractgenerator$output.blockforoutput(abstractgenerator.java:551)  at org.mortbay.jetty.abstractgenerator$output.flush(abstractgenerator.java:572)  at org.mortbay.jetty.httpconnection$output.flush(httpconnection.java:1012)  at org.mortbay.jetty.abstractgenerator$output.write(abstractgenerator.java:651)  at org.mortbay.jetty.abstractgenerator$output.write(abstractgenerator.java:580)  at com.sun.jersey.spi.container.servlet.webcomponent$writer.write(webcomponent.java:307)  at com.sun.jersey.spi.container.containerresponse$committingoutputstream.write(containerresponse.java:134)  at com.sun.xml.bind.v2.runtime.output.utf8xmloutput.flushbuffer(utf8xmloutput.java:416)  at com.sun.xml.bind.v2.runtime.output.utf8xmloutput.text(utf8xmloutput.java:369)  at com.sun.xml.bind.v2.runtime.unmarshaller.base64data.writeto(base64data.java:303)  at com.sun.xml.bind.v2.runtime.output.utf8xmloutput.text(utf8xmloutput.java:310)  at com.sun.xml.bind.v2.runtime.xmlserializer.text(xmlserializer.java:425)  at com.sun.xml.bind.v2.model.impl.runtimebuiltinleafinfoimpl$pcdataimpl.writetext(runtimebuiltinleafinfoimpl.java:177)  at com.sun.xml.bind.v2.runtime.reflect.transducedaccessor$compositetransducedaccessorimpl.writetext(transducedaccessor.java:261)  at com.sun.xml.bind.v2.runtime.property.valueproperty.serializebody(valueproperty.java:87)  at com.sun.xml.bind.v2.runtime.classbeaninfoimpl.serializebody(classbeaninfoimpl.java:344)  at com.sun.xml.bind.v2.runtime.xmlserializer.childasxsitype(xmlserializer.java:700)  at com.sun.xml.bind.v2.runtime.property.arrayelementnodeproperty.serializeitem(arrayelementnodeproperty.java:69)  at com.sun.xml.bind.v2.runtime.property.arrayelementproperty.serializelistbody(arrayelementproperty.java:172)  at com.sun.xml.bind.v2.runtime.property.arrayerproperty.serializebody(arrayerproperty.java:159)  at com.sun.xml.bind.v2.runtime.classbeaninfoimpl.serializebody(classbeaninfoimpl.java:344)  at com.sun.xml.bind.v2.runtime.xmlserializer.childasxsitype(xmlserializer.java:700)  at com.sun.xml.bind.v2.runtime.property.arrayelementnodeproperty.serializeitem(arrayelementnodeproperty.java:69)  at com.sun.xml.bind.v2.runtime.property.arrayelementproperty.serializelistbody(arrayelementproperty.java:172)  at com.sun.xml.bind.v2.runtime.property.arrayerproperty.serializebody(arrayerproperty.java:159)  at com.sun.xml.bind.v2.runtime.classbeaninfoimpl.serializebody(classbeaninfoimpl.java:344)  at com.sun.xml.bind.v2.runtime.xmlserializer.childassolecontent(xmlserializer.java:597)  at com.sun.xml.bind.v2.runtime.classbeaninfoimpl.serializeroot(classbeaninfoimpl.java:328)  at com.sun.xml.bind.v2.runtime.xmlserializer.childasroot(xmlserializer.java:498)  at com.sun.xml.bind.v2.runtime.marshallerimpl.write(marshallerimpl.java:320)  ... 29 more  caused by: java.io.ioexception: connection reset by peer  at sun.nio.ch.filedispatcher.write0(native method)  at sun.nio.ch.socketdispatcher.write(socketdispatcher.java:29)  at sun.nio.ch.ioutil.writefromnativebuffer(ioutil.java:69)  at sun.nio.ch.ioutil.write(ioutil.java:26)  at sun.nio.ch.socketchannelimpl.write(socketchannelimpl.java:336)  at org.mortbay.io.nio.channelendpoint.flush(channelendpoint.java:170)  at org.mortbay.io.nio.selectchannelendpoint.flush(selectchannelendpoint.java:221)  at org.mortbay.jetty.httpgenerator.flush(httpgenerator.java:725)  ... 59 more ",
        "label": 411
    },
    {
        "text": "wrongregionexception when setting region online after  meta  split  after splitting .meta. when updating region information in .meta. (e.g. processregionopen) the wrong .meta. region was retrieved in regionmanager from onlinemetaregions map.   this is due to a bug in regionmanager.getfirstmetaregionforregion that was using the wrong key to get data out of the map (the table name instead of the region name) return onlinemetaregions.get(onlinemetaregions.headmap(newregion.gettabledesc().getname()).lastkey()); and when adding the region to the map it was added with onlinemetaregions.put(metaregion.getstartkey(), metaregion); so it's supposed to be taken out with:   return onlinemetaregions.get(onlinemetaregions.headmap(newregion.getregionname()).lastkey()); ",
        "label": 113
    },
    {
        "text": "snapshotfilecache causes too many cache refreshes  right now we decide whether to refresh the cache based on the lastmodified timestamp of all the snapshots and those \"running\" snapshots which is located in the /hbase/.hbase-snapshot/.tmp/<snapshot> directory we ran a exportsnapshot job which takes around 7 minutes between creating the directory and copying all the files. thus the modified time for the   /hbase/.hbase-snapshot/.tmp directory was 7 minutes earlier than the modified time of the  /hbase/.hbase-snapshot/.tmp/<snapshot> directory thus the cache refresh happens and doesn't pick up all the files but thinks its up to date as the modified time of the .tmp directory never changes. this is a bug as when the export job starts the cache never contains the files for the \"running\" snapshot and will fail. ",
        "label": 522
    },
    {
        "text": "arrayindexoutofboundsexception in privatecellutil qualifierstartswith  privatecellutil#qualifierstartswith does not check the qualifier length before comparing the qualifier with the argument, resulting in arrayindexoutofboundsexception when the argument length exceeds a the qualifier length.     ",
        "label": 214
    },
    {
        "text": "remove needless volatile declaration  zknamespacemanager.java public class zknamespacemanager extends zklistener {   private static final log log = logfactory.getlog(zknamespacemanager.class);   private final string nsznode;   private volatile navigablemap<string,namespacedescriptor> cache; //here hbaseadmin.java public class hbaseadmin implements admin {   private static final log log = logfactory.getlog(hbaseadmin.class);   private clusterconnection connection;   private volatile configuration conf; //here bufferedmutatorimpl.java public class bufferedmutatorimpl implements bufferedmutator {   private static final log log = logfactory.getlog(bufferedmutatorimpl.class);   private final exceptionlistener listener;   private final tablename tablename;   private final configuration conf;   private final concurrentlinkedqueue<mutation> writeasyncbuffer = new concurrentlinkedqueue<>();   private final atomiclong currentwritebuffersize = new atomiclong(0);   /**    * count the size of {@link bufferedmutatorimpl#writeasyncbuffer}.    * the {@link concurrentlinkedqueue#size()} is not a constant-time operation.    */   private final atomicinteger undealtmutationcount = new atomicinteger(0);   private volatile long writebuffersize;  //here ",
        "label": 508
    },
    {
        "text": "  backport hbase the links in the backup masters template are bad  hyperlinks for the backup masters are missing the http. this is causing the host names to be interpreted as the protocol in the web browser. ",
        "label": 229
    },
    {
        "text": "abstracttestdls testthreersabort sometimes fails in pre commit  https://builds.apache.org/job/precommit-hbase-build/10554/artifact/patchprocess/patch-unit-hbase-server.txt the error message is a bit strange: [error] testthreersabort(org.apache.hadoop.hbase.master.testdlsasyncfswal) time elapsed: 20.627 s <<< error!  org.apache.hadoop.hbase.tablenotfoundexception: region of 'hbase:namespace,,1513320505933.451650152885a3b41d0b1110deca513c.' is expected in the table of 'testthreersabort', but hbase:meta says it is in the table of 'hbase:namespace'. hbase:meta might be damaged. it fails for both fshlog and asyncfswal. need to dig more. ",
        "label": 149
    },
    {
        "text": "a lot of data is lost when name node crashed  i'm not sure exactly what arose it. there is some split failed logs .  the master should shutdown itself when the hdfs is crashed.  the logs is :  2011-03-22 13:21:55,056 warn   org.apache.hadoop.hbase.master.logcleaner: error while cleaning the   logs  java.net.connectexception: call to c4c1/157.5.100.1:9000 failed on connection exception: java.net.connectexception: connection refused  at org.apache.hadoop.ipc.client.wrapexception(client.java:844)  at org.apache.hadoop.ipc.client.call(client.java:820)  at org.apache.hadoop.ipc.rpc$invoker.invoke(rpc.java:221)  at $proxy5.getlisting(unknown source)  at sun.reflect.generatedmethodaccessor9.invoke(unknown source)  at sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:25)  at java.lang.reflect.method.invoke(method.java:597)  at org.apache.hadoop.io.retry.retryinvocationhandler.invokemethod(retryinvocationhandler.java:82)  at org.apache.hadoop.io.retry.retryinvocationhandler.invoke(retryinvocationhandler.java:59)  at $proxy5.getlisting(unknown source)  at org.apache.hadoop.hdfs.dfsclient.listpaths(dfsclient.java:614)  at org.apache.hadoop.hdfs.distributedfilesystem.liststatus(distributedfilesystem.java:252)  at org.apache.hadoop.hbase.master.logcleaner.chore(logcleaner.java:121)  at org.apache.hadoop.hbase.chore.run(chore.java:66)  at   org.apache.hadoop.hbase.master.logcleaner.run(logcleaner.java:154)  caused by: java.net.connectexception: connection refused  at sun.nio.ch.socketchannelimpl.checkconnect(native method)  at sun.nio.ch.socketchannelimpl.finishconnect(socketchannelimpl.java:574)  at org.apache.hadoop.net.socketiowithtimeout.connect(socketiowithtimeout.java:206)  at org.apache.hadoop.net.netutils.connect(netutils.java:408)  at org.apache.hadoop.ipc.client$connection.setupiostreams(client.java:332)  at org.apache.hadoop.ipc.client$connection.access$2000(client.java:202)  at org.apache.hadoop.ipc.client.getconnection(client.java:943)  at org.apache.hadoop.ipc.client.call(client.java:788)  ... 13 more  2011-03-22 13:21:56,056 info org.apache.hadoop.ipc.client: retrying connect to server: c4c1/157.5.100.1:9000. already tried 0 time(s).  2011-03-22 13:21:57,057 info org.apache.hadoop.ipc.client: retrying connect to server: c4c1/157.5.100.1:9000. already tried 1 time(s).  2011-03-22 13:21:58,057 info org.apache.hadoop.ipc.client: retrying connect to server: c4c1/157.5.100.1:9000. already tried 2 time(s).  2011-03-22 13:21:59,057 info org.apache.hadoop.ipc.client: retrying connect to server: c4c1/157.5.100.1:9000. already tried 3 time(s).  2011-03-22 13:22:00,058 info org.apache.hadoop.ipc.client: retrying connect to server: c4c1/157.5.100.1:9000. already tried 4 time(s).  2011-03-22 13:22:01,058 info org.apache.hadoop.ipc.client: retrying connect to server: c4c1/157.5.100.1:9000. already tried 5 time(s).  2011-03-22 13:22:02,059 info org.apache.hadoop.ipc.client: retrying connect to server: c4c1/157.5.100.1:9000. already tried 6 time(s).  2011-03-22 13:22:03,059 info org.apache.hadoop.ipc.client: retrying connect to server: c4c1/157.5.100.1:9000. already tried 7 time(s).  2011-03-22 13:22:04,059 info org.apache.hadoop.ipc.client: retrying connect to server: c4c1/157.5.100.1:9000. already tried 8 time(s).  2011-03-22 13:22:05,060 info org.apache.hadoop.ipc.client: retrying connect to server: c4c1/157.5.100.1:9000. already tried 9 time(s).  2011-03-22 13:22:05,060 error   org.apache.hadoop.hbase.master.masterfilesystem: failed splitting   hdfs://c4c1:9000/hbase/.logs/c4c9.site,60020,1300767633398  java.net.connectexception: call to c4c1/157.5.100.1:9000 failed on connection exception: java.net.connectexception: connection refused  at org.apache.hadoop.ipc.client.wrapexception(client.java:844)  at org.apache.hadoop.ipc.client.call(client.java:820)  at org.apache.hadoop.ipc.rpc$invoker.invoke(rpc.java:221)  at $proxy5.getfileinfo(unknown source)  at sun.reflect.generatedmethodaccessor4.invoke(unknown source)  at sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:25)  at java.lang.reflect.method.invoke(method.java:597)  at org.apache.hadoop.io.retry.retryinvocationhandler.invokemethod(retryinvocationhandler.java:82)  at org.apache.hadoop.io.retry.retryinvocationhandler.invoke(retryinvocationhandler.java:59)  at $proxy5.getfileinfo(unknown source)  at org.apache.hadoop.hdfs.dfsclient.getfileinfo(dfsclient.java:623)  at org.apache.hadoop.hdfs.distributedfilesystem.getfilestatus(distributedfilesystem.java:461)  at org.apache.hadoop.fs.filesystem.exists(filesystem.java:690)  at org.apache.hadoop.hbase.regionserver.wal.hlogsplitter.splitlog(hlogsplitter.java:177)  at org.apache.hadoop.hbase.master.masterfilesystem.splitlog(masterfilesystem.java:196)  at org.apache.hadoop.hbase.master.handler.servershutdownhandler.process(servershutdownhandler.java:95)  at org.apache.hadoop.hbase.executor.eventhandler.run(eventhandler.java:151)  at java.util.concurrent.threadpoolexecutor$worker.runtask(threadpoolexecutor.java:886)  at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:908)  at java.lang.thread.run(thread.java:662)  caused by: java.net.connectexception: connection refused  at sun.nio.ch.socketchannelimpl.checkconnect(native method)  at sun.nio.ch.socketchannelimpl.finishconnect(socketchannelimpl.java:574)  at org.apache.hadoop.net.socketiowithtimeout.connect(socketiowithtimeout.java:206)  at org.apache.hadoop.net.netutils.connect(netutils.java:408)  at org.apache.hadoop.ipc.client$connection.setupiostreams(client.java:332)  at org.apache.hadoop.ipc.client$connection.access$2000(client.java:202)  at org.apache.hadoop.ipc.client.getconnection(client.java:943)  at org.apache.hadoop.ipc.client.call(client.java:788)  ... 18 more  2011-03-22 13:22:45,600 info org.apache.hadoop.ipc.client: retrying connect to server: c4c1/157.5.100.1:9000. already tried 0 time(s).  2011-03-22 13:22:46,600 info org.apache.hadoop.ipc.client: retrying connect to server: c4c1/157.5.100.1:9000. already tried 1 time(s).  2011-03-22 13:22:47,601 info org.apache.hadoop.ipc.client: retrying connect to server: c4c1/157.5.100.1:9000. already tried 2 time(s).  2011-03-22 13:22:48,601 info org.apache.hadoop.ipc.client: retrying connect to server: c4c1/157.5.100.1:9000. already tried 3 time(s).  2011-03-22 13:22:49,601 info org.apache.hadoop.ipc.client: retrying connect to server: c4c1/157.5.100.1:9000. already tried 4 time(s).  2011-03-22 13:22:50,602 info org.apache.hadoop.ipc.client: retrying connect to server: c4c1/157.5.100.1:9000. already tried 5 time(s).  2011-03-22 13:22:51,602 info org.apache.hadoop.ipc.client: retrying connect to server: c4c1/157.5.100.1:9000. already tried 6 time(s).  2011-03-22 13:22:52,602 info org.apache.hadoop.ipc.client: retrying connect to server: c4c1/157.5.100.1:9000. already tried 7 time(s).  2011-03-22 13:22:53,603 info org.apache.hadoop.ipc.client: retrying connect to server: c4c1/157.5.100.1:9000. already tried 8 time(s).  2011-03-22 13:22:54,603 info org.apache.hadoop.ipc.client: retrying connect to server: c4c1/157.5.100.1:9000. already tried 9 time(s).  2011-03-22 13:22:54,603 warn   org.apache.hadoop.hbase.master.logcleaner: error while cleaning the   logs  java.net.connectexception: call to c4c1/157.5.100.1:9000 failed on connection exception: java.net.connectexception: connection refused  at org.apache.hadoop.ipc.client.wrapexception(client.java:844)  at org.apache.hadoop.ipc.client.call(client.java:820)  at org.apache.hadoop.ipc.rpc$invok ",
        "label": 529
    },
    {
        "text": "in write heavy scenario one of the regions does not get flushed causing regiontoobusyexception  i got this while testing 0.98rc. but am not sure if it is specific to this version. doesn't seem so to me.   also it is something similar to hbase-5312 and hbase-5568. using 10 threads i do writes to 4 rs using ycsb. the table created has 200 regions. in one of the run with 0.98 server and 0.98 client i faced this problem like the hlogs became more and the system requested flushes for those many regions.  one by one everything was flushed except one and that one thing remained unflushed. the ripple effect of this on the client side com.yahoo.ycsb.dbexception: org.apache.hadoop.hbase.client.retriesexhaustedwithdetailsexception: failed 54 actions: regiontoobusyexception: 54 times,         at com.yahoo.ycsb.db.hbaseclient.cleanup(hbaseclient.java:245)         at com.yahoo.ycsb.dbwrapper.cleanup(dbwrapper.java:73)         at com.yahoo.ycsb.clientthread.run(client.java:307) caused by: org.apache.hadoop.hbase.client.retriesexhaustedwithdetailsexception: failed 54 actions: regiontoobusyexception: 54 times,         at org.apache.hadoop.hbase.client.asyncprocess$batcherrors.makeexception(asyncprocess.java:187)         at org.apache.hadoop.hbase.client.asyncprocess$batcherrors.access$500(asyncprocess.java:171)         at org.apache.hadoop.hbase.client.asyncprocess.geterrors(asyncprocess.java:897)         at org.apache.hadoop.hbase.client.htable.backgroundflushcommits(htable.java:961)         at org.apache.hadoop.hbase.client.htable.flushcommits(htable.java:1225)         at com.yahoo.ycsb.db.hbaseclient.cleanup(hbaseclient.java:232)         ... 2 more on one of the rs 2014-02-11 08:45:58,714 info  [regionserver60020.logroller] wal.fshlog: too many hlogs: logs=38, maxlogs=32; forcing flush of 23 regions(s): 97d8ae2f78910cc5ded5fbb1ddad8492, d396b8a1da05c871edcb68a15608fdf2, 01a68742a1be3a9705d574ad68fec1d7, 1250381046301e7465b6cf398759378e, 127c133f47d0419bd5ab66675aff76d4, 9f01c5d25ddc6675f750968873721253, 29c055b5690839c2fa357cd8e871741e, ca4e33e3eb0d5f8314ff9a870fc43463, acfc6ae756e193b58d956cb71ccf0aa3, 187ea304069bc2a3c825bc10a59c7e84, 0ea411edc32d5c924d04bf126fa52d1e, e2f9331fc7208b1b230a24045f3c869e, d9309ca864055eddf766a330352efc7a, 1a71bdf457288d449050141b5ff00c69, 0ba9089db28e977f86a27f90bbab9717, fdbb3242d3b673bbe4790a47bc30576f, bbadaa1f0e62d8a8650080b824187850, b1a5de30d8603bd5d9022e09c574501b, cc6a9fabe44347ed65e7c325faa72030, 313b17dbff2497f5041b57fe13fa651e, 6b788c498503ddd3e1433a4cd3fb4e39, 3d71274fe4f815882e9626e1cfa050d1, acc43e4b42c1a041078774f4f20a3ff5 ...................................................... 2014-02-11 08:47:49,580 info  [regionserver60020.logroller] wal.fshlog: too many hlogs: logs=53, maxlogs=32; forcing flush of 2 regions(s): fdbb3242d3b673bbe4790a47bc30576f, 6b788c498503ddd3e1433a4cd3fb4e39 2014-02-11 09:42:44,237 info  [regionserver60020.periodicflusher] regionserver.hregionserver: regionserver60020.periodicflusher requesting flush for region usertable,user3654,1392107806977.fdbb3242d3b673bbe4790a47bc30576f. after a delay of 16689 2014-02-11 09:42:44,237 info  [regionserver60020.periodicflusher] regionserver.hregionserver: regionserver60020.periodicflusher requesting flush for region usertable,user6264,1392107806983.6b788c498503ddd3e1433a4cd3fb4e39. after a delay of 15868 2014-02-11 09:42:54,238 info  [regionserver60020.periodicflusher] regionserver.hregionserver: regionserver60020.periodicflusher requesting flush for region usertable,user3654,1392107806977.fdbb3242d3b673bbe4790a47bc30576f. after a delay of 20847 2014-02-11 09:42:54,238 info  [regionserver60020.periodicflusher] regionserver.hregionserver: regionserver60020.periodicflusher requesting flush for region usertable,user6264,1392107806983.6b788c498503ddd3e1433a4cd3fb4e39. after a delay of 20099 2014-02-11 09:43:04,238 info  [regionserver60020.periodicflusher] regionserver.hregionserver: regionserver60020.periodicflusher requesting flush for region usertable,user3654,1392107806977.fdbb3242d3b673bbe4790a47bc30576f. after a delay of 8677 2014-02-11 10:31:21,020 info  [regionserver60020.logroller] wal.fshlog: too many hlogs: logs=54, maxlogs=32; forcing flush of 1 regions(s): fdbb3242d3b673bbe4790a47bc30576f i restarted another rs and there were region movements with other regions but this region stays with the rs that has this issue. one important observation is that in hregion.internalflushcache() we need to add a debug log here // if nothing to flush, return and avoid logging start/stop flush.     if (this.memstoresize.get() <= 0) {       return false;     } because we can see that the region is requsted for a flush but it does not happen and no logs related to flush are printed in the logs. so due to some reason this memstore.size() has become 0( i assume this). the earlier bugs were also due to similar reason. ",
        "label": 441
    },
    {
        "text": "integrationtestddlmasterfailover uses old style immutable column descriptors  ",
        "label": 320
    },
    {
        "text": "on assign  if connectexception  reassign another server  2010-10-19 13:29:56,116 debug [thread-216-eventthread] master.assignmentmanager(321): handling transition=m_zk_region_offline, server=172.24.152.112:51845, region=1028785192/.meta. 2010-10-19 13:29:56,116 error [master:0;172.24.152.112:51845] master.servermanager(573): error connecting to region server org.apache.hadoop.hbase.client.retriesexhaustedexception: failed setting up proxy interface org.apache.hadoop.hbase.ipc.hregioninterface to /172.24.152.112:51850 after attempts=1 at org.apache.hadoop.hbase.ipc.hbaserpc.waitforproxy(hbaserpc.java:351) at org.apache.hadoop.hbase.client.hconnectionmanager$hconnectionimplementation.gethregionconnection(hconnectionmanager.java:936) at org.apache.hadoop.hbase.master.servermanager.getserverconnection(servermanager.java:568) at org.apache.hadoop.hbase.master.servermanager.sendregionopen(servermanager.java:511) at org.apache.hadoop.hbase.master.assignmentmanager.assign(assignmentmanager.java:726) at org.apache.hadoop.hbase.master.assignmentmanager.assign(assignmentmanager.java:640) at org.apache.hadoop.hbase.master.assignmentmanager.assignmeta(assignmentmanager.java:935) at org.apache.hadoop.hbase.master.hmaster.assignrootandmeta(hmaster.java:430) at org.apache.hadoop.hbase.master.hmaster.finishinitialization(hmaster.java:377) at org.apache.hadoop.hbase.master.hmaster.run(hmaster.java:266) at java.lang.thread.run(thread.java:637) caused by: java.net.connectexception: connection refused at sun.nio.ch.socketchannelimpl.checkconnect(native method) at sun.nio.ch.socketchannelimpl.finishconnect(socketchannelimpl.java:574) at org.apache.hadoop.net.socketiowithtimeout.connect(socketiowithtimeout.java:206) at org.apache.hadoop.net.netutils.connect(netutils.java:404) at org.apache.hadoop.hbase.ipc.hbaseclient$connection.setupiostreams(hbaseclient.java:310) at org.apache.hadoop.hbase.ipc.hbaseclient.getconnection(hbaseclient.java:860) at org.apache.hadoop.hbase.ipc.hbaseclient.call(hbaseclient.java:728) at org.apache.hadoop.hbase.ipc.hbaserpc$invoker.invoke(hbaserpc.java:255) at $proxy10.getprotocolversion(unknown source) at org.apache.hadoop.hbase.ipc.hbaserpc.getproxy(hbaserpc.java:412) at org.apache.hadoop.hbase.ipc.hbaserpc.getproxy(hbaserpc.java:388) at org.apache.hadoop.hbase.ipc.hbaserpc.getproxy(hbaserpc.java:435) at org.apache.hadoop.hbase.ipc.hbaserpc.waitforproxy(hbaserpc.java:345) ... 10 more 2010-10-19 13:29:56,116 warn  [master:0;172.24.152.112:51845] master.assignmentmanager(730): failed assignment of .meta.,,1.1028785192 to servername=172.24.152.112,51850,1287520189982, load=(requests=0, regions=0, usedheap=60, maxheap=123) java.lang.runtimeexception: fatal error connection to rs at org.apache.hadoop.hbase.master.servermanager.getserverconnection(servermanager.java:574) at org.apache.hadoop.hbase.master.servermanager.sendregionopen(servermanager.java:511) at org.apache.hadoop.hbase.master.assignmentmanager.assign(assignmentmanager.java:726) at org.apache.hadoop.hbase.master.assignmentmanager.assign(assignmentmanager.java:640) at org.apache.hadoop.hbase.master.assignmentmanager.assignmeta(assignmentmanager.java:935) at org.apache.hadoop.hbase.master.hmaster.assignrootandmeta(hmaster.java:430) at org.apache.hadoop.hbase.master.hmaster.finishinitialization(hmaster.java:377) at org.apache.hadoop.hbase.master.hmaster.run(hmaster.java:266) at java.lang.thread.run(thread.java:637) caused by: org.apache.hadoop.hbase.client.retriesexhaustedexception: failed setting up proxy interface org.apache.hadoop.hbase.ipc.hregioninterface to /172.24.152.112:51850 after attempts=1 at org.apache.hadoop.hbase.ipc.hbaserpc.waitforproxy(hbaserpc.java:351) at org.apache.hadoop.hbase.client.hconnectionmanager$hconnectionimplementation.gethregionconnection(hconnectionmanager.java:936) at org.apache.hadoop.hbase.master.servermanager.getserverconnection(servermanager.java:568) ... 8 more caused by: java.net.connectexception: connection refused at sun.nio.ch.socketchannelimpl.checkconnect(native method) at sun.nio.ch.socketchannelimpl.finishconnect(socketchannelimpl.java:574) at org.apache.hadoop.net.socketiowithtimeout.connect(socketiowithtimeout.java:206) at org.apache.hadoop.net.netutils.connect(netutils.java:404) at org.apache.hadoop.hbase.ipc.hbaseclient$connection.setupiostreams(hbaseclient.java:310) at org.apache.hadoop.hbase.ipc.hbaseclient.getconnection(hbaseclient.java:860) at org.apache.hadoop.hbase.ipc.hbaseclient.call(hbaseclient.java:728) at org.apache.hadoop.hbase.ipc.hbaserpc$invoker.invoke(hbaserpc.java:255) at $proxy10.getprotocolversion(unknown source) at org.apache.hadoop.hbase.ipc.hbaserpc.getproxy(hbaserpc.java:412) at org.apache.hadoop.hbase.ipc.hbaserpc.getproxy(hbaserpc.java:388) at org.apache.hadoop.hbase.ipc.hbaserpc.getproxy(hbaserpc.java:435) at org.apache.hadoop.hbase.ipc.hbaserpc.waitforproxy(hbaserpc.java:345) ... 10 more ",
        "label": 314
    },
    {
        "text": "testcatalogjanitor occasionally fails  here is the os:  linux sea0 2.6.38-11-generic #48-ubuntu smp fri jul 29 19:02:55 utc 2011 x86_64 x86_64 x86_64 gnu/linux testarchiveoldregion(org.apache.hadoop.hbase.master.testcatalogjanitor)  time elapsed: 0.007 sec  <<< failure! java.lang.assertionerror: not the same number of current files expected (2):      gotten (0): not found: _store0 _store1 extra:   at org.junit.assert.fail(assert.java:93)   at org.junit.assert.asserttrue(assert.java:43)   at org.junit.assert.assertnull(assert.java:551)   at org.apache.hadoop.hbase.util.hfilearchivetestingutil.assertarchiveequaltooriginal(hfilearchivetestingutil.java:132)   at org.apache.hadoop.hbase.util.hfilearchivetestingutil.assertarchiveequaltooriginal(hfilearchivetestingutil.java:95)   at org.apache.hadoop.hbase.master.testcatalogjanitor.testarchiveoldregion(testcatalogjanitor.java:623) ",
        "label": 236
    },
    {
        "text": "hfile level load tester with compaction and random read workloads  this is a load testing tool for hfile implementations, which supports two workloads: compactions (merge the input hfiles). a special case of this is only one input, which allows to do hfile format conversions. random reads. launches the specified number of threads that do seeks and short scans on randomly generated keys. the original purpose of this tool was to ensure that hfile format v2 did not introduce performance regressions. keys for the read workload are generated randomly between the first and the last key of the hfile. at each position, instead of precisely calculating the correct probability for every byte value b, we select a uniformly random byte between in the allowed [low, high] range. in addition, there is a heuristic that determines the positions at which the key has hex characters, and the random key contains hex characters at those positions as well. example output for the random read workload:  time: 120 sec, seek/sec: 8290, kv/sec: 30351, kv bytes/sec: 91868121, blk/sec: 10147, unique keys: 232779 ",
        "label": 324
    },
    {
        "text": "regionserver doesn't retry to check if base node is available  i've a script that starts hbase and a couple of region servers in distributed mode (hbase.cluster.distributed = true) $hbase_home/bin/start-hbase.sh $hbase_home/bin/local-regionservers.sh start 1 2 3 but the region servers are not able to start...  it seems that during the rs start the the znode is still not available, and hregionserver.initializezookeeper() check just once if the base not is available. 2012-03-28 21:54:05,013 info org.apache.hadoop.hbase.regionserver.hregionserver: stopped: check the value configured in 'zookeeper.znode.parent'. there could be a mismatch with the one configured in the master. 2012-03-28 21:54:08,598 fatal org.apache.hadoop.hbase.regionserver.hregionserver: aborting region server localhost,60202,1332964444824: initialization of rs failed.  hence aborting rs. java.io.ioexception: received the shutdown message while waiting. at org.apache.hadoop.hbase.regionserver.hregionserver.blockandcheckifstopped(hregionserver.java:626) at org.apache.hadoop.hbase.regionserver.hregionserver.initializezookeeper(hregionserver.java:596) at org.apache.hadoop.hbase.regionserver.hregionserver.preregistrationinitialization(hregionserver.java:558) at org.apache.hadoop.hbase.regionserver.hregionserver.run(hregionserver.java:672) at java.lang.thread.run(thread.java:662) ",
        "label": 309
    },
    {
        "text": "checkandput implementation doesnt verify row param and writable row are the same  the api checkandput, and on the server side checkandmutate doesn't enforce that the row in the api call and the row in the passed writable that should be executed if the check passes, are the same row! looking at the code, if someone were to 'fool' us, we'd probably end up with rows in the wrong region in the worst case. or we'd end up with non-locked puts/deletes to different rows since the checkandmutate grabs the row lock and calls put/delete methods that do not grab row locks. ",
        "label": 547
    },
    {
        "text": "fix concerns raised in hbase related to halfstorefilereader  pls refer to the comment  https://issues.apache.org/jira/browse/hbase-5922?focusedcommentid=13269346&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13269346.  raised this issue to solve that comment. just incase we don't forget it. ",
        "label": 46
    },
    {
        "text": "long sleeping in hconnectionmanager after thread is interrupted  we run sometimes into the problem that when a thread running hbase client code is interrupted, it hangs. the problem is it is sleeping in hconnectionmanager, in the methods locateregioninmeta and getregionserverwithretries, where there is code like this: try{   thread.sleep(getpausetime(tries)); } catch (interruptedexception e) {   // continue } which is located in a for-loop, so it will keep retrying even when someone requested the thread to stop its work. the attached patch proposes as fix to re-assert the interrupted status of the thread and to throw an ioexception. some other cases of interruptedexception-handling in the same class do a similar thing, though sometimes returning null or breaking. i found returning null causes npe's in other locations so i think it is better to throw an informative exception. side thought: i would not be against propagating the interruptedexception all the way up to the client apis (htable/hbaseadmin), so that users who want to support interruptable threads do not have to check the interrupted flag. i'd need to check some more but i have the impression that now sometimes methods like htable.get() simply return null when a thread is interrupted. some background on good ways of handling interruptedexceptions can be found here:  http://www.ibm.com/developerworks/java/library/j-jtp05236.html ",
        "label": 83
    },
    {
        "text": "testsplitlogworker testmultipletasks fails occasionally  from https://builds.apache.org/job/hbase-trunk-on-hadoop-2.0.0/857/testreport/junit/org.apache.hadoop.hbase.regionserver/testsplitlogworker/testmultipletasks/ : 2013-11-30 01:13:23,022 info  [pool-1-thread-1] hbase.resourcechecker(147): before: regionserver.testsplitlogworker#testmultipletasks thread=16, openfiledescriptor=157, maxfiledescriptor=40000, systemloadaverage=338, processcount=144, availablememorymb=1474, connectioncount=0 2013-11-30 01:13:23,026 info  [pool-1-thread-1] zookeeper.minizookeepercluster(200): started minizk cluster and connect 1 zk server on client port: 53800 2013-11-30 01:13:23,029 info  [pool-1-thread-1] zookeeper.recoverablezookeeper(120): process identifier=split-log-worker-tests connecting to zookeeper ensemble=localhost:53800 2013-11-30 01:13:23,249 debug [pool-1-thread-1-eventthread] zookeeper.zookeeperwatcher(310): split-log-worker-tests, quorum=localhost:53800, baseznode=/hbase received zookeeper event, type=none, state=syncconnected, path=null 2013-11-30 01:13:23,251 debug [pool-1-thread-1-eventthread] zookeeper.zookeeperwatcher(387): split-log-worker-tests-0x142a69133500000 connected 2013-11-30 01:13:23,261 debug [pool-1-thread-1] regionserver.testsplitlogworker(105): /hbase created 2013-11-30 01:13:23,270 debug [pool-1-thread-1] regionserver.testsplitlogworker(108): /hbase/splitwal created 2013-11-30 01:13:23,278 debug [pool-1-thread-1] executor.executorservice(99): starting executor service name=rs_log_replay_ops-testsplitlogworker, corepoolsize=10, maxpoolsize=10 2013-11-30 01:13:23,278 info  [pool-1-thread-1] regionserver.testsplitlogworker(246): testmultipletasks 2013-11-30 01:13:23,280 info  [splitlogworker-tmt_svr,1,1] regionserver.splitlogworker(175): splitlogworker tmt_svr,1,1 starting 2013-11-30 01:13:23,380 info  [pool-1-thread-1] hbase.waiter(174): waiting up to [1,500] milli-secs(wait.for.ratio=[1]) 2013-11-30 01:13:23,394 debug [pool-1-thread-1-eventthread] zookeeper.zookeeperwatcher(310): split-log-worker-tests-0x142a69133500000, quorum=localhost:53800, baseznode=/hbase received zookeeper event, type=nodechildrenchanged, state=syncconnected, path=/hbase/splitwal 2013-11-30 01:13:23,394 debug [pool-1-thread-1-eventthread] regionserver.splitlogworker(595): tasks arrived or departed 2013-11-30 01:13:23,394 info  [pool-1-thread-1] hbase.waiter(174): waiting up to [1,500] milli-secs(wait.for.ratio=[1]) 2013-11-30 01:13:23,402 info  [splitlogworker-tmt_svr,1,1] regionserver.splitlogworker(363): worker tmt_svr,1,1 acquired task /hbase/splitwal/tmt_task 2013-11-30 01:13:23,410 debug [pool-1-thread-1-eventthread] zookeeper.zookeeperwatcher(310): split-log-worker-tests-0x142a69133500000, quorum=localhost:53800, baseznode=/hbase received zookeeper event, type=nodechildrenchanged, state=syncconnected, path=/hbase/splitwal 2013-11-30 01:13:23,410 debug [pool-1-thread-1-eventthread] regionserver.splitlogworker(595): tasks arrived or departed 2013-11-30 01:13:23,418 debug [pool-1-thread-1-eventthread] zookeeper.zookeeperwatcher(310): split-log-worker-tests-0x142a69133500000, quorum=localhost:53800, baseznode=/hbase received zookeeper event, type=nodedatachanged, state=syncconnected, path=/hbase/splitwal/tmt_task 2013-11-30 01:13:23,419 info  [pool-1-thread-1] hbase.waiter(174): waiting up to [1,500] milli-secs(wait.for.ratio=[1]) 2013-11-30 01:13:23,420 info  [pool-1-thread-1-eventthread] regionserver.splitlogworker(522): task /hbase/splitwal/tmt_task preempted from tmt_svr,1,1, current task state and owner=owned another-worker,1,1 2013-11-30 01:13:23,420 info  [pool-1-thread-1-eventthread] regionserver.splitlogworker(608): sending interrupt to stop the worker thread 2013-11-30 01:13:23,420 warn  [splitlogworker-tmt_svr,1,1] regionserver.splitlogworker(374): interrupted while yielding for other region servers java.lang.interruptedexception: sleep interrupted at java.lang.thread.sleep(native method) at org.apache.hadoop.hbase.regionserver.splitlogworker.grabtask(splitlogworker.java:372) at org.apache.hadoop.hbase.regionserver.splitlogworker.taskloop(splitlogworker.java:251) at org.apache.hadoop.hbase.regionserver.splitlogworker.run(splitlogworker.java:209) at java.lang.thread.run(thread.java:662) 2013-11-30 01:13:23,427 info  [splitlogworker-tmt_svr,1,1] regionserver.splitlogworker(363): worker tmt_svr,1,1 acquired task /hbase/splitwal/tmt_task_2 2013-11-30 01:13:24,331 debug [splitlogworker-tmt_svr,1,1] regionserver.splitlogworker(253): current region server tmt_svr,1,1 has 2 tasks in progress and can't take more. 2013-11-30 01:13:24,921 info  [pool-1-thread-1] regionserver.splitlogworker(608): sending interrupt to stop the worker thread 2013-11-30 01:13:24,921 info  [splitlogworker-tmt_svr,1,1] regionserver.splitlogworker(299): splitlogworker interrupted while waiting for task, exiting: java.lang.interruptedexception 2013-11-30 01:13:24,921 info  [splitlogworker-tmt_svr,1,1] regionserver.splitlogworker(216): splitlogworker tmt_svr,1,1 exiting 2013-11-30 01:13:24,922 warn  [rs_log_replay_ops-testsplitlogworker-0] regionserver.splitlogworker(426): interrupted while trying to assert ownership of /hbase/splitwal/tmt_task java.lang.interruptedexception at java.lang.object.wait(native method) at java.lang.object.wait(object.java:485) at org.apache.zookeeper.clientcnxn.submitrequest(clientcnxn.java:1309) at org.apache.zookeeper.zookeeper.setdata(zookeeper.java:1264) at org.apache.hadoop.hbase.zookeeper.recoverablezookeeper.setdata(recoverablezookeeper.java:407) at org.apache.hadoop.hbase.regionserver.splitlogworker.attempttoowntask(splitlogworker.java:406) at org.apache.hadoop.hbase.regionserver.splitlogworker$2.progress(splitlogworker.java:474) at org.apache.hadoop.hbase.regionserver.testsplitlogworker$2.exec(testsplitlogworker.java:135) at org.apache.hadoop.hbase.regionserver.handler.hlogsplitterhandler.process(hlogsplitterhandler.java:79) at org.apache.hadoop.hbase.executor.eventhandler.run(eventhandler.java:128) at java.util.concurrent.threadpoolexecutor$worker.runtask(threadpoolexecutor.java:895) at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:918) at java.lang.thread.run(thread.java:662) 2013-11-30 01:13:24,922 warn  [rs_log_replay_ops-testsplitlogworker-1] regionserver.splitlogworker(426): interrupted while trying to assert ownership of /hbase/splitwal/tmt_task_2 java.lang.interruptedexception at java.lang.object.wait(native method) at java.lang.object.wait(object.java:485) at org.apache.zookeeper.clientcnxn.submitrequest(clientcnxn.java:1309) at org.apache.zookeeper.zookeeper.setdata(zookeeper.java:1264) at org.apache.hadoop.hbase.zookeeper.recoverablezookeeper.setdata(recoverablezookeeper.java:407) at org.apache.hadoop.hbase.regionserver.splitlogworker.attempttoowntask(splitlogworker.java:406) at org.apache.hadoop.hbase.regionserver.splitlogworker$2.progress(splitlogworker.java:474) at org.apache.hadoop.hbase.regionserver.testsplitlogworker$2.exec(testsplitlogworker.java:135) at org.apache.hadoop.hbase.regionserver.handler.hlogsplitterhandler.process(hlogsplitterhandler.java:79) at org.apache.hadoop.hbase.executor.eventhandler.run(eventhandler.java:128) at java.util.concurrent.threadpoolexecutor$worker.runtask(threadpoolexecutor.java:895) at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:918) at java.lang.thread.run(thread.java:662) 2013-11-30 01:13:24,922 warn  [rs_log_replay_ops-testsplitlogworker-0] regionserver.splitlogworker$2(477): failed to heartbeat the task/hbase/splitwal/tmt_task 2013-11-30 01:13:24,923 warn  [rs_log_replay_ops-testsplitlogworker-1] regionserver.splitlogworker$2(477): failed to heartbeat the task/hbase/splitwal/tmt_task_2 2013-11-30 01:13:24,923 warn  [rs_log_replay_ops-testsplitlogworker-0] handler.hlogsplitterhandler(87): task execution prempted tmt_task 2013-11-30 01:13:24,923 warn  [rs_log_replay_ops-testsplitlogworker-1] handler.hlogsplitterhandler(87): task execution prempted tmt_task_2 2013-11-30 01:13:24,923 info  [rs_log_replay_ops-testsplitlogworker-0] handler.hlogsplitterhandler(107): worker tmt_svr,1,1 done with task /hbase/splitwal/tmt_task in 1520ms 2013-11-30 01:13:24,924 info  [rs_log_replay_ops-testsplitlogworker-1] handler.hlogsplitterhandler(107): worker tmt_svr,1,1 done with task /hbase/splitwal/tmt_task_2 in 1497ms 2013-11-30 01:13:24,951 error [syncthread:0] server.nioservercnxn(180): unexpected exception:  java.nio.channels.cancelledkeyexception at sun.nio.ch.selectionkeyimpl.ensurevalid(selectionkeyimpl.java:55) at sun.nio.ch.selectionkeyimpl.interestops(selectionkeyimpl.java:59) at org.apache.zookeeper.server.nioservercnxn.sendbuffer(nioservercnxn.java:153) at org.apache.zookeeper.server.nioservercnxn.sendresponse(nioservercnxn.java:1076) at org.apache.zookeeper.server.finalrequestprocessor.processrequest(finalrequestprocessor.java:404) at org.apache.zookeeper.server.syncrequestprocessor.flush(syncrequestprocessor.java:167) at org.apache.zookeeper.server.syncrequestprocessor.run(syncrequestprocessor.java:101) 2013-11-30 01:13:24,952 info  [pool-1-thread-1] zookeeper.minizookeepercluster(249): shutdown minizk cluster with all zk servers 2013-11-30 01:13:24,966 info  [pool-1-thread-1] hbase.resourcechecker(171): after: regionserver.testsplitlogworker#testmultipletasks thread=18 (was 16) potentially hanging thread: pool-1-thread-1-sendthread(localhost:53800) java.lang.thread.sleep(native method) org.apache.zookeeper.clientcnxnsocketnio.cleanup(clientcnxnsocketnio.java:219) org.apache.zookeeper.clientcnxn$sendthread.cleanup(clientcnxn.java:1157) org.apache.zookeeper.clientcnxn$sendthread.run(clientcnxn.java:1097)  - thread leak? -, openfiledescriptor=163 (was 157) - openfiledescriptor leak? -, maxfiledescriptor=40000 (was 40000), systemloadaverage=327 (was 338),  'interrupted while trying to assert ownership' doesn't show up in a green run. ",
        "label": 233
    },
    {
        "text": "testfulllogreconstruction has duplicate config setting  the 0.98 branch's version of testfulllogreconstruction has a duplicate config setting during setupbeforeclass 54    // faster failover with cluster.shutdown();fs.close() idiom 55    c.setint(\"hbase.ipc.client.connect.max.retries\", 1); 56    c.setint(\"hbase.ipc.client.connect.max.retries\", 1); the 0.98.4 release has a line for setting this config and for the hdfs version. the branch-1 and master versions of this set of patches have only the setting of the hbase one, so i think that's the correct behavior. ",
        "label": 455
    },
    {
        "text": "add unit tests for org apache hadoop hbase util byterangeutils and org apache hadoop hbase util classes  i've analysed your codebase and noticed that org.apache.hadoop.hbase.util.byterangeutils and classes is not fully tested.  i've written some tests for the methods in this class with the help of diffblue cover. hopefully, these tests will help you detect any regressions caused by future code changes. if you would find it useful to have additional tests written for this repository, i would be more than happy to look at other classes that you consider important in a subsequent pr. ",
        "label": 159
    },
    {
        "text": "race condition in tableauthmanager updateglobalcache   when new global permissions are assigned, there is a race condition, during which further authorization checks relying on global permissions may fail. in tableauthmanager.updateglobalcache(), we have:     user_cache.clear();     group_cache.clear();     try {       initglobal(conf);     } catch (ioexception e) {       // never happens       log.error(\"error occured while updating the user cache\", e);     }     for (map.entry<string,tablepermission> entry : userperms.entries()) {       if (accesscontrollists.isgroupprincipal(entry.getkey())) {         group_cache.put(accesscontrollists.getgroupname(entry.getkey()),                         new permission(entry.getvalue().getactions()));       } else {         user_cache.put(entry.getkey(), new permission(entry.getvalue().getactions()));       }     } if authorization checks come in following the .clear() but before repopulating, they will fail. we should have some synchronization here to serialize multiple updates and use a cow type rebuild and reassign of the new maps. this particular issue crept in with the fix in hbase-6157, so i'm flagging for 0.94 and 0.96. ",
        "label": 180
    },
    {
        "text": "expose regionsintransition on master ui  there have been some bugs in the past that can cause a region to get \"stuck\" in transition. it's currently hard to see this without tailing the logs and noticing periodic timeout messages, etc. i'd like to expose the regionsintransition map on the master ui, so ops can quickly identify what might be causing a region to get \"stuck\". ",
        "label": 453
    },
    {
        "text": "the version of jruby we use now can't get interactive input from prompt  case 1: press enter hbase(main):002:0> disable_all 'chia(.*)' chia_1                                                                                                                                                                                                      disable the above 1 tables (y/n)? y^m case 2: press ctrl-j hbase(main):001:0> disable_all 'chia(.*)' chia_1                                                                                                                                                                                                      disable the above 1 tables (y/n)? y^j1 tables successfully disabled took 5.0059 seconds   ",
        "label": 0
    },
    {
        "text": "rearchitecting of server  client  api  key format  etc for  to discuss all the new and potential issues coming out of the change in key format (hbase-1234): zero-copy reads, client binary protocol, update of api (hbase-880), server optimizations, etc... ",
        "label": 247
    },
    {
        "text": "adding some fuction to check if a table region is in compaction  this feature will be helpful to find out if a major compaction is going on.  we can show if it is in any minor compaction too. ",
        "label": 242
    },
    {
        "text": "adding metadata to a table in the shell is both arcane and painful  in production we have hundreds of tables w/ whack names like 'aliaserv', 'ashish_bulk', 'age_gender_topics', etc. it be grand if you could look in master ui and see stuff like owner, eng group responsible, miscellaneous description, etc. now, htd has support for this; each carries a dictionary. whats a pita though is adding attributes to the dictionary. here is what seems to work on trunk (though i do not trust it is doing the right thing): hbase> create 'some_tablename', {name => 'd', version => 1, compression => 'lzo'} hbase> # here is how i added metadata hbase> disable 'some_tablename' hbase> alter 'some_tablename', method => 'table_att', owner => 'someon', config => {'environment' => 'blah blah', 'sizing' => 'the size should be between 0-10k most of the time with new urls coming in and getting removed as they are processed unless the pipeline has fallen behind', 'miscellaneous' => 'holds the list of urls waiting to be processed in the parked page detection analyzer in ingestion pipeline.'} ... describe... enable... the above doesn't work in 0.94. complains about the config, the keyword we are using for the htd dictionary. it works in 0.96 though i'd have to poke around some more to ensure it is doing the right thing. but this method => 'table_att' stuff is really ugly.... can we fix it? and i can't add table attributes on table create seemingly. a little bit of thought and a bit of ruby could clean this all up. ",
        "label": 406
    },
    {
        "text": "getclosest doesn't understand delete family  manifests as  hregioninfo was null or empty in  meta  a k a the bs problem  getclosestatorbefore was not converted to deal with the new delete types. it only knows how to process old style deletes. usually all is well as edits come in but its possible to get into state where you have persisted in one file a deletefamily for all in meta and in the file behind it, there are entries on the info family. since closest doesn't understand deletefamily, it will return the put rows only for the subsequent getfull, which knows how to work with deletefamilies fail. once this happens, table is hosed. seen on bradford stephens upload and at powerset. \"fix\" is flush and major compact. gives impression that hbase is 'delicate'. fixing. ",
        "label": 314
    },
    {
        "text": "rest wiki documentation incorrect  the only source of documentation for the rest interface is the wiki page, located at http://wiki.apache.org/hadoop/hbase/hbaserest. on trying to use this interface, we have noted the following issues: the wiki page says that the content-type sent for xml data is application/xml - the correct content-type is text/xml the wiki page says that the content-type multipart/related is supported - it is not yet supported as far as i can tell from the source of rowhandler. values must always be base64 encoded - wiki page does not state this for put operations finally, i think it would be desirable to have a package.html in src/java/org/apache/hadoop/hbase/rest/ ",
        "label": 549
    },
    {
        "text": "getfakedkey  improvement  make generating faked key algo more aggressive ",
        "label": 290
    },
    {
        "text": "testofflineregionreassginedaftermasterrestart times out sometimes   sometimes, i got this test timed out. the log is attached. it could be because the new cluster takes a while to process the dead server, or assign meta. ",
        "label": 242
    },
    {
        "text": "reduce buffer copies in ipc server response path  the new pb code is sloppy with buffers and makes several needless copies. this increases gc time a lot. a few simple changes can cut this back down. ",
        "label": 314
    },
    {
        "text": "error while reading from hfile in  got the following stacktrace during region split. 2012-04-24 16:05:42,168 warn org.apache.hadoop.hbase.regionserver.store: failed getting store size for value java.io.ioexception: requested block is out of range: 2906737606134037404, lastdatablockoffset: 84764558 at org.apache.hadoop.hbase.io.hfile.hfilereaderv2.readblock(hfilereaderv2.java:278) at org.apache.hadoop.hbase.io.hfile.hfileblockindex$blockindexreader.midkey(hfileblockindex.java:285) at org.apache.hadoop.hbase.io.hfile.hfilereaderv2.midkey(hfilereaderv2.java:402) at org.apache.hadoop.hbase.regionserver.storefile$reader.midkey(storefile.java:1638) at org.apache.hadoop.hbase.regionserver.store.getsplitpoint(store.java:1943) at org.apache.hadoop.hbase.regionserver.regionsplitpolicy.getsplitpoint(regionsplitpolicy.java:77) at org.apache.hadoop.hbase.regionserver.hregion.checksplit(hregion.java:4921) at org.apache.hadoop.hbase.regionserver.hregionserver.splitregion(hregionserver.java:2901) ",
        "label": 544
    },
    {
        "text": " optimization  major compaction should remove deletes as well as the deleted cell  currently major compactions retains both deletes and the deleted cell. it should remove both. ",
        "label": 314
    },
    {
        "text": "expose hbase scan object's  batch  property for intra row batching in thrift api  hbase scan object has a property called \"batch\". this property allows intra row batching. this property is not exposed in the thrift tscan specification. ",
        "label": 416
    },
    {
        "text": "backport hbase to branch  ",
        "label": 352
    },
    {
        "text": "hlog writer can do sync operations after lease has been recovered for split process   testhlogsplit.testlogcannotbewrittenonceparsed is failing. this test starts a thread that writes one edit to the log, syncs and counts. during this, a hlog.splitlog operation is started. splitlog recovers the log lease before reading the log, so that the original regionserver could not wake up and write after the split process started.   the test compares the number of edits reported by the split process and by the writer thread. writer thread (called zombie in the test) should report <= than the splitlog (sync() might raise after the last edit gets written and the edit won't get counted by zombie thread). however it appears that the zombie counts 1-2 more edits. so it looks like it can sync without a lease. this might be a hdfs-0.20 related issue. ",
        "label": 453
    },
    {
        "text": "when verifyandassignroot throws exception  the deadservers state cannot be changed  when verifyandassignroot throw exception, the deadservers state can not be changed.  the hmaster log has a lot of 'not running balancer because processing dead regionserver(s): []' information. hmaster log:  2011-07-09 01:38:31,820 info org.apache.hadoop.hbase.regionserver.wal.hlogsplitter: closed path hdfs://162.2.16.6:9000/hbase/htable_ufdr_035/fe7e51c0a74fac096cea8cdb3c9497a6/recovered.edits/0000000000204525422 (wrote 8 edits in 61583ms)  2011-07-09 01:38:31,836 error org.apache.hadoop.hbase.master.masterfilesystem: failed splitting hdfs://162.2.16.6:9000/hbase/.logs/162-2-6-187,20020,1310107719056  java.io.ioexception: hdfs://162.2.16.6:9000/hbase/.logs/162-2-6-187,20020,1310107719056/162-2-6-187%3a20020.1310143885352, entrystart=1878997244, pos=1879048192, end=2003890606, edit=80274  at sun.reflect.nativeconstructoraccessorimpl.newinstance0(native method)  at sun.reflect.nativeconstructoraccessorimpl.newinstance(nativeconstructoraccessorimpl.java:39)  at sun.reflect.delegatingconstructoraccessorimpl.newinstance(delegatingconstructoraccessorimpl.java:27)  at java.lang.reflect.constructor.newinstance(constructor.java:513)  at org.apache.hadoop.hbase.regionserver.wal.sequencefilelogreader.addfileinfotoexception(sequencefilelogreader.java:244)  at org.apache.hadoop.hbase.regionserver.wal.sequencefilelogreader.next(sequencefilelogreader.java:200)  at org.apache.hadoop.hbase.regionserver.wal.sequencefilelogreader.next(sequencefilelogreader.java:172)  at org.apache.hadoop.hbase.regionserver.wal.hlogsplitter.parsehlog(hlogsplitter.java:429)  at org.apache.hadoop.hbase.regionserver.wal.hlogsplitter.splitlog(hlogsplitter.java:262)  at org.apache.hadoop.hbase.regionserver.wal.hlogsplitter.splitlog(hlogsplitter.java:188)  at org.apache.hadoop.hbase.master.masterfilesystem.splitlog(masterfilesystem.java:201)  at org.apache.hadoop.hbase.master.handler.servershutdownhandler.process(servershutdownhandler.java:114)  at org.apache.hadoop.hbase.executor.eventhandler.run(eventhandler.java:156)  at java.util.concurrent.threadpoolexecutor$worker.runtask(threadpoolexecutor.java:886)  at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:908)  at java.lang.thread.run(thread.java:662)  caused by: java.io.ioexception: could not obtain block: blk_1310107715558_225636 file=/hbase/.logs/162-2-6-187,20020,1310107719056/162-2-6-187%3a20020.1310143885352  at org.apache.hadoop.hdfs.dfsclient$dfsinputstream.choosedatanode(dfsclient.java:2491)  at org.apache.hadoop.hdfs.dfsclient$dfsinputstream.blockseekto(dfsclient.java:2256)  at org.apache.hadoop.hdfs.dfsclient$dfsinputstream.read(dfsclient.java:2441)  at java.io.datainputstream.read(datainputstream.java:132)  at java.io.datainputstream.readfully(datainputstream.java:178)  at org.apache.hadoop.io.dataoutputbuffer$buffer.write(dataoutputbuffer.java:63)  at org.apache.hadoop.io.dataoutputbuffer.write(dataoutputbuffer.java:101)  at org.apache.hadoop.io.sequencefile$reader.next(sequencefile.java:1984)  at org.apache.hadoop.io.sequencefile$reader.next(sequencefile.java:1884)  at org.apache.hadoop.io.sequencefile$reader.next(sequencefile.java:1930)  at org.apache.hadoop.hbase.regionserver.wal.sequencefilelogreader.next(sequencefilelogreader.java:198)  ... 10 more  2011-07-09 01:38:33,052 debug org.apache.hadoop.hbase.master.hmaster: not running balancer because processing dead regionserver(s): [162-2-6-187,20020,1310107719056]  2011-07-09 01:39:29,946 warn org.apache.hadoop.hbase.master.catalogjanitor: failed scan of catalog table  java.net.sockettimeoutexception: call to /162.2.6.187:20020 failed on socket timeout exception: java.net.sockettimeoutexception: 60000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.socketchannel[connected local=/162.2.6.187:38721 remote=/162.2.6.187:20020]  at org.apache.hadoop.hbase.ipc.hbaseclient.wrapexception(hbaseclient.java:802)  at org.apache.hadoop.hbase.ipc.hbaseclient.call(hbaseclient.java:775)  at org.apache.hadoop.hbase.ipc.hbaserpc$invoker.invoke(hbaserpc.java:257)  at $proxy6.getregioninfo(unknown source)  at org.apache.hadoop.hbase.catalog.catalogtracker.verifyregionlocation(catalogtracker.java:424)  at org.apache.hadoop.hbase.catalog.catalogtracker.getmetaserverconnection(catalogtracker.java:272)  at org.apache.hadoop.hbase.catalog.catalogtracker.waitformeta(catalogtracker.java:331)  at org.apache.hadoop.hbase.catalog.catalogtracker.waitformetaserverconnectiondefault(catalogtracker.java:364)  at org.apache.hadoop.hbase.catalog.metareader.fullscan(metareader.java:255)  at org.apache.hadoop.hbase.catalog.metareader.fullscan(metareader.java:237)  at org.apache.hadoop.hbase.master.catalogjanitor.scan(catalogjanitor.java:116)  at org.apache.hadoop.hbase.master.catalogjanitor.chore(catalogjanitor.java:85)  at org.apache.hadoop.hbase.chore.run(chore.java:66)  caused by: java.net.sockettimeoutexception: 60000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.socketchannel[connected local=/162.2.6.187:38721 remote=/162.2.6.187:20020]  at org.apache.hadoop.net.socketiowithtimeout.doio(socketiowithtimeout.java:165)  at org.apache.hadoop.net.socketinputstream.read(socketinputstream.java:155)  at org.apache.hadoop.net.socketinputstream.read(socketinputstream.java:128)  at java.io.filterinputstream.read(filterinputstream.java:116)  at org.apache.hadoop.hbase.ipc.hbaseclient$connection$pinginputstream.read(hbaseclient.java:299)  at java.io.bufferedinputstream.fill(bufferedinputstream.java:218)  at java.io.bufferedinputstream.read(bufferedinputstream.java:237)  at java.io.datainputstream.readint(datainputstream.java:370)  at org.apache.hadoop.hbase.ipc.hbaseclient$connection.receiveresponse(hbaseclient.java:539)  at org.apache.hadoop.hbase.ipc.hbaseclient$connection.run(hbaseclient.java:477)  2011-07-09 01:39:29,946 error org.apache.hadoop.hbase.executor.eventhandler: caught throwable while processing event m_meta_server_shutdown  java.net.sockettimeoutexception: call to /162.2.6.187:20020 failed on socket timeout exception: java.net.sockettimeoutexception: 60000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.socketchannel[connected local=/162.2.6.187:38721 remote=/162.2.6.187:20020]  at org.apache.hadoop.hbase.ipc.hbaseclient.wrapexception(hbaseclient.java:802)  at org.apache.hadoop.hbase.ipc.hbaseclient.call(hbaseclient.java:775)  at org.apache.hadoop.hbase.ipc.hbaserpc$invoker.invoke(hbaserpc.java:257)  at $proxy6.getregioninfo(unknown source)  at org.apache.hadoop.hbase.catalog.catalogtracker.verifyregionlocation(catalogtracker.java:424)  at org.apache.hadoop.hbase.catalog.catalogtracker.verifyrootregionlocation(catalogtracker.java:471)  at org.apache.hadoop.hbase.master.handler.servershutdownhandler.verifyandassignroot(servershutdownhandler.java:90)  at org.apache.hadoop.hbase.master.handler.servershutdownhandler.process(servershutdownhandler.java:126)  at org.apache.hadoop.hbase.executor.eventhandler.run(eventhandler.java:156)  at java.util.concurrent.threadpoolexecutor$worker.runtask(threadpoolexecutor.java:886)  at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:908)  at java.lang.thread.run(thread.java:662)  caused by: java.net.sockettimeoutexception: 60000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.socketchannel[connected local=/162.2.6.187:38721 remote=/162.2.6.187:20020]  at org.apache.hadoop.net.socketiowithtimeout.doio(socketiowithtimeout.java:165)  at org.apache.hadoop.net.socketinputstream.read(socketinputstream.java:155)  at org.apache.hadoop.net.socketinputstream.read(socketinputstream.java:128)  at java.io.filterinputstream.read(filterinputstream.java:116)  at org.apache.hadoop.hbase.ipc.hbaseclient$connection$pinginputstream.read(hbaseclient.java:299)  at java.io.bufferedinputstream.fill(bufferedinputstream.java:218)  at java.io.bufferedinputstream.read(bufferedinputstream.java:237)  at java.io.datainputstream.readint(datainputstream.java:370)  at org.apache.hadoop.hbase.ipc.hbaseclient$connection.receiveresponse(hbaseclient.java:539)  at org.apache.hadoop.hbase.ipc.hbaseclient$connection.run(hbaseclient.java:477)  2011-07-09 01:40:26,474 debug org.apache.hadoop.hbase.master.servermanager: server 162-2-6-187,20020,1310146825674 came back up, removed it from the dead servers list  2011-07-09 01:40:26,515 info org.apache.hadoop.hbase.master.servermanager: registering server=162-2-6-187,20020,1310146825674, regioncount=0, userload=false  2011-07-09 01:40:28,410 info org.apache.hadoop.hbase.catalog.catalogtracker: failed verification of .meta.,,1 at address=162-2-6-187:20020; org.apache.hadoop.hbase.notservingregionexception: org.apache.hadoop.hbase.notservingregionexception: region is not online: .meta.,,1  ...  2011-07-09 01:53:33,052 debug org.apache.hadoop.hbase.master.hmaster: not running balancer because processing dead regionserver(s): []  2011-07-09 01:58:33,060 debug org.apache.hadoop.hbase.master.hmaster: not running balancer because processing dead regionserver(s): []  2011-07-09 02:03:33,061 debug org.apache.hadoop.hbase.master.hmaster: not running balancer because processing dead regionserver(s): []  2011-07-09 02:08:33,061 debug org.apache.hadoop.hbase.master.hmaster: not running balancer because processing dead regionserver(s): [] ",
        "label": 528
    },
    {
        "text": "cleanup the usage of deprecated replicationadmin  ",
        "label": 226
    },
    {
        "text": "cleanup before merging snapshots branch to trunk  there have been a lot of review comments from https://reviews.apache.org/r/9416 since our goal of merging snapshot feature to trunk would preserve revision history, a separate jira is needed. ",
        "label": 441
    },
    {
        "text": "wait for regionservers to join the cluster  with hbase-10569, if regionservers are started a while after the master, all regions will be assigned to the master. that may not be what users expect. a work-around is to always start regionservers before masters. i was wondering if the master can wait a little for other regionservers to join. ",
        "label": 242
    },
    {
        "text": "testtablelockmanager fails intermittently in trunk builds  in build #3979:  testtablereadlock(org.apache.hadoop.hbase.master.testtablelockmanager): test timed out after 600000 milliseconds ",
        "label": 441
    },
    {
        "text": "web ui should be available during startup  currently, hbase does not provide a web interface during its start-up period \u2013 while it's waiting for rses to report in, replaying logs, etc. it would be great if the web ui was available and showed the current status. ",
        "label": 453
    },
    {
        "text": "add a configuration for the tcp backlog in the thrift server  once thrift-1868 goes in, we can start letting our users configure the tcp backlog. ",
        "label": 402
    },
    {
        "text": "add site target check to precommit tests  we should check that the maven 'site' target passes as part of precommit testing. see hbase-8022. ",
        "label": 314
    },
    {
        "text": "testnamespaceupgrade fails on hadoop due to existence of  snapshot directory in tar ball  here is partial listing of contents for testnamespaceupgrade.tgz : -rwxrwxrwx  0 fcliu  staff       0 may 13 10:50 hbase/.snapshot/ns.two.foo_snapshot2/7112077ccfba8a46c0694ca8c0a4bc2d/f/136799c89e244b9bad79281b37650927 -rwxrwxrwx  0 fcliu  staff       0 may 13 10:50 hbase/.snapshot/ns.two.foo_snapshot2/7112077ccfba8a46c0694ca8c0a4bc2d/f/98093488150c42229927fd2a1e8c5d69 -rw-r--r--  0 fcliu  staff      12 may 13 10:50 hbase/.snapshot/ns.two.foo_snapshot1/..snapshotinfo.crc running the test on hadoop 2.1, i saw the following in test output: 2013-08-08 19:59:29,834 warn  [ipc server handler 3 on 47143] ipc.server$handler(2044): ipc server handler 3 on 47143, call org.apache.hadoop.hdfs.protocol.clientprotocol.mkdirs from 127.0.0.1:46287 call#264 retry#0: error: org.apache.hadoop.hadoopillegalargumentexception: \".snapshot\" is a reserved name. org.apache.hadoop.hadoopillegalargumentexception: \".snapshot\" is a reserved name.         at org.apache.hadoop.hdfs.server.namenode.fsdirectory.verifyinodename(fsdirectory.java:2108)         at org.apache.hadoop.hdfs.server.namenode.fsdirectory.addchild(fsdirectory.java:2204)         at org.apache.hadoop.hdfs.server.namenode.fsdirectory.unprotectedmkdir(fsdirectory.java:2003)         at org.apache.hadoop.hdfs.server.namenode.fsdirectory.mkdirs(fsdirectory.java:1956)         at org.apache.hadoop.hdfs.server.namenode.fsnamesystem.mkdirsinternal(fsnamesystem.java:3379)         at org.apache.hadoop.hdfs.server.namenode.fsnamesystem.mkdirsint(fsnamesystem.java:3338)         at org.apache.hadoop.hdfs.server.namenode.fsnamesystem.mkdirs(fsnamesystem.java:3310)         at org.apache.hadoop.hdfs.server.namenode.namenoderpcserver.mkdirs(namenoderpcserver.java:694)         at org.apache.hadoop.hdfs.protocolpb.clientnamenodeprotocolserversidetranslatorpb.mkdirs(clientnamenodeprotocolserversidetranslatorpb.java:502)         at org.apache.hadoop.hdfs.protocol.proto.clientnamenodeprotocolprotos$clientnamenodeprotocol$2.callblockingmethod(clientnamenodeprotocolprotos.java:48089)         at org.apache.hadoop.ipc.protobufrpcengine$server$protobufrpcinvoker.call(protobufrpcengine.java:585)         at org.apache.hadoop.ipc.rpc$server.call(rpc.java:928)         at org.apache.hadoop.ipc.server$handler$1.run(server.java:2028)         at org.apache.hadoop.ipc.server$handler$1.run(server.java:2024)         at java.security.accesscontroller.doprivileged(native method)         at javax.security.auth.subject.doas(subject.java:415)         at org.apache.hadoop.security.usergroupinformation.doas(usergroupinformation.java:1477)         at org.apache.hadoop.ipc.server$handler.run(server.java:2022) put: \".snapshot\" is a reserved name. looks like the tar ball was generated using an old version of 0.94 ",
        "label": 174
    },
    {
        "text": "testsplittransactiononcluster testshutdownfixupwhendaughterhassplit failed in build   https://builds.apache.org/job/hbase-0.95/11/testreport/junit/org.apache.hadoop.hbase.regionserver/testsplittransactiononcluster/testshutdownfixupwhendaughterhassplit/ hard to tell which region is missing post crash. not logged. ",
        "label": 314
    },
    {
        "text": "fix javadoc warnings  there are javadoc warnings in both the 0.2 branch and in trunk. they must be fixed before 0.2.2 or 0.18.0 are released. ",
        "label": 241
    },
    {
        "text": "npe thrown in boundedrangefileinputstream  npe is thrown in boundedrangefileinputstream.read when attempting to synchronize on 'in' (line 97). this probably means the brfis was created with a null fsdis. ",
        "label": 314
    },
    {
        "text": "add normalization support to shell  https://issues.apache.org/jira/browse/hbase-13103 adds support for setting a normalization flag per htabledescriptor, along with the server side chore to do the work. what is lacking is to easily set this from the shell, right now you need to use the java api to modify the descriptor. this issue is to add the flag as a known attribute key and/or other means to toggle this per table. ",
        "label": 323
    },
    {
        "text": "miss metrics when coprocessor use region scanner to read data  region interface is exposed to coprocessor. so coprocessor use getscanner to get a region scanner to read data. but the scan metrics was only updated in region server level. so we will miss some scan metrics for the read from coprocessor. region operation   when to update requests metric get   update read metric in nextraw() put   update write metric in batchmutate() delete   update write metric in batchmutate() increment   update read metric by get() and update write metric in dodelta() append   update read metric by get() and update write metric in dodelta() mutaterow   update write metric in processrowswithlocks() mutaterowswithlocks   update write metric in processrowswithlocks() batchmutate   update write metric in batchmutate() checkandmutate   update read metric by get() and update write metric by mutaterow() checkandrowmutate   update read metric by get() and update write metric by dobatchmutate() processrowswithlocks   update write metric in processrowswithlocks() 1. move read requests to region level. because regionscanner exposed to cp.  2. update write requests count in processrowswithlocks. this was missed in previous implemenation, too.  3. remove requestrowactioncount in rsrpcservices. this metric can be computed by region's readrequestscount and writerequestscount. upload to review board: https://reviews.apache.org/r/63579/ ",
        "label": 187
    },
    {
        "text": "fix testassignmentmanagermetrics flaky test  testassignmentmanagermetrics fails constantly. after bisecting, it seems that commit 010012cbcb broke it (hbase-18946). the test method runs successfully, but it cannot shut the minicluster down, and hangs forever. ",
        "label": 149
    },
    {
        "text": "regionserver shutdown improperly and leaves the dir in  old not deleted  regionserver log 2013-12-18 15:17:45,771 debug org.apache.hadoop.hbase.regionserver.hregionserver: waiting on 51b27391410efdca841db264df46085f 2013-12-18 15:17:45,776 info org.apache.hadoop.hbase.regionserver.hregionserver: connected to master at null 2013-12-18 15:17:48,776 info org.apache.hadoop.hbase.regionserver.hregionserver: stopped: exiting; cluster shutdown set and not carrying any regions 2013-12-18 15:17:48,776 fatal org.apache.hadoop.hbase.regionserver.hregionserver: aborting region server node,60020,1384410974572: unhandled exception: null java.lang.nullpointerexception         at org.apache.hadoop.hbase.regionserver.hregionserver.tryregionserverreport(hregionserver.java:880)         at org.apache.hadoop.hbase.regionserver.hregionserver.run(hregionserver.java:753)         at java.lang.thread.run(thread.java:662) ",
        "label": 292
    },
    {
        "text": "npe in regionservercallable  saw this running hbase-it suite on test cluster. its tricky. needs a little study. connection or location became null in this code when we go to clear the caches:     if (t instanceof sockettimeoutexception ||         t instanceof connectexception ||         t instanceof retriesexhaustedexception ||         (location != null && getconnection().isdeadserver(location.getservername()))) {       // if thrown these exceptions, we clear all the cache entries that       // map to that slow/dead server; otherwise, let cache miss and ask       // hbase:meta again to find the new location       getconnection().clearcaches(location.getservername()); here is exception seen: 2013-10-17 09:05:44,569 info [thread-9] actions.action: killed region server:a1811.halxg.cloudera.com,60020,1382025707403. reported num of rs:4  2013-10-17 09:05:44,569 info [thread-9] actions.action: sleeping for:2961  exception in thread \"hbaseupdaterthread_3\" java.lang.nullpointerexception  at org.apache.hadoop.hbase.client.regionservercallable.throwable(regionservercallable.java:120)  at org.apache.hadoop.hbase.client.rpcretryingcaller.callwithretries(rpcretryingcaller.java:124)  at org.apache.hadoop.hbase.client.htable.get(htable.java:755)  at org.apache.hadoop.hbase.util.multithreadedupdater$hbaseupdaterthread.run(multithreadedupdater.java:159) ",
        "label": 314
    },
    {
        "text": "npe in storescanner on compaction  from zhenyu: 2009-12-01 00:35:05,321 info org.apache.hadoop.hbase.regionserver.hregion: starting compaction on region ip_info_238,41.214.148.221,1259132082707 2009-12-01 00:35:05,572 warn org.apache.hadoop.hbase.regionserver.store: not in setorg.apache.hadoop.hbase.regionserver.storescanner@7f821a6c 2009-12-01 00:35:05,572 warn org.apache.hadoop.hbase.regionserver.store: not in setorg.apache.hadoop.hbase.regionserver.storescanner@7f821a6c 2009-12-01 00:35:05,572 error org.apache.hadoop.hbase.regionserver.compactsplitthread: compaction failed for region ip_info_238,41.214.148.221,1259132082707 java.lang.nullpointerexception at org.apache.hadoop.hbase.regionserver.storescanner.updatereaders(storescanner.java:250) at org.apache.hadoop.hbase.regionserver.store.notifychangedreadersobservers(store.java:628) ... ",
        "label": 229
    },
    {
        "text": "rowmutations fail when delete and put on same columnfamily column row  when rowmutations have a delete followed by put to same column family or columns or rows, only the delete is happening while the put is ignored so atomicity of rowmutations is broken for such cases. attached is a unit test where the following tests are failing: testdeletecfthenputinsamecf: delete a column family and then put to same column family. testdeletecolumnthenputsamecolumn: delete a column and then put to same column. testdeleterowthenputsamerow: delete a row and then put to same row ",
        "label": 441
    },
    {
        "text": "fix coverage org apache hadoop hbase rest metrics  ",
        "label": 16
    },
    {
        "text": "slimming of maven dependency tree   improves assembly build speed   from a discussion on irc, the maven assembly speed is pretty bad, this is likely due to http://jira.codehaus.org/browse/massembly-424 (process fork per dependency, ouch). slimming the dependency tree will not only make the generated assembly more compact, it can speed up the build process. will attach patch to propose slimming the dependencies based on stacks comments on the mailing list: here is a list of things i found in lib that we don't need to run: -rwsrwsrwt 1 stack staff 1034049 mar 16 16:45 ant-1.6.5.jar  -rwsrwsrwt 1 stack staff 279781 mar 16 16:45 commons-httpclient-3.0.1.jar  -rwsrwsrwt 1 stack staff 706710 mar 16 16:45 hsqldb-1.8.0.10.jar  -rwsrwsrwt 1 stack staff 377780 mar 16 16:45 jets3t-0.7.1.jar  -rwsrwsrwt 1 stack staff 11981 mar 16 16:45 kfs-0.3.jar  -rwsrwsrwt 1 stack staff 388864 mar 16 16:45 mail-1.4.jar  -rwsrwsrwt 1 stack staff 65261 mar 16 16:45 oro-2.0.8.jar  -rwsrwsrwt 1 stack staff 28415 mar 16 16:45 paranamer-1.5.jar  -rwsrwsrwt 1 stack staff 3067 mar 16 16:45 paranamer-ant-1.5.jar  -rwsrwsrwt 1 stack staff 6841 mar 16 16:45 paranamer-generator-1.5.jar  -rwsrwsrwt 1 stack staff 167436 mar 16 16:45 qdox-1.9.1.jar  -rwsrwsrwt 1 stack staff 23445 mar 16 16:45 slf4j-api-1.5.8.jar  -rwsrwsrwt 1 stack staff 9679 mar 16 16:45 slf4j-log4j12-1.5.8.jar  -rwsrwsrwt 1 stack staff 7585 mar 16 16:45 slf4j-simple-1.5.8.jar to add exclusions, i need to add the exclusion on the dependency that  adds in the above? for most of the above, it looks like hadoop is the  includer. i'd look at its pom and figure which hadoop component  included the above and then add an exclusion in our pom on that  dependency? ",
        "label": 350
    },
    {
        "text": "npe caused by storefilescanner updatereaders  running a test to determine performance during inserts of many 100,000s of cells into a single column family in a single row, the region server involved went down after taking a npe: 2008-07-17 18:12:18,051 fatal org.apache.hadoop.hbase.regionserver.flusher: replay of hlog required. forcing server restart  org.apache.hadoop.hbase.droppedsnapshotexception  at org.apache.hadoop.hbase.regionserver.hregion.internalflushcache(hregion.java:1040)  at org.apache.hadoop.hbase.regionserver.hregion.flushcache(hregion.java:942)  at org.apache.hadoop.hbase.regionserver.flusher.flushregion(flusher.java:174)  at org.apache.hadoop.hbase.regionserver.flusher.run(flusher.java:93)  caused by: java.lang.nullpointerexception  at java.lang.string.<init>(string.java:516)  at org.apache.hadoop.hbase.util.bytes.tostring(bytes.java:71)  at org.apache.hadoop.hbase.regionserver.storefilescanner.updatereaders(storefilescanner.java:374)  at org.apache.hadoop.hbase.regionserver.hstore.notifychangedreadersobservers(hstore.java:797)  at org.apache.hadoop.hbase.regionserver.hstore.updatereaders(hstore.java:784)  at org.apache.hadoop.hbase.regionserver.hstore.internalflushcache(hstore.java:755)  at org.apache.hadoop.hbase.regionserver.hstore.flushcache(hstore.java:682)  at org.apache.hadoop.hbase.regionserver.hregion.internalflushcache(hregion.java:1030)  ... 3 more any ideas about this one? ",
        "label": 314
    },
    {
        "text": "odd behaviors of tablename for empty namespace  in the class tablename, public static byte [] islegalfullyqualifiedtablename(final byte[] tablename) { ... int namespacedelimindex = ... if (namespacedelimindex == 0 || namespacedelimindex == -1){   islegaltablequalifiername(tablename); } else { ... that means, for example, giving \":a\" as the argument throws an exception which says invalid qualifier, instead of invalid namespace. also, tablename.valueof(string) and valueof(byte[]) can create an instance with empty namespace, which is inconsistent. ",
        "label": 371
    },
    {
        "text": "shell  close region  reveals a master hrs problem  regions are not reassigned  when issuing a \"close_region\" on the shell the master logs these entries: ... 2009-06-09 22:11:31,141 debug org.apache.hadoop.hbase.master.regionmanager: applying operation in tasklists to region 2009-06-09 22:11:33,557 debug org.apache.hadoop.hbase.master.hmaster: attempting to close region: testtable,0000291328,1244572849139 2009-06-09 22:11:33,560 info org.apache.hadoop.hbase.master.hmaster: marking testtable,0000291328,1244572849139 as closed on 192.168.2.103:63745; cleaning server + startcode; master will tell regionserver to close region on next heartbeat 2009-06-09 22:11:34,156 debug org.apache.hadoop.hbase.master.regionmanager: applying operation in tasklists to region ... but that is it, no further processing is done. the regions stays closed, and even across a restart it stays closed. according to what i got told the region should be automatically reassigned to a new server. please confirm that this is what is expected. if not and the above seems right, then please disregard and close issue. ",
        "label": 314
    },
    {
        "text": "revert some of the stringency recently introduced by checkstyle tightening  i think we should undo some of the plugins that were recently added to checkstyle. they are too much. javadoctagcontinuationindentationcheck is about adding indent if javadoc is two lines or more (javadoc tool doesn't care) nonemptyatclausedescriptioncheck would have us add javadoc on each exception: e.g. @throws ioexception needs to have text added. needbracescheck has us undoing cases where an if fits all on one line (don't want to start style wars but if short and fits on one line, i think its more readable... but i could relent on this one.... ). the first two at least should go. you ok w/ that apekshit sharma ",
        "label": 314
    },
    {
        "text": "review documentation for o a h h mapreduce  documentation for tif is short and tifbase is a bit misleading. there are mixes of different apis in the sample code, batchupdate in package-overview. i've started to make a patch for this, just creating an issue so i don't forget to finish. hope to squeeze it in to 0.20.0 but leaving it off for now. ",
        "label": 314
    },
    {
        "text": "nightly job to check health of active branches  we should set up a job that runs apache yetus test patch's nightly mode. essentially, it produces a report that considers how the branch measures up against the things we check in our precommit checks. ",
        "label": 402
    },
    {
        "text": " fb  allow hbaseservers's callqueue to be better configurable to avoid ooms  the callqueue size (where requests get queued up if all handlers are busy) is a linkedblockingqueue of size 100 * number_of_handlers. so, with say 300 handler threads, the call queue can have upto 30k entries queued up. if the requests are large enough, this can result in oom or severe gc pauses. ideally, we should allow this param to be separately configurable independent of the numberof handlers; perhaps an even better approach would be to specify a memory size based limit, instead of a number of entries based limit. [i have not looked at the trunk version for this issue. so it may or may not be relevant there.] ",
        "label": 6
    },
    {
        "text": " backport  hbase add info port to servername to support multi instances in a node  backport this patch after testing it does not break anything. ",
        "label": 314
    },
    {
        "text": "make exportsnapshot extendable by removing 'final'  currently the exportsnapshot is defined as final class. this jira would like to remove 'final' to make the class extendable so that we can leverage the existing snapshot logic for backup/restore solution discussed in hbase-7912 ",
        "label": 38
    },
    {
        "text": "backport hbase to branch  ",
        "label": 53
    },
    {
        "text": "region assigments scan table directory making them slow for huge tables  on a table with 130k regions it takes about 3 seconds for a region server to open a region once it has been assigned. watching the threads for a region server running 0.94.5 that is opening many such regions shows the thread opening the reigon in code like this: \"pri ipc server handler 4 on 60020\" daemon prio=10 tid=0x00002aaac07e9000 nid=0x6566 runnable [0x000000004c46d000]    java.lang.thread.state: runnable         at java.lang.string.indexof(string.java:1521)         at java.net.uri$parser.scan(uri.java:2912)         at java.net.uri$parser.parse(uri.java:3004)         at java.net.uri.<init>(uri.java:736)         at org.apache.hadoop.fs.path.initialize(path.java:145)         at org.apache.hadoop.fs.path.<init>(path.java:126)         at org.apache.hadoop.fs.path.<init>(path.java:50)         at org.apache.hadoop.hdfs.protocol.hdfsfilestatus.getfullpath(hdfsfilestatus.java:215)         at org.apache.hadoop.hdfs.distributedfilesystem.makequalified(distributedfilesystem.java:252)         at org.apache.hadoop.hdfs.distributedfilesystem.liststatus(distributedfilesystem.java:311)         at org.apache.hadoop.fs.filterfilesystem.liststatus(filterfilesystem.java:159)         at org.apache.hadoop.fs.filesystem.liststatus(filesystem.java:842)         at org.apache.hadoop.fs.filesystem.liststatus(filesystem.java:867)         at org.apache.hadoop.hbase.util.fsutils.liststatus(fsutils.java:1168)         at org.apache.hadoop.hbase.util.fstabledescriptors.gettableinfopath(fstabledescriptors.java:269)         at org.apache.hadoop.hbase.util.fstabledescriptors.gettableinfopath(fstabledescriptors.java:255)         at org.apache.hadoop.hbase.util.fstabledescriptors.gettableinfomodtime(fstabledescriptors.java:368)         at org.apache.hadoop.hbase.util.fstabledescriptors.get(fstabledescriptors.java:155)         at org.apache.hadoop.hbase.util.fstabledescriptors.get(fstabledescriptors.java:126)         at org.apache.hadoop.hbase.regionserver.hregionserver.openregion(hregionserver.java:2834)         at org.apache.hadoop.hbase.regionserver.hregionserver.openregion(hregionserver.java:2807)         at sun.reflect.generatedmethodaccessor64.invoke(unknown source)         at sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:25)         at java.lang.reflect.method.invoke(method.java:597)         at org.apache.hadoop.hbase.ipc.writablerpcengine$server.call(writablerpcengine.java:320)         at org.apache.hadoop.hbase.ipc.hbaseserver$handler.run(hbaseserver.java:1426) to open the region, the region server first loads the latest htabledescriptor. since hbase-4553 htabledescriptor's are stored in the file system at \"/hbase/<tabledir>/.tableinfo.<sequencenum>\". the file with the largest sequencenum is the current descriptor. this is done so that the current descirptor is updated atomically. however, since the filename is not known in advance fstabledescriptors it has to do a filesystem.liststatus operation which has to list all files in the directory to find it. the directory also contains all the region directories, so in our case it has to load 130k filestatus objects. even using a globstatus matching function still transfers all the objects to the client before performing the pattern matching. furthermore hdfs uses a default of transferring 1000 directory entries in each rpc call, so it requires 130 roundtrips to the namenode to fetch all the directory entries. consequently, to reassign all the regions of a table (or a constant fraction thereof) requires time proportional to the square of the number of regions. in our case, if a region server fails with 200 such regions, it takes 10+ minutes for them all to be reassigned, after the zk expiration and log splitting. ",
        "label": 125
    },
    {
        "text": "let chaosmonkeyrunner expose the chaos monkey runner it creates  currently chaosmonkeyrunner#main() instantiates chaosmonkeyrunner without keeping track of the instance. this poses some challenge when chaosmonkeyrunner is used programmatically because the caller cannot get hold of the runner. as mike drob suggested, we should expose the chaos monkey runner. ",
        "label": 370
    },
    {
        "text": "keyonlykeyvalue tostring  passes wrong offset to keytostring   when debugging for hbase-11234, i found that debugger encountered exception displaying the string value of keyonlykeyvalue. it turns out that keyonlykeyvalue#tostring() passes wrong offset to keytostring(): row_offset should not be used.  another bug is that getvaluelength() shouldn't be called - it throws illegalargumentexception. ",
        "label": 544
    },
    {
        "text": "npe on stochasticloadbalancer balance involving rs with no regions  when stochasticloadbalancer attempts to balance a local rs with multiple regions with another local rs that had no regions the hbase shell call of 'balancer' gets the following npe: error: java.io.ioexception at org.apache.hadoop.hbase.ipc.rpcserver.call(rpcserver.java:2175) at org.apache.hadoop.hbase.ipc.callrunner.run(callrunner.java:106) at org.apache.hadoop.hbase.ipc.rpcexecutor.consumerloop(rpcexecutor.java:130) at org.apache.hadoop.hbase.ipc.rpcexecutor$1.run(rpcexecutor.java:107) at java.lang.thread.run(thread.java:745) caused by: java.lang.nullpointerexception at org.apache.hadoop.hbase.master.balancer.baseloadbalancer$cluster.getleastloadedtopserverforregion(baseloadbalancer.java:863) at org.apache.hadoop.hbase.master.balancer.stochasticloadbalancer$localitybasedcandidategenerator.generate(stochasticloadbalancer.java:724) at org.apache.hadoop.hbase.master.balancer.stochasticloadbalancer.balancecluster(stochasticloadbalancer.java:325) at org.apache.hadoop.hbase.master.balancer.stochasticloadbalancer.balancecluster(stochasticloadbalancer.java:263) at org.apache.hadoop.hbase.master.hmaster.balance(hmaster.java:1264) at org.apache.hadoop.hbase.master.masterrpcservices.balance(masterrpcservices.java:413) at org.apache.hadoop.hbase.protobuf.generated.masterprotos$masterservice$2.callblockingmethod(masterprotos.java:52450) at org.apache.hadoop.hbase.ipc.rpcserver.call(rpcserver.java:2133) ... 4 more issue only occurs when one of the rss has no regions before balancing. also, unsure if distributed rss would also have same issue. attached 'hbase-mwarhaftig-master-matts-mbp.log' is master's log of the error occurring. simpleloadbalancer rebalances correctly when used in the same situation. ",
        "label": 441
    },
    {
        "text": "support per cell ttls  ",
        "label": 38
    },
    {
        "text": "npe in replicationzklockcleanerchore  while i am watching hmaster log, i found nullpointerexception logs.  this occurs every minute. -------- 2017-07-06 09:05:02,579 debug [,1498445640728_choreservice_1] cleaner.cleanerchore: removing: hdfs://*** from archive  2017-07-06 09:05:02,585 error [,1498445640728_choreservice_2] hbase.scheduledchore: caught error  java.lang.nullpointerexception  at org.apache.hadoop.hbase.master.cleaner.replicationzklockcleanerchore.chore(replicationzklockcleanerchore.java:80)  at org.apache.hadoop.hbase.scheduledchore.run(scheduledchore.java:185)  at java.util.concurrent.executors$runnableadapter.call(executors.java:471)  at java.util.concurrent.futuretask.runandreset(futuretask.java:304)  at java.util.concurrent.scheduledthreadpoolexecutor$scheduledfuturetask.access$301(scheduledthreadpoolexecutor.java:178)  at java.util.concurrent.scheduledthreadpoolexecutor$scheduledfuturetask.run(scheduledthreadpoolexecutor.java:293)  at org.apache.hadoop.hbase.jitterscheduledthreadpoolexecutorimpl$jitteredrunnablescheduledfuture.run(jitterscheduledthreadpoolexecutorimpl.java:110)  at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1145)  at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:615)  at java.lang.thread.run(thread.java:745)  2017-07-06 09:05:02,585 debug [,1498445640728_choreservice_1] cleaner.cleanerchore: removing: hdfs://*** from archive  2017-07-06 09:05:02,586 debug [,1498445640728_choreservice_1] cleaner.cleanerchore: removing: hdfs://*** from archive -------- here is related code:  list<string> replicators = queues.getlistofreplicators();  for (string replicator: replicators) { ",
        "label": 38
    },
    {
        "text": "hbase broke build  i broke the build. fix coming. ",
        "label": 314
    },
    {
        "text": "test of indexed hbase broken  build is broken up against hudson. ",
        "label": 314
    },
    {
        "text": "reverse scan threw stackoverflow caused by readpt checking  i met stack overflow error in storefilescanner.seektopreviousrow using reversed scan. i searched and founded hbase-14155, but it seems to be a different reason. the seektopreviousrow will fetch the row which closest before, and compare mvcc to the readpt, which acquired when scanner created. if the row's mvcc is bigger than readpt, an recursive call of seektopreviousrow will invoked, to find the next closest before row. considering we created a scanner for reversed scan, and some data with smaller rows was written and flushed, before calling scanner next. when seektopreviousrow was invoked, it would call itself recursively, until all rows which written after scanner created were iterated. the depth of recursive calling stack depends on the count of rows, the stack overflow error will be threw if the count of rows is large, like 10000. ",
        "label": 498
    },
    {
        "text": "if millions of columns in a column family  hbase scanner won't come up  our daniel has uploaded a table that has a column family with millions of columns in it. he can get items from the table promptly specifying row and column. scanning is another matter. thread dumping i see we're stuck in the scanner constructor nexting through cells. ",
        "label": 247
    },
    {
        "text": " hbase  delete table does not remove the table directory in the fs  i deleted a table but its directory stays behind in hdfs. see listing below. testtable is the table removed. $ ./bin/hadoop fs -lsr / /hbase123       <dir>           2008-01-23 00:47        rwxr-xr-x       stack   supergroup /hbase123/-root-        <dir>           2008-01-22 22:56        rwxr-xr-x       stack   supergroup /hbase123/-root-/70236052       <dir>           2008-01-22 05:10        rwxr-xr-x       stack   supergroup /hbase123/-root-/70236052/info  <dir>           2008-01-22 05:10        rwxr-xr-x       stack   supergroup /hbase123/-root-/70236052/info/info     <dir>           2008-01-23 00:46        rwxr-xr-x       stack   supergroup /hbase123/-root-/70236052/info/info/2697897537613165523 <r 3>   9       2008-01-22 22:56        rw-r--r--       stack   supergroup /hbase123/-root-/70236052/info/info/6044008799898415360 <r 3>   9       2008-01-23 00:46        rw-r--r--       stack   supergroup /hbase123/-root-/70236052/info/mapfiles <dir>           2008-01-23 00:46        rwxr-xr-x       stack   supergroup /hbase123/-root-/70236052/info/mapfiles/2697897537613165523     <dir>           2008-01-22 22:56        rwxr-xr-x       stack   supergroup /hbase123/-root-/70236052/info/mapfiles/2697897537613165523/data        <r 3>   336     2008-01-22 22:56        rw-r--r--       stack   supergroup /hbase123/-root-/70236052/info/mapfiles/2697897537613165523/index       <r 3>   232     2008-01-22 22:56        rw-r--r--       stack   supergroup /hbase123/-root-/70236052/info/mapfiles/6044008799898415360     <dir>           2008-01-23 00:46        rwxr-xr-x       stack   supergroup /hbase123/-root-/70236052/info/mapfiles/6044008799898415360/data        <r 3>   230     2008-01-23 00:46        rw-r--r--       stack   supergroup /hbase123/-root-/70236052/info/mapfiles/6044008799898415360/index       <r 3>   230     2008-01-23 00:46        rw-r--r--       stack   supergroup /hbase123/-root-/compaction.dir <dir>           2008-01-22 22:56        rwxr-xr-x       stack   supergroup /hbase123/.meta.        <dir>           2008-01-22 19:12        rwxr-xr-x       stack   supergroup /hbase123/.meta./1028785192     <dir>           2008-01-22 05:10        rwxr-xr-x       stack   supergroup /hbase123/.meta./1028785192/info        <dir>           2008-01-22 05:10        rwxr-xr-x       stack   supergroup /hbase123/.meta./1028785192/info/info   <dir>           2008-01-23 00:46        rwxr-xr-x       stack   supergroup /hbase123/.meta./1028785192/info/info/1626684907024277671       <r 3>   9       2008-01-23 00:46        rw-r--r--       stack   supergroup /hbase123/.meta./1028785192/info/info/1714016229549960649       <r 3>   9       2008-01-22 19:12        rw-r--r--       stack   supergroup /hbase123/.meta./1028785192/info/info/8042950873311244716       <r 3>   9       2008-01-22 22:56        rw-r--r--       stack   supergroup /hbase123/.meta./1028785192/info/mapfiles       <dir>           2008-01-23 00:46        rwxr-xr-x       stack   supergroup /hbase123/.meta./1028785192/info/mapfiles/1626684907024277671   <dir>           2008-01-23 00:46        rwxr-xr-x       stack   supergroup /hbase123/.meta./1028785192/info/mapfiles/1626684907024277671/data      <r 3>   430     2008-01-23 00:46        rw-r--r--       stack   supergroup /hbase123/.meta./1028785192/info/mapfiles/1626684907024277671/index     <r 3>   245     2008-01-23 00:46        rw-r--r--       stack   supergroup /hbase123/.meta./1028785192/info/mapfiles/1714016229549960649   <dir>           2008-01-22 19:12        rwxr-xr-x       stack   supergroup /hbase123/.meta./1028785192/info/mapfiles/1714016229549960649/data      <r 3>   1192    2008-01-22 19:12        rw-r--r--       stack   supergroup /hbase123/.meta./1028785192/info/mapfiles/1714016229549960649/index     <r 3>   247     2008-01-22 19:12        rw-r--r--       stack   supergroup /hbase123/.meta./1028785192/info/mapfiles/8042950873311244716   <dir>           2008-01-22 22:56        rwxr-xr-x       stack   supergroup /hbase123/.meta./1028785192/info/mapfiles/8042950873311244716/data      <r 3>   430     2008-01-22 22:56        rw-r--r--       stack   supergroup /hbase123/.meta./1028785192/info/mapfiles/8042950873311244716/index     <r 3>   245     2008-01-22 22:56        rw-r--r--       stack   supergroup /hbase123/.meta./compaction.dir <dir>           2008-01-22 19:12        rwxr-xr-x       stack   supergroup /hbase123/testtable     <dir>           2008-01-23 00:48        rwxr-xr-x       stack   supergroup /hbase123/testtable/compaction.dir      <dir>           2008-01-22 18:52        rwxr-xr-x       stack   supergroup /hbase123/hbase.version <r 3>   5       2008-01-22 05:10        rw-r--r--       stack   supergroup /hbase123/log_xx.xx.xx.140_1201049243642_60020 <dir>           2008-01-23 00:47        rwxr-xr-x       stack   supergroup /hbase123/log_xx.xx.xx.140_1201049243642_60020/hlog.dat.000    <r 3>   0       2008-01-23 00:47        rw-r--r--       stack   supergroup ",
        "label": 86
    },
    {
        "text": "fix testmultitableinputformat for hadoop in  see parent. this test was removed from 0.95.2.  while investigating while it fails in 0.94 with hadoop2 i found it is extremely slow and uses up a lot of threads. michael stack, any input? ",
        "label": 286
    },
    {
        "text": "hbase web app  jmx throws an exception  hbasemaster:60010/jmx throws an nosuchmethoderror exception ",
        "label": 155
    },
    {
        "text": "formatting and grammar mistakes in schemadoc chapter  a grammatical error and formatting error in schema design doc. ",
        "label": 51
    },
    {
        "text": "throwing exception when meta region is not in open state in client registry may crash a master  2019-05-26 17:10:31,195 error [master/asf906:0:becomeactivemaster] helpers.markerignoringbase(159): failed to become active master org.apache.hadoop.hbase.client.retriesexhaustedexception: cannot get the location for replica0 of region for  in hbase:meta at org.apache.hadoop.hbase.client.rpcretryingcallerwithreadreplicas.getregionlocations(rpcretryingcallerwithreadreplicas.java:335) at org.apache.hadoop.hbase.client.scannercallablewithreplicas.call(scannercallablewithreplicas.java:153) at org.apache.hadoop.hbase.client.scannercallablewithreplicas.call(scannercallablewithreplicas.java:58) at org.apache.hadoop.hbase.client.rpcretryingcallerimpl.callwithoutretries(rpcretryingcallerimpl.java:192) at org.apache.hadoop.hbase.client.clientscanner.call(clientscanner.java:263) at org.apache.hadoop.hbase.client.clientscanner.loadcache(clientscanner.java:405) at org.apache.hadoop.hbase.client.clientscanner.nextwithsynccache(clientscanner.java:285) at org.apache.hadoop.hbase.client.clientscanner.next(clientscanner.java:564) at org.apache.hadoop.hbase.metatableaccessor.scanmeta(metatableaccessor.java:766) at org.apache.hadoop.hbase.metatableaccessor.scanmeta(metatableaccessor.java:734) at org.apache.hadoop.hbase.metatableaccessor.scanmeta(metatableaccessor.java:690) at org.apache.hadoop.hbase.metatableaccessor.fullscanregions(metatableaccessor.java:220) at org.apache.hadoop.hbase.master.assignment.regionstatestore.visitmeta(regionstatestore.java:77) at org.apache.hadoop.hbase.master.assignment.assignmentmanager.loadmeta(assignmentmanager.java:1294) at org.apache.hadoop.hbase.master.assignment.assignmentmanager.joincluster(assignmentmanager.java:1255) at org.apache.hadoop.hbase.master.hmaster.finishactivemasterinitialization(hmaster.java:1100) at org.apache.hadoop.hbase.master.hmaster.startactivemastermanager(hmaster.java:2375) at org.apache.hadoop.hbase.master.hmaster.lambda$run$0(hmaster.java:605) at java.lang.thread.run(thread.java:748) caused by: java.io.ioexception: meta region is in state opening at org.apache.hadoop.hbase.client.zkasyncregistry.lambda$getmetaregionlocation$1(zkasyncregistry.java:162) at org.apache.hadoop.hbase.util.futureutils.lambda$addlistener$0(futureutils.java:70) at java.util.concurrent.completablefuture.uniwhencomplete(completablefuture.java:760) at java.util.concurrent.completablefuture$uniwhencomplete.tryfire(completablefuture.java:736) at java.util.concurrent.completablefuture.postcomplete(completablefuture.java:474) at java.util.concurrent.completablefuture.complete(completablefuture.java:1962) at org.apache.hadoop.hbase.client.zkasyncregistry.lambda$getandconvert$0(zkasyncregistry.java:81) at org.apache.hadoop.hbase.util.futureutils.lambda$addlistener$0(futureutils.java:70) at java.util.concurrent.completablefuture.uniwhencomplete(completablefuture.java:760) at java.util.concurrent.completablefuture$uniwhencomplete.tryfire(completablefuture.java:736) at java.util.concurrent.completablefuture.postcomplete(completablefuture.java:474) at java.util.concurrent.completablefuture.complete(completablefuture.java:1962) at org.apache.hadoop.hbase.zookeeper.readonlyzkclient$zktask$1.exec(readonlyzkclient.java:174) at org.apache.hadoop.hbase.zookeeper.readonlyzkclient.run(readonlyzkclient.java:342) ... 1 more i think the logic is introduced at the time that we do not change the state of meta region on zk. but now, we will change the state of meta region, so maybe we should remove the logic. ",
        "label": 149
    },
    {
        "text": "hbase configuration wizard  there are some aspects of hbase configuration that will be daunting for new users. for example, zookeeper configuration needs to list all hosts so it can determine quorum. new users won't necessarily even understand the distinction between hbase and zookeeper. let's produce a bash configuration wizard that can generate all necessary config files or file edits based on the answers provided to a few simple questions. this will allow neophytes to quickly spin up clusters correctly without duplicating common errors. advanced configuration is out of scope for this issue. ",
        "label": 38
    },
    {
        "text": "remove deprecated collectionutils  the class collectionutils was deprecated and should be removed in 3.0.0. ",
        "label": 398
    },
    {
        "text": "trunk  shell command 'list' does not work  tables exist and respond to other commands however  list show no tables, but the webui shows many tables. describe and exists both work on specific table names that do exist. ",
        "label": 25
    },
    {
        "text": "access ssl passwords through credential provider api  hadoop-10607 introduced the credential provider api for allowing passwords and other sensitive configuration items to be stored in an external provider. restserver is accessing passwords stored in clear text in configuration through the standard get() method. by using the new configuration.getpassword method instead, the credential provider api will be checked first then fall back to clear text - when allowed. ",
        "label": 283
    },
    {
        "text": "backport hbase  sometimes some compacted storefiles are still opened after region failover  to branch  there appears to be a race condition between close and split which when combined with a side effect of hbase-20704, leads to the parent region store files getting archived and cleared while daughter regions still have references to those parent region store files. here is the timeline of events observed for an affected region: 1. rs1 faces zookeeper connectivity issue for master node and starts shutting itself down. as part of this it starts to close the store and clean up the compacted files (file a) 2. master starts bulk assigning regions and assign parent region to rs2 3. region opens on rs2 and ends up opening compacted store file(s) (suspect this is due to hbase-20724) 4. now split happens and daughter regions open on rs2 and try to run a compaction as part of post open 5. split request at this point is complete. however now archiving proceeds on rs1 and ends up archiving the store file that is referenced by the daughter. compaction fails due to filenotfoundexception and all subsequent attempts to open the region will fail until manual resolution. we think having hbase-20724 would help in such situations since we won't end up loading compacted store files in the first place.  ",
        "label": 3
    },
    {
        "text": "testassignmentmanageroncluster testopencloseracing fails intermittently  the test failure came from precommit build #8362 2014-01-08 08:50:01,584 debug [thread-415] master.assignmentmanager(2181): no previous transition plan found (or ignoring an existing plan) for testopencloseracing,a,    1389171001573.c18ad6dfb0055258336e96a299f57263.; generated random plan=hri=testopencloseracing,a,1389171001573.c18ad6dfb0055258336e96a299f57263., src=, dest=asf002.sp2.  ygridcore.net,59479,1389170993670; 4 (online=4, available=4) available servers, forcenewplan=false ... 2014-01-08 08:50:01,908 debug [thread-415] master.assignmentmanager(1694): offline testopencloseracing,a,1389171001573.c18ad6dfb0055258336e96a299f57263., it's not any    more on asf002.sp2.ygridcore.net,59479,1389170993670 org.apache.hadoop.hbase.notservingregionexception: org.apache.hadoop.hbase.notservingregionexception: the region c18ad6dfb0055258336e96a299f57263 was opening but not yet served. opening is cancelled.   at org.apache.hadoop.hbase.regionserver.hregionserver.closeregion(hregionserver.java:2553)   at org.apache.hadoop.hbase.regionserver.hregionserver.closeregion(hregionserver.java:3725)   at org.apache.hadoop.hbase.protobuf.generated.adminprotos$adminservice$2.callblockingmethod(adminprotos.java:19797)   at org.apache.hadoop.hbase.ipc.rpcserver.call(rpcserver.java:2008)   at org.apache.hadoop.hbase.ipc.callrunner.run(callrunner.java:92)   at org.apache.hadoop.hbase.ipc.simplerpcscheduler.consumerloop(simplerpcscheduler.java:160)   at org.apache.hadoop.hbase.ipc.simplerpcscheduler.access$000(simplerpcscheduler.java:38)   at org.apache.hadoop.hbase.ipc.simplerpcscheduler$1.run(simplerpcscheduler.java:110)   at java.lang.thread.run(thread.java:662)   at sun.reflect.nativeconstructoraccessorimpl.newinstance0(native method)   at sun.reflect.nativeconstructoraccessorimpl.newinstance(nativeconstructoraccessorimpl.java:39)   at sun.reflect.delegatingconstructoraccessorimpl.newinstance(delegatingconstructoraccessorimpl.java:27)   at java.lang.reflect.constructor.newinstance(constructor.java:513)   at org.apache.hadoop.ipc.remoteexception.instantiateexception(remoteexception.java:106)   at org.apache.hadoop.ipc.remoteexception.unwrapremoteexception(remoteexception.java:95)   at org.apache.hadoop.hbase.protobuf.protobufutil.getremoteexception(protobufutil.java:280)   at org.apache.hadoop.hbase.protobuf.protobufutil.closeregion(protobufutil.java:1594)   at org.apache.hadoop.hbase.master.servermanager.sendregionclose(servermanager.java:693)   at org.apache.hadoop.hbase.master.assignmentmanager.unassign(assignmentmanager.java:1672)   at org.apache.hadoop.hbase.master.assignmentmanager.forceregionstatetooffline(assignmentmanager.java:1773)   at org.apache.hadoop.hbase.master.assignmentmanager.assign(assignmentmanager.java:1423)   at org.apache.hadoop.hbase.master.testassignmentmanageroncluster.testopencloseracing(testassignmentmanageroncluster.java:622) ... 2014-01-08 08:50:01,919 debug [thread-415] master.assignmentmanager(2181): no previous transition plan found (or ignoring an existing plan) for testopencloseracing,a,    1389171001573.c18ad6dfb0055258336e96a299f57263.; generated random plan=hri=testopencloseracing,a,1389171001573.c18ad6dfb0055258336e96a299f57263., src=, dest=asf002.sp2.  ygridcore.net,59479,1389170993670; 4 (online=4, available=4) available servers, forcenewplan=true the second call to getregionplan() returned the same server, thus leading to assertion failure:       assertfalse(\"region should assigned on a new region server\",         oldservername.equals(servername)); ",
        "label": 441
    },
    {
        "text": "another npe in readwriteconsistencycontrol  this occurred on a cluster with 46 slaves, running a couple mr jobs. one doing heavy writes copying everything from one table to a new table with a different schema. after one regionserver went down, about 40 of them died within an hour before it was caught and the jobs stopped. let me know if any other piece of context would be particularly helpful. this exception appears in the .out file: exception in thread \"regionserver/192.168.41.2:60020\" java.lang.nullpointerexception  at org.apache.hadoop.hbase.regionserver.readwriteconsistencycontrol.getthreadreadpoint(readwriteconsistencycontrol.java:40)  at org.apache.hadoop.hbase.regionserver.memstore$memstorescanner.getnext(memstore.java:532)  at org.apache.hadoop.hbase.regionserver.memstore$memstorescanner.seek(memstore.java:558)  at org.apache.hadoop.hbase.regionserver.storescanner.reseek(storescanner.java:320)  at org.apache.hadoop.hbase.regionserver.storescanner.checkreseek(storescanner.java:306)  at org.apache.hadoop.hbase.regionserver.storescanner.peek(storescanner.java:143)  at org.apache.hadoop.hbase.regionserver.keyvalueheap$kvscannercomparator.compare(keyvalueheap.java:127)  at org.apache.hadoop.hbase.regionserver.keyvalueheap$kvscannercomparator.compare(keyvalueheap.java:117)  at java.util.priorityqueue.siftdownusingcomparator(priorityqueue.java:644)  at java.util.priorityqueue.siftdown(priorityqueue.java:612)  at java.util.priorityqueue.poll(priorityqueue.java:523)  at org.apache.hadoop.hbase.regionserver.keyvalueheap.close(keyvalueheap.java:151)  at org.apache.hadoop.hbase.regionserver.hregion$regionscanner.close(hregion.java:1971)  at org.apache.hadoop.hbase.regionserver.hregionserver.closeallregions(hregionserver.java:1610)  at org.apache.hadoop.hbase.regionserver.hregionserver.run(hregionserver.java:621)  at java.lang.thread.run(thread.java:619) ",
        "label": 547
    },
    {
        "text": "add metric for number of masterprocwals  lets add monitoring to this so that we can see when it starts. ",
        "label": 479
    },
    {
        "text": "clear cachedmaxversions when hcolumndescriptor setvalue versions  value  is called  hcolumndescriptor caches the value of versions in a cachedmaxversions member variable. this member variable should be reset or cleared when setvalue(hconstants.versions, value) is called, like this:   static final bytes[] versions_bytes = bytes.tobytes(hconstants.versions);   public hcolumndescriptor setvalue(byte[] key, byte[] value) {     if (bytes.compare(hconstants.versions_bytes, key) == 0) {         cachedmaxversions = uninitialized;     }     values.put(new immutablebyteswritable(key),       new immutablebyteswritable(value));     return this;   } otherwise, you continue getting back cachedmaxversions instead of the updated value. ",
        "label": 346
    },
    {
        "text": "share the same eventloopgroup for nettyrpcserver  nettyrpcclient and asyncfswalprovider at rs side  need a find a proper way to pass a eventloopgroup instance through a configuration object. ",
        "label": 149
    },
    {
        "text": "hbase native metrics and metric collection for coprocessors  it would help provide better visibility into what coprocessors are doing if we provided a way for coprocessors to export their own metrics. the general idea is to: extend access to the hbase \"metrics bus\" down into the coprocessor environments coprocessors can then register and increment custom metrics coprocessor metrics are then reported along with all others through normal mechanisms ",
        "label": 155
    },
    {
        "text": "old replica regions should be cleared from am memory after primary region split or merge  similar to hbase-18025, the replica parent's info is not removed from master. actually i think it can be removed after replica region is split or merged, i will check the logic and apply one patch. ",
        "label": 346
    },
    {
        "text": "testlogrolling testlogrollonpipelinerestart failed with hadoop  java.io.ioexception: cannot obtain block length for locatedblock {bp-1455809779-127.0.0.1-1336670196362:blk_-6960847342982670493_1028; getblocksize()=1474; corrupt=false; offset=0; locs=[127.0.0.1:58343, 127.0.0.1:48427]} at org.apache.hadoop.hdfs.dfsinputstream.readblocklength(dfsinputstream.java:232)  at org.apache.hadoop.hdfs.dfsinputstream.fetchlocatedblocksandgetlastblocklength(dfsinputstream.java:177)  at org.apache.hadoop.hdfs.dfsinputstream.openinfo(dfsinputstream.java:119)  at org.apache.hadoop.hdfs.dfsinputstream.<init>(dfsinputstream.java:112)  at org.apache.hadoop.hdfs.dfsclient.open(dfsclient.java:928)  at org.apache.hadoop.hdfs.distributedfilesystem.open(distributedfilesystem.java:212)  at org.apache.hadoop.hdfs.distributedfilesystem.open(distributedfilesystem.java:75)  at org.apache.hadoop.io.sequencefile$reader.openfile(sequencefile.java:1768)  at org.apache.hadoop.hbase.regionserver.wal.sequencefilelogreader$walreader.openfile(sequencefilelogreader.java:66)  at org.apache.hadoop.io.sequencefile$reader.<init>(sequencefile.java:1688)  at org.apache.hadoop.io.sequencefile$reader.<init>(sequencefile.java:1709)  at org.apache.hadoop.hbase.regionserver.wal.sequencefilelogreader$walreader.<init>(sequencefilelogreader.java:58)  at org.apache.hadoop.hbase.regionserver.wal.sequencefilelogreader.init(sequencefilelogreader.java:166)  at org.apache.hadoop.hbase.regionserver.wal.hlog.getreader(hlog.java:659)  at org.apache.hadoop.hbase.regionserver.wal.testlogrolling.testlogrollonpipelinerestart(testlogrolling.java:498)  at sun.reflect.nativemethodaccessorimpl.invoke0(native method)  at sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:39)  at sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:25)  at java.lang.reflect.method.invoke(method.java:597)  at org.junit.runners.model.frameworkmethod$1.runreflectivecall(frameworkmethod.java:45)  at org.junit.internal.runners.model.reflectivecallable.run(reflectivecallable.java:15)  at org.junit.runners.model.frameworkmethod.invokeexplosively(frameworkmethod.java:42)  at org.junit.internal.runners.statements.invokemethod.evaluate(invokemethod.java:20)  at org.junit.internal.runners.statements.runbefores.evaluate(runbefores.java:28)  at org.junit.internal.runners.statements.runafters.evaluate(runafters.java:30)  at org.junit.runners.parentrunner.runleaf(parentrunner.java:263)  at org.junit.runners.blockjunit4classrunner.runchild(blockjunit4classrunner.java:68)  at org.junit.runners.blockjunit4classrunner.runchild(blockjunit4classrunner.java:47)  at org.junit.runners.parentrunner$3.run(parentrunner.java:231)  at org.junit.runners.parentrunner$1.schedule(parentrunner.java:60)  at org.junit.runners.parentrunner.runchildren(parentrunner.java:229)  at org.junit.runners.parentrunner.access$000(parentrunner.java:50)  at org.junit.runners.parentrunner$2.evaluate(parentrunner.java:222)  at org.junit.internal.runners.statements.runbefores.evaluate(runbefores.java:28)  at org.junit.runners.parentrunner.run(parentrunner.java:300)  at org.eclipse.jdt.internal.junit4.runner.junit4testreference.run(junit4testreference.java:50)  at org.eclipse.jdt.internal.junit.runner.testexecution.run(testexecution.java:38)  at org.eclipse.jdt.internal.junit.runner.remotetestrunner.runtests(remotetestrunner.java:467)  at org.eclipse.jdt.internal.junit.runner.remotetestrunner.runtests(remotetestrunner.java:683)  at org.eclipse.jdt.internal.junit.runner.remotetestrunner.run(remotetestrunner.java:390)  at org.eclipse.jdt.internal.junit.runner.remotetestrunner.main(remotetestrunner.java:197) ",
        "label": 242
    },
    {
        "text": "error message for non existent namespace is inaccurate  on a secure cluster, when i issued this command where ns1 didn't exist: hbase(main):002:0> create 'ns1:t1', 'f1', splits => ['10', '20', '30', '40'] error: unknown namespace ns1:t1! creates a table. pass a table name, and a set of column family specifications (at least one), and, optionally, table configuration here is related code:           raise \"unknown namespace #{args.first}!\" simply quoting the argument is not accurate - namespace should be extracted from the argument ",
        "label": 407
    },
    {
        "text": "allow cps to request flush on region and know the completion of the requested flush  follow up for hbase-18183  as per that jira, we keep only requestcompaction api in region. we did not have any such for flush in region. only api which was there is a flush which will block the callee unless flush is done. this issue has to tacke  1. decide whether we need a requestflush in region and if so add  2. whether the requestcompaction (and requestflush too) should return a future? right now the former do not return any but allow to pass a compactionlifecycletracker which will get notified on start and end of compaction. ",
        "label": 149
    },
    {
        "text": "correct bloom filter documentation in the book  in section 96.4. bloom filters:  since hbase 0.96, row-based bloom filters are enabled by default. (hbase-) --> in hbase-8450 in section 94.4.3. configuring server-wide behavior of bloom filters: io.hfile.bloom.enabled --> io.storefile.bloom.enabled master switch to enable bloom filters  io.hfile.bloom.max.fold --> io.storefile.bloom.max.fold  io.hfile.bloom.error.rate --> io.storefile.bloom.error.rate  io.storefile.bloom.block.size --> default is 128*1024 = 131072 these properties are probably not tuned usually, but should still be fixed in the doc. ",
        "label": 499
    },
    {
        "text": "rest multi gets  users currently using the rest interface do not have a way to ask for multiple rows within one http call. for my use case i want to get a set of rows that i know the key before hand. it's a very small percentage of my table and may not be contiguous so the scanner is not the right use-case for me. currently the http overhead is the largest percentage of my processing time. ideally i'd like to create a patch that would act very similar to: get /table/?row[]=\"rowkey\"&row[]=\"rowkey_two\" http/1.1 200 ok  {   \"rows\":[ << array of results equivalent to a single get >>]  } this should be pretty backward compatible. as it's just making the row key into a query string. ",
        "label": 154
    },
    {
        "text": "add fixes for ted's review comments from hbase  i missed addressing a few of ted's comments on the end of my navigating hbase-5869 commit. fix here. make it a blocker. ",
        "label": 441
    },
    {
        "text": "addrowlock  may allocate duplicate lock id  causing the client to be blocked  protected long addrowlock(integer r, hregion region) throws leasestillheldexception { long lockid = -1l; lockid = rand.nextlong();               //!!!may generate duplicated id\uff0cbug? string lockname = string.valueof(lockid); rowlocks.put(lockname, r); this.leases.createlease(lockname, new rowlocklistener(lockname, region)); return lockid; } in addrowlock(),rand may generate duplicated lock id, it may cause regionserver throw exception(leases$leasestillheldexception).the client will be blocked until old rowlock is released. 2012-02-03 15:21:50,084 error org.apache.hadoop.hbase.regionserver.hregionserver: error obtaining row lock (fsok: true) org.apache.hadoop.hbase.regionserver.leases$leasestillheldexception         at org.apache.hadoop.hbase.regionserver.leases.createlease(leases.java:150)         at org.apache.hadoop.hbase.regionserver.hregionserver.addrowlock(hregionserver.java:1986)         at org.apache.hadoop.hbase.regionserver.hregionserver.lockrow(hregionserver.java:1963)         at sun.reflect.nativemethodaccessorimpl.invoke0(native method)         at sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:39)         at sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:25)         at java.lang.reflect.method.invoke(method.java:597)         at org.apache.hadoop.hbase.ipc.hbaserpc$server.call(hbaserpc.java:570)         at org.apache.hadoop.hbase.ipc.hbaseserver$handler.run(hbaseserver.java:1039) ",
        "label": 209
    },
    {
        "text": "undo core of hbase  caching of start and end row  profiling, i learned that the hbase-975 makes things worse rather than better. for every reader opened \u2013 one is opened per store file when we open a region as well as a reader per file when we compact and then another reader whenever a scanner is opened \u2013 the change adds about 4 seeks and at least in the case of compacting and scanning, to no benefit. even where it is of benefit, when going against halfmapfiles or when many store files and we're testing to see if row is in file, it looks like the number of seeks saved are miniscule \u2013 definetly not something that would show up in timings. this issue is about undoing the get of first and last key on open of a store file, the heart of hbase-975 (975 included a bunch of cleanup refactoring. that'll stay). profiling seeks, i did notice that we do an extra seek during a get, a reset that takes us to the start of the file. then internally to getclosest, the core of our get, we're also doing a seek to closest index. let me try undoing the extra seek and see if it breaks things. ",
        "label": 314
    },
    {
        "text": " rsgroups  retry assignments in failed open state when servers  re join the cluster  after all servers in the rsgroup are down the regions cannot be opened anywhere and transition rapidly into failed_open state. 2017-10-31 21:06:25,449 info [procedureexecutor-13] master.regionstates: transition {c6c8150c9f4b8df25ba32073f25a5143 state=offline, ts=1509483985448, server=node-5.cluster,16020,1509482700768} to {c6c8150c9f4b8df25ba32073f25a5143 state=failed_open, ts=1509483985449, server=node-5.cluster,16020,1509482700768} 2017-10-31 21:06:25,449 warn [procedureexecutor-13] master.regionstates: failed to open/close d4e2f173e31ffad6aac140f4bd7b02bc on node-5.cluster,16020,1509482700768, set to failed_open any region in failed_open state has to be manually reassigned, or the master can be restarted and this will also cause reattempt of assignment of any regions in failed_open state. this is not unexpected but is an operational headache. it would be better if the rsgroupinfomanager could automatically kick reassignments of regions in failed_open state when servers rejoin the cluster. ",
        "label": 38
    },
    {
        "text": "zookeeper  master's ephemeral node went away while it was still up and functioning normally  does the master watch its own znode? right around the time of regionserver problems described in hbase-1311, clients could no longer find the master, but according to its log it was up and functionling normally. i think the master and regionserver sessions expired at the same time, as they were started within seconds of each other. ",
        "label": 342
    },
    {
        "text": "hbck doesn't recover balance switch if exception occurs in onlinehbck   ",
        "label": 482
    },
    {
        "text": "scanning cursor for async client  ",
        "label": 149
    },
    {
        "text": "change default hadoop two version to x and remove the x hadoop checks  our nightly is failing so let's do this first, and for the ref guide changes can be done in another sub task. ",
        "label": 149
    },
    {
        "text": "quota table has a wrong description on the ui  ",
        "label": 53
    },
    {
        "text": "acquiring readlock does not apply timeout in hregion flushcache  hregion   public boolean flushcache() throws ioexception {        lock(lock.readlock());   } the hregion.flushcache is called by the normal flush cache, so if we use a timeout, the memstoreflusher may be get a regiontoobusyexception, it is safe to do not use a timeout. ",
        "label": 292
    },
    {
        "text": "region orphaned after failure during split  error: region hdfs://haus01.sf.cloudera.com:11020/hbase-normal/usertable/2ad8df700eea55f70e02ea89178a65a2 on hdfs, but not listed in meta or deployed on any region server.  error: found inconsistency in table usertable not sure how i got into this state, will look through logs. ",
        "label": 314
    },
    {
        "text": "stop using code mapping for method names in the rpc  since we use a sorted mapping of method names -> codes and send that over the wire, even trivial changes, such as adding a new call, become wire-incompatible. this means many features which could easily have gone into a minor update must wait for a major update. eg: 2066, 1845, etc. this will increase on-wire overhead, but the compatibility is worth it i think. ",
        "label": 547
    },
    {
        "text": "testzkpermissionswatcher testpermissionswatcher test failure  java.lang.assertionerror at org.junit.assert.fail(assert.java:86) at org.junit.assert.asserttrue(assert.java:41) at org.junit.assert.asserttrue(assert.java:52) at org.apache.hadoop.hbase.security.access.testzkpermissionswatcher.testpermissionswatcher(testzkpermissionswatcher.java:119) in testpermissionswatcher we are not always waiting long enough for the propagation of the permissions change for user \"george\" to take place. ",
        "label": 38
    },
    {
        "text": "add  ds store to  gitignore  stop letting .ds_store mess up our commit. ",
        "label": 136
    },
    {
        "text": "need a flush by regionserver rather than by table option  this evening needed to clean out logs on the cluster. logs are by regionserver. to let go of logs, we need to have all edits emptied from memory. only flush is by table or region. we need to be able to flush the regionserver. need to add this. ",
        "label": 98
    },
    {
        "text": "testaccesscontroller testbulkload failing on trunk  i've observed this in jenkins reports and also while i was working on hbase-8692, only on trunk/0.95, not on 0.94: failed tests: testbulkload(org.apache.hadoop.hbase.security.access.testaccesscontroller): expected action to pass for user 'rwuser' but was denied ",
        "label": 38
    },
    {
        "text": "export exporter could be replaced with identitytablemapper  the mapper implementation in export looks identical to identitytablemapper, except for the (poor) exception handling. i'd like to consolidate on identitytablemapper, but i'm looking for some historical perspective before doing so (cc michael stack) export$exporter's map method:     public void map(immutablebyteswritable row, result value, context context)     throws ioexception {       try {         context.write(row, value);       } catch (interruptedexception e) {         e.printstacktrace();       }     } identitytablemapper's map method:   public void map(immutablebyteswritable key, result value, context context)   throws ioexception, interruptedexception {     context.write(key, value);   } ",
        "label": 339
    },
    {
        "text": "testsplittransactiononcluster testsplitbeforesettingsplittinginzk failed times in a row  looks like the jenkins machines are flaky/slow again, causing this test to fail. same stacktrace all three times: java.lang.assertionerror at org.junit.assert.fail(assert.java:92) at org.junit.assert.asserttrue(assert.java:43) at org.junit.assert.asserttrue(assert.java:54) at org.apache.hadoop.hbase.regionserver.testsplittransactiononcluster.testsplitbeforesettingsplittinginzk(testsplittransactiononcluster.java:656) at org.apache.hadoop.hbase.regionserver.testsplittransactiononcluster.testsplitbeforesettingsplittinginzk(testsplittransactiononcluster.java:608) ",
        "label": 544
    },
    {
        "text": "chaos monkey should shut down faster  right now we have a couple of tests clusters that are just cycling through it tests. there's a pretty sizable gap between the last mr job stopping and the next one starting. it's almost always waiting on an action to finish. \"main\" #1 prio=5 os_prio=0 tid=0x00007f455000d800 nid=0x2a2773 in object.wait() [0x00007f4556e42000]    java.lang.thread.state: waiting (on object monitor) at java.lang.object.wait(native method) at java.lang.thread.join(thread.java:1245) - locked <0x00000003ef054138> (a java.lang.thread) at java.lang.thread.join(thread.java:1319) at org.apache.hadoop.hbase.chaos.monkies.policybasedchaosmonkey.waitforstop(policybasedchaosmonkey.java:149) at org.apache.hadoop.hbase.integrationtestbase.cleanupmonkey(integrationtestbase.java:173) at org.apache.hadoop.hbase.integrationtestbase.cleanupmonkey(integrationtestbase.java:167) at org.apache.hadoop.hbase.integrationtestbase.cleanup(integrationtestbase.java:139) at org.apache.hadoop.hbase.integrationtestbase.dowork(integrationtestbase.java:125) at org.apache.hadoop.hbase.util.abstracthbasetool.run(abstracthbasetool.java:112) at org.apache.hadoop.util.toolrunner.run(toolrunner.java:70) at org.apache.hadoop.hbase.test.integrationtestbiglinkedlist.main(integrationtestbiglinkedlist.java:1686) ",
        "label": 154
    },
    {
        "text": "request counters may become negative for heavily loaded regions  requests counter showing negative count, example under 'requests' column: -645470239 name region server start key end key requests usertable,user2037516127892189021,1326756873774.16833e4566d1daef109b8fdcd1f4b5a6.  xxx.com:60030  user2037516127892189021  user2296868939942738705  -645470239 regionload.readrequestscount and regionload.writerequestscount are of int type. our ops has been running lots of heavy load operation. regionload.getrequestscount() overflows int.max_value. it is set to d986e7e1. in table.jsp, regionload.getrequestscount() is assigned to long type. d986e7e1 is converted to long ffffffffd986e7e1 which is -645470239 in decimal. suggested fix is to make readrequestscount and writerequestscount long type. ",
        "label": 333
    },
    {
        "text": "region server logs its own address at the end of getmaster   i saw the following in region server log where a.ebay.com is region server itself: 2012-05-28 08:56:35,315 info org.apache.hadoop.hbase.regionserver.hregionserver: connected to master at a.ebay.com/10.115.13.20:60020 we should be logging the address of master ",
        "label": 441
    },
    {
        "text": "xmx setting in pom to use for tests surefire does not appear to work  i was running intense version of testrollingrestart and changing the xmx setting in our pom file wasn't changing anything. what we have now is:             <argline>-enableassertions</argline>             <argline>-xmx1400m</argline> but on process listing (and through experimentation with my tests), only -enableassertions is used. however, changing to below and it worked:             <argline>-enableassertions -xmx1400m</argline> just wanted to open a jira and see if i'm missing something from someone with more maven experience. ",
        "label": 247
    },
    {
        "text": "some low hanging read path improvement ideas  i was running some single threaded scan performance tests for a table with small sized rows that is fully cached. some observations... we seem to be doing several wasteful iterations over and/or building of temporary lists. 1) one such is the following code in hregionserver.next():    boolean morerows = s.next(values, hregion.metric_nextsize);    if (!values.isempty()) {      for (keyvalue kv : values) {              ------> #### wasteful in most cases        currentscanresultsize += kv.heapsize();    }    results.add(new result(values)); by default the \"maxscannerresultsize\" is long.max_value. in those cases,  we can avoid the unnecessary iteration to compute currentscanresultsize. 2) an example of a wasteful temporary array, is \"results\" in  regionscanner.next().       results.clear();       boolean returnresult = nextinternal(limit, metric);       outresults.addall(results); results then gets copied over to outresults via an addall(). not sure why we can not directly collect the results in outresults. 3) another almost similar exmaple of a wasteful array is \"results\" in storescanner.next(), which eventually also copies its results into \"outresults\". 4) reduce overhead of \"size metric\" maintained in storescanner.next().   if (metric != null) {      hregion.incrnumericmetric(this.metricnameprefix + metric,                                copykv.getlength());   }   results.add(copykv); a single call to next() might fetch a lot of kvs. we can first add up the size of those kvs in a local variable and then in a finally clause increment the metric one shot, rather than updating atomiclongs for each kv. 5) regionscanner.next() calls a helper regionscanner.next() on the same object. both are synchronized methods. synchronized methods calling nested synchronized methods on the same object are probably adding some small overhead. the inner next() calls isfilterdone() which is a also a synchronized method. we should factor the code to avoid these nested synchronized methods. ",
        "label": 139
    },
    {
        "text": "add override mechanism for the exempt classes when dynamically loading table coprocessor  as part of hadoop's timeline service v.2 (yarn-2928), we're adding a table coprocessor (yarn-4062). however, we're finding that the coprocessor cannot be loaded dynamically. a relevant snippet for the exception: java.io.ioexception: class org.apache.hadoop.yarn.server.timelineservice.storage.flow.flowruncoprocessor cannot be loaded     at org.apache.hadoop.hbase.master.hmaster.sanitychecktabledescriptor(hmaster.java:1329)     at org.apache.hadoop.hbase.master.hmaster.createtable(hmaster.java:1269)     at org.apache.hadoop.hbase.master.masterrpcservices.createtable(masterrpcservices.java:398)     at org.apache.hadoop.hbase.protobuf.generated.masterprotos$masterservice$2.callblockingmethod(masterprotos.java:42436)     at org.apache.hadoop.hbase.ipc.rpcserver.call(rpcserver.java:2031)     at org.apache.hadoop.hbase.ipc.callrunner.run(callrunner.java:107)     at org.apache.hadoop.hbase.ipc.rpcexecutor.consumerloop(rpcexecutor.java:130)     at org.apache.hadoop.hbase.ipc.rpcexecutor$1.run(rpcexecutor.java:107)     at java.lang.thread.run(thread.java:745) caused by: java.io.ioexception: class org.apache.hadoop.yarn.server.timelineservice.storage.flow.flowruncoprocessor cannot be loaded     at org.apache.hadoop.hbase.regionserver.regioncoprocessorhost.testtablecoprocessorattrs(regioncoprocessorhost.java:324)     at org.apache.hadoop.hbase.master.hmaster.checkclassloading(hmaster.java:1483)     at org.apache.hadoop.hbase.master.hmaster.sanitychecktabledescriptor(hmaster.java:1327)     ... 8 more caused by: java.lang.classnotfoundexception: org.apache.hadoop.yarn.server.timelineservice.storage.flow.flowruncoprocessor     at java.net.urlclassloader$1.run(urlclassloader.java:366)     at java.net.urlclassloader$1.run(urlclassloader.java:355)     at java.security.accesscontroller.doprivileged(native method)     at java.net.urlclassloader.findclass(urlclassloader.java:354)     at java.lang.classloader.loadclass(classloader.java:425)     at sun.misc.launcher$appclassloader.loadclass(launcher.java:308)     at java.lang.classloader.loadclass(classloader.java:358)     at org.apache.hadoop.hbase.util.coprocessorclassloader.loadclass(coprocessorclassloader.java:275)     at org.apache.hadoop.hbase.regionserver.regioncoprocessorhost.testtablecoprocessorattrs(regioncoprocessorhost.java:322)     ... 10 more we tracked it down to the fact that coprocessorclassloader regarding all hadoop classes as exempt from loading from the coprocessor jar. since our coprocessor sits in the coprocessor jar, and yet the loading of this class is delegated to the parent which does not have this jar, the classloading fails. what would be nice is the ability to exclude certain classes from the exempt classes so that they can be loaded via table coprocessor classloader. see hadoop's applicationclassloader for a similar feature. is there any other way to load this coprocessor at the table scope? ",
        "label": 441
    },
    {
        "text": "scanner retry behavior with rpc timeout on next  seems incorrect  i'm seeing the following behavior: set rpc timeout to a short value call next() for some batch of rows, big enough so the client times out before the result is returned the hconnectionmanager stuff will retry the next() call to the same server. at this point, one of two things can happen: 1) the previous next() call will still be processing, in which case you get a leaseexception, because it was removed from the map during the processing, or 2) the next() call will succeed but skip the prior batch of rows. ",
        "label": 46
    },
    {
        "text": "when a shutdown is requested  stop scanning meta regions immediately  during shutdown of cluster, half way through quiescing servers there is a meta scan in the master. the regions from servers whose leases are already canceled show up as invalid. (72.34.249.208 is hosting meta) 2009-01-31 10:25:42,571 info org.apache.hadoop.hbase.master.hmaster: cluster shutdown requested. starting to quiesce servers 2009-01-31 10:25:45,868 info org.apache.hadoop.hbase.master.servermanager: cancelling lease for 72.34.249.211:60020 2009-01-31 10:25:45,868 info org.apache.hadoop.hbase.master.servermanager: region server 72.34.249.211:60020: msg_report_exiting -- lease cancelled 2009-01-31 10:25:47,480 info org.apache.hadoop.hbase.master.servermanager: cancelling lease for 72.34.249.216:60020 2009-01-31 10:25:47,480 info org.apache.hadoop.hbase.master.servermanager: region server 72.34.249.216:60020: msg_report_exiting -- lease cancelled 2009-01-31 10:25:47,840 info org.apache.hadoop.hbase.master.servermanager: region server 72.34.249.210:60020 quiesced 2009-01-31 10:25:47,944 info org.apache.hadoop.hbase.master.servermanager: cancelling lease for 72.34.249.215:60020 2009-01-31 10:25:47,944 info org.apache.hadoop.hbase.master.servermanager: region server 72.34.249.215:60020: msg_report_exiting -- lease cancelled 2009-01-31 10:25:48,403 info org.apache.hadoop.hbase.master.servermanager: cancelling lease for 72.34.249.213:60020 2009-01-31 10:25:48,403 info org.apache.hadoop.hbase.master.servermanager: region server 72.34.249.213:60020: msg_report_exiting -- lease cancelled 2009-01-31 10:25:49,378 info org.apache.hadoop.hbase.master.servermanager: region server 72.34.249.218:60020 quiesced 2009-01-31 10:25:50,465 info org.apache.hadoop.hbase.master.servermanager: cancelling lease for 72.34.249.214:60020 2009-01-31 10:25:50,465 info org.apache.hadoop.hbase.master.servermanager: region server 72.34.249.214:60020: msg_report_exiting -- lease cancelled 2009-01-31 10:25:59,531 info org.apache.hadoop.hbase.master.basescanner: regionmanager.metascanner scanning meta region {regionname: .meta.,,1, startkey: <>, server: 72.34.249.218:60020} 2009-01-31 10:25:59,544 debug org.apache.hadoop.hbase.master.basescanner: current assignment of activitydupehash,,1229364212541 is not valid;  server '72.34.249.214:60020' unknown. 2009-01-31 10:25:59,545 debug org.apache.hadoop.hbase.master.basescanner: current assignment of api,,1229364235220 is not valid;  server '72.34.249.216:60020' unknown. 2009-01-31 10:25:59,552 debug org.apache.hadoop.hbase.master.basescanner: current assignment of apps,,1229364222879 is not valid;  server '72.34.249.215:60020' unknown. 2009-01-31 10:25:59,552 debug org.apache.hadoop.hbase.master.basescanner: current assignment of assigners,,1229364037757 is not valid;  server '72.34.249.214:60020' unknown. 2009-01-31 10:25:59,554 debug org.apache.hadoop.hbase.master.basescanner: current assignment of canoncache,,1229364041955 is not valid;  server '72.34.249.215:60020' unknown. 2009-01-31 10:25:59,555 debug org.apache.hadoop.hbase.master.basescanner: current assignment of chunks,,1229390225893 is not valid;  server '72.34.249.211:60020' unknown. shutdown then continues as the last servers are quiesced, but at the same time the master expires the lease on the regionserver that was hosting meta and that it just scanned. it then starts to replay the logs for that regionserver in the middle of the shutdown. 2009-01-31 10:25:59,799 info org.apache.hadoop.hbase.master.basescanner: regionmanager.metascanner scan of 512 row(s) of meta region {regionname: .meta.,,1, startkey: <>, server: 72.34.249.218:60020}  complete 2009-01-31 10:25:59,799 info org.apache.hadoop.hbase.master.basescanner: all 1 .meta. region(s) scanned 2009-01-31 10:26:59,530 info org.apache.hadoop.hbase.master.basescanner: regionmanager.metascanner scanning meta region {regionname: .meta.,,1, startkey: <>, server: 72.34.249.218:60020} 2009-01-31 10:26:59,720 info org.apache.hadoop.hbase.master.basescanner: regionmanager.metascanner scan of 512 row(s) of meta region {regionname: .meta.,,1, startkey: <>, server: 72.34.249.218:60020}  complete 2009-01-31 10:26:59,720 info org.apache.hadoop.hbase.master.basescanner: all 1 .meta. region(s) scanned 2009-01-31 10:27:40,374 info org.apache.hadoop.hbase.master.servermanager: 72.34.249.218:60020 lease expired 2009-01-31 10:27:40,375 debug org.apache.hadoop.hbase.master.hmaster: processing todo: processservershutdown of 72.34.249.218:60020 2009-01-31 10:27:40,375 info org.apache.hadoop.hbase.master.regionserveroperation: process shutdown of server 72.34.249.218:60020: logsplit: false, rootrescanned: false, numberofmetaregions: 1, onlin emetaregions.size(): 1 2009-01-31 10:27:40,387 info org.apache.hadoop.hbase.regionserver.hlog: splitting 44 log(s) in hdfs://mb0:9000/hbase/log_72.34.249.218_1232996040351_60020 2009-01-31 10:27:40,387 debug org.apache.hadoop.hbase.regionserver.hlog: splitting 1 of 44: hdfs://mb0:9000/hbase/log_72.34.249.218_1232996040351_60020/hlog.dat.1232996040603 2009-01-31 10:27:40,443 debug org.apache.hadoop.hbase.regionserver.hlog: creating new log file writer for path hdfs://mb0:9000/hbase/.meta./1028785192/oldlogfile.log and region .meta.,,1 2009-01-31 10:27:40,575 debug org.apache.hadoop.hbase.regionserver.hlog: creating new log file writer for path hdfs://mb0:9000/hbase/sources/671225115/oldlogfile.log and region sources,,1229364117966 2009-01-31 10:27:41,171 debug org.apache.hadoop.hbase.regionserver.hlog: applied 100003 total edits from hdfs://mb0:9000/hbase/log_72.34.249.218_1232996040351_60020/hlog.dat.1232996040603 2009-01-31 10:27:41,173 debug org.apache.hadoop.hbase.regionserver.hlog: splitting 2 of 44: hdfs://mb0:9000/hbase/log_72.34.249.218_1232996040351_60020/hlog.dat.1233093726382 2009-01-31 10:27:41,429 debug org.apache.hadoop.hbase.regionserver.hlog: creating new log file writer for path hdfs://mb0:9000/hbase/dupehash/1607532582/oldlogfile.log and region dupehash,o\ufffd\ufffd<l;h\ufffd,12 31779694744 2009-01-31 10:27:41,462 info org.apache.hadoop.hbase.master.servermanager: 72.34.249.217:60020 lease expired 2009-01-31 10:27:41,499 info org.apache.hadoop.hbase.master.servermanager: all user tables quiesced. proceeding with shutdown 2009-01-31 10:27:41,499 debug org.apache.hadoop.hbase.master.regionmanager: telling root scanner to stop 2009-01-31 10:27:41,499 debug org.apache.hadoop.hbase.master.regionmanager: telling meta scanner to stop 2009-01-31 10:27:41,499 debug org.apache.hadoop.hbase.master.regionmanager: meta and root scanners notified 2009-01-31 10:27:41,499 info org.apache.hadoop.hbase.master.rootscanner: regionmanager.rootscanner exiting 2009-01-31 10:27:41,499 info org.apache.hadoop.hbase.master.metascanner: regionmanager.metascanner exiting 2009-01-31 10:27:41,780 debug org.apache.hadoop.hbase.regionserver.hlog: applied 100001 total edits from hdfs://mb0:9000/hbase/log_72.34.249.218_1232996040351_60020/hlog.dat.1233093726382 2009-01-31 10:27:41,781 debug org.apache.hadoop.hbase.regionserver.hlog: splitting 3 of 44: hdfs://mb0:9000/hbase/log_72.34.249.218_1232996040351_60020/hlog.dat.1233101015153 2009-01-31 10:27:41,838 info org.apache.hadoop.hbase.master.servermanager: 72.34.249.210:60020 lease expired 2009-01-31 10:27:41,866 info org.apache.hadoop.hbase.master.servermanager: all user tables quiesced. proceeding with shutdown 2009-01-31 10:27:41,866 debug org.apache.hadoop.hbase.master.regionmanager: telling root scanner to stop 2009-01-31 10:27:41,866 debug org.apache.hadoop.hbase.master.regionmanager: telling meta scanner to stop 2009-01-31 10:27:41,866 debug org.apache.hadoop.hbase.master.regionmanager: meta and root scanners notified 2009-01-31 10:27:42,557 info org.apache.hadoop.hbase.master.servermanager: 72.34.249.212:60020 lease expired 2009-01-31 10:27:42,581 info org.apache.hadoop.hbase.master.servermanager: all user tables quiesced. proceeding with shutdown 2009-01-31 10:27:42,581 debug org.apache.hadoop.hbase.master.regionmanager: telling root scanner to stop 2009-01-31 10:27:42,581 debug org.apache.hadoop.hbase.master.regionmanager: telling meta scanner to stop 2009-01-31 10:27:42,581 debug org.apache.hadoop.hbase.master.regionmanager: meta and root scanners notified 2009-01-31 10:27:42,615 debug org.apache.hadoop.hbase.regionserver.hlog: applied 100002 total edits from hdfs://mb0:9000/hbase/log_72.34.249.218_1232996040351_60020/hlog.dat.1233101015153 2009-01-31 10:27:42,618 debug org.apache.hadoop.hbase.regionserver.hlog: splitting 4 of 44: hdfs://mb0:9000/hbase/log_72.34.249.218_1232996040351_60020/hlog.dat.1233111791302 2009-01-31 10:27:43,356 debug org.apache.hadoop.hbase.regionserver.hlog: applied 100001 total edits from hdfs://mb0:9000/hbase/log_72.34.249.218_1232996040351_60020/hlog.dat.1233111791302 2009-01-31 10:27:43,359 debug org.apache.hadoop.hbase.regionserver.hlog: splitting 5 of 44: hdfs://mb0:9000/hbase/log_72.34.249.218_1232996040351_60020/hlog.dat.1233122447841 2009-01-31 10:27:43,404 info org.apache.hadoop.hbase.master.servermanager: all user tables quiesced. proceeding with shutdown 2009-01-31 10:27:43,404 debug org.apache.hadoop.hbase.master.regionmanager: telling root scanner to stop 2009-01-31 10:27:43,404 debug org.apache.hadoop.hbase.master.regionmanager: telling meta scanner to stop 2009-01-31 10:27:43,404 debug org.apache.hadoop.hbase.master.regionmanager: meta and root scanners notified 2009-01-31 10:27:43,991 debug org.apache.hadoop.hbase.regionserver.hlog: applied 100001 total edits from hdfs://mb0:9000/hbase/log_72.34.249.218_1232996040351_60020/hlog.dat.1233122447841 during the log replay, a log file was missing from hdfs. not sure why, there was a datanode crash that could be related. more importantly, once it trips on the missing file it stops the replay (even though there's another 37 logs). 2009-01-31 10:27:43,992 debug org.apache.hadoop.hbase.regionserver.hlog: splitting 6 of 44: hdfs://mb0:9000/hbase/log_72.34.249.218_1232996040351_60020/hlog.dat.1233132556827 2009-01-31 10:27:44,022 warn org.apache.hadoop.hbase.master.hmaster: processing pending operations: processservershutdown of 72.34.249.218:60020 java.io.filenotfoundexception: file does not exist: hdfs://mb0:9000/hbase/log_72.34.249.218_1232996040351_60020/hlog.dat.1233132556827         at org.apache.hadoop.hdfs.distributedfilesystem.getfilestatus(distributedfilesystem.java:394)         at org.apache.hadoop.fs.filesystem.getlength(filesystem.java:679)         at org.apache.hadoop.io.sequencefile$reader.<init>(sequencefile.java:1417)         at org.apache.hadoop.io.sequencefile$reader.<init>(sequencefile.java:1412)         at org.apache.hadoop.hbase.regionserver.hlog.splitlog(hlog.java:742)         at org.apache.hadoop.hbase.regionserver.hlog.splitlog(hlog.java:705)         at org.apache.hadoop.hbase.master.processservershutdown.process(processservershutdown.java:249)         at org.apache.hadoop.hbase.master.hmaster.processtodoqueue(hmaster.java:427)         at org.apache.hadoop.hbase.master.hmaster.run(hmaster.java:360) 2009-01-31 10:27:44,022 debug org.apache.hadoop.hbase.master.regionmanager: telling root scanner to stop 2009-01-31 10:27:44,022 debug org.apache.hadoop.hbase.master.regionmanager: telling meta scanner to stop 2009-01-31 10:27:44,022 debug org.apache.hadoop.hbase.master.regionmanager: meta and root scanners notified 2009-01-31 10:27:44,023 debug org.apache.hadoop.hbase.regionhistorian: offlined 2009-01-31 10:27:44,023 info org.apache.hadoop.hbase.master.hmaster: stopping infoserver 2009-01-31 10:27:44,023 info org.mortbay.util.threadedserver: stopping acceptor serversocket[addr=0.0.0.0/0.0.0.0,port=0,localport=60010] 2009-01-31 10:27:44,026 info org.mortbay.http.socketlistener: stopped socketlistener on 0.0.0.0:60010 ",
        "label": 241
    },
    {
        "text": "log the client ip port of the balancer invoker  there's no way for any ops to answer today: \"who turned off/on the balancer?\". all the logs print is the state when the rpc call is invoked, nothing else. given this is a critical piece of admin functionality, we should log the ip for it at least. ",
        "label": 314
    },
    {
        "text": "remove htablepool and all hconnection pooling related apis  the recommended way is now: 1. create an hconnection: hconnectionmanager.createconnection(...) 2. create a light htable: hconnection.gettable(...) 3. table.close() 4. connection.close() all other api and pooling will be removed. ",
        "label": 339
    },
    {
        "text": "fix testfshdfsutils against java7 test re ordering  the test methods of testfshdfsutils depends on hbase.lease.recovery.dfs.timeout, which is overwritten by testisfileclosed. in case it runs first, it fails testrecoverlease because it assumes a different value. this makes this test flakey in java7 environment. the proposed fix is to let both tests specify the property value in their definition. ",
        "label": 199
    },
    {
        "text": "add vectorportal com to notices txt as src of our logo  ",
        "label": 314
    },
    {
        "text": "make it obvious in the documentation that zookeeper needs permanent storage  if our users let hbase manage zk, they probably won't bother combing through hbase-default.xml to figure that they need to set hbase.zookeeper.property.datadir to something else than /tmp. it probably happened to deinspanjer in prod today and that's a show stopper. the fix would be, at least, to improve the getting started documentation to include that configuration in the \"fully-distributed operation\" section. ",
        "label": 229
    },
    {
        "text": "correct typo in argument name for walsplitter writeregionsequenceidfile  in {{walsplitter]] we have this code:   public static long writeregionsequenceidfile(final filesystem fs, final path regiondir,       long newseqid, long saftybumper) throws ioexception { we should fix the parameter name to be safetybumper. same for the javadoc above the method. ",
        "label": 177
    },
    {
        "text": "testdistributedlogsplitting testlogreplayfordisablingtable fails sometimes  http://54.241.6.143/job/hbase-0.95-hadoop-2/org.apache.hbase$hbase-server/634/testreport/junit/org.apache.hadoop.hbase.master/testdistributedlogsplitting/testlogreplayfordisablingtable/ java.lang.assertionerror: expected:<1000> but was:<0> at org.junit.assert.fail(assert.java:88) at org.junit.assert.failnotequals(assert.java:743) at org.junit.assert.assertequals(assert.java:118) at org.junit.assert.assertequals(assert.java:555) at org.junit.assert.assertequals(assert.java:542) at org.apache.hadoop.hbase.master.testdistributedlogsplitting.testlogreplayfordisablingtable(testdistributedlogsplitting.java:797) at sun.reflect.nativemethodaccessorimpl.invoke0(native method) at sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:39) at sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:25) at java.lang.reflect.method.invoke(method.java:597) at org.junit.runners.model.frameworkmethod$1.runreflectivecall(frameworkmethod.java:47) at org.junit.internal.runners.model.reflectivecallable.run(reflectivecallable.java:12) at org.junit.runners.model.frameworkmethod.invokeexplosively(frameworkmethod.java:44) at org.junit.internal.runners.statements.invokemethod.evaluate(invokemethod.java:17) at org.junit.internal.runners.statements.failontimeout$statementthread.run(failontimeout.java:74) ",
        "label": 233
    },
    {
        "text": "recovered wal directories not getting cleaned up  while colocating the recovered edits directory with hbase.wal.dir, base_namespace_dir got missed. this results in recovered edits being put in a separate directory rather than the default region directory even if the hbase.wal.dir is not overridden. eg. if data is stored in /hbase/data/namespace/table1, recovered edits are put in  /hbase/namespace/table1. this also messes up the regular cleaner chores which never operate on this new directory and these directories will never be deleted, even for split parents or dropped tables. we should change the default back to have the base namespace directory in path. ",
        "label": 149
    },
    {
        "text": "testsnapshotfilecache never worked properly  error-prone noticed we were asking iterables.contains() questions with the wrong type in testsnapshotfilecache. i've attached a fixed version of the test. the results suggest the cache is not evicting entries properly. java.lang.assertionerror: cache found 'hdfs://localhost:52867/user/apurtell/test-data/8ce04c85-ce4b-4844-b454-5303482ade95/data/default/snapshot1/9e49edd0ab41657fb0c6ebb4d9dfad15/cf/f132e5b06f66443f8003363ed1535aac', but it shouldn't have. at org.junit.assert.fail(assert.java:88) at org.junit.assert.asserttrue(assert.java:41) at org.junit.assert.assertfalse(assert.java:64) at org.apache.hadoop.hbase.master.snapshot.testsnapshotfilecache.createandtestsnapshot(testsnapshotfilecache.java:260) at org.apache.hadoop.hbase.master.snapshot.testsnapshotfilecache.createandtestsnapshotv1(testsnapshotfilecache.java:206) at org.apache.hadoop.hbase.master.snapshot.testsnapshotfilecache.testreloadmodifieddirectory(testsnapshotfilecache.java:102) java.lang.assertionerror: cache found 'hdfs://localhost:52867/user/apurtell/test-data/8ce04c85-ce4b-4844-b454-5303482ade95/data/default/snapshot1a/2e81adb9212c98cff970eafa006fc40b/cf/a2ec478d850e4e348359699c53b732c4', but it shouldn't have. at org.junit.assert.fail(assert.java:88) at org.junit.assert.asserttrue(assert.java:41) at org.junit.assert.assertfalse(assert.java:64) at org.apache.hadoop.hbase.master.snapshot.testsnapshotfilecache.createandtestsnapshot(testsnapshotfilecache.java:260) at org.apache.hadoop.hbase.master.snapshot.testsnapshotfilecache.createandtestsnapshotv1(testsnapshotfilecache.java:206) at org.apache.hadoop.hbase.master.snapshot.testsnapshotfilecache.testloadanddelete(testsnapshotfilecache.java:88) these changes are part of hbase-19239 i've disabled the offending test cases with @ignore in that patch, but they should be reenabled and fixed. ",
        "label": 494
    },
    {
        "text": "authfailedexception in zookeeper may block replication forever  replicationsource will rechoose sinks when encounted exceptions during skipping edits to the current sink. but if the zookeeper client for peer cluster go to auth_failed state, the replicationsource will always get authfailedexception. the replicationsource does not reconnect the peer, because reconnectpeer only handle connectionlossexception and sessionexpiredexception. as a result, the replication will print log: 2014-01-14,12:07:06,892 info org.apache.hadoop.hbase.replication.regionserver.replicationsource: getting 0 rs from peer cluster # 20  2014-01-14,12:07:06,892 info org.apache.hadoop.hbase.replication.regionserver.replicationsource: slave cluster looks down: 20 has 0 region servers and be blocked forever. i think other places may have same problems for not handling authfailedexception in zookeeper. eg: hbase-8675.  andrew kyle purtell ",
        "label": 411
    },
    {
        "text": "introduce wrong version depencency of servlet api jar  build a tarball. mvn -dskiptests clean install && mvn -dskiptests package assembly:single tar zxvf hbase-2.0.0-beta-1-snapshot-bin.tar.gz then i found there is a servlet-api-2.5.jar in the lib directory. the right depencency should be javax.servlet-api-3.1.0.jar. start a distributed cluster with this tarball. and got exception when access master/rs info jsp. 2017-11-27,10:02:05,066 warn org.eclipse.jetty.server.httpchannel: / java.lang.nosuchmethoderror: javax.servlet.http.httpservletrequest.isasyncsupported()z         at org.eclipse.jetty.server.resourceservice.senddata(resourceservice.java:689)         at org.eclipse.jetty.server.resourceservice.doget(resourceservice.java:294)         at org.eclipse.jetty.servlet.defaultservlet.doget(defaultservlet.java:458)         at javax.servlet.http.httpservlet.service(httpservlet.java:707)         at javax.servlet.http.httpservlet.service(httpservlet.java:820)         at org.eclipse.jetty.servlet.servletholder.handle(servletholder.java:841)         at org.eclipse.jetty.servlet.servlethandler$cachedchain.dofilter(servlethandler.java:1650)         at org.apache.hadoop.hbase.http.lib.staticuserwebfilter$staticuserfilter.dofilter(staticuserwebfilter.java:113)         at org.eclipse.jetty.servlet.servlethandler$cachedchain.dofilter(servlethandler.java:1637)         at org.apache.hadoop.hbase.http.clickjackingpreventionfilter.dofilter(clickjackingpreventionfilter.java:48)         at org.eclipse.jetty.servlet.servlethandler$cachedchain.dofilter(servlethandler.java:1637)         at org.apache.hadoop.hbase.http.httpserver$quotinginputfilter.dofilter(httpserver.java:1374)         at org.eclipse.jetty.servlet.servlethandler$cachedchain.dofilter(servlethandler.java:1637)         at org.apache.hadoop.hbase.http.nocachefilter.dofilter(nocachefilter.java:49)         at org.eclipse.jetty.servlet.servlethandler$cachedchain.dofilter(servlethandler.java:1637)         at org.apache.hadoop.hbase.http.nocachefilter.dofilter(nocachefilter.java:49)         at org.eclipse.jetty.servlet.servlethandler$cachedchain.dofilter(servlethandler.java:1637)         at org.eclipse.jetty.servlet.servlethandler.dohandle(servlethandler.java:533) try mvn depencency:tree but didn't find why servlet-api-2.5.jar was introduced. i download hbase-2.0.0-alpha4-bin.tar.gz and didn't find servlet-api-2.5.jar. and build a tar from hbase-2.0.0-alpha4-src.tar.gz and didn't find servlet-api-2.5.jar, too. so this may be introduced by recently commits. and should fix this when release 2.0.0-beta1. ",
        "label": 187
    },
    {
        "text": "mapreducedependencyclasspathtool does not include hbase server as a dependency  this would introduce runtime errors when using snapshot input format. ",
        "label": 314
    },
    {
        "text": "forward port  hbase hostname returned via reverse dns lookup contains trailing period if configured interface is not 'default'   ",
        "label": 314
    },
    {
        "text": "fuzzyrowfilter fails and matches all the rows in the table if the mask consists of all 0s  while using fuzzyrowfilter we noticed that if the mask array consists of all 0s (fixed) the fuzzyrowfilter matches all the rows in the table. we noticed this on hbase 1.1, 1.2 and higher. after some digging we suspect that this is because of ispreprocessedmask() check which is used in preprocessmask() which was added here: https://issues.apache.org/jira/browse/hbase-13761 if the mask consists of all 0s then the ispreprocessedmask() returns true and the preprocessing which responsible for changing 0s to -1 doesn't happen and hence all rows are matched in scan. this scenario can be tested in testfuzzyrowfilterendtoend#testhbase14782() if we change the   byte[] fuzzykey = bytes.tobytesbinary(\"\\\\x00\\\\x00 x044\");  byte[] mask = new byte[] {1,0,0,0} ;  to   byte[] fuzzykey = bytes.tobytesbinary(\"\\\\x9b\\\\x00 x044e\");  byte[] mask = new byte[] {0,0,0,0,0} ; we expect one match but this will match all the rows in the table. ",
        "label": 308
    },
    {
        "text": "cleanup masterobserver hooks which takes ia private params  these are the ones in masterobserver preabortprocedure  -  procedureexecutor postgetprocedures  - procedure postgetlocks  - lockedresource prerequestlock  - locktype postrequestlock  - locktype prelockheartbeat  - lockprocedure postlockheartbeat  - lockprocedure ",
        "label": 314
    },
    {
        "text": "server shutdown handlers deadlocked waiting for meta  i have a situation where both of my master_meta_server_operations handlers are handling server shutdowns, and both of them are waiting on root, which isn't coming up. unclear exactly how this happened, but i triggered it by doing a rolling restart. ",
        "label": 314
    },
    {
        "text": "assignmentmanager getregion  logging nit adds a redundant ' '  from the logs of hmaster: 2012-01-10 17:28:24,370 debug org.apache.hadoop.hbase.master.assignmentmanager: found an existing plan for root,,0.70236052 destination server is + localhost,60020,1326242475275 was the '+' intended to be there , as part of some token for log verification or just being redundant , w.r.t the following string append ? ",
        "label": 266
    },
    {
        "text": "enhance test patch sh with post back of snippet of compilation error if any is detected  currently test-patch.sh would post back something like this: -1 hadoop1.0. the patch failed to compile against the hadoop 1.0 profile. snippet of the compilation error should be included so that people can see what caused the error. ",
        "label": 441
    },
    {
        "text": "allow null qualifier for all table operations  if qualifier to check is null, the checkandmutate/checkandput/checkanddelete will encounter npe.  the test code: table.checkandput(row, family, null, bytes.tobytes(0), new put(row).addcolumn(family, null, bytes.tobytes(1))); the exception: exception in thread \"main\" org.apache.hadoop.hbase.client.retriesexhaustedexception: failed after attempts=3, exceptions: fri apr 08 15:51:31 cst 2016, rpcretryingcaller{globalstarttime=1460101891615, pause=100, maxattempts=3}, java.io.ioexception: com.google.protobuf.serviceexception: java.lang.nullpointerexception fri apr 08 15:51:31 cst 2016, rpcretryingcaller{globalstarttime=1460101891615, pause=100, maxattempts=3}, java.io.ioexception: com.google.protobuf.serviceexception: java.lang.nullpointerexception fri apr 08 15:51:32 cst 2016, rpcretryingcaller{globalstarttime=1460101891615, pause=100, maxattempts=3}, java.io.ioexception: com.google.protobuf.serviceexception: java.lang.nullpointerexception at org.apache.hadoop.hbase.client.rpcretryingcallerimpl.callwithretries(rpcretryingcallerimpl.java:120) at org.apache.hadoop.hbase.client.htable.checkandput(htable.java:772) at ... caused by: java.io.ioexception: com.google.protobuf.serviceexception: java.lang.nullpointerexception at org.apache.hadoop.hbase.protobuf.protobufutil.getremoteexception(protobufutil.java:341) at org.apache.hadoop.hbase.client.htable$7.call(htable.java:768) at org.apache.hadoop.hbase.client.htable$7.call(htable.java:755) at org.apache.hadoop.hbase.client.rpcretryingcallerimpl.callwithretries(rpcretryingcallerimpl.java:99) ... 2 more caused by: com.google.protobuf.serviceexception: java.lang.nullpointerexception at org.apache.hadoop.hbase.ipc.abstractrpcclient.callblockingmethod(abstractrpcclient.java:239) at org.apache.hadoop.hbase.ipc.abstractrpcclient$blockingrpcchannelimplementation.callblockingmethod(abstractrpcclient.java:331) at org.apache.hadoop.hbase.protobuf.generated.clientprotos$clientservice$blockingstub.mutate(clientprotos.java:35252) at org.apache.hadoop.hbase.client.htable$7.call(htable.java:765) ... 4 more caused by: java.lang.nullpointerexception at com.google.protobuf.literalbytestring.size(literalbytestring.java:76) at com.google.protobuf.codedoutputstream.computebytessizenotag(codedoutputstream.java:767) at com.google.protobuf.codedoutputstream.computebytessize(codedoutputstream.java:539) at org.apache.hadoop.hbase.protobuf.generated.clientprotos$condition.getserializedsize(clientprotos.java:7483) at com.google.protobuf.codedoutputstream.computemessagesizenotag(codedoutputstream.java:749) at com.google.protobuf.codedoutputstream.computemessagesize(codedoutputstream.java:530) at org.apache.hadoop.hbase.protobuf.generated.clientprotos$mutaterequest.getserializedsize(clientprotos.java:12431) at org.apache.hadoop.hbase.ipc.ipcutil.gettotalsizewhenwrittendelimited(ipcutil.java:311) at org.apache.hadoop.hbase.ipc.asyncrpcchannel.writerequest(asyncrpcchannel.java:409) at org.apache.hadoop.hbase.ipc.asyncrpcchannel.callmethod(asyncrpcchannel.java:333) at org.apache.hadoop.hbase.ipc.asyncrpcclient.call(asyncrpcclient.java:245) at org.apache.hadoop.hbase.ipc.abstractrpcclient.callblockingmethod(abstractrpcclient.java:226) ... 7 more the reason is literalbytestring.size() will throw npe if wrapped byte array is null. it is possible to invoke put and checkandmutate on the same column, because null qualifier is allowed for put, users may be confused if null qualifier is not allowed for checkandmutate. we can also convert null qualifier to empty byte array for checkandmutate in client side. discussions and suggestions are welcomed. ",
        "label": 187
    },
    {
        "text": "replication reacts slowly on a lightly loaded cluster  replicationsource uses a backing-off algorithm to sleep for an increasing duration when an error is encountered in the replication run loop. however, this backing-off is also performed when there is nothing found to replicate in the hlog. assuming default settings (1 second base retry sleep time, and maximum multiplier of 10), this means that replication takes up to 10 seconds to occur when there is a break of about 55 seconds without anything being written. as there is no error condition, and there is apparently no substantial load on the regionserver in this situation, it would probably make more sense to not back off in non-error situations. ",
        "label": 178
    },
    {
        "text": "mapreduce rowcounter returns incorrect result with binary row key inputs  org.apache.hadoop.hbase.mapreduce.rowcounter takes optional start/end key as inputs (-range option). it would work only when the string representation of value is identical to the string. when row key is binary, the string representation of the value would look like this: \"\\x00\\x01\", which would be incorrect interpreted as 8 char string in the current implementation: https://github.com/apache/hbase/blob/master/hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/rowcounter.java to fix that, we need change how the value is converted from command line inputs: change   scan.setstartrow(bytes.tobytes(startkey));  to  scan.setstartrow(bytes.tobytesbinary(startkey)); do the same conversion to end key as well. the issue was discovered when the utility was used to calcualte row distribution on regions from table with binary row keys. the hbase:meta contains the start key of each region in format of above example. ",
        "label": 308
    },
    {
        "text": "testweakobjectpool time out  on last branch-2 build, this small test timed out. timeout is 1second which given how hostile apache infra has been of late is way to short. change the test to do category-base timeout. here is the report: regression org.apache.hadoop.hbase.util.testweakobjectpool.testcongestion failing for the past 1 build (since failed#778 ) took 1.1 sec. add description error message test timed out after 1000 milliseconds stacktrace org.junit.runners.model.testtimedoutexception: test timed out after 1000 milliseconds at org.apache.hadoop.hbase.util.testweakobjectpool.testcongestion(testweakobjectpool.java:128) standard output ",
        "label": 314
    },
    {
        "text": "backport hbase exportsnapshot should provide capability to limit bandwidth consumption  hbase-11083 allows exportsnapshot to limit bandwidth usage.  here is one approach for backporting: create the following classes (class name is tentative):  hbase-hadoop1-compat/src/main/java/org/apache/hadoop/hbase/util/throttledinputstream.java  hbase-hadoop2-compat/src/main/java/org/apache/hadoop/hbase/util/throttledinputstream.java each of which extends the corresponding throttledinputstream in hadoop-1 / hadoop-2 exportsnapshot would reference util.throttledinputstream, depending on which compatibility module gets bundled. throttledinputstream.java in hadoop-1 branch was backported through mapreduce-5081 which went into 1.2.0 release.  we need to decide how hadoop releases earlier than 1.2.0 should be supported. second approach for backporting is to make a copy of throttledinputstream and include it in hbase codebase. ",
        "label": 441
    },
    {
        "text": "if a master dies and comes back up before his znode expires  the rs heartbeat can lock up  during a rolling restart, we ran into a case where a master was shutdown and then brought back up before the znode expired. on the rs side, while the master was down, it was getting connectionrefused exceptions trying to heartbeat to what it thinks is the active master. once the master process comes back up, the next heartbeat done by all the rss just blocks indefinitely. this is somewhat related to hbase-3141 ",
        "label": 547
    },
    {
        "text": "can't delete in trunk shell  makes it hard doing admin repairs  because shell uses old api, it runs into the \"can't add deletes to a batchupdate\" issue. add new api to do shell delete and deleteall. just a few lines. ",
        "label": 314
    },
    {
        "text": "compaction marker whose region name doesn't match current region's needs to be handled  one customer encountered the following error when replaying recovered edits, leading to region open failure: region=table1,d6b-2282-9223370590058224807-u-9856557-        ej452727-16313786400171,1449616291799.fa8a526f2578eb3630bb08a4b1648f5d., starting to roll back the global memstore   size. org.apache.hadoop.hbase.regionserver.wrongregionexception: compaction marker from wal table_name: \"table1\" encoded_region_name: \"d389c70fde9ec07971d0cfd20ef8f575\" ... region_name: \"table1,d6b-2282-9223370590058224807-u-9856557-ej452727-16313786400171,1449089609367.d389c70fde9ec07971d0cfd20ef8f575.\"  targetted for region d389c70fde9ec07971d0cfd20ef8f575 does not match this region: {encoded => fa8a526f2578eb3630bb08a4b1648f5d, name => 'table1,d6b-2282-                        9223370590058224807-u-9856557-ej452727-16313786400171,1449616291799.fa8a526f2578eb3630bb08a4b1648f5d.', startkey => 'd6b-2282-9223370590058224807-u-9856557-ej452727-             16313786400171', endkey => 'd76-2553-9223370588576178807-u-7416904-ek875822-17662180600000'}   at org.apache.hadoop.hbase.regionserver.hregion.checktargetregion(hregion.java:4592)   at org.apache.hadoop.hbase.regionserver.hregion.replaywalcompactionmarker(hregion.java:3831)   at org.apache.hadoop.hbase.regionserver.hregion.replayrecoverededits(hregion.java:3747)   at org.apache.hadoop.hbase.regionserver.hregion.replayrecoverededitsifany(hregion.java:3601)   at org.apache.hadoop.hbase.regionserver.hregion.initializeregionstores(hregion.java:911)   at org.apache.hadoop.hbase.regionserver.hregion.initializeregioninternals(hregion.java:789)   at org.apache.hadoop.hbase.regionserver.hregion.initialize(hregion.java:762)   at org.apache.hadoop.hbase.regionserver.hregion.openhregion(hregion.java:5774)   at org.apache.hadoop.hbase.regionserver.hregion.openhregion(hregion.java:5744) this was likely caused by the following action of hbck: 15/12/08 18:11:34 info util.hbasefsck: [hbasefsck-pool1-t37] moving files from hdfs://zealand/hbase/data/default/table1/d389c70fde9ec07971d0cfd20ef8f575/recovered.edits into     containing region hdfs://zealand/hbase/data/default/table1/fa8a526f2578eb3630bb08a4b1648f5d/recovered.edits the recovered.edits for d389c70fde9ec07971d0cfd20ef8f575 contained compaction marker which couldn't be replayed against fa8a526f2578eb3630bb08a4b1648f5d ",
        "label": 441
    },
    {
        "text": "set up doxygen for documentation  ",
        "label": 154
    },
    {
        "text": "incorrect handling of null value in coprocessor aggregation function min   both in aggregateimplementation and aggregationclient, the evaluation of the current minimum value is like:  min = (min == null || ci.compare(result, min) < 0) ? result : min; the longcolumninterpreter takes null value is treated as the least value, while the above expression takes min as the greater value when it is null. thus, the real minimum value gets discarded if a null value comes later.  max() could also be wrong if a different columninterpreter other than longcolumninterpreter treats null value differently (as the greatest). ",
        "label": 482
    },
    {
        "text": "specification of scope is missing for certain hadoop dependencies  konstantin i boudnik reported in the mailing thread, 'hbase 0.98.x dependency problems', that specifying hadoop-two.version with value other than 2.2.0 pulls in incorrect dependencies such as: [info] |  \\- org.apache.hadoop:hadoop-hdfs:test-jar:tests:2.2.0:compile this is due to missing specification of scope in the pom.xml files. ",
        "label": 279
    },
    {
        "text": "protobufutil multi behavior is inconsistent in case of errors  protobufutil splits operations by regions and performs multiple client.multi calls. in case if there are certain errors inside rs, hregionserver adds the corresponding exceptions to multiresponse, pu continues the multi request for other regions, and returns partial failure.   in case of other errors (for example, region not served exception), the entire multi operation stops executing, and previous successes and partial results are disregarded.  protobufutil should probably catch serviceexception separately for each client.multi call, make it a partial-failure exception for all actions for this region, and also continue the batch, to make the behavior consistent.  alternatively, if we want to avoid continuing the batch in case of some server-wide errors/connection problems/etc., server should do that for region-specific errors (add exception to results for each action). ",
        "label": 155
    },
    {
        "text": "expose more statistics from hbase master node  we can add the following statistics to the master. some stats that can be added are:   1. number of logs split   2. size of logs split  3. number of region servers online   4. number of region servers opened  5. number of region servers expired ",
        "label": 154
    },
    {
        "text": " rest stargate  uri decoding in rowresource  currently the rowresource constructor uri-decodes the rowspec string before passing it to the rowspec constructor, which breaks rowspecs whose row, column etc identifiers contain slashes. when addressing a row and/or column whose identifier contains a slash, the client must uri-encode the values, so for example a row whose identifier is 'http://hbase.apache.org/' would be addressed as:  /tablename/http%3a%2f%2fhbase.apache.org%2f/column:qualifier currently rowresource() decodes this before passing to rowspec(), so rowspec() recieves:  /tablename/http://hbase.apache.org//column:qualifier  which cannot be correctly parsed because of the extra slashes. rowresource() should pass the string on to rowspec() undecoded, and rowspec() should decode the components individually after piecing apart the path. ",
        "label": 38
    },
    {
        "text": "zookeeperwatcher interruptedexception should throw exception  currently zookeeper#interruptedexception will swallow the interruptedexception and only log, which might cause unexpected behavior, such as when invoking zkutil#checkexists and the watcher thread somehow interrupted, the method will return -1 which means the checked znode doesn't exist, while actually the znode exists. we could also see a todo tag in the javadoc, which indicates we need some fix/improvement here:   /**    * handles interruptedexceptions in client calls.    * <p>    * this may be temporary but for now this gives one place to deal with these.    * <p>    * todo: currently, this method does nothing.    *       is this ever expected to happen?  do we abort or can we let it run?    *       maybe this should be logged as warn?  it shouldn't happen?    * <p>    * @param ie    */ here we propose to throw a keeperexception$systemerrorexception in zookeeperwatcher#interruptedexception, and will add a ut case to cover the interruption scenario. ",
        "label": 504
    },
    {
        "text": "table ui showed exception message when table is disabled  compaction java.util.concurrent.completablefuture.reportget(completablefuture.java:357)java.util.concurrent.completablefuture.get(completablefuture.java:1895)org.apache.hadoop.hbase.generated.master.table_jsp._jspservice(table_jsp.java:299)org.apache.jasper.runtime.httpjspbase.service(httpjspbase.java:111)javax.servlet.http.httpservlet.service(httpservlet.java:790)org.eclipse.jetty.servlet.servletholder.handle(servletholder.java:840)org.eclipse.jetty.servlet.servlethandler$cachedchain.dofilter(servlethandler.java:1780)org.apache.hadoop.hbase.http.lib.staticuserwebfilter$staticuserfilter.dofilter(staticuserwebfilter.java:112)org.eclipse.jetty.servlet.servlethandler$cachedchain.dofilter(servlethandler.java:1767)org.apache.hadoop.hbase.http.clickjackingpreventionfilter.dofilter(clickjackingpreventionfilter.java:48)org.eclipse.jetty.servlet.servlethandler$cachedchain.dofilter(servlethandler.java:1767)org.apache.hadoop.hbase.http.httpserver$quotinginputfilter.dofilter(httpserver.java:1391)org.eclipse.jetty.servlet.servlethandler$cachedchain.dofilter(servlethandler.java:1767)org.apache.hadoop.hbase.http.nocachefilter.dofilter(nocachefilter.java:49)org.eclipse.jetty.servlet.servlethandler$cachedchain.dofilter(servlethandler.java:1767)org.apache.hadoop.hbase.http.nocachefilter.dofilter(nocachefilter.java:49)org.eclipse.jetty.servlet.servlethandler$cachedchain.dofilter(servlethandler.java:1767)org.eclipse.jetty.servlet.servlethandler.dohandle(servlethandler.java:583)org.eclipse.jetty.server.handler.scopedhandler.handle(scopedhandler.java:143)org.eclipse.jetty.security.securityhandler.handle(securityhandler.java:548)org.eclipse.jetty.server.session.sessionhandler.dohandle(sessionhandler.java:226)org.eclipse.jetty.server.handler.contexthandler.dohandle(contexthandler.java:1180)org.eclipse.jetty.servlet.servlethandler.doscope(servlethandler.java:513)org.eclipse.jetty.server.session.sessionhandler.doscope(sessionhandler.java:185)org.eclipse.jetty.server.handler.contexthandler.doscope(contexthandler.java:1112)org.eclipse.jetty.server.handler.scopedhandler.handle(scopedhandler.java:141)org.eclipse.jetty.server.handler.handlercollection.handle(handlercollection.java:119)org.eclipse.jetty.server.handler.handlerwrapper.handle(handlerwrapper.java:134)org.eclipse.jetty.server.server.handle(server.java:539)org.eclipse.jetty.server.httpchannel.handle(httpchannel.java:333)org.eclipse.jetty.server.httpconnection.onfillable(httpconnection.java:251)org.eclipse.jetty.io.abstractconnection$readcallback.succeeded(abstractconnection.java:283)org.eclipse.jetty.io.fillinterest.fillable(fillinterest.java:108)org.eclipse.jetty.io.selectchannelendpoint$2.run(selectchannelendpoint.java:93)org.eclipse.jetty.util.thread.strategy.executeproduceconsume.executeproduceconsume(executeproduceconsume.java:303)org.eclipse.jetty.util.thread.strategy.executeproduceconsume.produceconsume(executeproduceconsume.java:148)org.eclipse.jetty.util.thread.strategy.executeproduceconsume.run(executeproduceconsume.java:136)org.eclipse.jetty.util.thread.queuedthreadpool.runjob(queuedthreadpool.java:671)org.eclipse.jetty.util.thread.queuedthreadpool$2.run(queuedthreadpool.java:589)java.lang.thread.run(thread.java:748) unknown ",
        "label": 187
    },
    {
        "text": "fix testmastermetrics that were disabled by proc v2 am in hbase  with core proc-v2 am change in hbase-14614, stuff is different now around startup which messes up the testmastermetrics test. hbase-14614 disabled two of three tests. this jira tracks work to fix the disabled tests. ",
        "label": 478
    },
    {
        "text": "migration tool that checks presence of hfile v1 files  below was stack's comment from hbase-7660: regards the migration 'tool', or 'tool' to check for presence of v1 files, i imagine it as an addition to the hfile tool http://hbase.apache.org/book.html#hfile_tool2 the hfile tool already takes a bunch of args including printing out meta. we could add an option to print out version only \u2013 or return 1 if version 1 or some such \u2013 and then do a bit of code to just list all hfiles and run this script against each. could mr it if too many files. ",
        "label": 199
    },
    {
        "text": "prevent unnecessary caching of blocks during compactions  when running any kind of compaction, we read every block of every storefile being compacted into the block cache. we would like to reuse any already cached blocks, if available, but otherwise we should not bog down the lru with unnecessary blocks. this is not as bad as it was with the old lru because the latest lru implementation (hbase-1460) is scan-resistant. this ensures that we are not causing massive eviction of the blocks that are being read multiple times or from in-memory tables. however, this does add to the gc-woes of an import because each block gets further referenced, and for longer periods of time. there is also overhead in running the lru evictions. ",
        "label": 247
    },
    {
        "text": "change thread join on exit to a timed thread join  here is a hungup regionserver stuck on the running of the dfs shutdown thread: \"thread-11\" prio=10 tid=0x00007fcd00a9b400 nid=0x751d waiting on condition [0x0000000042458000..0x0000000042458d00]    java.lang.thread.state: timed_waiting (sleeping)         at java.lang.thread.sleep(native method)         at org.apache.hadoop.ipc.client.stop(client.java:667)         at org.apache.hadoop.ipc.rpc$clientcache.stopclient(rpc.java:189)         at org.apache.hadoop.ipc.rpc$clientcache.access$400(rpc.java:138)         at org.apache.hadoop.ipc.rpc$invoker.close(rpc.java:229)         - locked <0x00007fcd06c6b470> (a org.apache.hadoop.ipc.rpc$invoker)         at org.apache.hadoop.ipc.rpc$invoker.access$500(rpc.java:196)         at org.apache.hadoop.ipc.rpc.stopproxy(rpc.java:353)         at org.apache.hadoop.hdfs.dfsclient.close(dfsclient.java:213)         - locked <0x00007fcd06c6b3a0> (a org.apache.hadoop.hdfs.dfsclient)         at org.apache.hadoop.hdfs.distributedfilesystem.close(distributedfilesystem.java:243)         at org.apache.hadoop.fs.filesystem$cache.closeall(filesystem.java:1413)         - locked <0x00007fcd06ab9b68> (a org.apache.hadoop.fs.filesystem$cache)         at org.apache.hadoop.fs.filesystem.closeall(filesystem.java:236)         at org.apache.hadoop.fs.filesystem$clientfinalizer.run(filesystem.java:221)         - locked <0x00007fcd06aaeee0> (a org.apache.hadoop.fs.filesystem$clientfinalizer) above is just doing this:     // wait until all connections are closed     while (!connections.isempty()) {       try {         thread.sleep(100);       } catch (interruptedexception e) {       }     } might never go down or wont' go down promptly. should interrupt threads if join timesout and just continue with exit. ",
        "label": 314
    },
    {
        "text": "resolve npe in backup master ui when access to procedures jsp  when accessing procedures.jsp ,the npe comes in backup master ui:  http error 500 problem accessing /procedures.jsp. reason:  internal_server_error  caused by: java.lang.nullpointerexception  at org.apache.hadoop.hbase.generated.master.procedures_jsp._jspservice(procedures_jsp.java:67)  at org.apache.jasper.runtime.httpjspbase.service(httpjspbase.java:98)  at javax.servlet.http.httpservlet.service(httpservlet.java:820)  at org.mortbay.jetty.servlet.servletholder.handle(servletholder.java:511)  at org.mortbay.jetty.servlet.servlethandler$cachedchain.dofilter(servlethandler.java:1221)  at org.apache.hadoop.hbase.http.lib.staticuserwebfilter$staticuserfilter.dofilter(staticuserwebfilter.java:113)  at org.mortbay.jetty.servlet.servlethandler$cachedchain.dofilter(servlethandler.java:1212)  at org.apache.hadoop.hbase.http.clickjackingpreventionfilter.dofilter(clickjackingpreventionfilter.java:48)  at org.mortbay.jetty.servlet.servlethandler$cachedchain.dofilter(servlethandler.java:1212)  at org.apache.hadoop.hbase.http.httpserver$quotinginputfilter.dofilter(httpserver.java:1354)  at org.mortbay.jetty.servlet.servlethandler$cachedchain.dofilter(servlethandler.java:1212)  at org.apache.hadoop.hbase.http.nocachefilter.dofilter(nocachefilter.java:49)  at org.mortbay.jetty.servlet.servlethandler$cachedchain.dofilter(servlethandler.java:1212)  at org.apache.hadoop.hbase.http.nocachefilter.dofilter(nocachefilter.java:49)  at org.mortbay.jetty.servlet.servlethandler$cachedchain.dofilter(servlethandler.java:1212)  at org.mortbay.jetty.servlet.servlethandler.handle(servlethandler.java:399) in server ,only the active master initialize procedurestore in hmaster.  so ,i think it will be better to remove procedures.jsp link in backup master ui ",
        "label": 415
    },
    {
        "text": " accesscontroller  issues with covering cell permission checks  refer to discussion in hbase-10823. the exact version deletion also check for the preceeding version though the latest version allows the permission this solves the problems   1. exact version delete checks only the relevant cell version permission (not all versions under this)  2. when put/delete contains individual cell ts, this check cell permissions for only relevant covering cell(s) under that specified ts (in mutation kv) ",
        "label": 46
    },
    {
        "text": " replication  npe in replicationsource when creating a stream to an inexistent cluster  this is from 0.92.1-ish: 2012-03-15 09:52:16,589 error org.apache.hadoop.hbase.replication.regionserver.replicationsource: unexpected exception in replicationsource, currentpath=null java.lang.nullpointerexception        at org.apache.hadoop.hbase.replication.regionserver.replicationsource.choosesinks(replicationsource.java:223)        at org.apache.hadoop.hbase.replication.regionserver.replicationsource.connecttopeers(replicationsource.java:442)        at org.apache.hadoop.hbase.replication.regionserver.replicationsource.run(replicationsource.java:246) i wanted to add a replication stream to a cluster that wasn't existing yet so that the logs would be buffered until then. this should just be treated as if there was no region servers. ",
        "label": 229
    },
    {
        "text": "unhealthy region is on service caused by rollback of region splitting  if region splitting is failed in the state of journalentry.closed_parent_region  it will be rollback as the following steps: 1.case closed_parent_region:   this.parent.initialize();         break; 2.case create_split_dir:      this.parent.writestate.writesenabled = true;         cleanupsplitdir(fs, this.splitdir);         break; 3.case set_splitting_in_zk:         if (server != null && server.getzookeeper() != null) {           cleanzk(server, this.parent.getregioninfo());         }         break; if this.parent.initialize() throws ioexception in step 1,  if check filesystem is ok. it will do nothing.  however, the parent region is on service now. ",
        "label": 107
    },
    {
        "text": "set versions for verifyreplication  currently, there is no argument to set versions for verifyreplication tool. it might be useful to have such argument if we want to verify multi-versions. ",
        "label": 238
    },
    {
        "text": "hregion checkandmutate uses incorrect comparison result for       and    in hregion.checkandmutate, incorrect comparison results are used for <, <=, > and >=, as below:  switch (compareop) {  case less:  matches = compareresult <= 0; // should be '<' here  break;  case less_or_equal:  matches = compareresult < 0; // should be '<=' here  break;  case equal:  matches = compareresult == 0;  break;  case not_equal:  matches = compareresult != 0;  break;  case greater_or_equal:  matches = compareresult > 0; // should be '>=' here  break;  case greater:  matches = compareresult >= 0; // should be '>' here  break; ",
        "label": 203
    },
    {
        "text": "mapping a very big table kills region servers  currently tableinputformat doesn't change the block caching behavior of scans and one of our table grew so big that using the defaults we kill a least one region server per job run (because of gcs even if we have a heap of 7gb). this doesn't scale well, we should set it by default to false. ",
        "label": 229
    },
    {
        "text": " thrift  make principal configurable in democlient java  in the thrift1 demo client we have this code: transport = new tsaslclienttransport(\"gssapi\", null,   \"hbase\", // thrift server user name, should be an authorized proxy user.   host, // thrift server domain   saslproperties, null, transport); this will only work when the thrift server is started with the hbase principal. often this may deviate, for example i am using hbase-thrift to separate the names from those of backend servers. what we need is either an additional command line option to specify the name, or a property that can be set with -d and can be passed at runtime. i prefer the former, as the latter is making this a little convoluted. ",
        "label": 439
    },
    {
        "text": "index is not incremented in putsortreducer reduce   starting at line 76:       int index = 0;       for (keyvalue kv : map) {         context.write(row, kv);         if (index > 0 && index % 100 == 0)           context.setstatus(\"wrote \" + index); index is a variable inside while loop that is never incremented.  the condition \"index > 0\" cannot be true. ",
        "label": 191
    },
    {
        "text": "committing batchupdate with no row should complain  running this code: batchupdate update = new batchupdate();  update.put(key, value);  table.commit(update); down in getregionserver, this triggers an npe because the row is null (which i saw because i was running in a debugger); this npe gets retried somewhere in the bowels of ipc. instead, we should either remove the zero-arg batchupdate constructor, or have table.commit throw a runtimeexception if the row is null. ",
        "label": 38
    },
    {
        "text": "procedure v2   web ui displaying queues  we can query masterprocedurescheduler to display the various procedures and who is holding table/region locks. each procedure is in a tablequeue or serverqueue, so it is easy to display the procedures in its own group. ",
        "label": 60
    },
    {
        "text": "hlog tool documentation should be updated to use fshlog for trunk and   the wal tool section in the hbase book suggests   $ ./bin/hbase org.apache.hadoop.hbase.regionserver.wal.hlog --dump hdfs://example.org:8020/hbase/.logs/example.org,60020,1283516293161/10.10.21.10%3a60020.1283973724012 but in trunk hlog is an interface and fshlog is the implementation. the doc has to be updated accordingly. even if we don't do this now we have to when the trunk version gets released. ",
        "label": 314
    },
    {
        "text": "dropping a table always prints a tableinfomissingexception in the master log  everytime i drop a table i get the same stack trace in the master's log: 2013-08-22 23:11:31,939 debug [master_table_operations-jdec2hbase0403-1:60000-0] org.apache.hadoop.hbase.master.handler.deletetablehandler: table 't' archived! 2013-08-22 23:11:31,939 debug [master_table_operations-jdec2hbase0403-1:60000-0] org.apache.hadoop.hbase.master.handler.deletetablehandler: removing 't' descriptor. 2013-08-22 23:11:31,940 debug [master_table_operations-jdec2hbase0403-1:60000-0] org.apache.hadoop.hbase.master.handler.deletetablehandler: marking 't' as deleted. 2013-08-22 23:11:31,944 debug [master_table_operations-jdec2hbase0403-1:60000-0] org.apache.hadoop.hbase.zookeeper.lock.zkinterprocesslockbase: released /hbase/table-lock/t/write-master:600000000000002 2013-08-22 23:11:32,024 debug [rpcserver.handler=0,port=60000] org.apache.hadoop.hbase.util.fstabledescriptors: exception during readtabledecriptor. current table name = t org.apache.hadoop.hbase.tableinfomissingexception: no table descriptor file under hdfs://jdec2hbase0403-1.vpc.cloudera.com:9000/hbase/data/default/t at org.apache.hadoop.hbase.util.fstabledescriptors.gettabledescriptorandmodtime(fstabledescriptors.java:503) at org.apache.hadoop.hbase.util.fstabledescriptors.gettabledescriptorandmodtime(fstabledescriptors.java:496) at org.apache.hadoop.hbase.util.fstabledescriptors.get(fstabledescriptors.java:170) at org.apache.hadoop.hbase.master.hmaster.gettabledescriptors(hmaster.java:2629) at org.apache.hadoop.hbase.protobuf.generated.mastermonitorprotos$mastermonitorservice$2.callblockingmethod(mastermonitorprotos.java:4634) at org.apache.hadoop.hbase.ipc.rpcserver.call(rpcserver.java:2156) at org.apache.hadoop.hbase.ipc.rpcserver$handler.run(rpcserver.java:1861) 2013-08-22 23:11:32,024 warn  [rpcserver.handler=0,port=60000] org.apache.hadoop.hbase.util.fstabledescriptors: the following folder is in hbase's root directory and doesn't contain a table descriptor, do consider deleting it: t but the operation completes. ",
        "label": 38
    },
    {
        "text": "to columnvaluefilter  add filterifcolumnmissing property  add substring operator  couple minor changes i needed: allow one to toggle if columnvaluefilter should filter rows if the column is missing. (the current behavior is to filter f they are missing the column, sometimes i want the rows with the missing column to get through). a special-case sub_string operator which does a case-insensitive string substring check. ",
        "label": 110
    },
    {
        "text": "for intra row scanning  the update readers notification resets the query matcher and can lead to incorrect behavior  in storescanner.resetscannerstack(), which is called on the first next() call after readers have been updated, we do a query matcher reset. normally this is not an issue because the query matcher does not need to maintain state between rows. however, if doing intra-row scanning w/ the specified limit, we could have the query matcher reset in the middle of reading a row. this could lead to incorrect behavior (too many versions coming back, etc). ",
        "label": 38
    },
    {
        "text": "hbase tags are server side only   hbase tags are server side only. in the apache hbase documentation, in section 62.1.1 http://hbase.apache.org/book.html#_implementation_details , i am going to add a sentence to state explicitly that \"tags are not available for get/set from client operations including coprocessors\". ",
        "label": 445
    },
    {
        "text": "nullpointerexception thrown while use canary with ' regionserver' option  the nullpointerexception will be thrown while using following command hadoop_classpath=\"`bin/hbase classpath`\" hadoop org.apache.hadoop.hbase.tool.canary -regionserver the error msg as follows ... 13/12/09 05:17:02 info zookeeper.clientcnxn: session establishment complete on server scottm-hbase-1.lab/10.1.145.175:2181, sessionid = 0x142d5c52b030015, negotiated timeout = 90000 exception in thread \"thread-1\" java.lang.nullpointerexception         at org.apache.hadoop.hbase.tool.canary$regionservermonitor.checknotablenames(canary.java:564)         at org.apache.hadoop.hbase.tool.canary$regionservermonitor.run(canary.java:545)         at java.lang.thread.run(thread.java:662) ",
        "label": 551
    },
    {
        "text": "add bloom filter support to hfileoutputformat  add bloom filter support for bulk imports. lacking a bloom filter, even on a single imported file, can cause perf degradation. since we now set our compression type based on the hbase cf configuration, it would be good to follow this path for the bloom filter addition. ",
        "label": 46
    },
    {
        "text": "block encoder unnecessarily copies the key for each reseek  in hfilereaderv2.abstractscannerv2.reseekto(...) we have this:         bytebuffer bb = getkey();         compared = reader.getcomparator().compare(key, offset,             length, bb.array(), bb.arrayoffset(), bb.limit()); getkey() creates two bytebuffers in scannerv2 and makes a deep copy of the key in encodedscannerv2. ",
        "label": 286
    },
    {
        "text": "create a new  replay  command so that recovered edits won't mess up normal coprocessing   metrics  ",
        "label": 233
    },
    {
        "text": "put has  can't determine result correctly  the public method 'has(byte [] family, byte [] qualifier)' internally invoked the private method 'has(byte [] family, byte [] qualifier, long ts, byte [] value, boolean ignorets, boolean ignorevalue)' with 'value=new byte[0], ignorets=true, ignorevalue=true', but there's a logical error in the body, it'll enter the block else if (ignorevalue) {       for (keyvalue kv: list) {         if (arrays.equals(kv.getfamily(), family) && arrays.equals(kv.getqualifier(), qualifier)             && kv.gettimestamp() == ts) {           return true;         }       }     } the expression 'kv.gettimestamp() == ts' in the if conditions should only exist when 'ignorets=false', otherwise, the following code will return false! put put = new put(bytes.tobytes(\"row-01\")); put.add(bytes.tobytes(\"family-01\"), bytes.tobytes(\"qualifier-01\"), 1234567l, bytes.tobytes(\"value-01\")); system.out.println(put.has(bytes.tobytes(\"family-01\"), bytes.tobytes(\"qualifier-01\"))); ",
        "label": 21
    },
    {
        "text": "table commit should throw nosuchcolumnfamilyexception if column family doesn't exist  java.io.ioexception: java.io.ioexception: requested column family referer: does not exist in hregion michael_test,,1212093731315 for table michael_test  at org.apache.hadoop.hbase.hregion.checkcolumn(hregion.java:1678)  at org.apache.hadoop.hbase.hregion.localput(hregion.java:1598)  at org.apache.hadoop.hbase.hregion.batchupdate(hregion.java:1421)  at org.apache.hadoop.hbase.hregionserver.batchupdate(hregionserver.java:1552)  at sun.reflect.nativemethodaccessorimpl.invoke0(native method)  at sun.reflect.nativemethodaccessorimpl.invoke(unknown source)  at sun.reflect.delegatingmethodaccessorimpl.invoke(unknown source)  at java.lang.reflect.method.invoke(unknown source)  at org.apache.hadoop.hbase.ipc.hbaserpc$server.call(hbaserpc.java:413)  at org.apache.hadoop.ipc.server$handler.run(server.java:901)  at sun.reflect.nativeconstructoraccessorimpl.newinstance0(native method)  at sun.reflect.nativeconstructoraccessorimpl.newinstance(nativeconstructoraccessorimpl.java:39)  at sun.reflect.delegatingconstructoraccessorimpl.newinstance(delegatingconstructoraccessorimpl.java:27)  at java.lang.reflect.constructor.newinstance(constructor.java:494)  at org.apache.hadoop.hbase.remoteexceptionhandler.decoderemoteexception(remoteexceptionhandler.java:82)  at org.apache.hadoop.hbase.htable.getregionserverwithretries(htable.java:1028)  at org.apache.hadoop.hbase.htable.commit(htable.java:763) this is what happened when i tried to add a row with a non-existent column family. in principle, it should be easy to create the column family and try again. i'd like to have hbase throw a nosuchcolumnfamilyexception so i can figure out i need to create the column family. alternately, it would be even better if there were some option to make hbase create the column family for me. ",
        "label": 314
    },
    {
        "text": "hbasemaster requires hdfs superuser privileges due to waitonsafemode  repro:  1) enable dfs.permissions  2) start hbasemaster in a different linux user account from hdfs. i get the following exception in the log. it looks like waitonsafemode requires hdfs superuser privileges which i do not grant to hbase. 2009-12-29 14:44:27,503 error org.apache.hadoop.hbase.master.hmaster: can not start master java.lang.reflect.invocationtargetexception         at sun.reflect.nativeconstructoraccessorimpl.newinstance0(native method)         at sun.reflect.nativeconstructoraccessorimpl.newinstance(nativeconstructoraccessorimpl.java:39)         at sun.reflect.delegatingconstructoraccessorimpl.newinstance(delegatingconstructoraccessorimpl.java:27)         at java.lang.reflect.constructor.newinstance(constructor.java:513)         at org.apache.hadoop.hbase.master.hmaster.domain(hmaster.java:1227)         at org.apache.hadoop.hbase.master.hmaster.main(hmaster.java:1268) caused by: org.apache.hadoop.ipc.remoteexception: org.apache.hadoop.security.accesscontrolexception: superuser privilege is requ ired         at org.apache.hadoop.hdfs.server.namenode.fsnamesystem.checksuperuserprivilege(fsnamesystem.java:4528)         at org.apache.hadoop.hdfs.server.namenode.fsnamesystem.datanodereport(fsnamesystem.java:3560)         at org.apache.hadoop.hdfs.server.namenode.namenode.getdatanodereport(namenode.java:596)         at sun.reflect.nativemethodaccessorimpl.invoke0(native method)         at sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:39)         at sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:25)         at java.lang.reflect.method.invoke(method.java:597)         at org.apache.hadoop.ipc.rpc$server.call(rpc.java:508)         at org.apache.hadoop.ipc.server$handler$1.run(server.java:959)         at org.apache.hadoop.ipc.server$handler$1.run(server.java:955)         at java.security.accesscontroller.doprivileged(native method)         at javax.security.auth.subject.doas(subject.java:396)         at org.apache.hadoop.ipc.server$handler.run(server.java:953)         at org.apache.hadoop.ipc.client.call(client.java:739)         at org.apache.hadoop.ipc.rpc$invoker.invoke(rpc.java:220)         at $proxy0.getdatanodereport(unknown source)         at sun.reflect.nativemethodaccessorimpl.invoke0(native method)         at sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:39)         at sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:25)         at java.lang.reflect.method.invoke(method.java:597)         at org.apache.hadoop.io.retry.retryinvocationhandler.invokemethod(retryinvocationhandler.java:82)         at org.apache.hadoop.io.retry.retryinvocationhandler.invoke(retryinvocationhandler.java:59)         at $proxy0.getdatanodereport(unknown source)         at org.apache.hadoop.hdfs.dfsclient.datanodereport(dfsclient.java:818)         at org.apache.hadoop.hdfs.distributedfilesystem.getdatanodestats(distributedfilesystem.java:353)         at org.apache.hadoop.hbase.util.fsutils.waitonsafemode(fsutils.java:146)         at org.apache.hadoop.hbase.master.hmaster.<init>(hmaster.java:197) ",
        "label": 38
    },
    {
        "text": "performance issue  clientasyncprefetchscanner is slower than clientsimplescanner  copied the test result from hbase-17994. ./bin/hbase org.apache.hadoop.hbase.performanceevaluation --rows=100000 --nomapred scan 1 ./bin/hbase org.apache.hadoop.hbase.performanceevaluation --rows=100000 --nomapred --asyncprefetch=true scan 1 mean latency.   test1  test2   test3   test4  test5 scan  12.21   14.32   13.25   13.07   11.83 scan with prefetch=true   37.36   37.88   37.56   37.66   38.28 ",
        "label": 187
    },
    {
        "text": "hcolumndescriptor is a little too restrictive with family names  hcolumndescriptor crrently requires of its family names that they be letters, digits, underscores or periods. character.isletterordigit(b[i]) || b[i] == '_' || b[i] == '.' it would be nice if it let rather more characters be used (personally, i'd like to use a hyphen!) ",
        "label": 38
    },
    {
        "text": "increment timerange not serialized to server  before hbase-1.2, the increment timerange set on the client was serialized over to the server. as of hbase 1.2, this appears to no longer be true, as my preincrement coprocessor always gets hconstants.latest_timestamp as the value of increment.gettimerange().getmax() regardless of what the client has specified. ",
        "label": 441
    },
    {
        "text": " hadoop native lib  config is deprecated  when using hbase shell, we see: 12/03/09 09:06:58 warn conf.configuration: hadoop.native.lib is deprecated. instead, use io.native.lib.available \"io.native.lib.available\" should be used. ",
        "label": 163
    },
    {
        "text": "disable hanging test testnamespaceauditor  the test hung here: https://builds.apache.org/job/precommit-hbase-build/15893//console it hangs quite regularly. any chance of taking a look vandana ayyalasomayajula? else, i'll just disable it so we can get clean builds again. thanks. ",
        "label": 314
    },
    {
        "text": "maven hadoop profile  version  needs to be updated with latest snapshot  current profile is still pointing to 0.23.1-snapshot.   this is failing to build as 23.1 is already released and snapshot is not available anymore.  we can update this to 0.23.2-snapshot. ",
        "label": 287
    },
    {
        "text": "remove replicationqueues  use replicationqueuestorage directly  ",
        "label": 149
    },
    {
        "text": "in some situations data is not replicated to slaves when deferredlogsync is enabled  this is a subtle issue. when deferredlogsync is enabled, there are chances we could flush data before syncing all hlog entries. assuming we just flush the internal cache and the server dies with some unsynced hlog entries. data is not lost at the source cluster while replication is based on wal files and some changes we flushed at the source won't be replicated the slave clusters. although enabling deferredlogsync with tolerances of data loss, it breaks the replication assumption that whatever persisted in the source should be replicated to its slave clusters. in short, the slave cluster could end up with double losses: the data loss in the source and some data stored in source cluster may not be replicated to slaves either. the fix of the issue isn't hard. basically we can invoke sync during each flush when replication is enabled for a region server. since sync returns immediately when nothing to sync so there should be no performance impact. please let me know what you think! thanks,  -jeffrey ",
        "label": 233
    },
    {
        "text": "procedure v2  core assignment manager  new assignmentmanager implemented using proc-v2. assignprocedure handle assignment operation unassignprocedure handle unassign operation moveregionprocedure handle move/balance operation concurrent assign operations are batched together and sent to the balancer  concurrent assign and unassign operation ready to be sent to the rs are batched together this patch is an intermediate state where we add the new am as assignmentmanager2() to the master, to be reached by tests. but the new am will not be integrated with the rest of the system. only new am unit-tests will exercise the new assigment manager. the integration with the master code is part of hbase-14616 ",
        "label": 309
    },
    {
        "text": "regionserver deadlock  we periodically see a situation where the regionserver process exists in the process list, zookeeper thread sends the keepalive so the master won't remove it from the active list, yet the regionserver will not serve data. hadoop(cdh3u0), hbase 0.90.3 (apache version), under load from an internal testing tool. attached is the full jstack ",
        "label": 544
    },
    {
        "text": "hbase broke testcompaction  fix and reenable  ",
        "label": 314
    },
    {
        "text": "testiofencing testfencingaroundcompaction occasionally fails  from https://builds.apache.org/job/precommit-hbase-build/6232//testreport/org.apache.hadoop.hbase/testiofencing/testfencingaroundcompaction/ : java.lang.assertionerror: timed out waiting for new server to open region at org.junit.assert.fail(assert.java:88) at org.junit.assert.asserttrue(assert.java:41) at org.apache.hadoop.hbase.testiofencing.dotest(testiofencing.java:269) at org.apache.hadoop.hbase.testiofencing.testfencingaroundcompaction(testiofencing.java:205) 2013-07-06 23:13:53,120 info  [pool-1-thread-1] hbase.testiofencing(266): waiting for the new server to pick up the region tabletest,,1373152125442.6e62d3b24ea23160931362b60359ff03. 2013-07-06 23:13:54,120 info  [pool-1-thread-1] hbase.testiofencing(266): waiting for the new server to pick up the region tabletest,,1373152125442.6e62d3b24ea23160931362b60359ff03. 2013-07-06 23:13:55,121 debug [pool-1-thread-1] hbase.testiofencing$compactionblockerregion(102): allowing compactions 2013-07-06 23:13:55,121 info  [pool-1-thread-1] hbase.hbasetestingutility(911): shutting down minicluster 2013-07-06 23:13:55,121 debug [pool-1-thread-1] util.jvmclusterutil(237): shutting down hbase cluster 2013-07-06 23:13:55,121 info  [rs:0;asf002:39065-smallcompactions-1373152134716] regionserver.hstore(951): starting compaction of 2 file(s) in family of tabletest,,1373152125442.6e62d3b24ea23160931362b60359ff03. into tmpdir=hdfs://localhost:50140/user/jenkins/hbase/tabletest/6e62d3b24ea23160931362b60359ff03/.tmp, totalsize=108.4k ... 2013-07-06 23:13:55,155 info  [rs:0;asf002:39065] regionserver.hregionserver(2476): received close for the region: 6e62d3b24ea23160931362b60359ff03 ,which we are already trying to close 2013-07-06 23:13:55,157 warn  [rs:0;asf002:39065] regionserver.hregionserver(2414): failed to close tabletest,,1373152125442.6e62d3b24ea23160931362b60359ff03. - ignoring and continuing org.apache.hadoop.hbase.exceptions.notservingregionexception: the region 6e62d3b24ea23160931362b60359ff03 was already closing. new close request is ignored. at org.apache.hadoop.hbase.regionserver.hregionserver.closeregion(hregionserver.java:2479) at org.apache.hadoop.hbase.regionserver.hregionserver.closeregionignoreerrors(hregionserver.java:2409) at org.apache.hadoop.hbase.regionserver.hregionserver.closeuserregions(hregionserver.java:2011) at org.apache.hadoop.hbase.regionserver.hregionserver.run(hregionserver.java:903) at org.apache.hadoop.hbase.minihbasecluster$minihbaseclusterregionserver.runregionserver(minihbasecluster.java:158) at org.apache.hadoop.hbase.minihbasecluster$minihbaseclusterregionserver.access$000(minihbasecluster.java:110) at org.apache.hadoop.hbase.minihbasecluster$minihbaseclusterregionserver$1.run(minihbasecluster.java:142) at java.security.accesscontroller.doprivileged(native method) at javax.security.auth.subject.doas(subject.java:337) at org.apache.hadoop.security.usergroupinformation.doas(usergroupinformation.java:1131) at sun.reflect.nativemethodaccessorimpl.invoke0(native method) at sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:39) at sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:25) at java.lang.reflect.method.invoke(method.java:597) at org.apache.hadoop.hbase.util.methods.call(methods.java:41) at org.apache.hadoop.hbase.security.user.call(user.java:420) at org.apache.hadoop.hbase.security.user.access$300(user.java:51) at org.apache.hadoop.hbase.security.user$securehadoopuser.runas(user.java:260) at org.apache.hadoop.hbase.minihbasecluster$minihbaseclusterregionserver.run(minihbasecluster.java:140) ",
        "label": 441
    },
    {
        "text": "add a htable get obtainscanner method that retrieves all versions of a particular column and row between two timestamps  the use case: a weblog application for which rows are user ids and posts are stored in a single column, with post date specified by the cell's timestamp. the application would then need to be able to display all posts for the last week or month. a feedfetcher for which rows are urls and feed posts are stored in a single column with the post publish date or fetch time stored in the cell's timestamp. the application would then need to be able to display all posts for the last week or month. proposed api: // get all versions of the specified row and column whose timestamps are in [mintimestamp, maxtimestamp]  sortedmap<long, byte[]> gettimestamps(text row, text column, long mintimestamp, long maxtimestamp); // get all versions of the specified row and column whose timestamps are >= mintimestamp  sortedmap<long, byte[]> gettimestamps(text row, text column, long mintimestamp); i'd be happy to take this on myself, as i need it for the above use cases before migrating my application over to hbase. ",
        "label": 247
    },
    {
        "text": "generate the protobuf classes with hadoop maven plugin  for now, the protobuf classes are generated once by a dev, and put in src/main/resouce. this allows the other dev to not have the correct protoc version available on their machine. however, when a dev wants to modify the protoc messages, he has to know how to generate the classes. this could be documented... another approach would be to put a harder requirement on the hbase developers (protoc available) and let the hadoop-maven-plugin (http://central.maven.org/maven2/org/apache/hadoop/hadoop-maven-plugins/2.0.5-alpha) to do the work (i have bad experience with other maven protobuf plugins, the hadoop one works just out of the box). i don't think asking to install protoc to build hbase is so difficult, but that's an additional step between the dev and the artifcat. the advantage would be to allow to have different protobuf versions for different hbase distributions (perfectly possible but quite theorical). so  option 1: we are happy to keep the classes in src/main/java  option 2: we want to move to hadoop-maven-plugin   option 3: i may be short of idea... any other input? ",
        "label": 158
    },
    {
        "text": "upgrade to zookeeper  zookeeper 3.4.8 has been released.  among the fixes the following are desirable: zookeeper-706 large numbers of watches can cause session re-establishment to fail   zookeeper-1797 purgetxnlog may delete data logs during roll this issue upgrades zookeeper dependency to 3.4.8 ",
        "label": 441
    },
    {
        "text": "update download mirror link  where we refer to www.apache.org/dyn/closer.cgi, we need to refer to  www.apache.org/dyn/closer.lua instead . ",
        "label": 284
    },
    {
        "text": "backport hbase to  string and concurrenthashmap sizes change on jdk7 this was brought up by discussion from hbase-8014: https://issues.apache.org/jira/browse/hbase-8014?focusedcommentid=13665711&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13665711 ",
        "label": 441
    },
    {
        "text": "scan javadoc doesn't fully capture semantics of start and stop row  the current javadoc for scan#setstartrow and scan#setstoprow methods don't accurately capture the semantics of the use of row prefix values. both methods describe the use of a trailing null byte to change the inclusive/exclusive the respective semantics of setstartrow and setstoprow. the use of a trailing null byte for start row exclusion only works in the case that exact full matching is done on row keys. the use of a trailing null byte for stop row inclusion has even more limitations (see hbase-9035). the basic example is having the following rows: aab abb bbc bcc setting the start row to a and the stop row to b will include aab and ab. setting the start row to a\\x0 and the stop row to b\\x0 will result in the same two rows coming out of the scan, instead of having an effect on the inclusion/exclusion semantics. ",
        "label": 178
    },
    {
        "text": "bump log4j to  hadoop bumped to 1.2.17 log4j (hadoop-8687), we should probably as well. ",
        "label": 248
    },
    {
        "text": "better handle invalid local directory for dynamicclassloader  if you give hbase an hbase.local.dir (usually, \"hbase.tmp.dir/local\") which is not writable to it, you will get some weird errors on the scan path. i just saw this (again?) with phoenix. specifically, the first attempt to reference dynamicclassloader (via protobufutil), will result in an exceptionininitializationerror because the unchecked exception coming out of dynamicclassloader's constructor interrupts the loading of dynamicclassloader.class. 2019-07-14 06:25:34,284 error [rpcserver.metadata.fifo.handler=12,queue=0,port=16020] coprocessor.metadataendpointimpl: droptable failed org.apache.hadoop.hbase.donotretryioexception: java.lang.exceptionininitializererror         at org.apache.hadoop.hbase.client.rpcretryingcallerimpl.translateexception(rpcretryingcallerimpl.java:221)         at org.apache.hadoop.hbase.client.rpcretryingcallerimpl.callwithoutretries(rpcretryingcallerimpl.java:194)         at org.apache.hadoop.hbase.client.scannercallablewithreplicas$retryingrpc.call(scannercallablewithreplicas.java:387)         at org.apache.hadoop.hbase.client.scannercallablewithreplicas$retryingrpc.call(scannercallablewithreplicas.java:361)         at org.apache.hadoop.hbase.client.rpcretryingcallerimpl.callwithretries(rpcretryingcallerimpl.java:107)         at org.apache.hadoop.hbase.client.resultboundedcompletionservice$queueingfuture.run(resultboundedcompletionservice.java:80)         at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1149)         at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624)         at java.lang.thread.run(thread.java:748) caused by: java.lang.exceptionininitializererror         at org.apache.hadoop.hbase.shaded.protobuf.protobufutil.tofilter(protobufutil.java:1598)         at org.apache.hadoop.hbase.shaded.protobuf.protobufutil.toscan(protobufutil.java:1152)         at org.apache.hadoop.hbase.regionserver.rsrpcservices.newregionscanner(rsrpcservices.java:2967)         at org.apache.hadoop.hbase.regionserver.rsrpcservices.scan(rsrpcservices.java:3301)         at org.apache.hadoop.hbase.client.scannercallable.openscanner(scannercallable.java:332)         at org.apache.hadoop.hbase.client.scannercallable.rpccall(scannercallable.java:242)         at org.apache.hadoop.hbase.client.scannercallable.rpccall(scannercallable.java:58)         at org.apache.hadoop.hbase.client.regionservercallable.call(regionservercallable.java:127)         at org.apache.hadoop.hbase.client.rpcretryingcallerimpl.callwithoutretries(rpcretryingcallerimpl.java:192)         ... 7 more caused by: java.lang.runtimeexception: failed to create local dir /hadoopfs/fs1/hbase/local/jars, dynamicclassloader failed to init         at org.apache.hadoop.hbase.util.dynamicclassloader.inittempdir(dynamicclassloader.java:110)         at org.apache.hadoop.hbase.util.dynamicclassloader.<init>(dynamicclassloader.java:98)         at org.apache.hadoop.hbase.shaded.protobuf.protobufutil$classloaderholder.lambda$static$0(protobufutil.java:261)         at java.security.accesscontroller.doprivileged(native method)         at org.apache.hadoop.hbase.shaded.protobuf.protobufutil$classloaderholder.<clinit>(protobufutil.java:260)         ... 16 more every subsequent call will result in a noclassdeffounderror, because we already tried to load dynamicclassloader.class once and failed. 2019-07-14 06:25:34,380 error [rpcserver.metadata.fifo.handler=2,queue=2,port=16020] coprocessor.metadataendpointimpl: droptable failed org.apache.hadoop.hbase.donotretryioexception: java.lang.noclassdeffounderror: could not initialize class org.apache.hadoop.hbase.shaded.protobuf.protobufutil$classloaderholder         at org.apache.hadoop.hbase.client.rpcretryingcallerimpl.translateexception(rpcretryingcallerimpl.java:221)         at org.apache.hadoop.hbase.client.rpcretryingcallerimpl.callwithoutretries(rpcretryingcallerimpl.java:194)         at org.apache.hadoop.hbase.client.scannercallablewithreplicas$retryingrpc.call(scannercallablewithreplicas.java:387)         at org.apache.hadoop.hbase.client.scannercallablewithreplicas$retryingrpc.call(scannercallablewithreplicas.java:361)         at org.apache.hadoop.hbase.client.rpcretryingcallerimpl.callwithretries(rpcretryingcallerimpl.java:107)         at org.apache.hadoop.hbase.client.resultboundedcompletionservice$queueingfuture.run(resultboundedcompletionservice.java:80)         at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1149)         at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:624)         at java.lang.thread.run(thread.java:748) caused by: java.lang.noclassdeffounderror: could not initialize class org.apache.hadoop.hbase.shaded.protobuf.protobufutil$classloaderholder         at org.apache.hadoop.hbase.shaded.protobuf.protobufutil.tofilter(protobufutil.java:1598)         at org.apache.hadoop.hbase.shaded.protobuf.protobufutil.toscan(protobufutil.java:1152)         at org.apache.hadoop.hbase.regionserver.rsrpcservices.newregionscanner(rsrpcservices.java:2967)         at org.apache.hadoop.hbase.regionserver.rsrpcservices.scan(rsrpcservices.java:3301)         at org.apache.hadoop.hbase.client.scannercallable.openscanner(scannercallable.java:332)         at org.apache.hadoop.hbase.client.scannercallable.rpccall(scannercallable.java:242)         at org.apache.hadoop.hbase.client.scannercallable.rpccall(scannercallable.java:58)         at org.apache.hadoop.hbase.client.regionservercallable.call(regionservercallable.java:127)         at org.apache.hadoop.hbase.client.rpcretryingcallerimpl.callwithoutretries(rpcretryingcallerimpl.java:192)         ... 7 more the client gets an error about this, and would presumably know that something is amiss, but an operator wouldn't potentially see this on their own. i see two options: 1. we abort the regionserver when the dynamicclassloader fails to run 2. we catch the exception and treat the dynamicclassloader as disabled (same action as if you had set hbase.use.dynamic.jars=false). i want to do #1 so that we don't propagate bogus configuration, but it feels a bit \"harsh\" to do that. i think #2 is the right solution with a big-fat-warning. ",
        "label": 252
    },
    {
        "text": "ensure hbase is covered by thrift  hbase-7035 is about leaking open tables. make sure thrift 2 handles that properly. ",
        "label": 285
    },
    {
        "text": "improve split compact result page for regionserver status page  when you click on split/compact in the table.jsp (or the new jamon template) you get: split request accepted. reload. reloading seems the wrong advice as it triggers the action over and over again.  we should have a link back to the previous page (could be  \"history.back()\" or so), or simple add a proper forwarding after 5  secs. ",
        "label": 289
    },
    {
        "text": "allow emitting deletes out of new tablereducer  do\u011facan g\u00fcney (nutch) wants to emit delete from tablereduce. currently we only do put. ",
        "label": 285
    },
    {
        "text": "major compaction periodicity should be specifyable at the column family level  not cluster wide  jon gray has a table of ten rows and a couple of columns that is constantly being updated. has max versions of 2. this table is growing fast because all versions written are kept until a major compaction. the way this table is being used is different than that of others. would be good if he could have major compactions run more often than the default once a day. ",
        "label": 247
    },
    {
        "text": "fix increased javadoc warns  6 warnings [warning] javadoc warnings [warning] /home/jenkins/jenkins-slave/workspace/precommit-hbase-build/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/hregionserver.java:338: warning - tag @link: can't find isa in org.apache.hadoop.hbase.regionserver.hregionserver [warning] /home/jenkins/jenkins-slave/workspace/precommit-hbase-build/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/rpcserverinterface.java:45: warning - tag @link: can't find openserver() in org.apache.hadoop.hbase.ipc.rpcserverinterface [warning] /home/jenkins/jenkins-slave/workspace/precommit-hbase-build/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/rpcserverinterface.java:45: warning - tag @link: can't find startthreads() in org.apache.hadoop.hbase.ipc.rpcserverinterface [warning] /home/jenkins/jenkins-slave/workspace/precommit-hbase-build/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/rpcserverinterface.java:45: warning - tag @link: can't find openserver() in org.apache.hadoop.hbase.ipc.rpcserverinterface [warning] /home/jenkins/jenkins-slave/workspace/precommit-hbase-build/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/rpcserverinterface.java:45: warning - tag @link: can't find startthreads() in org.apache.hadoop.hbase.ipc.rpcserverinterface [warning] /home/jenkins/jenkins-slave/workspace/precommit-hbase-build/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/master/masterrpcservices.java:721: warning - @param argument \"controller\" is not a parameter name. ",
        "label": 46
    },
    {
        "text": "convert wal to pb  from hbase-7201 ",
        "label": 406
    },
    {
        "text": "redo test patch personality 'hadoopcheck' to better account for feature branches  right now our 'which hadoop checks do we need' check looks like this:   if [[ \"${patch_branch}\" = \"master\" ]]; then     hbase_hadoop2_versions=${hbase_master_hadoop2_versions}     hbase_hadoop3_versions=${hbase_master_hadoop3_versions}   elif [[ ${patch_branch} = branch-2* ]]; then     hbase_hadoop2_versions=${hbase_branch2_hadoop2_versions}     hbase_hadoop3_versions=${hbase_branch2_hadoop3_versions}   else     hbase_hadoop2_versions=${hbase_hadoop2_versions}     hbase_hadoop3_versions=${hbase_hadoop3_versions}   fi the check is basically \"if master do this, if like branch-2 do that, otherwise behave like branch-1\". we often have feature branches that thus end up being treated like branch-1, even though those branches should all be based off of master. (since we follow a master-first development approach.) we should redo this check so it's \"if branch-1 do this, if branch-2 do that, otherwise behave like master\" ",
        "label": 402
    },
    {
        "text": " amv2  split merge need cleanup  currently they diverge and do not fully embrace amv2 world  region split and merge work on the new amv2 but they work differently. this issue is about bringing them back together and fully embracing the amv2 program. they both have issues mostly the fact that they carry around baggage no longer necessary in the new world of assignment. here are some of the items: split and merge metadata modifications are done by the master now but we have vestige of split/merge on rs still; e.g. when we split, we ask the master which asks the rs, which turns around, and asks the master to run the operation. fun. merge is all done master-side. clean this up. remove asking rs to run split and remove regionmergerequest, etc. on rs-side. also remove ponr. we don\u2019t points-of-no-return now we are up on pv2. remove all calls in interfaces; they are unused. make rs still able to detect when split, but have it be a client of master like anyone else. split is async but does not return procid split is async. doesn\u2019t return the procid though. merge does. fix. only hard part here i think is the admin api does not allow procid return. flags currently offline is determined by looking either at the master instance of htd (isoffline) and/or at the regionstate#state. ditto for split. for merge, we rely on regionstate#state. related is a note above on how split works \u2013 there is a split flag in htd when there should not be. todo is move to rely on regionstate#state exclusively in master. from split/merge procedures need finishing in https://docs.google.com/document/d/1evka7fhdeoj1-9o8yzcotaqbv0u0bblblcczvsin69g/edit#heading=h.4b60dc1h4m1f ",
        "label": 499
    },
    {
        "text": "testcompaction times out in latest release  testcompaction is timing out in 0.89.20100924. it's using hregion directly and writing too much data, so the writes start blocking forever. ",
        "label": 314
    },
    {
        "text": "regionserver oome handler should dump vital stats  on oome the regionserver should dump into the log some vital stats: number of regions number of store files estimated item count and size of memcache(s) estimated item count and size of store file indexes assumes the reserve can be released upon oome to allow the additional actions. ",
        "label": 314
    },
    {
        "text": "add integration test for bulkload with replicas  should verify bulkload is not affected by region replicas. ",
        "label": 139
    },
    {
        "text": "shell is failing on subsequent split calls  while working on hbase-3492 i came across another oddity with manual splits: hbase(main):003:0> split 'testtable'                                                                                                                  0 row(s) in 3.0590 seconds hbase(main):004:0> scan '.meta.', { columns => ['info:regioninfo'] }                                                                                  row                                       column+cell                                                                                                              testtable,,1296545855212.5e4ef9631cacb6b column=info:regioninfo, timestamp=1296545855770, value=region => {name => 'testtable,,1296545855212.5e4ef9631cacb6b2c6c  2c6c338140c53cad4.                       338140c53cad4.', startkey => '', endkey => 'row-mdc', encoded => 5e4ef9631cacb6b2c6c338140c53cad4, table => {{name => '                                           testtable', families => [{name => 'cf1', bloomfilter => 'none', replication_scope => '0', versions => '3', compression                                            => 'none', ttl => '2147483647', blocksize => '65536', in_memory => 'false', blockcache => 'true'}, {name => 'cf2', bloo                                           mfilter => 'none', replication_scope => '0', versions => '3', compression => 'none', ttl => '2147483647', blocksize =>                                            '65536', in_memory => 'false', blockcache => 'true'}]}}                                                                  testtable,row-mdc,1296545855212.46e57f0c column=info:regioninfo, timestamp=1296545855774, value=region => {name => 'testtable,row-mdc,1296545855212.46e57f0ca4eb  a4eba8d3e5bef6365159a660.                a8d3e5bef6365159a660.', startkey => 'row-mdc', endkey => '', encoded => 46e57f0ca4eba8d3e5bef6365159a660, table => {{na                                           me => 'testtable', families => [{name => 'cf1', bloomfilter => 'none', replication_scope => '0', versions => '3', compr                                           ession => 'none', ttl => '2147483647', blocksize => '65536', in_memory => 'false', blockcache => 'true'}, {name => 'cf2                                           ', bloomfilter => 'none', replication_scope => '0', versions => '3', compression => 'none', ttl => '2147483647', blocks                                           ize => '65536', in_memory => 'false', blockcache => 'true'}]}}                                                          2 row(s) in 0.6690 seconds hbase(main):005:0> split 'testtable'                                 0 row(s) in 0.4030 seconds hbase(main):006:0> split 'testtable' error: org.apache.hadoop.ipc.remoteexception: org.apache.hadoop.hbase.notservingregionexception: region is not online: testtable,,1296545855212.5e4ef9631cacb6b2c6c338140c53cad4.         at org.apache.hadoop.hbase.regionserver.hregionserver.getregion(hregionserver.java:2376)         at org.apache.hadoop.hbase.regionserver.hregionserver.splitregion(hregionserver.java:2196)         at sun.reflect.nativemethodaccessorimpl.invoke0(native method)         at sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:39)         at sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:25)         at java.lang.reflect.method.invoke(method.java:597)         at org.apache.hadoop.hbase.ipc.writablerpcengine$server.call(writablerpcengine.java:309)         at org.apache.hadoop.hbase.ipc.hbaseserver$handler.run(hbaseserver.java:1057) here is some help for this command: split entire table or pass a region to split individual region.  with the  second parameter, you can specify an explicit split key for the region.   examples:     split 'tablename'     split 'regionname' # format: 'tablename,startkey,id'     split 'tablename', 'splitkey'     split 'regionname', 'splitkey' it takes minutes for this to clear out eventually. why is this not retried or flushed out right away? a few minutes later i see this in the logs: 2011-02-01 08:42:42,062 info org.apache.hadoop.hbase.catalog.metaeditor: deleted daughter reference testtable,,1296545879295.dfcc24e02e27e60160612dd5398cbd1e., qualifier=splita, from parent testtable,,1296545855212.5e4ef9631cacb6b2c6c338140c53cad4. 2011-02-01 08:42:42,064 debug org.apache.hadoop.hbase.ipc.hbaserpc: call: getregioninfo 1 2011-02-01 08:42:42,064 debug org.apache.hadoop.hbase.ipc.hbaserpc: call: delete 0 2011-02-01 08:42:42,064 info org.apache.hadoop.hbase.catalog.metaeditor: deleted daughter reference testtable,row-dau,1296545879295.4073eb6c82755aab57778af2dba39e22., qualifier=splitb, from parent testtable,,1296545855212.5e4ef9631cacb6b2c6c338140c53cad4. 2011-02-01 08:42:42,064 debug org.apache.hadoop.hbase.master.catalogjanitor: deleting region testtable,,1296545855212.5e4ef9631cacb6b2c6c338140c53cad4. because daughter splits no longer hold references 2011-02-01 08:42:42,065 debug org.apache.hadoop.hbase.regionserver.hregion: deleting region file:/tmp/hbase-larsgeorge/hbase/testtable/5e4ef9631cacb6b2c6c338140c53cad4 2011-02-01 08:42:42,067 debug org.apache.hadoop.hbase.ipc.hbaserpc: call: getregioninfo 1 2011-02-01 08:42:42,067 debug org.apache.hadoop.hbase.ipc.hbaserpc: call: delete 0 2011-02-01 08:42:42,067 info org.apache.hadoop.hbase.catalog.metaeditor: deleted region testtable,,1296545855212.5e4ef9631cacb6b2c6c338140c53cad4. from meta 2011-02-01 08:42:42,069 debug org.apache.hadoop.hbase.ipc.hbaserpc: call: getregioninfo 0 2011-02-01 08:42:42,070 debug org.apache.hadoop.hbase.ipc.hbaserpc: call: delete 1 2011-02-01 08:42:42,071 info org.apache.hadoop.hbase.catalog.metaeditor: deleted daughter reference testtable,row-mdc,1296545879558.94cb351e5dd36c269247dd8a1a79373c., qualifier=splita, from parent testtable,row-mdc,1296545855212.46e57f0ca4eba8d3e5bef6365159a660. 2011-02-01 08:42:42,073 debug org.apache.hadoop.hbase.ipc.hbaserpc: call: getregioninfo 1 2011-02-01 08:42:42,074 debug org.apache.hadoop.hbase.ipc.hbaserpc: call: delete 1 2011-02-01 08:42:42,074 info org.apache.hadoop.hbase.catalog.metaeditor: deleted daughter reference testtable,row-seq,1296545879558.43c5ffe1ca7dd6d1374b7b7430a7d261., qualifier=splitb, from parent testtable,row-mdc,1296545855212.46e57f0ca4eba8d3e5bef6365159a660. 2011-02-01 08:42:42,074 debug org.apache.hadoop.hbase.master.catalogjanitor: deleting region testtable,row-mdc,1296545855212.46e57f0ca4eba8d3e5bef6365159a660. because daughter splits no longer hold references 2011-02-01 08:42:42,074 debug org.apache.hadoop.hbase.regionserver.hregion: deleting region file:/tmp/hbase-larsgeorge/hbase/testtable/46e57f0ca4eba8d3e5bef6365159a660 the the next split call works while the subsequent ones fail again. in other words the split is dropped somewhere and picked up by the catalog classes later while the shell does not see the new daughter regions? even .meta. is off hbase(main):011:0> scan '.meta.', { columns => ['info:regioninfo'] } row                                       column+cell                                                                                                              testtable,,1296545879295.dfcc24e02e27e60 column=info:regioninfo, timestamp=1296546225693, value=region => {name => 'testtable,,1296545879295.dfcc24e02e27e601606  160612dd5398cbd1e.                       12dd5398cbd1e.', startkey => '', endkey => 'row-dau', encoded => dfcc24e02e27e60160612dd5398cbd1e, offline => true, spl                                           it => true, table => {{name => 'testtable', families => [{name => 'cf1', bloomfilter => 'none', replication_scope => '0                                           ', versions => '3', compression => 'none', ttl => '2147483647', blocksize => '65536', in_memory => 'false', blockcache                                            => 'true'}, {name => 'cf2', bloomfilter => 'none', replication_scope => '0', versions => '3', compression => 'none', tt                                           l => '2147483647', blocksize => '65536', in_memory => 'false', blockcache => 'true'}]}}                                  testtable,,1296546225506.f3a53bfa1bfd5ae column=info:regioninfo, timestamp=1296546225763, value=region => {name => 'testtable,,1296546225506.f3a53bfa1bfd5ae6cbb  6cbb0641d43f8a242.                       0641d43f8a242.', startkey => '', endkey => 'row-aaa', encoded => f3a53bfa1bfd5ae6cbb0641d43f8a242, table => {{name => '                                           testtable', families => [{name => 'cf1', bloomfilter => 'none', replication_scope => '0', versions => '3', compression                                            => 'none', ttl => '2147483647', blocksize => '65536', in_memory => 'false', blockcache => 'true'}, {name => 'cf2', bloo                                           mfilter => 'none', replication_scope => '0', versions => '3', compression => 'none', ttl => '2147483647', blocksize =>                                            '65536', in_memory => 'false', blockcache => 'true'}]}}                                                                  testtable,row-aaa,1296546225506.4253ecd9 column=info:regioninfo, timestamp=1296546225761, value=region => {name => 'testtable,row-aaa,1296546225506.4253ecd9c94c  c94c38b66bdf8cd17b07efcb.                38b66bdf8cd17b07efcb.', startkey => 'row-aaa', endkey => 'row-dau', encoded => 4253ecd9c94c38b66bdf8cd17b07efcb, table                                            => {{name => 'testtable', families => [{name => 'cf1', bloomfilter => 'none', replication_scope => '0', versions => '3'                                           , compression => 'none', ttl => '2147483647', blocksize => '65536', in_memory => 'false', blockcache => 'true'}, {name                                            => 'cf2', bloomfilter => 'none', replication_scope => '0', versions => '3', compression => 'none', ttl => '2147483647',                                            blocksize => '65536', in_memory => 'false', blockcache => 'true'}]}}                                                    testtable,row-dau,1296545879295.4073eb6c column=info:regioninfo, timestamp=1296546225913, value=region => {name => 'testtable,row-dau,1296545879295.4073eb6c8275  82755aab57778af2dba39e22.                5aab57778af2dba39e22.', startkey => 'row-dau', endkey => 'row-mdc', encoded => 4073eb6c82755aab57778af2dba39e22, offlin                                           e => true, split => true, table => {{name => 'testtable', families => [{name => 'cf1', bloomfilter => 'none', replicati                                           on_scope => '0', versions => '3', compression => 'none', ttl => '2147483647', blocksize => '65536', in_memory => 'false                                           ', blockcache => 'true'}, {name => 'cf2', bloomfilter => 'none', replication_scope => '0', versions => '3', compression                                            => 'none', ttl => '2147483647', blocksize => '65536', in_memory => 'false', blockcache => 'true'}]}}                    testtable,row-dau,1296546225769.529fdb6b column=info:regioninfo, timestamp=1296546225971, value=region => {name => 'testtable,row-dau,1296546225769.529fdb6bcca8  cca8459349c81b518a24436b.                459349c81b518a24436b.', startkey => 'row-dau', endkey => 'row-gbo', encoded => 529fdb6bcca8459349c81b518a24436b, table                                            => {{name => 'testtable', families => [{name => 'cf1', bloomfilter => 'none', replication_scope => '0', versions => '3'                                           , compression => 'none', ttl => '2147483647', blocksize => '65536', in_memory => 'false', blockcache => 'true'}, {name                                            => 'cf2', bloomfilter => 'none', replication_scope => '0', versions => '3', compression => 'none', ttl => '2147483647',                                            blocksize => '65536', in_memory => 'false', blockcache => 'true'}]}}                                                    testtable,row-gbo,1296546225769.374d4364 column=info:regioninfo, timestamp=1296546225968, value=region => {name => 'testtable,row-gbo,1296546225769.374d4364574a  574ad1c5f522aa55b3d81586.                d1c5f522aa55b3d81586.', startkey => 'row-gbo', endkey => 'row-mdc', encoded => 374d4364574ad1c5f522aa55b3d81586, table                                            => {{name => 'testtable', families => [{name => 'cf1', bloomfilter => 'none', replication_scope => '0', versions => '3'                                           , compression => 'none', ttl => '2147483647', blocksize => '65536', in_memory => 'false', blockcache => 'true'}, {name                                            => 'cf2', bloomfilter => 'none', replication_scope => '0', versions => '3', compression => 'none', ttl => '2147483647',                                            blocksize => '65536', in_memory => 'false', blockcache => 'true'}]}}                                                    testtable,row-mdc,1296545879558.94cb351e column=info:regioninfo, timestamp=1296545879815, value=region => {name => 'testtable,row-mdc,1296545879558.94cb351e5dd3  5dd36c269247dd8a1a79373c.                6c269247dd8a1a79373c.', startkey => 'row-mdc', endkey => 'row-seq', encoded => 94cb351e5dd36c269247dd8a1a79373c, table                                            => {{name => 'testtable', families => [{name => 'cf1', bloomfilter => 'none', replication_scope => '0', versions => '3'                                           , compression => 'none', ttl => '2147483647', blocksize => '65536', in_memory => 'false', blockcache => 'true'}, {name                                            => 'cf2', bloomfilter => 'none', replication_scope => '0', versions => '3', compression => 'none', ttl => '2147483647',                                            blocksize => '65536', in_memory => 'false', blockcache => 'true'}]}}                                                    testtable,row-seq,1296545879558.43c5ffe1 column=info:regioninfo, timestamp=1296546226107, value=region => {name => 'testtable,row-seq,1296545879558.43c5ffe1ca7d  ca7dd6d1374b7b7430a7d261.                d6d1374b7b7430a7d261.', startkey => 'row-seq', endkey => '', encoded => 43c5ffe1ca7dd6d1374b7b7430a7d261, offline => tr                                           ue, split => true, table => {{name => 'testtable', families => [{name => 'cf1', bloomfilter => 'none', replication_scop                                           e => '0', versions => '3', compression => 'none', ttl => '2147483647', blocksize => '65536', in_memory => 'false', bloc                                           kcache => 'true'}, {name => 'cf2', bloomfilter => 'none', replication_scope => '0', versions => '3', compression => 'no                                           ne', ttl => '2147483647', blocksize => '65536', in_memory => 'false', blockcache => 'true'}]}}                           testtable,row-seq,1296546225975.c9188f86 column=info:regioninfo, timestamp=1296546226161, value=region => {name => 'testtable,row-seq,1296546225975.c9188f869822  9822da3ff21215a98a99ff5a.                da3ff21215a98a99ff5a.', startkey => 'row-seq', endkey => 'row-vfk', encoded => c9188f869822da3ff21215a98a99ff5a, table                                            => {{name => 'testtable', families => [{name => 'cf1', bloomfilter => 'none', replication_scope => '0', versions => '3'                                           , compression => 'none', ttl => '2147483647', blocksize => '65536', in_memory => 'false', blockcache => 'true'}, {name                                            => 'cf2', bloomfilter => 'none', replication_scope => '0', versions => '3', compression => 'none', ttl => '2147483647',                                            blocksize => '65536', in_memory => 'false', blockcache => 'true'}]}}                                                    testtable,row-vfk,1296546225975.682a4dbf column=info:regioninfo, timestamp=1296546226156, value=region => {name => 'testtable,row-vfk,1296546225975.682a4dbf9800  980035dc379c6ccd7418cb08.                35dc379c6ccd7418cb08.', startkey => 'row-vfk', endkey => '', encoded => 682a4dbf980035dc379c6ccd7418cb08, table => {{na                                           me => 'testtable', families => [{name => 'cf1', bloomfilter => 'none', replication_scope => '0', versions => '3', compr                                           ession => 'none', ttl => '2147483647', blocksize => '65536', in_memory => 'false', blockcache => 'true'}, {name => 'cf2                                           ', bloomfilter => 'none', replication_scope => '0', versions => '3', compression => 'none', ttl => '2147483647', blocks                                           ize => '65536', in_memory => 'false', blockcache => 'true'}]}}                                                          10 row(s) in 0.2610 seconds look at the enkdeys. ",
        "label": 285
    },
    {
        "text": "zkcli fails when server gc opts is enabled  hbase-7091 added logic to separate gc logging options for some client commands versus server commands. it uses a list of known client commands (\"shell\" \"hbck\" \"hlog\" \"hfile\" \"zkcli\") and uses the server gc logging options for all other invocations of bin/hbase. when zkcli is invoked, it in turn invokes \"hbase org.apache.hadoop.hbase.zookeeper.zookeepermainserverarg\" to gather the server command line arguments, but because org.apache.hadoop.hbase.zookeeper.zookeepermainserverarg is not on the white list it enables server gc logging, which causes extra output that causes the zkcli invocation to break. hbase-7153 addressed this but the fix only solved the array syntax - not the white list, so the zkcli command still fails. there are many other tools you can invoke that are more likely to \"client\" than \"server\" options. for example, \"bin/hbase org.jruby.main region_mover.rb\" or \"bin/hbase org.apache.hadoop.hbase.mapreduce.copytable\" or \"bin/hbase version\" or \"bin/hbase org.apache.hadoop.hbase.mapreduce.export\". the whitelist of server commands is shorter and easier to maintain than a whitelist of client commands. ",
        "label": 125
    },
    {
        "text": "nullpointerexception with an open scanner that expired causing an immediate region server shutdown  2009-12-29 18:05:55,432 info org.apache.hadoop.hbase.regionserver.hregionserver: scanner -4250070597157694417 lease expired  2009-12-29 18:05:55,443 error org.apache.hadoop.hbase.regionserver.hregionserver:   java.lang.nullpointerexception  at org.apache.hadoop.hbase.keyvalue$kvcomparator.compare(keyvalue.java:1310)  at org.apache.hadoop.hbase.regionserver.keyvalueheap$kvscannercomparator.compare(keyvalueheap.java:136)  at org.apache.hadoop.hbase.regionserver.keyvalueheap$kvscannercomparator.compare(keyvalueheap.java:127)  at org.apache.hadoop.hbase.regionserver.keyvalueheap$kvscannercomparator.compare(keyvalueheap.java:117)  at java.util.priorityqueue.siftdownusingcomparator(priorityqueue.java:641)  at java.util.priorityqueue.siftdown(priorityqueue.java:612)  at java.util.priorityqueue.poll(priorityqueue.java:523)  at org.apache.hadoop.hbase.regionserver.keyvalueheap.next(keyvalueheap.java:113)  at org.apache.hadoop.hbase.regionserver.hregion$regionscanner.nextinternal(hregion.java:1776)  at org.apache.hadoop.hbase.regionserver.hregion$regionscanner.next(hregion.java:1719)  at org.apache.hadoop.hbase.regionserver.hregionserver.next(hregionserver.java:1944)  at sun.reflect.generatedmethodaccessor13.invoke(unknown source)  at sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:25)  at java.lang.reflect.method.invoke(method.java:597)  at org.apache.hadoop.hbase.ipc.hbaserpc$server.call(hbaserpc.java:648)  at org.apache.hadoop.hbase.ipc.hbaseserver$handler.run(hbaseserver.java:915)  2009-12-29 18:05:55,446 info org.apache.hadoop.ipc.hbaseserver: ipc server handler 7 on 55260, call next(-4250070597157694417, 10000) from 192.168.1.90:54011: error: java.io.ioexception: java.lang.nullpointerexception  java.io.ioexception: java.lang.nullpointerexception  at org.apache.hadoop.hbase.regionserver.hregionserver.convertthrowabletoioe(hregionserver.java:869)  at org.apache.hadoop.hbase.regionserver.hregionserver.convertthrowabletoioe(hregionserver.java:859)  at org.apache.hadoop.hbase.regionserver.hregionserver.next(hregionserver.java:1965)  at sun.reflect.generatedmethodaccessor13.invoke(unknown source)  at sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:25)  at java.lang.reflect.method.invoke(method.java:597)  at org.apache.hadoop.hbase.ipc.hbaserpc$server.call(hbaserpc.java:648)  at org.apache.hadoop.hbase.ipc.hbaseserver$handler.run(hbaseserver.java:915)  caused by: java.lang.nullpointerexception  at org.apache.hadoop.hbase.keyvalue$kvcomparator.compare(keyvalue.java:1310)  at org.apache.hadoop.hbase.regionserver.keyvalueheap$kvscannercomparator.compare(keyvalueheap.java:136)  at org.apache.hadoop.hbase.regionserver.keyvalueheap$kvscannercomparator.compare(keyvalueheap.java:127)  at org.apache.hadoop.hbase.regionserver.keyvalueheap$kvscannercomparator.compare(keyvalueheap.java:117)  at java.util.priorityqueue.siftdownusingcomparator(priorityqueue.java:641)  at java.util.priorityqueue.siftdown(priorityqueue.java:612)  at java.util.priorityqueue.poll(priorityqueue.java:523)  at org.apache.hadoop.hbase.regionserver.keyvalueheap.next(keyvalueheap.java:113)  at org.apache.hadoop.hbase.regionserver.hregion$regionscanner.nextinternal(hregion.java:1776)  at org.apache.hadoop.hbase.regionserver.hregion$regionscanner.next(hregion.java:1719)  at org.apache.hadoop.hbase.regionserver.hregionserver.next(hregionserver.java:1944)  ... 5 more  2009-12-29 18:05:55,447 warn org.apache.hadoop.ipc.hbaseserver: ipc server responder, call next(-4250070597157694417, 10000) from 192.168.1.90:54011: output error  2009-12-29 18:05:55,448 info org.apache.hadoop.ipc.hbaseserver: ipc server handler 7 on 55260 caught: java.nio.channels.closedchannelexception  at sun.nio.ch.socketchannelimpl.ensurewriteopen(socketchannelimpl.java:126)  at sun.nio.ch.socketchannelimpl.write(socketchannelimpl.java:324)  at org.apache.hadoop.hbase.ipc.hbaseserver.channelwrite(hbaseserver.java:1125)  at org.apache.hadoop.hbase.ipc.hbaseserver$responder.processresponse(hbaseserver.java:615)  at org.apache.hadoop.hbase.ipc.hbaseserver$responder.dorespond(hbaseserver.java:679)  at org.apache.hadoop.hbase.ipc.hbaseserver$handler.run(hbaseserver.java:943) 2009-12-29 18:05:56,322 info org.apache.hadoop.ipc.hbaseserver: stopping server on 55260  2009-12-29 18:05:56,322 info org.apache.hadoop.ipc.hbaseserver: stopping ipc server listener on 55260 ",
        "label": 392
    },
    {
        "text": "regions stuck in transition after rs failure  testing 0.90rc2 i ran into this issue. the test scenario was to kill -9 the server hosting root and meta, and before it had been detected, run \"balancer\" from the shell. after logs were split and regions were reassigned, i ended up with some regions stuck in transition. ",
        "label": 247
    },
    {
        "text": "sanity check visiblity and audience for server side modules   similar to hbase-9495 we should audit the hbase-hadoop*-compat, hbase-prefix-tree, hbase-protocol and hbase server-modules. i'll go through each module first making most things private, and then do a second pass using some sort of limitedprivate marking for apis that we'd expect coprocs or advanced tests to use. this is less urgent that the work for the client facing apis. ",
        "label": 248
    },
    {
        "text": "optionally verify bulk loaded hfiles  we rely on users to produce properly formatted hfiles for bulk import. attached patch adds an optional code path, toggled by a configuration property, that verifies the hfile under consideration for import is properly sorted. the default maintains the current behavior, which does not scan the file for correctness. patch is against trunk but can apply against all active branches. ",
        "label": 38
    },
    {
        "text": "hbase tgz does not include lib junit jar  the 0.95 release of hbase does not include junit-*.jar in the lib/ dir. this is required to run the hbase-it suite from the tarball. ",
        "label": 314
    },
    {
        "text": "update hadoop libs in hbase  move hbase trunk on to an hadoop rc  ",
        "label": 314
    },
    {
        "text": " shell  altering a family shouldn't reset to default unchanged attributes  i changed the replication on a family that was also versions => 1 and compression => lzo. i forgot that you have to respecify everything everytime you alter a family, so both were reset to 3 and none. then the regions were compacted... and it has been splitting for about 20 minutes now. fortunately this is our mr environment so our web site isn't affected, but it's still a major pain. oh and also the table cannot be disabled to be re-altered since split parents are always present (i hope it'll stop splitting before midnight). the shell should use the old values for attributes that aren't changed. ",
        "label": 229
    },
    {
        "text": "allow adding attributes to scan  there's sometimes a need to add custom attribute to scan object so that it can be accessed on server side.  example of the case where it is needed discussed here: http://search-hadoop.com/m/v3jtb2gkio. there might be other cases where it is useful, which are mostly about logging/gathering stats on server side. alternative to allowing adding any custom attributes to scan could be adding some fixed field, like \"type\" to the class. ",
        "label": 18
    },
    {
        "text": "make it so can send email and have it show as comments in jira  some discussion up in mailing list suggests it may be just a matter of removing the 'reply-to' which has the list in it. i filed infra-2533. i also tested replying to an issue emission and changing the to to be jira@apache.org instead and my comment went into the issue as a comment. ",
        "label": 314
    },
    {
        "text": "slabcache size logging on initialization is wrong  from the logs: 2013-12-17 23:57:40,060 info  [main] slab.slabcache: creating a slab of blocksize 72089 with 140233 blocks, 1.4 gbytes. 2013-12-17 23:57:43,622 info  [main] slab.slabcache: creating a slab of blocksize 137625 with 18363 blocks, -1.6 gbytes. by my math, these values should be 9.4g and 2.4g respectively. ",
        "label": 141
    },
    {
        "text": "subclasses of o a h h chaos actions action all use the same logger  a bunch of the actions all use the same logger inherited from the super class. we should have them declare distinct loggers, either each one in class or perhaps we can do something dynamically like logfactory.getlogger(methodhandles.lookup().lookupclass() and drop the static modifier on the log field. i'm not sure that exact incantation would actually work, but the methodhandles approach in general is how logger resolution happens in solr and it actually works out pretty well. ",
        "label": 363
    },
    {
        "text": "some integration tests can no longer be run using maven  when i run mvn test (or verify) - dtest=integrationtestingest, the test fails instantly, seemingly because initialization doesn't run. i am assuming junit is not picking before-after methods from the superclass, could be some other issue. also, if it does run, it won't be very useful because it runs with calm monkey by default.  we need to detect being run locally rather than as abstracthbasetool (probably any time junit-annotated methods like before are called), and set up a different chaos monkey, such as an old default one. may also apply to other tests. ",
        "label": 406
    },
    {
        "text": " shell  support for getting counters  from the list: on fri, mar 12, 2010 at 7:11 am, ray duong <ray.duong@gmail.com> wrote: > hi hbase, > > i'm a little confuse on how the auto increment works in hbase.  shouldn't > the value be a number instead of a bytearray?  is there a way to convert the > value into a string? > > > hbase(main):013:0> create 'testcounter', 'cf' > 0 row(s) in 2.0950 seconds > 3854.986: [gc 3854.987: [parnew: 19136k->1671k(19136k), 0.0175270 secs] > 27147k->11204k(83008k) icms_dc=7 , 0.0177320 secs] [times: user=0.02 > sys=0.03, real=0.01 secs] > hbase(main):014:0> scan 'testcounter' > row > column+cell > > 0 row(s) in 0.0080 seconds > hbase(main):015:0> incr 'testcounter', 'r1', 'cf:counter', 1 > 0 row(s) in 0.0040 seconds > hbase(main):016:0> scan 'testcounter' > row > column+cell > >  r1                          column=cf:counter, timestamp=1268406376222, > value=\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x0 > > 1 > > 1 row(s) in 0.0110 seconds > hbase(main):017:0> incr 'testcounter', 'r1', 'cf:counter', 1 > 0 row(s) in 0.0030 seconds > hbase(main):018:0> scan 'testcounter' > row > column+cell > >  r1                          column=cf:counter, timestamp=1268406376222, > value=\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x0 > > 2 > > 1 row(s) in 0.0090 seconds > hbase(main):019:0> incr 'testcounter', 'r1', 'cf:counter', 1 > 0 row(s) in 0.0040 seconds > hbase(main):020:0> scan 'testcounter' > row > column+cell > >  r1                          column=cf:counter, timestamp=1268406376222, > value=\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x0 > > 3 > > 1 row(s) in 0.0080 seconds > hbase(main):021:0> incr 'testcounter', 'r1', 'cf:counter', 10 > 0 row(s) in 0.0040 seconds > hbase(main):022:0> scan 'testcounter' > row > column+cell > >  r1                          column=cf:counter, timestamp=1268406376222, > value=\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x0 > > d > > 1 row(s) in 0.0090 seconds > hbase(main):023:0> incr 'testcounter', 'r1', 'cf:counter', 100 > 0 row(s) in 0.0030 seconds > hbase(main):024:0> scan 'testcounter' > row > column+cell > >  r1                          column=cf:counter, timestamp=1268406376222, > value=\\x00\\x00\\x00\\x00\\x00\\x00\\x00q > 1 row(s) in 0.0230 seconds > add support for counters, something that will get the cell value, turn it into a value and emit it as a jruby int. ",
        "label": 25
    },
    {
        "text": "rest interface  more generic column family configure and also get rows using offset and limit  the update column family operation in rest interface will overwrite the default metadata using the default value which is unexpected.   we should use the column family to get the old value and then do update if requested by the users. also, for non-default metadata value, such as \"hbase.hregion.majorcompaction\", we should still be enable to create/update it using rest interface. for rowhandler, the user can request with offset and limit and get the rows. ",
        "label": 549
    },
    {
        "text": "procedure proto can't be compiled to c   eof is a defined symbol in c and c++. ",
        "label": 154
    },
    {
        "text": "some improvement in snapshot  (1)timeout for procedure can not be configured. procedure's timeout procedurecoordinator   final static long timeout_millis_default = 60000;    createprocedure(foreignexceptiondispatcher fed, string procname, byte[] procargs,       list<string> expectedmembers) {     // build the procedure     return new procedure(this, fed, wake_millis_default, timeout_millis_default,         procname, procargs, expectedmembers);   } regionserversnapshotmanager:   /** conf key for max time to keep threads in snapshot request pool waiting */   public static final string snapshot_timeout_millis_key = \"hbase.snapshot.region.timeout\";   /** keep threads alive in request pool for max of 60 seconds */   public static final long snapshot_timeout_millis_default = 60000;   public subprocedure buildsubprocedure(snapshotdescription snapshot) {     long timeoutmillis = conf.getlong(snapshot_timeout_millis_key,         snapshot_timeout_millis_default);     case flush:       snapshotsubprocedurepool taskmanager =         new snapshotsubprocedurepool(rss.getservername().tostring(), conf);   } (2)takesnapshothandler  after snapshotregions we should call monitor.rethrowexception(); to check if there is exception and if there is we can skip the verifysnapshot (3)too much error message when error happened in some place. ",
        "label": 309
    },
    {
        "text": "testadmin testcreatebadtables is failing occasionally  see in a 0.94 test run.  looks like in some cases it is possible to create two tables with the same name, which is worrisome. java.lang.assertionerror: expected:<1> but was:<2> at org.junit.assert.fail(assert.java:93) at org.junit.assert.failnotequals(assert.java:647) at org.junit.assert.assertequals(assert.java:128) at org.junit.assert.assertequals(assert.java:472) at org.junit.assert.assertequals(assert.java:456) at org.apache.hadoop.hbase.client.testadmin.testcreatebadtables(testadmin.java:1091) ",
        "label": 411
    },
    {
        "text": "testdistributedlogsplitting testmarkregionsrecoveringinzk fails intermittently due to lack of online region  from http://54.241.6.143/job/hbase-trunk/org.apache.hbase$hbase-server/297/testreport/junit/org.apache.hadoop.hbase.master/testdistributedlogsplitting/testmarkregionsrecoveringinzk/ : stacktrace java.lang.indexoutofboundsexception: index: 0, size: 0 at java.util.arraylist.rangecheck(arraylist.java:547) at java.util.arraylist.get(arraylist.java:322) at org.apache.hadoop.hbase.master.testdistributedlogsplitting.testmarkregionsrecoveringinzk(testdistributedlogsplitting.java:612) at sun.reflect.nativemethodaccessorimpl.invoke0(native method) at sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:39) at sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:25) at java.lang.reflect.method.invoke(method.java:597) at org.junit.runners.model.frameworkmethod$1.runreflectivecall(frameworkmethod.java:47) at org.junit.internal.runners.model.reflectivecallable.run(reflectivecallable.java:12) the assertion occurred on second line below:     list<hregioninfo> regions = protobufutil.getonlineregions(hrs);     hregioninfo region = regions.get(0); this meant that there was no online region at that moment. ",
        "label": 233
    },
    {
        "text": "alter statement in the hbase shell doesn't match documentation   the documentation claims this should work. perhaps this jira could be a starting point for a more detailed explanation of alter hbase shell commands:  alter alter column family schema; pass table name and a dictionary  specifying new column family schema. dictionaries are described  below in the general notes section. dictionary must include name  of column family to alter. for example,  to change or add the 'f1' column family in table 't1' from defaults  to instead keep a maximum of 5 cell versions, do:  hbase> alter 't1', {name => 'f1', versions => 5}    to delete the 'f1' column family in table 't1', do:  hbase> alter 't1', {name => 'f1', method => 'delete'}    you can also change table-scope attributes like max_filesize  memstore_flushsize and readonly.    for example, to change the max size of a family to 128mb, do:  hbase> alter 't1', {method => 'table_att', max_filesize => '134217728'}  ....  ase shell; enter 'help<return>' for list of supported commands.  version: 0.20.3, r902334, mon jan 25 13:13:08 pst 2010  hbase(main):001:0> drop 't3'  0 row(s) in 0.0060 seconds  0 row(s) in 0.0050 seconds  0 row(s) in 0.1560 seconds  hbase(main):002:0> create 't3'  0 row(s) in 2.1050 seconds  hbase(main):003:0> disable 't3'  0 row(s) in 2.0980 seconds  hbase(main):004:0> alter 't3', {name => 'f1', versions => 5} nativeexception: java.lang.nullpointerexception: null ",
        "label": 21
    },
    {
        "text": "hmaster and hregionserver should be able to login from kerberos keytab when running on security enabled hadoop  currently hbase can run on top of hadoop 0.20 with security apis, but only using the \"simple\" authentication method. there is currently no configuration or hooks for the hbase process to obtain kerberos credentials so it can authenticate against secure hadoop. we should extend the current org.apache.hadoop.hbase.security.user hooks to allow obtaining credentials from a keytab file when security is enabled. ",
        "label": 180
    },
    {
        "text": "allow heapsize of different units to be passed as hbase heapsize  currently hbase_heapsize doesn't expect units. $ hbase_heapsize=5g /usr/lib/hbase/bin/hbase shell invalid maximum heap size: -xmx5gm error: could not create the java virtual machine. error: a fatal exception has occurred. program will exit. it would be more user friendly if different units of heapsize can be passed through hbase_heapsize  if unit ('m' or 'g') is specified, 'm' doesn't need to be appended. ",
        "label": 441
    },
    {
        "text": "hdfs and native libs for hbase  this issue is about figuring how to get hdfs-127 patch into hbase trunk and for updating native libs; i added the hadoop 0.21 jars but haven't yet added in the hdfs-127 patch (it needs some careful surgery \u2013 stuff has changed). also no native libs in new hadoop... need to go see what story is (do we need them)? ",
        "label": 314
    },
    {
        "text": "icv optimization to look in memstore first and then store files  hbase  does not work when deletes are in the mix  for incrementcolumnvalue() hbase-3082 adds an optimization to check memstores first, and only if not present in the memstore then check the store files. in the presence of deletes, the above optimization is not reliable. if the column is marked as deleted in the memstore, one should not look further into the store files. but currently, the code does so. sample test code outline: admin.createtable(desc) table = htable.new(conf, tablename) table.incrementcolumnvalue(bytes.tobytes(\"row\"), cf1name, bytes.tobytes(\"column\"), 5); admin.flush(tablename) sleep(2) del = delete.new(bytes.tobytes(\"row\")) table.delete(del) table.incrementcolumnvalue(bytes.tobytes(\"row\"), cf1name, bytes.tobytes(\"column\"), 5); get = get.new(bytes.tobytes(\"row\")) keyvalues = table.get(get).raw() keyvalues.each do |keyvalue|   puts \"expect 5; got value=#{bytes.tolong(keyvalue.getvalue())}\"; end the above prints: expect 5; got value=10 ",
        "label": 286
    },
    {
        "text": "separate read write handler for priority request especially for meta   client may give too many read pressure on meta, so blocking master write meta for region open. ",
        "label": 292
    },
    {
        "text": "improve rowcounter to count rows in a specific key range   currently rowcounter in mr package is a very simple map only job that does a full scan of a table. enhance the utility to let the user specify a key range and count the number of rows in this range. ",
        "label": 341
    },
    {
        "text": " teststorereconstruction broke in trunk  ",
        "label": 314
    },
    {
        "text": "rpc handler   task monitoring seems to be broken after  in 0.96, we have the rpc handlers listed as tasks and show them in the web ui as well: tasks: =========================================================== task: rpcserver.handler=0,port=64231 status: waiting:waiting for a call running for 932s task: rpcserver.handler=1,port=64231 status: waiting:waiting for a call running for 932s task: rpcserver.handler=2,port=64231 status: waiting:waiting for a call running for 932s after pluggable rpc scheduler, the way the tasks work for the handlers got changed. we no longer list idle rpc handlers in the tasks, but we register them dynamically to taskmonitor through callrunner. however, the ipc readers are still registered the old way (meaning that idle readers are listed as tasks, but not idle handlers). from the javadoc of monitoredrpchandlerimpl, it seems that we are not optimizing the allocation for the monitoredtask anymore, but instead allocate one for every rpc call breaking the pattern (see callrunner.getstatus()). /**  * a monitoredtask implementation designed for use with rpc handlers   * handling frequent, short duration tasks. string concatenations and object   * allocations are avoided in methods that will be hit by every rpc call.  */ @interfaceaudience.private public class monitoredrpchandlerimpl extends monitoredtaskimpl there is also one more side affect that, since the callrunner is a per-rpc object and created in the rpc listener thread, the created task ends up having a name \"listener\" although the actual processing happens in a handler thread. this is obviously very confusing during debugging. ",
        "label": 198
    },
    {
        "text": "create connection and connectionmanager  this is further cleanup of the hbase interface for 1.0 after implementing the new table and admin interfaces. following enis's guidelines in hbase-10602, this jira will generate a new connectionmanager to replace hcm and connection to replace hconnection. for more detail, this jira intends to implement this portion: interface connection extends closeable{   table gettable(), and rest of hconnection methods    getadmin()   // no deprecated methods (cache related etc) } @deprecated interface hconnection extends connection {   @deprecated   htableinterface gettable()   // users are encouraged to use connection } class connectionmanager {   createconnection(configuration) // not sure whether we want a static factory method to create connections or a ctor } @deprecated class hcm extends connectionmanager {   // users are encouraged to use connectionmanager } ",
        "label": 422
    },
    {
        "text": "fix flaky test testverifyreplication testhbase14905  [error] failures:   [error] testverifyreplication.testhbase14905:246 expected:<3> but was:<2>  [error] errors:   [error] org.apache.hadoop.hbase.replication.testverifyreplicationcrossdiffhdfs.org.apache.hadoop.hbase.replication.testverifyreplicationcrossdiffhdfs  [error] run 1: testverifyreplicationcrossdiffhdfs.testverifyrepbysnapshot:199 \u00bb testtimedout ...  [error] run 2: testverifyreplicationcrossdiffhdfs.org.apache.hadoop.hbase.replication.testverifyreplicationcrossdiffhdfs \u00bb   it failed many time when i try all ut for branch-2.2. ",
        "label": 187
    },
    {
        "text": "add transparent data encryption support for fanoutoneblockasyncdfsoutput  http://hadoop.apache.org/docs/r2.6.4/hadoop-project-dist/hadoop-hdfs/transparentencryption.html ",
        "label": 149
    },
    {
        "text": " per kv security  visibility labels  implement accumulo-style visibility labels. consider the following design principles: coprocessor based implementation minimal to no changes to core code use keyvalue tags (hbase-7448) to carry labels use operationwithattributes# {get,set} attribute for handling visibility labels in the api implement a new filter for evaluating visibility labels as kvs are streamed through. this approach would be consistent in deployment and api details with other per-kv security work, supporting environments where they might be both be employed, even stacked on some tables. see the parent issue for more discussion. ",
        "label": 46
    },
    {
        "text": "backport hbase 'metaservershutdownhandler may potentially keep bumping up deadserver numprocessing' to  hbase-8097 fixes a problem to do with exception handling in metassh. we should backport that part of the fix to 0.94. ",
        "label": 233
    },
    {
        "text": "remove extra useless    [hregion.java]  log.info(\"flushing \" + + storestoflush.size() + \"/\" + stores.size() + \" column families,\" + [hstore.java]  \", sequenceid=\" + +storefile.getreader().getsequenceid() + \", filesize=\" [loadincrementalhfiles.java] log.info(\"split occurred while grouping hfiles, retry attempt \" + +count + \" with \" +   has 3 extra/useless \"+\". ",
        "label": 542
    },
    {
        "text": " fb  remove the thrift dependency in regionexception  regionexception was derived from ioerror to capture the backoff timeout,  information required by the thrift clients to reduce the load on the  overloaded region servers. the exception was derived from ioerror to  make it compatible with thrift. when this change was ported to neptune,  it created a new dependency on the thrift package. ",
        "label": 378
    },
    {
        "text": "revisit arraylist creation  i am attaching the file which lists the files where arraylist() is called without specifying initial size.  we should identify which calls should use pre-sizing to boost performance. ",
        "label": 441
    },
    {
        "text": " hbase  allow user add arbitrary key value pairs to table and column descriptors  folks have asked if they can tag columns and tables with markings of their own designation. examples include 'type' and 'descriptiion'. ",
        "label": 314
    },
    {
        "text": "branch build fails in the checkstyle phase  this was the first build with the error: https://builds.apache.org/job/hbase-2.0/7/jdk=jdk%201.8%20(latest),label=hadoop/consolefull [error] failed to execute goal org.apache.maven.plugins:maven-checkstyle-plugin:2.17:checkstyle (default-cli) on project hbase: execution default-cli of goal org.apache.maven.plugins:maven-checkstyle-plugin:2.17:checkstyle failed: plugin org.apache.maven.plugins:maven-checkstyle-plugin:2.17 or one of its dependencies could not be resolved: could not find artifact org.apache.hbase:hbase-checkstyle:jar:2.0.0-alpha-1 in nexus (http://repository.apache.org/snapshots) -> [help 1] [error]  ",
        "label": 314
    },
    {
        "text": "storescanner need to be able to be subclassed  storescanner can be replaced by prestorescanneropen hook with cp. in order to reuse most of the logic in current storescanner, subclass it might be the best approaching. thus a lot of private member need to be changed from private to protected. at present, in order to to implement a custom storescanner for dot (hbase-6805), only a few of the private member need to be changed as in the attached storescanner.patch, while should we change all the reasonable field from private to protected as in hbase-7387-v?.patch ",
        "label": 369
    },
    {
        "text": "introduce sequential znode based read write locks  this is a continuation of hbase-5494: currently table-level write locks have been implemented using non-sequential znodes as part of hbase-5494 and committed to 89-fb branch. this issue is to track converting the table-level locks to sequential znodes and supporting read-write locks, as to solve the issue of preventing schema changes during region splits or merges. ",
        "label": 19
    },
    {
        "text": "fix rat license complaint about website jenkins scripts  {{2 unknown licenses ***************************************************** files with unapproved licenses:  dev-support/jenkins-scripts/check-website-links.sh  dev-support/jenkins-scripts/generate-hbase-website.sh *****************************************************  }} ",
        "label": 163
    },
    {
        "text": "move replication znodes to pb  ",
        "label": 103
    },
    {
        "text": "remove transactional contrib  it has been decided to remove the transactional/tableindexed contrib from hbase. it will live in github instead. ",
        "label": 110
    },
    {
        "text": "testshell and testadminshell2 are broken  ",
        "label": 149
    },
    {
        "text": "no region is added to regionsintransitioninrs  we have a skip list set called regionsintransitioninrs (introduced in hbase-3741) where we try to maintain a list to know the currently processing regions for closing and opening.  in open region handler we are trying to throw an error if the regions are in transition on that rs when we get an open call for the same region.  but we are not adding the region into the set anywhere. ",
        "label": 441
    },
    {
        "text": "ugly stack trace just because regionserver comes up before master   i see this in the logs on simple startup: 2013-03-20 10:20:00,990 warn org.apache.hadoop.hbase.regionserver.hregionserver: error telling master we are up com.google.protobuf.serviceexception: methodname=regionserverstartup         at org.apache.hadoop.hbase.ipc.protobufrpcclientengine$invoker.invoke(protobufrpcclientengine.java:147)         at com.sun.proxy.$proxy8.regionserverstartup(unknown source)         at org.apache.hadoop.hbase.regionserver.hregionserver.reportforduty(hregionserver.java:1783)         at org.apache.hadoop.hbase.regionserver.hregionserver.run(hregionserver.java:713)         at java.lang.thread.run(thread.java:680) caused by: org.apache.hadoop.hbase.exceptions.servernotrunningyetexception: org.apache.hadoop.hbase.exceptions.servernotrunningyetexception: server is not running yet         at sun.reflect.nativeconstructoraccessorimpl.newinstance0(native method)         at sun.reflect.nativeconstructoraccessorimpl.newinstance(nativeconstructoraccessorimpl.java:39)         at sun.reflect.delegatingconstructoraccessorimpl.newinstance(delegatingconstructoraccessorimpl.java:27)         at java.lang.reflect.constructor.newinstance(constructor.java:513)         at org.apache.hadoop.ipc.remoteexception.instantiateexception(remoteexception.java:95)         at org.apache.hadoop.ipc.remoteexception.unwrapremoteexception(remoteexception.java:79)         at org.apache.hadoop.hbase.ipc.protobufrpcclientengine$invoker.invoke(protobufrpcclientengine.java:146)         ... 4 more caused by: org.apache.hadoop.hbase.ipc.remotewithextrasexception: org.apache.hadoop.hbase.exceptions.servernotrunningyetexception: server is not running yet         at org.apache.hadoop.hbase.ipc.hbaseserver$handler.run(hbaseserver.java:1855)         at org.apache.hadoop.hbase.ipc.hbaseclient.call(hbaseclient.java:1317)         at org.apache.hadoop.hbase.ipc.protobufrpcclientengine$invoker.invoke(protobufrpcclientengine.java:131)         ... 4 more 2013-03-20 10:20:00,991 warn org.apache.hadoop.hbase.regionserver.hregionserver: reportforduty failed; sleeping and then retrying. ",
        "label": 314
    },
    {
        "text": "hconnection interface is public but is used internally  and contains a bunch of methods  hconnection has too many methods for a public interface, and some of these should not be public.  it is used extensively for internal purposes, so we keep adding methods to it that may not make sense for public interface. the idea is to create a separate internal interface inheriting hconnection, copy some methods to it and deprecate them on hconnection. new methods for internal use would be added to new interface; the deprecated methods would eventually be removed from public interface. ",
        "label": 406
    },
    {
        "text": "log when we add remove failed servers in client  currently we log if a server is in the failed server list when we go to connect to it, but we don't log anything about when the server got into the list. this means we have to search the log for errors involving the same server name that (hopefully) managed to get into the log within failed_server_expiry_key milliseconds earlier (default 2 seconds). ",
        "label": 27
    },
    {
        "text": "unvalidated redirect in hmaster  see owasp page on why we should clean it up someday: https://www.owasp.org/index.php/unvalidated_redirects_and_forwards_cheat_sheet here is where we do the redirect:     @override     public void doget(httpservletrequest request,         httpservletresponse response) throws servletexception, ioexception {       string redirecturl = request.getscheme() + \"://\"         + request.getservername() + \":\" + regionserverinfoport         + request.getrequesturi();       response.sendredirect(redirecturl);     }   } ",
        "label": 402
    },
    {
        "text": "regionmovedexception is handled incorrectly for multi region requests that fail completely  regionmovedexception is currently thrown on global level, and due to how protobufutil does things, it fails the entire multi-request, see hbase-8036. rme also doesn't specify the region.  thus, if it's thrown for one region and there are multiple regions in the request, hcm applies it to all of them, which causes clients to become confused temporarily. we should either fix hbase-8036 or add region encoded name in the description. ",
        "label": 406
    },
    {
        "text": "enhance the spark hbase connector catalog with json format  ",
        "label": 512
    },
    {
        "text": "add new hadoop releases to the pre commit hadoop check  3.0.0-alpha3 is out, we should replace the old alpha2 release with alpha3. and we should add new 2.x releases also. ",
        "label": 149
    },
    {
        "text": "keyvalue expiration by time to live during major compaction is broken  during a major compaction on a region in a column family with a configured ttl, it looks like all keyvalues in a row after the first expired keyvalue are skipping and thrown out of the newly written file (regardless of whether the would have been expired or not). the storescanner is skipping to the next row, even when other columns with a non-expirable timestamp exists. unless i'm misunderstanding it, it seems like it should just seek to the next column instead. i discovered this when altering a table to lower the ttl for a column family and force the expiration of some data which led to the entire row being expired in some instances. ",
        "label": 180
    },
    {
        "text": "transfer big cells or upserted appended cells into mslab upon flattening to cellchunkmap  cellchunkmap segment index requires all cell data to be written in the mslab chunks. eventhough mslab is enabled, cells bigger than chunk size or upserted/incremented/appended cells are still allocated on the jvm stack. if such cells are found in the process of flattening into cellchunkmap (in-memory-flush) they need to be copied into mslab. ",
        "label": 179
    },
    {
        "text": "improve the selection of regions to balance  currently loadbalancer goes through the list of regions per rs and grabs the few first ones to balance. this is not bad, but that list is often sorted naturally since the a rs that boots will open the regions in a sequential and sorted order (since it comes from .meta.) which means that we're balancing regions starting in an almost sorted fashion. we discovered that because one of our internal users created a new table starting with letter \"p\" which has now grown to 100 regions in the last few hours and they are all served by 1 region server. looking at the master's log, the balancer has moved as many regions from that region server but they are all from the same table that starts with letter \"a\" (and the regions that were moved all come one after the other). the part of the code that should be modified is: for (hregioninfo hri: regions) {   // don't rebalance meta regions.   if (hri.ismetaregion()) continue;    regionstomove.add(new regionplan(hri, serverinfo, null));   numtaken++;   if (numtaken >= numtooffload) break; } ",
        "label": 441
    },
    {
        "text": "increment multiple columns in a row at once  currently there is no way to do multiple increments to a single row in one rpc. this jira is about adding an htable and hregioninterface method to increment multiple columns within a single row at once. ",
        "label": 247
    },
    {
        "text": "for idempotent operation dups  return the result instead of throwing conflict exception  after hbase-3787, we could store mvcc in operation context, and use it to convert the modification request into read on dups instead of throwing operationconflictexception.  mvcc tracking will have to be aware of such mvcc numbers present. given that scanners are usually relatively short-lived, that would prevent low watermark from advancing for quite a bit more time ",
        "label": 187
    },
    {
        "text": "move report of split to master off the heartbeat channel  the heartbeat in hbase is about to go away. see hbase-1502. this issue is about moving the report of a split region off the heartbeat channel. this work needs to be done before i can finish up hbase-1502. here is a provisional 'design' for how report of split to master will now work. instead of riding a split message on the regionserver to master heartbeat, the regionserver will put up a znode under (the badly named) 'unassigned' directory; i.e. the regionserver will put the region into 'transition' (rit). usually the master does all rit machinations. splits will be an exception. the regionserver will move the znode through two states: splitting and split. the master will clean up the split znode on receipt of child changed callback. there will be no extra data in the splitting znode beyond the splitting state name. the split znode will contain the name of the split daughters. any region in rit will block the balancer running. this could be an issue if lots of splits going on across a cluster. master will need to handle new split and splitting states and that another may have already written the rit (unit tests). as before, regionserver figures region to split and runs compactsplitthread#split. as before, this invokes splittransaction with its prepare, execute and when necessary rollback phase. into the execute we'll add the setting of splitting znode into rit. the execution will end with setting the split znode state. master will read and clear the split state when done. ",
        "label": 314
    },
    {
        "text": "handle split region related failures on master restart and rs restart  this issue is raised to solve issues that comes out of partial region split happened and the region node in the zk which is in rs_zk_region_splitting and rs_zk_region_split is not yet processed.  this also tries to address hbase-5615. ",
        "label": 100
    },
    {
        "text": "backport hbase to branch  see discussion here: http://search-hadoop.com/m/mjbid1aaztr1/backporting+hbase-3777+to+0.90&subj=backporting+hbase+3777+to+0+90 rocketfuel has been running 0.90.3 with hbase-3777 since its resolution.  they have 10 rs nodes , 1 master and 1 zookeeper  live writes and reads but super heavy on reads. cache hit is pretty high.  the qps on one of their data centers is 50k. ",
        "label": 81
    },
    {
        "text": "hadoop2 mr tests fail occasionally because of mapreduce jobhistory address is no set in job conf  hadoop2 mr tests fail occasionally with output like this: ------------------------------------------------------------------------------- test set: org.apache.hadoop.hbase.mapreduce.testtableinputformatscan1 ------------------------------------------------------------------------------- tests run: 5, failures: 0, errors: 5, skipped: 0, time elapsed: 347.57 sec <<< failure! testscanemptytoapp(org.apache.hadoop.hbase.mapreduce.testtableinputformatscan1)  time elapsed: 50.047 sec  <<< error! java.io.ioexception: java.net.connectexception: call from liushaohui-optiplex-990/127.0.0.1 to 0.0.0.0:10020 failed on connection exception: java.net.connectexception: connection refused; for more details see:  http://wiki.apache.org/hadoop/connectionrefused at org.apache.hadoop.mapred.clientservicedelegate.invoke(clientservicedelegate.java:334) at org.apache.hadoop.mapred.clientservicedelegate.getjobstatus(clientservicedelegate.java:419) at org.apache.hadoop.mapred.yarnrunner.getjobstatus(yarnrunner.java:524) at org.apache.hadoop.mapreduce.job$1.run(job.java:314) at org.apache.hadoop.mapreduce.job$1.run(job.java:311) at java.security.accesscontroller.doprivileged(native method)      ... the reason is that when mr job was running, the job client pulled the job status from appmaster. when the job is completed, the appmaster will exit. at this time, if the job client have not got the job completed event from appmaster, it will switch to get job report from history server. but in hbasetestingutility#startminimapreducecluster, the config: mapreduce.jobhistory.address is not copied to testutil's config. crunch-249 reported the same problem. ",
        "label": 411
    },
    {
        "text": "remove testfromclientside testpoolbehavior  this test tests the underlying threadpoolexecutor's thread management, and has nothing to do with hbase functionality. i suggest we should delete it. ",
        "label": 199
    },
    {
        "text": "deprecate remove o a h h util keying class   this is ancient code that is likely not used. deprecate in 0.96 and remove from 0.98 ",
        "label": 248
    },
    {
        "text": "coprocessor fix and cleanup before release  as discussed in hbase-18038. in regionserverservices, region and storefile interfaces we expose too many unnecessary methods. we need to find a way to not expose these methods to cp. ",
        "label": 149
    },
    {
        "text": "the balancer shouldn't try balancing one node  in my logs, testing 0.95.1 rc1, i see: 2013-06-07 17:31:47,377 debug [ip-10-20-46-44.novalocal,48569,1370640098134-balancerchore] balancer.stochasticloadbalancer: could not find a better load balance plan.  tried 3200 different configurations in 27ms, and did not find anything with a computed cost less than 25.0 ideally we'd not even try one configuration, let alone 3.2k. ",
        "label": 224
    },
    {
        "text": "data gc  remove all versions   ttl except the last written version  we were chatting today about our backup cluster. what we want is to be able to restore the dataset from any point of time but only within a limited timeframe \u2013 say one week. thereafter, if the versions are older than one week, rather than as we do with ttl where we let go of all versions older than ttl, instead, let go of all versions except the last one written. so, its like versions==1 when ttl > one week. we want to allow that if an error is caught within a week of its happening \u2013 user mistakenly removes a critical table \u2013 then we'll be able to restore up the the moment just before catastrophe hit otherwise, we keep one version only. ",
        "label": 286
    },
    {
        "text": "don't ship hbase till hadoop  or, soon as 0.19.1 hadoop comes out, we need a new hbase release: from hadoop list: yes guys. we observed such problems. they will be common for 0.18.2 and 0.19.0 exactly as you described it when data-nodes become unstable. there were several issues, please take a look hadoop-4997 workaround for tmp file handling on datanodes hadoop-4663 - links to other related hadoop-4810 data lost at cluster startup hadoop-4702 failed block replication leaves an incomplete block .... we run 0.18.3 now and it does not have these problems. 0.19.1 should be the same. thanks, --konstantin zak, richard [usa] wrote: > it happens right after the mr job (though once or twice its happened > during).  i am not using ebs, just hdfs between the machines.  as for tasks, > there are 4 mappers and 0 reducers. > > > richard j. zak > > -----original message----- > from: jdcryans@gmail.com [mailto:jdcryans@gmail.com] on behalf of > jean-daniel cryans > sent: friday, january 23, 2009 13:24 > to: core-user@hadoop.apache.org > subject: re: hdfs loosing blocks or connection error > > xlarge is good. is it normally happening during a mr job? if so, how many > tasks do you have running at the same moment overall? also, is your data > stored on ebs? > > thx, > > j-d > > on fri, jan 23, 2009 at 12:55 pm, zak, richard [usa] > <zak_richard@bah.com>wrote: > >> 4 slaves, 1 master, all are the m1.xlarge instance type. >> >> >> richard j. zak >> >> -----original message----- >> from: jdcryans@gmail.com [mailto:jdcryans@gmail.com] on behalf of jean-daniel cryans >> sent: friday, january 23, 2009 12:34 >> to: core-user@hadoop.apache.org >> subject: re: hdfs loosing blocks or connection error >> >> richard, >> >> this happens when the datanodes are too slow and eventually all replicas for a single block are tagged as \"bad\".  what kind of instances are you using? >> how many of them? >> >> j-d >> >> on fri, jan 23, 2009 at 12:13 pm, zak, richard [usa] >> <zak_richard@bah.com>wrote: >> >>>  might there be a reason for why this seems to routinely happen to me when using hadoop 0.19.0 on amazon ec2? >>> >>> 09/01/23 11:45:52 info hdfs.dfsclient: could not obtain block >>> blk_-1757733438820764312_6736 from any node:  java.io.ioexception: no live nodes contain current block >>> 09/01/23 11:45:55 info hdfs.dfsclient: could not obtain block  ",
        "label": 314
    },
    {
        "text": "bad enum in hbase meta info state column can fail loadmeta and stop startup  had a bad value in info:state field in meta and it made it so couldn't start up the cluster; loadmeta would not succeed. if a bad state, should note it, compensate, and move on. the bad entry was an own goal that happened while trying to fix other issues in a pre-hbck2 cluster. here was the exception: java.lang.illegalargumentexception: no enum constant org.apache.hadoop.hbase.master.regionstate.state.1 at java.lang.enum.valueof(enum.java:238) at org.apache.hadoop.hbase.master.regionstate$state.valueof(regionstate.java:37) at org.apache.hadoop.hbase.master.assignment.regionstatestore.getregionstate(regionstatestore.java:338) at org.apache.hadoop.hbase.master.assignment.regionstatestore.visitmetaentry(regionstatestore.java:116) at org.apache.hadoop.hbase.master.assignment.regionstatestore.access$100(regionstatestore.java:59) at org.apache.hadoop.hbase.master.assignment.regionstatestore$1.visit(regionstatestore.java:87) at org.apache.hadoop.hbase.metatableaccessor.scanmeta(metatableaccessor.java:769) at org.apache.hadoop.hbase.metatableaccessor.scanmeta(metatableaccessor.java:734) at org.apache.hadoop.hbase.metatableaccessor.scanmeta(metatableaccessor.java:690) at org.apache.hadoop.hbase.metatableaccessor.fullscanregions(metatableaccessor.java:220) at org.apache.hadoop.hbase.master.assignment.regionstatestore.visitmeta(regionstatestore.java:77) at org.apache.hadoop.hbase.master.assignment.assignmentmanager.loadmeta(assignmentmanager.java:1248) at org.apache.hadoop.hbase.master.assignment.assignmentmanager.joincluster(assignmentmanager.java:1209) at org.apache.hadoop.hbase.master.hmaster.finishactivemasterinitialization(hmaster.java:998) at org.apache.hadoop.hbase.master.hmaster.startactivemastermanager(hmaster.java:2260) at org.apache.hadoop.hbase.master.hmaster.lambda$run$0(hmaster.java:583) at java.lang.thread.run(thread.java:748) ",
        "label": 394
    },
    {
        "text": "purge servers of text  chatting with jim while looking at profiler outputs, we should make an effort at purging the servers of the text type so hregionserver doesn't ever have to deal in characters and the concomitant encode/decode to utf-8. toward this end, we'd make changes like moving hstorekey to have four rather than 3 data members: column family, column family qualifier, row + timestamp done as a basic writable \u2013 immutablebyteswritable? \u2013 and a long rather than a text column, text row and a timestamp long. this would save on our having to do the relatively expensive 'find' of the column family separator inside in extractfamily (>10% of cpu scanning). chatting about it, we could effect the change without change in the public client api; clients could continue to take text type for row and column and then client-side, the convertion to hstorekey could be done before crossing the wire to the server. ",
        "label": 314
    },
    {
        "text": "avoid using math abs when selecting syncrunner in fshlog  fshlog.java int index = math.abs(this.syncrunnerindex++) % this.syncrunners.length;           try {             this.syncrunners[index].offer(sequence, this.syncfutures, this.syncfuturescount);           } catch (exception e) {             // should never get here.             requestlogroll();             this.exception = new damagedwalexception(\"failed offering sync\", e);           } math.abs will return integer.min_value if you pass integer.min_value in since the actual absolute value of integer.min_value is out of range. i think this.syncrunnerindex++ will overflow eventually if we keep the regionserver running for enough time. ",
        "label": 149
    },
    {
        "text": "revert hbase  add a test scope dependency on org slf4j slf4j api to hbase client   observed behavior:  in my automation, i have a call to hbase zkcli. that call recently broke with this checkin: https://github.com/apache/hbase/commit/5af0a60efed91ac2084f25f13edb21db0f510e7c the error that is reported is: ++ ./hbase zkcli 11:19:58  warning: $hadoop_home is deprecated. 11:19:58   11:20:00  exception in thread \"main\" java.lang.illegalaccesserror: tried to access field org.slf4j.impl.staticloggerbinder.singleton from class org.slf4j.loggerfactory 11:20:00   at org.slf4j.loggerfactory.<clinit>(loggerfactory.java:60) 11:20:00   at org.apache.zookeeper.zookeepermain.<clinit>(zookeepermain.java:50) 11:20:00   at org.apache.hadoop.hbase.zookeeper.zookeepermainserver.main(zookeepermainserver.java:78) 11:20:00  build step 'execute shell' marked build as failure that said, this checkin is perfectly valid as each component should be allowed to specify its own dependencies. the issue is a deeper one of dependency mismatches. note: this issue only affects hadoop1, not hadoop2. it also appears in trunk, where there is a similar checkin, but since trunk is not required to work against hadoop1, this is not an issue for trunk. ",
        "label": 38
    },
    {
        "text": "enhance hbase load test tool to automatically create column families if not present  the load test tool currently disables the table and applies any changes to the cf descriptor if any, but does not create the cf if not present. ",
        "label": 406
    },
    {
        "text": "more testing of enable disable uncovered base condition not in place  i e  that only one enable disable runs at a time  testing, uncovered fact that master has 3 handlers currently for enable/disable/delete and modify when hbase-3112 was built on supposition that there was only one. ",
        "label": 314
    },
    {
        "text": "enable jmx metrics collection for the thrift proxy  we need to enable jmx on the thrift proxy on a separate port different from the jmx port used by regionserver. this is necessary for metrics collection. ",
        "label": 324
    },
    {
        "text": "improve the selection of regions to balance  part  see 'hbase-3586 improve the selection of regions to balance' for discussion of algorithms that improve on current random assignment. ",
        "label": 441
    },
    {
        "text": "master and regionserver not able to communicate if both bound to different network interfaces on the same machine   while testing hbase-8640 fix found that master and regionserver running on different interfaces are not communicating properly.  i have two interfaces 1) lo 2) eth0 in my machine and default hostname interface is lo.  i have configured master ipc address to ip of eth0 interface. started master and regionserver on the same machine.  1) master rpc server bound to eth0 and rs rpc server bound to lo  2) since rpc client is not binding to any ip address, when rs is reporting rs startup its getting registered with eth0 ip address(but actually it should register localhost) here are rs logs: 2013-05-31 06:05:28,608 warn  [regionserver60020] org.apache.hadoop.hbase.regionserver.hregionserver: reportforduty failed; sleeping and then retrying. 2013-05-31 06:05:31,609 info  [regionserver60020] org.apache.hadoop.hbase.regionserver.hregionserver: attempting connect to master server at 192.168.0.100,60000,1369960497008 2013-05-31 06:05:31,609 info  [regionserver60020] org.apache.hadoop.hbase.regionserver.hregionserver: telling master at 192.168.0.100,60000,1369960497008 that we are up with port=60020, startcode=1369960502544 2013-05-31 06:05:31,618 debug [regionserver60020] org.apache.hadoop.hbase.regionserver.hregionserver: config from master: hbase.rootdir=hdfs://localhost:2851/hbase 2013-05-31 06:05:31,618 debug [regionserver60020] org.apache.hadoop.hbase.regionserver.hregionserver: config from master: fs.default.name=hdfs://localhost:2851 2013-05-31 06:05:31,618 info  [regionserver60020] org.apache.hadoop.hbase.regionserver.hregionserver: master passed us a different hostname to use; was=localhost, but now=192.168.0.100 here are master logs: 2013-05-31 06:05:31,615 info  [ipc server handler 9 on 60000] org.apache.hadoop.hbase.master.servermanager: registering server=192.168.0.100,60020,1369960502544 since master has wrong rpc server address of rs, meta is not getting assigned. 2013-05-31 06:05:34,362 debug [master-192.168.0.100,60000,1369960497008] org.apache.hadoop.hbase.master.assignmentmanager: no previous transition plan was found (or we are ignoring an existing plan) for .meta.,,1.1028785192 so generated a random one; hri=.meta.,,1.1028785192, src=, dest=192.168.0.100,60020,1369960502544; 1 (online=1, available=1) available servers, forcenewplan=false ----- org.apache.hadoop.hbase.master.assignmentmanager: failed assignment of .meta.,,1.1028785192 to 192.168.0.100,60020,1369960502544, trying to assign elsewhere instead; try=1 of 10 java.net.connectexception: connection refused at sun.nio.ch.socketchannelimpl.checkconnect(native method) at sun.nio.ch.socketchannelimpl.finishconnect(socketchannelimpl.java:592) at org.apache.hadoop.net.socketiowithtimeout.connect(socketiowithtimeout.java:206) at org.apache.hadoop.net.netutils.connect(netutils.java:511) at org.apache.hadoop.net.netutils.connect(netutils.java:481) at org.apache.hadoop.hbase.ipc.rpcclient$connection.setupconnection(rpcclient.java:549) at org.apache.hadoop.hbase.ipc.rpcclient$connection.setupiostreams(rpcclient.java:813) at org.apache.hadoop.hbase.ipc.rpcclient.getconnection(rpcclient.java:1422) at org.apache.hadoop.hbase.ipc.rpcclient.call(rpcclient.java:1315) at org.apache.hadoop.hbase.ipc.rpcclient.callblockingmethod(rpcclient.java:1532) at org.apache.hadoop.hbase.ipc.rpcclient$blockingrpcchannelimplementation.callblockingmethod(rpcclient.java:1587) at org.apache.hadoop.hbase.protobuf.generated.adminprotos$adminservice$blockingstub.openregion(adminprotos.java:15039) at org.apache.hadoop.hbase.master.servermanager.sendregionopen(servermanager.java:627) at org.apache.hadoop.hbase.master.assignmentmanager.assign(assignmentmanager.java:1826) at org.apache.hadoop.hbase.master.assignmentmanager.assign(assignmentmanager.java:1453) at org.apache.hadoop.hbase.master.assignmentmanager.assign(assignmentmanager.java:1432) at org.apache.hadoop.hbase.master.handler.closedregionhandler.process(closedregionhandler.java:104) at org.apache.hadoop.hbase.master.assignmentmanager.addtoritandcallclose(assignmentmanager.java:699) at org.apache.hadoop.hbase.master.assignmentmanager.processregionsintransition(assignmentmanager.java:584) at org.apache.hadoop.hbase.master.assignmentmanager.processregionintransition(assignmentmanager.java:517) at org.apache.hadoop.hbase.master.assignmentmanager.processregionintransitionandblockuntilassigned(assignmentmanager.java:473) at org.apache.hadoop.hbase.master.hmaster.assignmeta(hmaster.java:917) at org.apache.hadoop.hbase.master.hmaster.finishinitialization(hmaster.java:803) at org.apache.hadoop.hbase.master.hmaster.run(hmaster.java:547) at java.lang.thread.run(thread.java:636) ",
        "label": 543
    },
    {
        "text": "have a single executor for all zkworkers in the assignment manager  the current strategy is to have an array of monothreaded executor, and hash the zk path to ensure that there are no two events on the same region executed in parallel i think a single executor, as presented in the attached patch, is better because: we're guaranteed to use all threads at any time if managing one of the event takes longer that expected, the slowness is limited to this region, and not to all regions that have the same hashed/moduloed code for the nodechildrenchanged, there is no need to choose randomly one of the worker (or, once again, the risk to get stuck if one of the event takes time to be managed). ",
        "label": 340
    },
    {
        "text": "hide row keys and such from the web uis  the table details on the master ui lists the start row keys of the regions. the row keys might have sensitive data. we should hide them based on whether or not the user accessing has the required authorization to view the table.. to start with, we could make the display of row keys and such based on a configuration being true or false. if it is false, such potentially sensitive data is never displayed on the web ui. ",
        "label": 139
    },
    {
        "text": "two protos missing in hbase protocol pom xml  visibilitylabels.proto and encryption.proto are missing in hbase-protocol/pom.xml. the corresponding classes are not regenerated in maven cmd: mvn compile -pcompile-protobuf ",
        "label": 411
    },
    {
        "text": "update apache jenkins to include and builds against hadoop  currently there is no hbase 0.94 apache jenkins build and the trunk on hadoop 0.23 builds are disabled. ideally we should add the former and re-enable the latter. ",
        "label": 314
    },
    {
        "text": "false positive for error prone warnings in pre commit job  https://builds.apache.org/job/precommit-hbase-build/16516/artifact/patchprocess/branch-compile-javac-hbase-client.txt [warning] /testptch/hbase/hbase-client/src/main/java/org/apache/hadoop/hbase/client/asyncrpcretryingcaller.java:[125,69] [unusedvariable] the parameter 'updatecachedlocation' is never read. [warning] /testptch/hbase/hbase-client/src/main/java/org/apache/hadoop/hbase/client/asyncrpcretryingcaller.java:[125,42] [unusedvariable] the parameter 'error' is never read. https://builds.apache.org/job/precommit-hbase-build/16516/artifact/patchprocess/patch-compile-javac-hbase-client.txt [warning] /testptch/hbase/hbase-client/src/main/java/org/apache/hadoop/hbase/client/asyncrpcretryingcaller.java:[125,42] [unusedvariable] the parameter 'error' is never read. [warning] /testptch/hbase/hbase-client/src/main/java/org/apache/hadoop/hbase/client/asyncrpcretryingcaller.java:[125,69] [unusedvariable] the parameter 'updatecachedlocation' is never read. and the output is 1 new and 1 fixed, the new one is [warning] /testptch/hbase/hbase-client/src/main/java/org/apache/hadoop/hbase/client/asyncrpcretryingcaller.java:[125,69] [unusedvariable] the parameter 'updatecachedlocation' is never read. i think here we should report nothing, as it is just an order change... ",
        "label": 149
    },
    {
        "text": "midkey found compacting is the first  not necessarily the optimal  it does this in hregion:       for (hstore store: stores.values()) {         final byte [] key = store.compact(force);                                                                                           if (key != null && midkey == null) {                                                                                                  midkey = key;                                                                                                                     }       } if many families, then we can return a suboptimal midkey. marking minor but including in 0.2 because (i think) the fix is trivial. ",
        "label": 241
    },
    {
        "text": "correct link to trafodion  appendix f in the hbase reference guide available here (https://hbase.apache.org/book.html#sql) has an incorrect link to the site for trafodion. the new trafodion url is: http://trafodion.incubator.apache.org/ ",
        "label": 177
    },
    {
        "text": "stargate does not support content type  application json and content encoding  gzip in parallel  when:  curl -h \"accept: application/json\" http://localhost:3000/version -v response is: about to connect() to localhost port 3000 (#0)  trying 127.0.0.1... connected  connected to localhost (127.0.0.1) port 3000 (#0)  > get /version http/1.1  > user-agent: curl/7.19.7 (universal-apple-darwin10.0) libcurl/7.19.7 openssl/0.9.8r zlib/1.2.3  > host: localhost:3000  > accept: application/json  >   < http/1.1 200 ok  < cache-control: no-cache  < content-type: application/json  < transfer-encoding: chunked  <  connection #0 to host localhost left intact  closing connection #0 {\"server\":\"jetty/6.1.26\",\"rest\":\"0.0.2\",\"os\":\"linux 2.6.32-bpo.5-amd64 amd64\",\"jersey\":\"1.4\",\"jvm\":\"sun microsystems inc. 1.6.0_22-17.1-b03\"} but with compression:  curl -h \"accept: application/json\" http://localhost:3000/version -v --compressed reponse is: about to connect() to localhost port 3000 (#0)  trying 127.0.0.1 ... connected  connected to localhost (127.0.0.1) port 3000 (#0)  > get /version http/1.1  > user-agent: curl/7.19.7 (universal-apple-darwin10.0) libcurl/7.19.7 openssl/0.9.8r zlib/1.2.3  > host: localhost:3000  > accept-encoding: deflate, gzip  > accept: application/json  >   < http/1.1 200 ok  < cache-control: no-cache  < content-type: application/json  < content-encoding: gzip  < transfer-encoding: chunked  <  connection #0 to host localhost left intact  closing connection #0 and the stargate server throws the following exception: 11/07/14 11:21:44 error mortbay.log: /version  java.lang.classcastexception: org.mortbay.jetty.httpconnection$output cannot be cast to org.apache.hadoop.hbase.rest.filter.gzipresponsestream  at org.apache.hadoop.hbase.rest.filter.gzipfilter.dofilter(gzipfilter.java:54)  at org.mortbay.jetty.servlet.servlethandler$cachedchain.dofilter(servlethandler.java:1212)  at org.mortbay.jetty.servlet.servlethandler.handle(servlethandler.java:399)  at org.mortbay.jetty.servlet.sessionhandler.handle(sessionhandler.java:182)  at org.mortbay.jetty.handler.contexthandler.handle(contexthandler.java:766)  at org.mortbay.jetty.handler.handlerwrapper.handle(handlerwrapper.java:152)  at org.mortbay.jetty.server.handle(server.java:326)  at org.mortbay.jetty.httpconnection.handlerequest(httpconnection.java:542)  at org.mortbay.jetty.httpconnection$requesthandler.headercomplete(httpconnection.java:928)  at org.mortbay.jetty.httpparser.parsenext(httpparser.java:549)  at org.mortbay.jetty.httpparser.parseavailable(httpparser.java:212)  at org.mortbay.jetty.httpconnection.handle(httpconnection.java:404)  at org.mortbay.jetty.bio.socketconnector$connection.run(socketconnector.java:228)  at org.mortbay.thread.queuedthreadpool$poolthread.run(queuedthreadpool.java:582) this is not reproduceable with content type text/plain and gzip. this is somehow related to https://issues.apache.org/jira/browse/hbase-3275 ",
        "label": 38
    },
    {
        "text": "replicationlogcleaner can delete wals not yet replicated in case of a keeperexception  replicationstatezkbase#getlistofreplicators does not rethrow a keeperexception and returns null in such a case. replicationlogcleaner just assumes that there are no replicators and deletes everything. replicationstatezkbase: public list<string> getlistofreplicators() {     list<string> result = null;     try {       result = zkutil.listchildrennowatch(this.zookeeper, this.queuesznode);     } catch (keeperexception e) {       this.abortable.abort(\"failed to get list of replicators\", e);     }     return result;   } replicationlogcleaner: private set<string> loadwalsfromqueues() throws keeperexception {     for (int retry = 0; ; retry++) {       int v0 = replicationqueues.getqueuesznodecversion();       list<string> rss = replicationqueues.getlistofreplicators();       if (rss == null) {         log.debug(\"didn't find any region server that replicates, won't prevent any deletions.\");         return immutableset.of();       }       ... ",
        "label": 64
    },
    {
        "text": "rename of hfile min blocksize size in hbase reverted in hbase  hbase-2899 renamed hfile.min.blocksize.size to hbase.mapreduce.hfileoutputformat.blocksize. however, hbase-1861 (committed after hbase-2899) reverted this change. ",
        "label": 1
    },
    {
        "text": "ui shows hadoop version  not hbase version  running a 0.1.0 hbase, i see this as version in ui: version 0.16.0, r618351 hbase version and svn revision looks like the version is properly updated but the jsp needs to be regenerated for it to show. fix by integrating jsp build into general build. ",
        "label": 314
    },
    {
        "text": " hbck  verify and test the the number of regions is correct   hbase-4322 updated the algorithm behind hbck's region split problem detection but it may be report the an incorrect number of total regions. need to investigate and add a test. ",
        "label": 248
    },
    {
        "text": "master does not respect generation stamps  may result in meta getting permanently offlined  this happens if the rs is restarted before the zk node expires. the sequence is as follows: 1. rs1 dies - lets say its server string was host1:port1:ts1  2. in a few seconds rs1 is restarted, it comes up as host1:port1:ts2 (ts2 is more recent than ts1)  3. master gets a start up message from rs1 with the server name as host1:port1:ts2  4. master adds this as a new rs, tries to red  ---- the master does not use the generation stamps to detect that rs1 has already restarted.  ---- also, if rs1 contained meta, master would try to go to host1:port1:ts1. it would end up talking to host1:port1:ts2, which spews a bunch of not serving region exceptions.  5. zk node expires for host1:port1:ts1  6. master tries to process shutdown for host1:port1:ts1 - this probably interferes with host1:port1:ts2 and ends up somehow removing the reassign meta in the master's queue.  ---- meta never comes online and master continues logging the following exception indefinitely: 2010-04-06 11:02:23,988 debug org.apache.hadoop.hbase.master.hmaster: processing todo: processregionclose of test1,7094000000,1270220428234, false, reassign: true  2010-04-06 11:02:23,988 debug org.apache.hadoop.hbase.master.processregionclose$1: exception in retryablemetaoperation:  java.lang.nullpointerexception  at org.apache.hadoop.hbase.master.retryablemetaoperation.dowithretries(retryablemetaoperation.java:64)  at org.apache.hadoop.hbase.master.processregionclose.process(processregionclose.java:63)  at org.apache.hadoop.hbase.master.hmaster.processtodoqueue(hmaster.java:494)  at org.apache.hadoop.hbase.master.hmaster.run(hmaster.java:429) ",
        "label": 314
    },
    {
        "text": "mapreduce walplayer issue with notagskeyvalue  running mapreduce walplayer to convert wal into hfiles: 15/10/05 20:28:08 info mapred.jobclient: task id : attempt_201508031611_0029_m_000000_0, status : failed java.io.ioexception: type mismatch in value from map: expected org.apache.hadoop.hbase.keyvalue, recieved org.apache.hadoop.hbase.notagskeyvalue         at org.apache.hadoop.mapred.maptask$mapoutputbuffer.collect(maptask.java:997)         at org.apache.hadoop.mapred.maptask$newoutputcollector.write(maptask.java:689)         at org.apache.hadoop.mapreduce.task.taskinputoutputcontextimpl.write(taskinputoutputcontextimpl.java:89)         at org.apache.hadoop.mapreduce.lib.map.wrappedmapper$context.write(wrappedmapper.java:112)         at org.apache.hadoop.hbase.mapreduce.walplayer$walkeyvaluemapper.map(walplayer.java:111)         at org.apache.hadoop.hbase.mapreduce.walplayer$walkeyvaluemapper.map(walplayer.java:96)         at org.apache.hadoop.mapreduce.mapper.run(mapper.java:140)         at org.apache.hadoop.mapred.maptask.runnewmapper(maptask.java:751)         at org.apache.hadoop.mapred.maptask.run(maptask.java:368)         at org.apache.hadoop.mapred.child$4.run(child.java:255)         at java.security.accesscontroller.doprivileged(accesscontroller.java:369)         at javax.security.auth.subject.doas(subject.java:572)         at org.apache.hadoop.security.usergroupinformation.doas(usergroupinformation.java:1502)         at org.apache.hadoop.mapred.child.main(child.java:249) ",
        "label": 46
    },
    {
        "text": "automatically delete empty directories in cleanerchore  currently the cleanerchore asks cleaner delegates if both directories and files should be deleted. however, this leads to somewhat odd behavior in some delegates - you don't actually care if the directory hierarchy is preserved, the files; this means you always will delete directories and then implement the logic you actually want for preserving files. instead we can handle this logic one layer higher in the cleanerchore and let the delegates just worry about preserving files. ",
        "label": 236
    },
    {
        "text": "delete command with no where clause  using hbaseadmin.deletecolumn() method. delete column_name from table_name; ",
        "label": 152
    },
    {
        "text": "better approximate high percentile percentile latency metrics  the existing reservoir-sampling based latency metrics in hbase are not well-suited for providing accurate estimates of high-percentile (e.g. 90th, 95th, or 99th) latency. this is a well-studied problem in the literature (see [1] and [2]), the question is determining which methods best suit our needs and then implementing it. ideally, we should be able to estimate these high percentiles with minimal memory and cpu usage as well as minimal error (e.g. 1% error on 90th, or .1% on 99th). it's also desirable to provide this over different time-based sliding windows, e.g. last 1 min, 5 mins, 15 mins, and 1 hour. i'll note that this would also be useful in hdfs, or really anywhere latency metrics are kept. [1] http://www.cs.rutgers.edu/~muthu/bquant.pdf  [2] http://infolab.stanford.edu/~manku/papers/04pods-sliding.pdf ",
        "label": 39
    },
    {
        "text": "npes in server shutdown  2011-07-11 10:26:01,268 error org.apache.hadoop.hbase.executor.eventhandler: caught throwable while processing event m_server_shutdown  java.lang.nullpointerexception  at org.apache.hadoop.hbase.master.handler.servershutdownhandler.process(servershutdownhandler.java:145)  at org.apache.hadoop.hbase.executor.eventhandler.run(eventhandler.java:156)  at java.util.concurrent.threadpoolexecutor$worker.runtask(threadpoolexecutor.java:886)  at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:908)  at java.lang.thread.run(thread.java:662)  2011-07-11 10:26:01,268 info org.apache.hadoop.hbase.master.handler.servershutdownhandler: splitting logs for sv2borg164,60020,1309996983328  2011-07-11 10:26:01,269 error org.apache.hadoop.hbase.executor.eventhandler: caught throwable while processing event m_server_shutdown  java.lang.nullpointerexception  at org.apache.hadoop.hbase.master.handler.servershutdownhandler.process(servershutdownhandler.java:145)  at org.apache.hadoop.hbase.executor.eventhandler.run(eventhandler.java:156)  at java.util.concurrent.threadpoolexecutor$worker.runtask(threadpoolexecutor.java:886)  at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:908)  at java.lang.thread.run(thread.java:662) ",
        "label": 314
    },
    {
        "text": "hlog cacheflushlock not cleared  hangs a region  i have a region that is stuck in a close that was ordained by a split. here is what i have from the log pertaining to the stuck region: 4    6416 2008-05-29 22:29:03,433 info org.apache.hadoop.hbase.hregion: checking compaction completed on region enwiki,ik9swdhje6ffgzgfpsqivk==,1212092907061 in 12sec 5    6417 2008-05-29 22:29:03,439 info org.apache.hadoop.hbase.hregion: splitting enwiki,ik9swdhje6ffgzgfpsqivk==,1212092907061 because largest aggregate size is 288.3m and desired size is 256.0m                                                                     6    6418 2008-05-29 22:29:03,443 debug org.apache.hadoop.hbase.hregion: compactions and cache flushes disabled for region enwiki,ik9swdhje6ffgzgfpsqivk==,1212092907061 7    6419 2008-05-29 22:29:03,443 debug org.apache.hadoop.hbase.hregion: new updates and scanners for region enwiki,ik9swdhje6ffgzgfpsqivk==,1212092907061 disabled                                                                                                     8    6420 2008-05-29 22:29:03,443 debug org.apache.hadoop.hbase.hregion: no more active scanners for region enwiki,ik9swdhje6ffgzgfpsqivk==,1212092907061 9    6421 2008-05-29 22:29:03,443 debug org.apache.hadoop.hbase.hregion: no more row locks outstanding on region enwiki,ik9swdhje6ffgzgfpsqivk==,1212092907061                                                                                                         10   6422 2008-05-29 22:29:03,443 debug org.apache.hadoop.hbase.hregionserver: enwiki,ik9swdhje6ffgzgfpsqivk==,1212092907061 closing (adding to retiringregions) 11   6423 2008-05-29 22:29:03,443 debug org.apache.hadoop.hbase.hregion: started memcache flush for region enwiki,ik9swdhje6ffgzgfpsqivk==,1212092907061. current region memcache size 2.1m                                                                            12    6424 2008-05-29 22:29:03,561 info org.apache.hadoop.ipc.server: ipc server handler 0 on 60020, call batchupdate(enwiki,ik9swdhje6ffgzgfpsqivk==,1212092907061, 1171081390000, org.apache.hadoop.hbase.io.batchupdate@2eeb0275) from 208.76.44.139:49358: err        or: org.        apache.hadoop.hbase.notservingregionexception: enwiki,ik9swdhje6ffgzgfpsqivk==,1212092907061                                                                                                                                                         13   6425 org.apache.hadoop.hbase.notservingregionexception: enwiki,ik9swdhje6ffgzgfpsqivk==,1212092907061 14   6434 2008-05-29 22:29:03,982 info org.apache.hadoop.ipc.server: ipc server handler 9 on 60020, call batchupdate(enwiki,ik9swdhje6ffgzgfpsqivk==,1212092907061, 1202595259000, org.apache.hadoop.hbase.io.batchupdate@46ee6763) from 208.76.44.139:49358: err        or: org.        apache.hadoop.hbase.notservingregionexception: enwiki,ik9swdhje6ffgzgfpsqivk==,1212092907061 15   6435 org.apache.hadoop.hbase.notservingregionexception: enwiki,ik9swdhje6ffgzgfpsqivk==,1212092907061 then in thread dump, i have two threads blocked on the hlog#cacheflushlock but looking in code, there is no obvious code path that would get a situation where a lock is held and then not released. \"regionserver/0:0:0:0:0:0:0:0:60020.compactor\" daemon prio=1 tid=0x00002aab381e5fd0 nid=0x6195 waiting on condition [0x0000000041c6c000..0x0000000041c6ce00]         at sun.misc.unsafe.park(native method)         at java.util.concurrent.locks.locksupport.park(unknown source)         at java.util.concurrent.locks.abstractqueuedsynchronizer.parkandcheckinterrupt(unknown source)         at java.util.concurrent.locks.abstractqueuedsynchronizer.acquirequeued(unknown source)         at java.util.concurrent.locks.abstractqueuedsynchronizer.acquire(unknown source)         at java.util.concurrent.locks.reentrantlock$nonfairsync.lock(unknown source)         at java.util.concurrent.locks.reentrantlock.lock(unknown source)         at org.apache.hadoop.hbase.hlog.startcacheflush(hlog.java:459)         at org.apache.hadoop.hbase.hregion.internalflushcache(hregion.java:1089)         at org.apache.hadoop.hbase.hregion.close(hregion.java:594)         - locked <0x00002aaab70bf3a0> (a java.lang.integer)         at org.apache.hadoop.hbase.hregion.splitregion(hregion.java:759)         - locked <0x00002aaab70bf3a0> (a java.lang.integer)         at org.apache.hadoop.hbase.hregionserver$compactsplitthread.split(hregionserver.java:248)         at org.apache.hadoop.hbase.hregionserver$compactsplitthread.run(hregionserver.java:204) ... \"regionserver/0:0:0:0:0:0:0:0:60020.logroller\" daemon prio=1 tid=0x00002aab38181d70 nid=0x6193 waiting on condition [0x0000000041a6a000..0x0000000041a6ab00]         at sun.misc.unsafe.park(native method)         at java.util.concurrent.locks.locksupport.park(unknown source)         at java.util.concurrent.locks.abstractqueuedsynchronizer.parkandcheckinterrupt(unknown source)         at java.util.concurrent.locks.abstractqueuedsynchronizer.acquirequeued(unknown source)         at java.util.concurrent.locks.abstractqueuedsynchronizer.acquire(unknown source)         at java.util.concurrent.locks.reentrantlock$nonfairsync.lock(unknown source)         at java.util.concurrent.locks.reentrantlock.lock(unknown source)         at org.apache.hadoop.hbase.hlog.rollwriter(hlog.java:219)         at org.apache.hadoop.hbase.hregionserver$logroller.run(hregionserver.java:615)         - locked <0x00002aaab69ccf00> (a java.lang.integer) ... ",
        "label": 314
    },
    {
        "text": "hbck should not take a lock unless fixing errors  by default, hbck is run in a read-only checker mode. in this case, it is  sensible to let others run. by default, the balancer is left alone,  which may cause spurious errors, but cannot leave the balancer in a bad  state. it is dangerous to leave the balancer by accident, so it is only  ever enabled after fixing, it will never be forced off because of  racing. when hbck is run in fixer mode, it must take an exclusive lock and  disable the balancer, or all havoc will break loose. if you want to stop hbck from running in parallel, the -exclusive flag  will create the lock file. if you want to force -disablebalancer, that  option is available too. this makes more semantic sense than -nolock and  -noswitchbalancer, respectively. this task is related to hbase-14092. ",
        "label": 420
    },
    {
        "text": "graceful stop sh does not pass on the  config its passed to its internal invocations of other hbase scripts  means, unless conf is in default location, we mess up asking zk for state (we'll be pointed at wrong ensemble), etc. ",
        "label": 314
    },
    {
        "text": "hbase broke mapreduce when using result list   not sure if it is just me, but using mr over hbase employing a tablereducer is not working. after the first row is read all subsequent rows get the same result's of that very first row. after tracing this from the map phase i found the culprit in result and the hbase-1765 delayed field parsing change. this is the code i use in the reduce():    @override     protected void reduce(immutablebyteswritable key, iterable<result> values,         context context) throws ioexception, interruptedexception {       string skey = bytes.tostring(key.get());       context.getcounter(counterstotals.rows).increment(1);       for (result result : values) {         for (keyvalue kv: result.list()) {           try {             if (log.isdebugenabled()) log.debug(\"reduce: key -> \" + skey + \", kv -> \" + kv);             ... here is the current list() implementation:   public list<keyvalue> list() {     if(this.kvs == null) {       readfields();     }     return isempty()? null: arrays.aslist(sorted());   } the problem is that readfields(datainput) does not clear kvs!   public void readfields(final datainput in)   throws ioexception {     familymap = null;     row = null;     int totalbuffer = in.readint();     if(totalbuffer == 0) {       bytes = null;       return;     }     byte [] raw = new byte[totalbuffer];     in.readfully(raw, 0, totalbuffer);     bytes = new immutablebyteswritable(raw, 0, totalbuffer);   } the above is called by the mr framework's writableserialization for each map output. but since \"kvs\" is already set \"list()\" returns the old data! i assume the only change needed is clearing kvs as well:   public void readfields(final datainput in)   throws ioexception {     familymap = null;     row = null;     kvs = null;     .... i'll test that now and report. ",
        "label": 285
    },
    {
        "text": "prcoess rit on master restart can try assigning the region if the region is found on a dead server instead of waiting for timeout monitor  currently on master restart if it tries to do processrit, any region if found on dead server tries to avoid the nwe assignment so that timeout monitor can take care.  this case is more prominent if the node is found in rs_zk_region_opening state. i think we can handle this by triggering a new assignment with a new plan. ",
        "label": 56
    },
    {
        "text": "remove need for heartbeats in hbase  hbase currently uses heartbeats between region servers and the master, piggybacking information on them when it can. this issue is to investigate if we can get rid of the need for those using zookeeper events. ",
        "label": 314
    },
    {
        "text": "column length is not checked before saved to memstore  i added some debuging to line 511 in hfile.java and found that the column is causing my problem it was > max size  we should check this before saving the record to memstore as of 0.20.0-rc2 the server dies and cause the hlogs to be read again by the next region server that gets the region in the end it cause the whole cluster to go down sense the bad data is in the hlog at this point. 2009-08-18 12:54:16,572 fatal  org.apache.hadoop.hbase.regionserver.memstoreflusher: replay of hlog  required. forcing server shutdown org.apache.hadoop.hbase.droppedsnapshotexception: region:  webdata,http:\\x2f\\x2fanaal-genomen.isporno.nl\\x2f,1250569930062         at org.apache.hadoop.hbase.regionserver.hregion.internalflushcache(hregion.java:950)         at org.apache.hadoop.hbase.regionserver.hregion.flushcache(hregion.java:843)         at org.apache.hadoop.hbase.regionserver.memstoreflusher.flushregion(memstoreflusher.java:241)         at org.apache.hadoop.hbase.regionserver.memstoreflusher.run(memstoreflusher.java:149) caused by: java.io.ioexception: key length 183108 > 65536         at org.apache.hadoop.hbase.io.hfile.hfile$writer.checkkey(hfile.java:511)         at org.apache.hadoop.hbase.io.hfile.hfile$writer.append(hfile.java:479)         at org.apache.hadoop.hbase.io.hfile.hfile$writer.append(hfile.java:447)         at org.apache.hadoop.hbase.regionserver.store.internalflushcache(store.java:525)         at org.apache.hadoop.hbase.regionserver.store.flushcache(store.java:489)         at org.apache.hadoop.hbase.regionserver.hregion.internalflushcache(hregion.java:935)         ... 3 more ",
        "label": 30
    },
    {
        "text": "correct  throws in comment  correct @throws in comment.  in the comment of class org.apache.hadoop.hbase.client.retryingcallerinterceptor's method  public abstract void intercept(  retryingcallerinterceptorcontext abstractretryingcallerinterceptorcontext)  throws ioexception;  it was a preemptivefastfailexception before while it's current ioexception ",
        "label": 487
    },
    {
        "text": "thread chaosmonkey steps on its own toes  chaosmonkey with one destructive and one volatility (flush-compact-split-etc.) threads steps on its own toes and logs a lot of exceptions.  a simple solution would be to catch most (or all), like notservingregionexception, and log less (not a full callstack for example, it's not very useful anyway).  a more complicated/complementary one would be to keep track which regions the destructive thread affects and use other regions for volatile one. ",
        "label": 406
    },
    {
        "text": "improve documentation of importtsv and bulk loads  right now our bulk load features are a little confusing. we have loadtable.rb for new tables and completebulkload for existing tables. the docs only talk about the incremental case, and there are basically no docs for the ruby script. we should conslidate these things and make the documentation a little more clear on the full story. ",
        "label": 1
    },
    {
        "text": "org apache hadoop hbase client rsgroup testshellrsgroups hangs fails  sometime in the past couple of weeks, testshellrsgroups has started timing-out/failing for me. it will get stuck on a call to movetables() \"main\" #1 prio=5 os_prio=31 tid=0x00007ff012004800 nid=0x1703 in object.wait() [0x000070000020d000]    java.lang.thread.state: waiting (on object monitor)         at java.lang.object.wait(native method)         at java.lang.object.wait(object.java:502)         at org.apache.hadoop.hbase.ipc.blockingrpccallback.get(blockingrpccallback.java:62)         - locked <0x000000078d1003f0> (a org.apache.hadoop.hbase.ipc.blockingrpccallback)         at org.apache.hadoop.hbase.ipc.abstractrpcclient.callblockingmethod(abstractrpcclient.java:328)         at org.apache.hadoop.hbase.ipc.abstractrpcclient.access$200(abstractrpcclient.java:94)         at org.apache.hadoop.hbase.ipc.abstractrpcclient$blockingrpcchannelimplementation.callblockingmethod(abstractrpcclient.java:567)         at org.apache.hadoop.hbase.shaded.protobuf.generated.masterprotos$masterservice$blockingstub.execmasterservice(masterprotos.java)         at org.apache.hadoop.hbase.client.connectionimplementation$3.execmasterservice(connectionimplementation.java:1500)         at org.apache.hadoop.hbase.client.hbaseadmin$67$1.rpccall(hbaseadmin.java:2991)         at org.apache.hadoop.hbase.client.hbaseadmin$67$1.rpccall(hbaseadmin.java:2986)         at org.apache.hadoop.hbase.client.mastercallable.call(mastercallable.java:98)         at org.apache.hadoop.hbase.client.hbaseadmin$67.callexecservice(hbaseadmin.java:2997)         at org.apache.hadoop.hbase.client.synccoprocessorrpcchannel.callblockingmethod(synccoprocessorrpcchannel.java:69)         at org.apache.hadoop.hbase.protobuf.generated.rsgroupadminprotos$rsgroupadminservice$blockingstub.movetables(rsgroupadminprotos.java:13171)         at org.apache.hadoop.hbase.rsgroup.rsgroupadminclient.movetables(rsgroupadminclient.java:117) the server-side end of the rpc is waiting on a procedure to finish: \"rpcserver.default.fpbq.fifo.handler=27,queue=0,port=64242\" #289 daemon prio=5 os_prio=31 tid=0x00007ff015b7c000 nid=0x1e603 waiting on condition [0x000070000dbc9000]    java.lang.thread.state: timed_waiting (sleeping)         at java.lang.thread.sleep(native method)         at org.apache.hadoop.hbase.master.procedure.proceduresyncwait.waitfor(proceduresyncwait.java:184)         at org.apache.hadoop.hbase.master.procedure.proceduresyncwait.waitfor(proceduresyncwait.java:171)         at org.apache.hadoop.hbase.master.procedure.proceduresyncwait.waitforproceduretocomplete(proceduresyncwait.java:141)         at org.apache.hadoop.hbase.master.procedure.proceduresyncwait.waitforproceduretocompleteioe(proceduresyncwait.java:130)         at org.apache.hadoop.hbase.master.procedure.proceduresyncwait.submitandwaitprocedure(proceduresyncwait.java:123)         at org.apache.hadoop.hbase.master.assignment.assignmentmanager.unassign(assignmentmanager.java:478)         at org.apache.hadoop.hbase.master.assignment.assignmentmanager.unassign(assignmentmanager.java:465)         at org.apache.hadoop.hbase.rsgroup.rsgroupadminserver.movetables(rsgroupadminserver.java:432)         at org.apache.hadoop.hbase.rsgroup.rsgroupadminendpoint$rsgroupadminserviceimpl.movetables(rsgroupadminendpoint.java:174)         at org.apache.hadoop.hbase.protobuf.generated.rsgroupadminprotos$rsgroupadminservice.callmethod(rsgroupadminprotos.java:12786)         at org.apache.hadoop.hbase.master.masterrpcservices.execmasterservice(masterrpcservices.java:673)         at org.apache.hadoop.hbase.shaded.protobuf.generated.masterprotos$masterservice$2.callblockingmethod(masterprotos.java)         at org.apache.hadoop.hbase.ipc.rpcserver.call(rpcserver.java:406)         at org.apache.hadoop.hbase.ipc.callrunner.run(callrunner.java:133)         at org.apache.hadoop.hbase.ipc.rpcexecutor$handler.run(rpcexecutor.java:278)         at org.apache.hadoop.hbase.ipc.rpcexecutor$handler.run(rpcexecutor.java:258)    locked ownable synchronizers:         - none i don't see anything else running in the thread dump, but i do see that meta was closed. eventually the client (i think) gives up and retries, but then fails because meta isn't assigned. 2017-06-20 15:07:45,720 debug [rs_close_meta-hw10447:64242-0] assignment.regiontransitionprocedure(200): received report closed seqid=-1, pid=12, state=runnable:region_transition_dispatch; unassignprocedure table=hbase:meta, region=1588230740, server=hw10447.local,64242,1497985650605; rit=closing, location=hw10447.local,64242,1497985650605 2017-06-20 15:07:45,720 debug [rs_close_meta-hw10447:64242-0] handler.closeregionhandler(122): closed hbase:meta,,1.1588230740 2017-06-20 15:07:45,722 warn  [procexecwrkr-9] zookeeper.metatablelocator(443): tried to set null servername in hbase:meta; skipping -- servername required 2017-06-20 15:07:45,724 info  [procexecwrkr-9] procedure2.procedureexecutor(1167): finished pid=12, state=success; unassignprocedure table=hbase:meta, region=1588230740, server=hw10447.local,64242,1497985650605 in 379msec 2017-06-20 15:07:46,454 debug [rpcserver.default.fpbq.fifo.handler=27,queue=0,port=64242] procedure.proceduresyncwait(192): waitfor pid=12 2017-06-20 15:07:47,458 info  [rpcserver.default.fpbq.fifo.handler=27,queue=0,port=64242] rsgroup.rsgroupadminserver(345): unassigning 0 region(s) from hw10447.local:64242 for server move to test_group 2017-06-20 15:07:48,462 info  [rpcserver.default.fpbq.fifo.handler=27,queue=0,port=64242] rsgroup.rsgroupadminserver(378): move server done: default=>test_group took 4.2749 seconds2017-06-20 15:07:48,488 debug [rpcserver.default.fpbq.fifo.handler=27,queue=0,port=64242] rsgroup.rsgroupinfomanagerimpl(480): updating znode: /hbase/rsgroup/test_group 2017-06-20 15:07:48,488 debug [rpcserver.default.fpbq.fifo.handler=27,queue=0,port=64242] rsgroup.rsgroupinfomanagerimpl(480): updating znode: /hbase/rsgroup/default 2017-06-20 15:07:48,488 debug [rpcserver.default.fpbq.fifo.handler=27,queue=0,port=64242] rsgroup.rsgroupinfomanagerimpl(486): writing zk groupinfo count: 4 2017-06-20 15:07:48,598 debug [rpcserver.default.fpbq.fifo.handler=27,queue=0,port=64242] procedure2.procedureexecutor(792): stored pid=13, state=runnable; org.apache.hadoop.hbase.master.locking.lockprocedure, tablename=test_table, type=exclusive 2017-06-20 15:07:48,600 debug [procexecwrkr-10] locking.lockprocedure(313): locked pid=13, state=runnable; org.apache.hadoop.hbase.master.locking.lockprocedure, tablename=test_table, type=exclusive 2017-06-20 15:07:48,600 info  [procexecwrkr-10] procedure2.procedureexecutor$timeoutexecutorthread(1743): added pid=13, state=waiting_timeout; org.apache.hadoop.hbase.master.locking.lockprocedure, tablename=test_table, type=exclusive; timeout=600000, timestamp=1497986268600 2017-06-20 15:07:48,706 debug [rpcserver.default.fpbq.fifo.handler=27,queue=0,port=64242] procedure2.procedureexecutor(792): stored pid=14, state=runnable:region_transition_dispatch; unassignprocedure table=test_table, region=578de877b09db11dcc129a6ff5b22406, server=hw10447.local,64263,1497985652273 2017-06-20 15:07:49,179 warn  [hbase-metrics2-1] impl.metricsconfig(125): cannot locate configuration: tried hadoop-metrics2-hbase.properties,hadoop-metrics2.properties 2017-06-20 15:07:49,708 debug [rpcserver.default.fpbq.fifo.handler=27,queue=0,port=64242] procedure.proceduresyncwait(192): waitfor pid=14 2017-06-20 15:08:02,376 debug [procexectimeout] procedure2.procedureexecutor$completedprocedurecleaner(190): evict completed assignprocedure table=hbase:meta, region=1588230740 pid=1, owner=jelser.hfs.3, state=success, submittedtime=29sec ago, lastupdate=29sec ago 2017-06-20 15:08:02,376 debug [procexectimeout] procedure2.procedureexecutor$completedprocedurecleaner(190): evict completed createtableprocedure table=hbase:namespace pid=2, owner=jelser.hfs.3, state=success, submittedtime=27sec ago, lastupdate=27sec ago 2017-06-20 15:08:02,376 debug [procexectimeout] procedure2.procedureexecutor$completedprocedurecleaner(190): evict completed createnamespaceprocedure, namespace=default pid=4, owner=jelser.hfs.3, state=success, submittedtime=27sec ago, lastupdate=27sec ago 2017-06-20 15:08:02,376 debug [procexectimeout] procedure2.procedureexecutor$completedprocedurecleaner(190): evict completed createtableprocedure table=hbase:rsgroup pid=5, owner=jelser.hfs.3, state=success, submittedtime=27sec ago, lastupdate=27sec ago 2017-06-20 15:08:02,376 debug [procexectimeout] procedure2.procedureexecutor$completedprocedurecleaner(190): evict completed createnamespaceprocedure, namespace=hbase pid=7, owner=jelser.hfs.3, state=success, submittedtime=26sec ago, lastupdate=26sec ago 2017-06-20 15:08:02,376 debug [procexectimeout] procedure2.procedureexecutor$completedprocedurecleaner(190): evict completed unassignprocedure table=hbase:namespace, region=a47624f5345a80b72f278f79a432955b, server=hw10447.local,64242,1497985650605 pid=11, owner=jelser, state=success, submittedtime=18sec ago, lastupdate=18sec ago 2017-06-20 15:08:02,376 debug [procexectimeout] procedure2.procedureexecutor$completedprocedurecleaner(190): evict completed unassignprocedure table=hbase:meta, region=1588230740, server=hw10447.local,64242,1497985650605 pid=12, owner=jelser, state=success, submittedtime=17sec ago, lastupdate=17sec ago ",
        "label": 426
    },
    {
        "text": "use getvisiblelength public api from hdfsdatainputstream from hadoop   sequencfilelogreader: currently hbase using getfilelength api from dfsinputstream class by reflection. dfsinputstream is not exposed as public. so, this may change in future. now hdfs exposed hdfsdatainputstream as public api.  we can make use of it, when we are not able to find the getfilelength api from dfsinputstream as a else condition. so, that we will not have any sudden surprise like we are facing today. also, it is just logging one warn message and proceeding if it throws any exception while getting the length. i think we can re-throw the exception because there is no point in continuing with dataloss. long adjust = 0;           try {             field fin = filterinputstream.class.getdeclaredfield(\"in\");             fin.setaccessible(true);             object realin = fin.get(this.in);             // in hadoop 0.22, dfsinputstream is a standalone class.  before this,             // it was an inner class of dfsclient.             if (realin.getclass().getname().endswith(\"dfsinputstream\")) {               method getfilelength = realin.getclass().                 getdeclaredmethod(\"getfilelength\", new class<?> []{});               getfilelength.setaccessible(true);               long reallength = ((long)getfilelength.                 invoke(realin, new object []{})).longvalue();               assert(reallength >= this.length);               adjust = reallength - this.length;             } else {               log.info(\"input stream class: \" + realin.getclass().getname() +                   \", not adjusting length\");             }           } catch(exception e) {             sequencefilelogreader.log.warn(               \"error while trying to get accurate file length.  \" +               \"truncation / data loss may occur if regionservers die.\", e);           }           return adjust + super.getpos(); ",
        "label": 53
    },
    {
        "text": "hbase design overview  i'm going to make wiki page contain hbase design overview. that will cover architecture of hbase, used solutions unresolved problems it should be something like http://labs.google.com/papers/bigtable.html focused on implementation part. ",
        "label": 167
    },
    {
        "text": "ability to export the list of files for a some or all column families for a given region  should be able to query the regionservers to figure out the list of files in one/some/all column families for a given regions to determine which files to copy for a backup. ",
        "label": 300
    },
    {
        "text": "more log edits  we log too much  at the moment i am trying to debug failures on a laptop. as is, all i can see (w/ a small font) most of the time is timestamp, thread name, and class name and then i have to scroll right. this is untenable, frustrating debug. our logs need to be less profuse and more dense. + our thread names are nice and descriptive and are useful particularly when running standlone mode but it gets silly printing out full thread names when distributed on each log (we could turn off printing thread name but can be helpful).  + do we have to print the fully qualified path for all files every time? lines get really long and hard to read. ditto for region names.  + can we print out just the class name rather than full package qualified class name. for example: 2013-05-25 12:21:01,912 debug [rs_open_region-sss-2.ent.cloudera.com,60020,1369507494038-2] org.apache.hadoop.hbase.regionserver.handler.openregionhandler: region transitioned to opened in zookeeper: {name => 'integrationtestdataingestwithchaosmonkey,c28f5c19,1369509660096.4e91d414f14a75cf367609ce9c4377c7.', startkey => 'c28f5c19', endkey => 'ccccccbc', encoded => 4e91d414f14a75cf367609ce9c4377c7,}, server: sss-2.ent.cloudera.com,60020,1369507494038 should the above just be: 2013-05-25 12:21:01,912 debug [rs_open_region-sss-2.ent.cloudera.com,60020,1369507494038-2] openregionhandler: region 4e91d414f14a75cf367609ce9c4377c7 transitioned to opened + some logging is bound to freak operators. we print out the full stack trace when we are logging failed assignment because of connection refused.  + should make sure we tell a decent story when info level only enabled. at moment it is scattershot. ",
        "label": 314
    },
    {
        "text": "testnamespaceupgrade fails in trunk  i see the following in test output:     <error message=\"can&apos;t get the location\" type=\"org.apache.hadoop.hbase.client.retriesexhaustedexception\">org.apache.hadoop.hbase.client.retriesexhaustedexception: can&apos;t get the location   at org.apache.hadoop.hbase.client.rpcretryingcallerwithreadreplicas.getregionlocations(rpcretryingcallerwithreadreplicas.java:287)   at org.apache.hadoop.hbase.client.scannercallablewithreplicas.call(scannercallablewithreplicas.java:132)   at org.apache.hadoop.hbase.client.scannercallablewithreplicas.call(scannercallablewithreplicas.java:1)   at org.apache.hadoop.hbase.client.rpcretryingcaller.callwithoutretries(rpcretryingcaller.java:179)   at org.apache.hadoop.hbase.client.clientscanner.call(clientscanner.java:287)   at org.apache.hadoop.hbase.client.clientscanner.nextscanner(clientscanner.java:267)   at org.apache.hadoop.hbase.client.clientscanner.initializescannerinconstruction(clientscanner.java:139)   at org.apache.hadoop.hbase.client.clientscanner.&lt;init&gt;(clientscanner.java:134)   at org.apache.hadoop.hbase.client.htable.getscanner(htable.java:814)   at org.apache.hadoop.hbase.migration.testnamespaceupgrade.setupbeforeclass(testnamespaceupgrade.java:147) ... caused by: org.apache.hadoop.hbase.client.noserverforregionexception: no server address listed in hbase:meta for region hbase:acl,,1376029204842.                          06dfcfc239196403c5f1135b91dedc64. containing row   at org.apache.hadoop.hbase.client.connectionmanager$hconnectionimplementation.locateregioninmeta(connectionmanager.java:1233)   at org.apache.hadoop.hbase.client.connectionmanager$hconnectionimplementation.locateregion(connectionmanager.java:1099)   at org.apache.hadoop.hbase.client.rpcretryingcallerwithreadreplicas.getregionlocations(rpcretryingcallerwithreadreplicas.java:279)   ... 31 more the cause for the above error is that the acl table contained in the image (w.r.t. hbase:meta table) doesn't have server address. jimmy xiang: what do you think would be proper fix ? ",
        "label": 242
    },
    {
        "text": "purge rollback support in store etc   rollback is no longer needed after \"hbase-15158 change order in which we do write pipeline operations; do all under row locks\". purge support. will simplify this segment work. ",
        "label": 314
    },
    {
        "text": "unable to grant user permission to namespace  in a secure cluster, i tried to grant user 'hrt_1' permission to namespace x hbase(main):002:0> grant 'hrt_1', 'w', '@x' error: no method 'grant' for arguments (org.apache.hadoop.hbase.protobuf.generated.accesscontrolprotos.accesscontrolservice.blockingstub,org.jruby.rubystring,org.jruby.java.proxies.arrayjavaproxy,org.jruby.java.proxies.arrayjavaproxy) on java::orgapachehadoophbaseprotobuf::protobufutil   available overloads:     (org.apache.hadoop.hbase.protobuf.generated.accesscontrolprotos.accesscontrolservice.blockinginterface,java.lang.string,java.lang.string,org.apache.hadoop.hbase.security.access.permission.action[])     (org.apache.hadoop.hbase.protobuf.generated.accesscontrolprotos.accesscontrolservice.blockinginterface,java.lang.string,org.apache.hadoop.hbase.tablename,byte[],byte[],org.apache.hadoop.hbase.security.access.permission.action[])     (org.apache.hadoop.hbase.protobuf.generated.accesscontrolprotos.accesscontrolservice.blockinginterface,java.lang.string,org.apache.hadoop.hbase.security.access.permission.action[]) here is some help for this command: grant users specific rights. syntax : grant <user> <permissions> [<table> [<column family> [<column qualifier>]] permissions is either zero or more letters from the set \"rwxca\". read('r'), write('w'), exec('x'), create('c'), admin('a') for example:     hbase> grant 'bobsmith', 'rwxca'     hbase> grant 'bobsmith', 'rw', 't1', 'f1', 'col1' ",
        "label": 441
    },
    {
        "text": "hbase broke checkandput with null value  the previous code called bytes.equal() which does a check for \"null\" on the left or right argument. now the comparator calls bytes.compareto() - which has no check for null. but this is a valid input and checks for existence. i actually noticed this running https://github.com/larsgeorge/hbase-book/blob/master/ch04/src/main/java/client/checkandputexample.java this used to work, now it throws an npe caused by: java.lang.nullpointerexception at org.apache.hadoop.hbase.util.bytes.compareto(bytes.java:854) at org.apache.hadoop.hbase.filter.writablebytearraycomparable.compareto(writablebytearraycomparable.java:63) at org.apache.hadoop.hbase.regionserver.hregion.checkandmutate(hregion.java:1681) at org.apache.hadoop.hbase.regionserver.hregionserver.checkandmutate(hregionserver.java:1693) ... 6 more at org.apache.hadoop.hbase.client.hconnectionmanager$hconnectionimplementation.getregionserverwithretries(hconnectionmanager.java:1026) at org.apache.hadoop.hbase.client.htable.checkandput(htable.java:750) at client.checkandputexample.main(checkandputexample.java:33) easy fixable, just needs to handle the null value before even calling comparator.compareto(). ",
        "label": 326
    },
    {
        "text": "processing a regionserver message   open  close  split  etc    and if we're carrying more than one message in payload  if exception  all messages that follow are dropped on floor  just saw this in pset cluster. marking blocker. we had an incidence of hbase-1344 on our 0.19.x era hbase cluster. the report from the regionserver was carrying at least two open messages. the first provoked the exception, the second open message was never processed. regionserver thought it had successfully opened region. master didn't know anything about it. ",
        "label": 314
    },
    {
        "text": "set region split size on table creation  right now the region size before a split is determined by a global configuration. it would be nice to configure tables independently of the global parameter. ",
        "label": 38
    },
    {
        "text": " rest  support multipart related instead of xml input output  xml is bulky and slow, but the only way currently supported for multi-column gets/puts/etc. we should add support for multipart/related encoded entity bodies since that will be all binary and presumably faster and more compact. ",
        "label": 38
    },
    {
        "text": "we don't put the port for hregionserver up into znode since new master  found by jd ",
        "label": 314
    },
    {
        "text": "region server incorrectly reports its own address as master's address  region server incorrectly reports its own address as master's address while announcing successful connection to master. example: ine-51 is a rs connecting to master at ine-60 2012-08-22 20:16:02,427 info org.apache.hadoop.hbase.regionserver.hregionserver: attempting connect to master server at ine-60.rfiserve.net,60000,1345680901361 2012-08-22 20:16:09,501 info org.apache.hadoop.hbase.regionserver.hregionserver: connected to master at ine-51.rfiserve.net/172.22.2.51:60020 bug is introduced by a typo, the variable isa is declared both as a field in class and local variable in the method printing this line. log.info(\"connected to master at \" + isa); ",
        "label": 417
    },
    {
        "text": "add a utility to reload configurations in region server  create a utility that can talk to the region servers and make them reload configurations on disk. ",
        "label": 181
    },
    {
        "text": "the shutdown regionserver could be added to assignmentmanager servers again  the folling steps can easily recreate the problem:  1. there's thousands of regions in the cluster.  2. stop the cluster.  3. start the cluster. killing one regionserver while the regions were opening. restarted it after 10 seconds. the shutted regionserver will appear in the assignmentmanager.servers list again. for example: issue 1: 2011-06-23 14:14:30,775 debug org.apache.hadoop.hbase.master.loadbalancer: server information: 167-6-1-12,20020,1308803390123=2220, 167-6-1-13,20020,1308803391742=2374, 167-6-1-11,20020,1308803386333=2205, 167-6-1-13,20020,1308803514394=2183 two regionservers(one of it had aborted) had the same hostname but different startcode:  167-6-1-13,20020,1308803391742=2374  167-6-1-13,20020,1308803514394=2183 issue 2: (1).the rs 167-6-1-11,20020,1308105402003 finished shutdown at \"10:46:37,774\":  10:46:37,774 info org.apache.hadoop.hbase.master.handler.servershutdownhandler: finished processing of shutdown of 167-6-1-11,20020,1308105402003 (2).overwriting happened, it seemed the rs was still exist in the set of assignmentmanager#regions:  10:45:55,081 warn org.apache.hadoop.hbase.master.assignmentmanager: overwriting 612342de1fe4733f72299d70addb6d11 on servername=167-6-1-11,20020,1308105402003, load=(requests=0, regions=0, usedheap=0, maxheap=0) (3).region was assigned to this dead rs again at \"10:50:20,671\":  10:50:20,671 debug org.apache.hadoop.hbase.master.assignmentmanager: assigning region jeason10,08058613800000030,1308032774777.612342de1fe4733f72299d70addb6d11. to 167-6-1-11,20020,1308105402003 ",
        "label": 240
    },
    {
        "text": "make mapreduce tests pass on hadoop2  hbase-7904 was a first attempt at making this work but it got lost in the weeds. this is a new attempt at making hbase mapreduce jobs run on hadoop2 (w/o breaking mapreduce on hadoop1) ",
        "label": 248
    },
    {
        "text": "regionserver graceful stop   decommissioning  right now, we have a weird way of node decommissioning / graceful stop, which is a graceful_stop.sh bash script, and a region_mover ruby script, and some draining server support which you have to manually write to a znode (really!). also draining servers is only partially supported in lb operations (lb does take that into account for roundrobin assignment, but not for normal balance)   see   http://hbase.apache.org/book/node.management.html and hbase-3071 i think we should support graceful stop as a first class citizen. thinking about it, it seems that the difference between regionserver stop and graceful stop is that regionserver stop will close the regions, but the master will only assign them after the znode is deleted. in the new master design (or even before), if we allow rs to be able to close regions on its own (without master initiating it), then graceful stop becomes regular stop. the rs already closes the regions cleanly, and will reject new region assignments, so that we don't need much of the balancer or draining server trickery. this ties into the new master/am redesign (hbase-5487), but still deserves it's own jira. let's use this to brainstorm on the design. ",
        "label": 234
    },
    {
        "text": "graceful decommissioning of a regionserver  currently if you stop a regionserver nicely, it'll put up its stopping flag and then close all hosted regions. while the stopping flag is in place all region requests are rejected. if this server was under load, closing could take a while. only after all is closed is the master informed and it'll restart assigning (in old master, master woud get a report with list of all regions closed, in new master the zk expired is triggered and we'll run shutdown handler). at least in new master, we have means of disabling balancer, and then moving the regions off the server one by one via hbaseadmin methods \u2013 we shoud write a script to do this at least for rolling restarts \u2013 but we need something better. ",
        "label": 314
    },
    {
        "text": "upload hbase jars to a public maven repository  there are many cool release of hadoop hbase and this project is an apache project, as the maven project. but the released jars must be download manually and then deploy to a private repository before they can be used by developer using maven2. please could you upload the hbase jars on the public maven2 repository ? of course, we can help to deploy those artifact if necessary. ",
        "label": 266
    },
    {
        "text": "hbase shell client 'scan table' operation is getting failed inbetween the when the regions are shifted from one region server to another region server  problem: hbase shell/client 'scan table' operation is getting failed inbetween the when the regions are shifted from one region server to another region server when the table regions data moved from one region server to another region server then the client/shell should be able to handle the data from the  new region server automatically (because when we have huge data in terms of gb/tb at that time one of the region server going down in the cluster is frequent) procedure: 1. setup non ha hadoop cluster with two nodes (node1-xx.xx.xx.xx,  node2-yy.yy.yy.yy) 2. install zookeeper, hmaster & hregionserver in node-1 3. install hregionserver in node-2 4. from node2 create hbase table ( table name 't1' with one column family 'cf1' ) 5. add around 367120 rows to the table 6. scan the table 't1' using hbase shell & at the same time switch the region server 1 & 2 (so that the table 't1' regions data are moved from region server 1 to 1 & vice versa) 7. during this time hbase shell is getting failed in between of the scan operation as below ...................................................................                                  row172266                        column=cf1:a, timestamp=1379680737307, value=100                                                row172267                        column=cf1:a, timestamp=1379680737311, value=100                                                row172268                        column=cf1:a, timestamp=1379680737314, value=100                                                row172269                        column=cf1:a, timestamp=1379680737317, value=100                                                row17227                         column=cf1:a, timestamp=1379679668631, value=100                                                row17227                         column=cf1:b, timestamp=1379681090560, value=200                                              error: java.lang.runtimeexception: org.apache.hadoop.hbase.client.retriesexhaustedexception: failed after attempts=7, exceptions: fri sep 20 18:20:58 ist 2013, org.apache.hadoop.hbase.client.scannercallable@1999dc4f, java.net.connectexception: connection refused fri sep 20 18:20:59 ist 2013, org.apache.hadoop.hbase.client.scannercallable@1999dc4f, org.apache.hadoop.hbase.ipc.hbaseclient$failedserverexception: this server is in the failed servers list: host-yy.yy.yy.yy/yy.yy.yy.yy:61020 fri sep 20 18:21:00 ist 2013, org.apache.hadoop.hbase.client.scannercallable@1999dc4f, java.net.connectexception: connection refused fri sep 20 18:21:01 ist 2013, org.apache.hadoop.hbase.client.scannercallable@1999dc4f, org.apache.hadoop.hbase.ipc.hbaseclient$failedserverexception: this server is in the failed servers list: host-yy.yy.yy.yy/yy.yy.yy.yy:61020 fri sep 20 18:21:07 ist 2013, org.apache.hadoop.hbase.client.scannercallable@1999dc4f, java.net.connectexception: connection refused fri sep 20 18:21:09 ist 2013, org.apache.hadoop.hbase.client.scannercallable@1999dc4f, java.net.connectexception: connection refused fri sep 20 18:21:17 ist 2013, org.apache.hadoop.hbase.client.scannercallable@1999dc4f, java.net.connectexception: connection refused hbase(main):014:0>  ",
        "label": 543
    },
    {
        "text": "testhlog doesn't clean up after itself  testhlog has been hanging during shutdown of the mini cluster after all tests are run. further investigation shows that there are many places where the testhlog tests are not cleaning up after themselves. necessary changes are: since all tests use hlog directly, a minihbasecluster is not needed. the test should only launch a minidfscluster several tests do not close the created hlog at completion the test class should shutdown the mini cluster in an @afterclass method ",
        "label": 180
    },
    {
        "text": "handle rs that fails while processing the failure of another one  hbase-2223 doesn't manage region servers that fail while doing the transfer of hlogs queues from other region servers that failed. devise a reliable way to do it. ",
        "label": 199
    },
    {
        "text": "improvements to the import flow  following improvements can be made to the import logic a) make the import extensible (i.e., remove the filter from being a static member of import and make it an instance variable of the mapper, make the mappers or variables of interest protected. ) b) make sure that the import calls filterrowkey method of the filter (useful if we want to filter the data of an organization based on the row key or using filters like prefixfilter which filter the data in filterrowkey method rather than the filterkeyvalue method). the existing test case in testimportexport#testwithfilter works with this assumption but is so far successful because there is only one row inserted into the table. c) provide an option to specify the durability during the import (specifying the durability as skip_wal would improve the performance of restore considerably.) [~lhofhansl] suggested that this should be a parameter to the import. d) some minor refactoring to avoid building a comma separated string for the filter args. ",
        "label": 464
    },
    {
        "text": "purge apache forrest from trunk  remove all of the apache-forrest dirs from trunk. we don't do apache-forrest any more. we use maven generating out site. ",
        "label": 314
    },
    {
        "text": "secure hbase builds fail  i saw the following in hbase-0.92-security build #39: [error] failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:2.0.2:testcompile (default-testcompile) on project hbase: compilation failure [error] <https://builds.apache.org/job/hbase-0.92-security/ws/trunk/src/test/java/org/apache/hadoop/hbase/regionserver/teststore.java>:[590,4] method does not override or implement a method from a supertype [error] -> [help 1] org.apache.maven.lifecycle.lifecycleexecutionexception: failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:2.0.2:testcompile (default-testcompile) on project hbase: compilation failure <https://builds.apache.org/job/hbase-0.92-security/ws/trunk/src/test/java/org/apache/hadoop/hbase/regionserver/teststore.java>:[590,4] method does not override or implement a method from a supertype the above was probably introduced by hbase-5006 ",
        "label": 314
    },
    {
        "text": "backport hbase to branch  the regionserver log is : 2019-12-04 11:32:37,238 info  [regionserver/localhost/0.0.0.0:16020-splits-0] regionserver.splitrequest: running rollback/cleanup of failed split of online:testtable,\\x00999999999\\x0014aa9,1575406565984.48f462e65b7961420737797c2ccf76c9.; failed localhost,16020,1574999150042-daughteropener=aad203e7b1aa26a26b50c84f70397456 java.io.ioexception: failed localhost,16020,1574999150042-daughteropener=aad203e7b1aa26a26b50c84f70397456         at org.apache.hadoop.hbase.regionserver.splittransactionimpl.opendaughters(splittransactionimpl.java:504)         at org.apache.hadoop.hbase.regionserver.splittransactionimpl.stepsafterponr(splittransactionimpl.java:598)         at org.apache.hadoop.hbase.regionserver.splittransactionimpl.execute(splittransactionimpl.java:581)         at org.apache.hadoop.hbase.regionserver.splitrequest.dosplitting(splitrequest.java:82)         at org.apache.hadoop.hbase.regionserver.splitrequest.run(splitrequest.java:153)         at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1142)         at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:617)         at java.lang.thread.run(thread.java:745) caused by: java.io.ioexception: java.io.ioexception: java.lang.nullpointerexception         at org.apache.hadoop.hbase.regionserver.hregion.initializestores(hregion.java:1041)         at org.apache.hadoop.hbase.regionserver.hregion.initializeregioninternals(hregion.java:916)         at org.apache.hadoop.hbase.regionserver.hregion.initialize(hregion.java:884)         at org.apache.hadoop.hbase.regionserver.hregion.openhregion(hregion.java:7098)         at org.apache.hadoop.hbase.regionserver.splittransactionimpl.opendaughterregion(splittransactionimpl.java:732)         at org.apache.hadoop.hbase.regionserver.splittransactionimpl$daughteropener.run(splittransactionimpl.java:712)        ... 1 more caused by: java.io.ioexception: java.lang.nullpointerexception         at org.apache.hadoop.hbase.regionserver.hstore.openstorefiles(hstore.java:577)         at org.apache.hadoop.hbase.regionserver.hstore.loadstorefiles(hstore.java:532)         at org.apache.hadoop.hbase.regionserver.hstore.<init>(hstore.java:281)         at org.apache.hadoop.hbase.regionserver.hregion.instantiatehstore(hregion.java:5469)         at org.apache.hadoop.hbase.regionserver.hregion$1.call(hregion.java:1015)         at org.apache.hadoop.hbase.regionserver.hregion$1.call(hregion.java:1012)         at java.util.concurrent.futuretask.run(futuretask.java:266)         at java.util.concurrent.executors$runnableadapter.call(executors.java:511)         at java.util.concurrent.futuretask.run(futuretask.java:266)         at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1142)         at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:617)         ... 1 more caused by: java.lang.nullpointerexception         at org.apache.hadoop.hbase.io.hfile.blockcacheutil.comparecacheblock(blockcacheutil.java:185)         at org.apache.hadoop.hbase.io.hfile.blockcacheutil.validateblockaddition(blockcacheutil.java:204)         at org.apache.hadoop.hbase.io.hfile.blockcacheutil.shouldreplaceexistingcacheblock(blockcacheutil.java:233)         at org.apache.hadoop.hbase.io.hfile.bucket.bucketcache.cacheblockwithwait(bucketcache.java:433)         at org.apache.hadoop.hbase.io.hfile.bucket.bucketcache.cacheblock(bucketcache.java:419)         at org.apache.hadoop.hbase.io.hfile.combinedblockcache.cacheblock(combinedblockcache.java:68)         at org.apache.hadoop.hbase.io.hfile.hfilereaderv2.readblock(hfilereaderv2.java:462)         at org.apache.hadoop.hbase.io.hfile.hfileblockindex$blockindexreader.loaddatablockwithscaninfo(hfileblockindex.java:269)         at org.apache.hadoop.hbase.io.hfile.hfilereaderv2$abstractscannerv2.seekto(hfilereaderv2.java:651)         at org.apache.hadoop.hbase.io.hfile.hfilereaderv2$abstractscannerv2.seekto(hfilereaderv2.java:601)         at org.apache.hadoop.hbase.io.halfstorefilereader$1.seekto(halfstorefilereader.java:190)         at org.apache.hadoop.hbase.io.halfstorefilereader.getfirstkey(halfstorefilereader.java:365)         at org.apache.hadoop.hbase.regionserver.storefile.open(storefile.java:546)         at org.apache.hadoop.hbase.regionserver.storefile.createreader(storefile.java:563)         at org.apache.hadoop.hbase.regionserver.storefile.createreader(storefile.java:553)         at org.apache.hadoop.hbase.regionserver.hstore.createstorefileandreader(hstore.java:707)         at org.apache.hadoop.hbase.regionserver.hstore.access$000(hstore.java:122)         at org.apache.hadoop.hbase.regionserver.hstore$1.call(hstore.java:552)         at org.apache.hadoop.hbase.regionserver.hstore$1.call(hstore.java:549)         ... 6 more 2019-12-04 11:32:37,288 warn  [regionserver/localhost/0.0.0.0:16020-splits-0] regionserver.splittransaction: should use rollback(server, regionserverservices, user) 2019-12-04 11:32:37,294 fatal [regionserver/localhost/0.0.0.0:16020-splits-0] regionserver.hregionserver: aborting region server localhost,16020,1574999150042: abort; we got an error after point-of-no-return     ",
        "label": 59
    },
    {
        "text": "cross site scripting  reflected in table jsp  minor issue where we write back table name in a few places. should clean it up:  } else {        out.write(\"\\n        <title>table: \");       out.print( fqtn );       out.write(\"</title>\\n    \");  }  ",
        "label": 393
    },
    {
        "text": "branch times out and is taking hours to complete  sean has been looking at tooling and infra. this umbrellas is about looking at actual tests. for example, running locally on dedicated machine i picked a random test, testpercolumnfamilyflush. in my test run, it wrote 16m lines. it seems to be having zk issues but it is catching interrupts and ignoring them ([~carp84] fixed this in later versions over in hbase-18441). let me try and do some fixup under this umbrella so we can get a 1.2.7 out the door. ",
        "label": 314
    },
    {
        "text": "zookeeper ensureparentexists calls fail on absolute path  if user specifies absolute path for one of the files in zookeeper, the following will not do what it's supposed to: if (!ensureznodeexists(parentznode)) {  ... because the user specified path is not a child of parentznode, all operations on it will fail. ",
        "label": 342
    },
    {
        "text": "hlog recovery is not performed after master failure  i have a local cluster running, and its logging to  <hbase>/log_x.x.x.x_1213228101021_60020/ then i kill both master and regionserver, and restart. looking through  the logs i don't see anything about trying to recover from this hlog,  it just creates a new hlog alongside the existing one (with a new  startcode). the older hlog seems to be ignored, and the tables  created in the inital session are all gone. ",
        "label": 229
    },
    {
        "text": "there is data loss when master failovers  it goes like this: master crashed , at the same time rs with meta is crashing, but rs doesn't eixt.  master startups again and finds all living rs.   master verifies the meta failed, because this rs is crashing.  master reassigns the meta, but it doesn't split the hlog. so some meta data is loss. about the logs of a failover test case fail. //it said that we want to kill a rs 2011-09-28 19:54:45,694 info [thread-988] regionserver.hregionserver(1443): stopped: killing for unit test  2011-09-28 19:54:45,694 info [thread-988] master.testmasterfailover(1007): rs 192.168.2.102,54385,1317264874629 killed //rs didn't crash.   2011-09-28 19:54:51,763 info [master:0;192.168.2.102,54557,1317264885720] master.hmaster(458): registering server found up in zk: 192.168.2.102,54385,1317264874629  2011-09-28 19:54:51,763 info [master:0;192.168.2.102,54557,1317264885720] master.servermanager(232): registering server=192.168.2.102,54385,1317264874629  2011-09-28 19:54:51,770 debug [master:0;192.168.2.102,54557,1317264885720] zookeeper.zkutil(491): master:54557-0x132b31adbb30005 unable to get data of znode /hbase/unassigned/1028785192 because node does not exist (not an error)  2011-09-28 19:54:51,771 debug [master:0;192.168.2.102,54557,1317264885720] zookeeper.zkutil(1003): master:54557-0x132b31adbb30005 retrieved 33 byte(s) of data from znode /hbase/root-region-server and set watcher; 192.168.2.102,54383,131726487... //meta verification failed and ressigned the meta. so all the regions in the meta is loss. 2011-09-28 19:54:51,773 info [master:0;192.168.2.102,54557,1317264885720] catalog.catalogtracker(476): failed verification of .meta.,,1 at address=192.168.2.102,54385,1317264874629; org.apache.hadoop.hbase.regionserver.regionserverstoppedexception: org.apache.hadoop.hbase.regionserver.regionserverstoppedexception: server 192.168.2.102,54385,1317264874629 not running, aborting  2011-09-28 19:54:51,773 debug [master:0;192.168.2.102,54557,1317264885720] catalog.catalogtracker(316): new .meta. server: 192.168.2.102,54385,1317264874629 isn't valid. cached .meta. server: null  2011-09-28 19:54:52,274 debug [master:0;192.168.2.102,54557,1317264885720] zookeeper.zkutil(1003): master:54557-0x132b31adbb30005 retrieved 33 byte(s) of data from znode /hbase/root-region-server and set watcher; 192.168.2.102,54383,131726487...  2011-09-28 19:54:52,277 info [master:0;192.168.2.102,54557,1317264885720] catalog.catalogtracker(476): failed verification of .meta.,,1 at address=192.168.2.102,54385,1317264874629; org.apache.hadoop.hbase.regionserver.regionserverstoppedexception: org.apache.hadoop.hbase.regionserver.regionserverstoppedexception: server 192.168.2.102,54385,1317264874629 not running, aborting  2011-09-28 19:54:52,277 debug [master:0;192.168.2.102,54557,1317264885720] catalog.catalogtracker(316): new .meta. server: 192.168.2.102,54385,1317264874629 isn't valid. cached .meta. server: null  2011-09-28 19:54:52,778 debug [master:0;192.168.2.102,54557,1317264885720] zookeeper.zkutil(1003): master:54557-0x132b31adbb30005 retrieved 33 byte(s) of data from znode /hbase/root-region-server and set watcher; 192.168.2.102,54383,131726487...  2011-09-28 19:54:52,782 info [master:0;192.168.2.102,54557,1317264885720] catalog.catalogtracker(476): failed verification of .meta.,,1 at address=192.168.2.102,54385,1317264874629; org.apache.hadoop.hbase.regionserver.regionserverstoppedexception: org.apache.hadoop.hbase.regionserver.regionserverstoppedexception: server 192.168.2.102,54385,1317264874629 not running, aborting  2011-09-28 19:54:52,782 debug [master:0;192.168.2.102,54557,1317264885720] catalog.catalogtracker(316): new .meta. server: 192.168.2.102,54385,1317264874629 isn't valid. cached .meta. server: null  2011-09-28 19:54:52,782 debug [master:0;192.168.2.102,54557,1317264885720] zookeeper.zkassign(264): master:54557-0x132b31adbb30005 creating (or updating) unassigned node for 1028785192 with offline state  2011-09-28 19:54:52,825 debug [thread-988-eventthread] zookeeper.zookeeperwatcher(233): master:54557-0x132b31adbb30005 received zookeeper event, type=nodecreated, state=syncconnected, path=/hbase/unassigned/1028785192 //it said that master clean the cluster.  2011-09-28 19:54:52,889 info [master:0;192.168.2.102,54557,1317264885720] master.assignmentmanager(383): clean cluster startup. assigning userregions  2011-09-28 19:54:52,889 debug [master:0;192.168.2.102,54557,1317264885720] zookeeper.zkassign(494): master:54557-0x132b31adbb30005 deleting any existing unassigned nodes ",
        "label": 314
    },
    {
        "text": "add testing of hbck  fix  hbase-3337 adds a new method of hbck -fix'ing unassignment and dupe assignment. we should add a unit test which verifies this detects and repairs correctly. ",
        "label": 248
    },
    {
        "text": "nullpointerexception is thrown when root and meta table regions are assigning to another rs   lets suppose we have two region servers rs1 and rs2.  if region server (rs1) having root and meta regions went down, master will assign them to another region server rs2. at that time recieved nullpointerexception. 2012-05-04 20:19:52,912 debug org.apache.hadoop.hbase.client.hconnectionmanager$hconnectionimplementation: looked up root region location, connection=org.apache.hadoop.hbase.client.hconnectionmanager$hconnectionimplementation@25de152f; servername= 2012-05-04 20:19:52,914 debug org.apache.hadoop.hbase.client.hconnectionmanager$hconnectionimplementation: looked up root region location, connection=org.apache.hadoop.hbase.client.hconnectionmanager$hconnectionimplementation@25de152f; servername= 2012-05-04 20:19:52,916 warn org.apache.hadoop.hbase.regionserver.handler.openregionhandler: exception running postopendeploytasks; region=1028785192 java.lang.nullpointerexception at org.apache.hadoop.hbase.client.hconnectionmanager$hconnectionimplementation.processbatchcallback(hconnectionmanager.java:1483) at org.apache.hadoop.hbase.client.hconnectionmanager$hconnectionimplementation.processbatch(hconnectionmanager.java:1367) at org.apache.hadoop.hbase.client.htable.flushcommits(htable.java:945) at org.apache.hadoop.hbase.client.htable.doput(htable.java:801) at org.apache.hadoop.hbase.client.htable.put(htable.java:776) at org.apache.hadoop.hbase.catalog.metaeditor.put(metaeditor.java:98) at org.apache.hadoop.hbase.catalog.metaeditor.puttocatalogtable(metaeditor.java:88) at org.apache.hadoop.hbase.catalog.metaeditor.updatelocation(metaeditor.java:259) at org.apache.hadoop.hbase.catalog.metaeditor.updatemetalocation(metaeditor.java:221) at org.apache.hadoop.hbase.regionserver.hregionserver.postopendeploytasks(hregionserver.java:1625) at org.apache.hadoop.hbase.regionserver.handler.openregionhandler$postopendeploytasksthread.run(openregionhandler.java:241) 2012-05-04 20:19:52,920 debug org.apache.hadoop.hbase.regionserver.hregion: closing .meta.,,1.1028785192: disabling compactions & flushes 2012-05-04 20:19:52,920 debug org.apache.hadoop.hbase.regionserver.hregion: updates disabled for region .meta.,,1.1028785192 ",
        "label": 544
    },
    {
        "text": " outdated  references to svn trunk in documentation  looking at https://svn.apache.org/repos/asf/hbase/tags/ svn is no longer seems to be updated. is http://hbase.apache.org/ being built from git? https://issues.apache.org/jira/browse/infra-7768 is also being discussed. can those updated to master (or removed)? thanks ",
        "label": 177
    },
    {
        "text": "filter singlecolumnvaluefilter combined with nullcomparator does not work  i want to filter out from the scan the rows that does not have a specific column qualifier. for this purpose i use the filter singlecolumnvaluefilter combined with the nullcomparator.  but every time i use this in a scan, i get the following exception: java.lang.runtimeexception: org.apache.hadoop.hbase.donotretryioexception: failed after retry of outoforderscannernextexception: was there a rpc timeout?     at org.apache.hadoop.hbase.client.abstractclientscanner$1.hasnext(abstractclientscanner.java:47)     at com.xxx.xxx.test.hbaseregression.nullcomparator(hbaseregression.java:92)     at sun.reflect.nativemethodaccessorimpl.invoke0(native method)     at sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:57)     at sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43)     at java.lang.reflect.method.invoke(method.java:606)     at org.junit.runners.model.frameworkmethod$1.runreflectivecall(frameworkmethod.java:44)     at org.junit.internal.runners.model.reflectivecallable.run(reflectivecallable.java:15)     at org.junit.runners.model.frameworkmethod.invokeexplosively(frameworkmethod.java:41)     at org.junit.internal.runners.statements.invokemethod.evaluate(invokemethod.java:20)     at org.junit.internal.runners.statements.runbefores.evaluate(runbefores.java:28)     at org.junit.runners.blockjunit4classrunner.runnotignored(blockjunit4classrunner.java:79)     at org.junit.runners.blockjunit4classrunner.runchild(blockjunit4classrunner.java:71)     at org.junit.runners.blockjunit4classrunner.runchild(blockjunit4classrunner.java:49)     at org.junit.runners.parentrunner$3.run(parentrunner.java:193)     at org.junit.runners.parentrunner$1.schedule(parentrunner.java:52)     at org.junit.runners.parentrunner.runchildren(parentrunner.java:191)     at org.junit.runners.parentrunner.access$000(parentrunner.java:42)     at org.junit.runners.parentrunner$2.evaluate(parentrunner.java:184)     at org.junit.runners.parentrunner.run(parentrunner.java:236)     at org.eclipse.jdt.internal.junit4.runner.junit4testreference.run(junit4testreference.java:50)     at org.eclipse.jdt.internal.junit.runner.testexecution.run(testexecution.java:38)     at org.eclipse.jdt.internal.junit.runner.remotetestrunner.runtests(remotetestrunner.java:467)     at org.eclipse.jdt.internal.junit.runner.remotetestrunner.runtests(remotetestrunner.java:683)     at org.eclipse.jdt.internal.junit.runner.remotetestrunner.run(remotetestrunner.java:390)     at org.eclipse.jdt.internal.junit.runner.remotetestrunner.main(remotetestrunner.java:197) caused by: org.apache.hadoop.hbase.donotretryioexception: failed after retry of outoforderscannernextexception: was there a rpc timeout?     at org.apache.hadoop.hbase.client.clientscanner.next(clientscanner.java:391)     at org.apache.hadoop.hbase.client.abstractclientscanner$1.hasnext(abstractclientscanner.java:44)     ... 25 more caused by: org.apache.hadoop.hbase.exceptions.outoforderscannernextexception: org.apache.hadoop.hbase.exceptions.outoforderscannernextexception: expected nextcallseq: 1 but the nextcallseq got from client: 0; request=scanner_id: 7998309028985532303 number_of_rows: 100 close_scanner: false next_call_seq: 0     at org.apache.hadoop.hbase.regionserver.hregionserver.scan(hregionserver.java:3011)     at org.apache.hadoop.hbase.protobuf.generated.clientprotos$clientservice$2.callblockingmethod(clientprotos.java:26929)     at org.apache.hadoop.hbase.ipc.rpcserver.call(rpcserver.java:2175)     at org.apache.hadoop.hbase.ipc.rpcserver$handler.run(rpcserver.java:1879)     at sun.reflect.nativeconstructoraccessorimpl.newinstance0(native method)     at sun.reflect.nativeconstructoraccessorimpl.newinstance(nativeconstructoraccessorimpl.java:57)     at sun.reflect.delegatingconstructoraccessorimpl.newinstance(delegatingconstructoraccessorimpl.java:45)     at java.lang.reflect.constructor.newinstance(constructor.java:526)     at org.apache.hadoop.ipc.remoteexception.instantiateexception(remoteexception.java:106)     at org.apache.hadoop.ipc.remoteexception.unwrapremoteexception(remoteexception.java:95)     at org.apache.hadoop.hbase.protobuf.protobufutil.getremoteexception(protobufutil.java:277)     at org.apache.hadoop.hbase.client.scannercallable.call(scannercallable.java:198)     at org.apache.hadoop.hbase.client.scannercallable.call(scannercallable.java:57)     at org.apache.hadoop.hbase.client.rpcretryingcaller.callwithretries(rpcretryingcaller.java:120)     at org.apache.hadoop.hbase.client.rpcretryingcaller.callwithretries(rpcretryingcaller.java:96)     at org.apache.hadoop.hbase.client.clientscanner.next(clientscanner.java:343)     ... 26 more caused by: org.apache.hadoop.hbase.ipc.remotewithextrasexception(org.apache.hadoop.hbase.exceptions.outoforderscannernextexception): org.apache.hadoop.hbase.exceptions.outoforderscannernextexception: expected nextcallseq: 1 but the nextcallseq got from client: 0; request=scanner_id: 7998309028985532303 number_of_rows: 100 close_scanner: false next_call_seq: 0     at org.apache.hadoop.hbase.regionserver.hregionserver.scan(hregionserver.java:3011)     at org.apache.hadoop.hbase.protobuf.generated.clientprotos$clientservice$2.callblockingmethod(clientprotos.java:26929)     at org.apache.hadoop.hbase.ipc.rpcserver.call(rpcserver.java:2175)     at org.apache.hadoop.hbase.ipc.rpcserver$handler.run(rpcserver.java:1879)     at org.apache.hadoop.hbase.ipc.rpcclient.call(rpcclient.java:1449)     at org.apache.hadoop.hbase.ipc.rpcclient.callblockingmethod(rpcclient.java:1653)     at org.apache.hadoop.hbase.ipc.rpcclient$blockingrpcchannelimplementation.callblockingmethod(rpcclient.java:1711)     at org.apache.hadoop.hbase.protobuf.generated.clientprotos$clientservice$blockingstub.scan(clientprotos.java:27332)     at org.apache.hadoop.hbase.client.scannercallable.call(scannercallable.java:168)     ... 30 more it seems like there is a regression. i was previously using hbase 0.92 and this was working well. you can find in attachement a test case reproducing the issue. ",
        "label": 168
    },
    {
        "text": "truncate and preserve region boundaries option  a tool that would be useful for testing (and maybe in prod too) would be a truncate option to keep the current region boundaries. right now what you have to do is completely kill the table and recreate it with the correct regions. ",
        "label": 275
    },
    {
        "text": "hlogsplitter renaming recovered edits and cj removing the parent directory race  making the hbck think cluster is inconsistent   the scenario is like this  -> a region is getting splitted.  -> the master is still not processed the split .  -> region server goes down.  -> split log manager starts splitting the logs and creates the recovered.edits in the splitlog path.  -> cj starts and deletes the entry from meta and also just completes the deletion of the region dir.  -> in hlogsplitter on final step we rename the recovered.edits to come under the regiondir.  there if the regiondir doesnot exist we tend to create and then add the recovered.edits. because of this hbck thinks it to be an orphan region because we have the regiondir but with no regioninfo.  ideally cluster is fine but we it is misleading.         } else {           path dstdir = dst.getparent();           if (!fs.exists(dstdir)) {             if (!fs.mkdirs(dstdir)) log.warn(\"mkdir failed on \" + dstdir);           }         }         fs.rename(src, dst);         log.debug(\" moved \" + src + \" => \" + dst);       } else {         log.debug(\"could not move recovered edits from \" + src +             \" as it doesn't exist\");       }     }     archivelogs(null, corruptedlogs, processedlogs,         oldlogdir, fs, conf); ",
        "label": 544
    },
    {
        "text": "compaction creates empty hfile  then selects this file for compaction and creates empty hfile and over again  (1) select hfile for compaction 2014-01-16 01:01:25,111 info org.apache.hadoop.hbase.regionserver.compactions.compactselection: deleting the expired store file by compaction: hdfs://dump002002.cm6:9000/hbase-0.90/storagetable/7d8941661904fb99a41f79a1fce47767/a/f3e38d10d579420494079e17a2557f0b whose maxtimestamp is -1 while the max expired timestamp is 1389632485111 (2) compact 2014-01-16 01:01:26,042 debug org.apache.hadoop.hbase.regionserver.compactor: compacting hdfs://dump002002.cm6:9000/hbase-0.90/storagetable/7d8941661904fb99a41f79a1fce47767/a/f3e38d10d579420494079e17a2557f0b, keycount=0, bloomtype=none, size=534, encoding=none 2014-01-16 01:01:26,045 debug org.apache.hadoop.hbase.util.fsutils: creating file=hdfs://dump002002.cm6:9000/hbase-0.90/storagetable/7d8941661904fb99a41f79a1fce47767/.tmp/40de5d79f80e4fb197e409fb99ab0fd8 with permission=rwxrwxrwx 2014-01-16 01:01:26,076 info org.apache.hadoop.hbase.regionserver.store: renaming compacted file at hdfs://dump002002.cm6:9000/hbase-0.90/storagetable/7d8941661904fb99a41f79a1fce47767/.tmp/40de5d79f80e4fb197e409fb99ab0fd8 to hdfs://dump002002.cm6:9000/hbase-0.90/storagetable/7d8941661904fb99a41f79a1fce47767/a/40de5d79f80e4fb197e409fb99ab0fd8 2014-01-16 01:01:26,142 info org.apache.hadoop.hbase.regionserver.store: completed compaction of 1 file(s) in a of storagetable,01:,1369377609136.7d8941661904fb99a41f79a1fce47767. into 40de5d79f80e4fb197e409fb99ab0fd8, size=534; total size for store is 399.0 m 2014-01-16 01:01:26,142 info org.apache.hadoop.hbase.regionserver.compactions.compactionrequest: completed compaction: regionname=storagetable,01:,1369377609136.7d8941661904fb99a41f79a1fce47767., storename=a, filecount=1, filesize=534, priority=16, time=18280340606333745; duration=0sec (3) select hfile for compaction 2014-01-16 03:48:05,120 info org.apache.hadoop.hbase.regionserver.compactions.compactselection: deleting the expired store file by compaction: hdfs://dump002002.cm6:9000/hbase-0.90/storagetable/7d8941661904fb99a41f79a1fce47767/a/40de5d79f80e4fb197e409fb99ab0fd8 whose maxtimestamp is -1 while the max expired timestamp is 1389642485120 (4) compact 2014-01-16 03:50:17,731 debug org.apache.hadoop.hbase.regionserver.compactor: compacting hdfs://dump002002.cm6:9000/hbase-0.90/storagetable/7d8941661904fb99a41f79a1fce47767/a/40de5d79f80e4fb197e409fb99ab0fd8, keycount=0, bloomtype=none, size=534, encoding=none 2014-01-16 03:50:17,732 debug org.apache.hadoop.hbase.util.fsutils: creating file=hdfs://dump002002.cm6:9000/hbase-0.90 ...   this loop for ever. ",
        "label": 292
    },
    {
        "text": "add documentation for hbase  add documentation for min versions to the hbase book.  i'll add patch soon. ",
        "label": 286
    },
    {
        "text": "improve client scanner interface  the current client scanner interface is pretty ugly. you need to instantiate an hstorekey and sortedmap<text, byte[]> externally and then pass them into next. this is pretty bad, because for starters, the client has to choose the implementation of the map when they create it, so it's extra brain cycles to figure that out. hstorekey doesn't show up anywhere else in the entire client side api, but here it bubbles out of next as a way to get the row and presumably the timestamp of the columns. i propose that we supplant hscannerinterface with scanner, an easier-to-use version for clients. its next method would look something like: public rowresult next() throws ioexception; this packs the data up much more cleanly, including using cells as values instead of raw byte[], meaning you have much more granular timestamp information. you also don't need hstorekey anymore. by breaking scanner away from hscannerinterface, we can leave the internal scanning code completely alone (keep using hstorekeys and such) but make the client cleaner. ",
        "label": 86
    },
    {
        "text": "broken build  testgetrowversions testgetrowmultipleversions  hudson is broke. ",
        "label": 314
    },
    {
        "text": "release  ",
        "label": 149
    },
    {
        "text": "need to be able to rolling restart hbase  once a hbase install goes live, unless you can take the readers offline, you cannot stop and start the cluster to issue config changes, and other generalized changes. we need to do a rolling restart. my own experiments confirmed that: restarting a regionserver works, you lose access to those regions, but comes back when that regionserver restarts moments later. maybe there should be a 'reassign these regions because i am going to shut down' flag/code/command. restarting .meta. regionserver just does not work. the master becomes confused. i have seen it reassign the .meta. but not update root, now no one knows where it is, and the root/meta scanners in the master just get hung. cant restart master yet, need multi-master election via zk to make this happen. this is a combo bug/feature request. ",
        "label": 314
    },
    {
        "text": "importer for exported tables  once hbase tables are backed up to a well known location, we need to be able to import them. a few flavors need to be supported here:  1. running cluster or a cluster that is not up and running  2. same tablename or a different one ",
        "label": 268
    },
    {
        "text": "upgrading guava broke hadoop profile  after hbase-17908 upgrade guava, we have failures with the hadoop-3.0 profile. [info] --- maven-enforcer-plugin:1.4.1:enforce (banned-jsr305) @ hbase-client --- [warning] rule 0: org.apache.maven.plugins.enforcer.banneddependencies failed with message: we don't allow the jsr305 jar from the findbugs project, see hbase-16321. found banned dependency: com.google.code.findbugs:jsr305:jar:1.3.9 use 'mvn dependency:tree' to locate the source of the banned dependencies. [info] --- maven-dependency-plugin:2.10:tree (default-cli) @ hbase-client --- [info] org.apache.hbase:hbase-client:jar:2.0.0-alpha-2-snapshot [info] +- org.apache.hadoop:hadoop-auth:jar:3.0.0-alpha4:compile [info] |  +- org.apache.httpcomponents:httpclient:jar:4.5.3:compile [info] |  |  \\- org.apache.httpcomponents:httpcore:jar:4.4.6:compile [info] |  +- com.nimbusds:nimbus-jose-jwt:jar:3.9:compile [info] |  |  +- net.jcip:jcip-annotations:jar:1.0:compile [info] |  |  \\- net.minidev:json-smart:jar:1.1.1:compile [info] |  +- org.apache.kerby:kerb-simplekdc:jar:1.0.0-rc2:compile [info] |  |  +- org.apache.kerby:kerby-config:jar:1.0.0-rc2:compile [info] |  |  +- org.apache.kerby:kerb-core:jar:1.0.0-rc2:compile [info] |  |  |  +- org.apache.kerby:kerby-asn1:jar:1.0.0-rc2:compile [info] |  |  |  \\- org.apache.kerby:kerby-pkix:jar:1.0.0-rc2:compile [info] |  |  |     \\- org.apache.kerby:kerby-util:jar:1.0.0-rc2:compile [info] |  |  +- org.apache.kerby:kerb-client:jar:1.0.0-rc2:compile [info] |  |  |  \\- org.apache.kerby:kerb-common:jar:1.0.0-rc2:compile [info] |  |  +- org.apache.kerby:kerb-util:jar:1.0.0-rc2:compile [info] |  |  |  \\- org.apache.kerby:kerb-crypto:jar:1.0.0-rc2:compile [info] |  |  +- org.apache.kerby:kerb-server:jar:1.0.0-rc2:compile [info] |  |  |  \\- org.apache.kerby:kerb-identity:jar:1.0.0-rc2:compile [info] |  |  \\- org.apache.kerby:kerb-admin:jar:1.0.0-rc2:compile [info] |  \\- com.google.guava:guava:jar:11.0.2:compile [info] |     \\- com.google.code.findbugs:jsr305:jar:1.3.9:compile ",
        "label": 320
    },
    {
        "text": "need programmatic way to add column family  need programmatic way to enable disable table  from hadoop-2292: > what you might do is open a htable on the meta region (hconstants.meta_table_name) and scan hconstants.col_regioninfo_array which will give you back hregioninfo objects (as bytes).  > find the table in question by comparing your table name to regioninfo.gettabledesc().getname()  > if adding or deleting columns, check regioninfo.gettabledesc().hasfamily()  > if changing table on/off line check regioninfo.isoffline()  > if any of the regions don't meet the criteria, close the scanner, sleep and rescan. this is a bit too complicated for me. if you won't make enabletable/disabletable synchronous, we should at least have a htable.istabledisabled method. ",
        "label": 241
    },
    {
        "text": "add cp hooks in regionobserver for in memory compaction  this is a hole in our cp hooks. ",
        "label": 149
    },
    {
        "text": "all jsp pages don't clean their hba  noticed by dave latham, refreshing the zk web page will eventually make that machine run out of connections with zk. it's because we don't close the connection created inside hba. ",
        "label": 229
    },
    {
        "text": "make observercontext an interface and remove private testing methods  observercontext is ia.limitedprivate because cp implementations want getenvironment(), bypass(), etc.  we can split interface and implementations (suggested by [~apache9]). ",
        "label": 48
    },
    {
        "text": "hmaster sometimes hangs during initialization due to missing notify call  during hmaster.finishinitialization(), assignrootandmeta() is called, which at some point does: this.assignmentmanager.waitforassignment(hregioninfo.first_meta_regioninfo); and waitforassignment does this:     synchronized(regions) {       while(!regions.containskey(regioninfo)) {         regions.wait();       }     } however, i could not find any call to regions.notify(), so this could wait forever. i have not noticed this problem on a real cluster, only when using hbasetestingutility on a slow and low-memory hudson server (i can reproduce it on my local machine by creating some background load). adding a notify() call when regions.put() is called seems to fix the problem. will attach patch. for reference, this was based on seeing the following from jstack: \"master:0;lat:44776\" prio=10 tid=0x08d5b400 nid=0x381a in object.wait() [0x9c76d000]    java.lang.thread.state: waiting (on object monitor)         at java.lang.object.wait(native method)         - waiting on <0xa5196fb8> (a java.util.treemap)         at java.lang.object.wait(object.java:485)         at org.apache.hadoop.hbase.master.assignmentmanager.waitforassignment(assignmentmanager.java:1152)         - locked <0xa5196fb8> (a java.util.treemap)         at org.apache.hadoop.hbase.master.hmaster.assignrootandmeta(hmaster.java:440)         at org.apache.hadoop.hbase.master.hmaster.finishinitialization(hmaster.java:382)         at org.apache.hadoop.hbase.master.hmaster.run(hmaster.java:277)         at java.lang.thread.run(thread.java:619) ",
        "label": 83
    },
    {
        "text": "superusers does not consider the keytab credentials  after hbase-13755 the superuser we add by default (the process running hbase) does not take in consideration the keytab credential. we have an env with the process user being hbase and the keytab being hbasefoo.  from superusers trace i see, the hbase being picked up trace superusers: current user name is hbase from the rs audit i see the hbasefoo making requests \"allowed\":true,\"servicename\":\"hbase-1\",\"username\":\"hbasefoo... looking at the code in hregionserver we do public hregionserver(configuration conf, coordinatedstatemanager csm)       throws ioexception {    ...     this.userprovider = userprovider.instantiate(conf);     superusers.initialize(conf);    ..    // login the server principal (if using secure hadoop)     login(userprovider, hostname);   .. before hbase-13755 we were initializing the super user in the acl coprocessor, so after the login. but now we do that before the login. i'm not sure if we can just move the superuser.initialize() after the login mikhail antonov? ",
        "label": 309
    },
    {
        "text": "client api for determining if server side supports cell level security  add a client api for determining if the server side supports cell level security. ask the master, assuming as we do in many other instances that the master and regionservers all have a consistent view of site configuration. return true if all features required for cell level security are present, false otherwise, or throw unsupportedoperationexception if the master does not have support for the rpc call. ",
        "label": 38
    },
    {
        "text": "master should display currently unassigned regions in ui  the master often knows that a region is unassigned, but thinks it's getting assigned. it would be very useful to display the current set of unassigned regions in the ui, as well as their current state (eg where it's supposed to be getting assigned, how long ago it last heard from it, etc). this would be useful in debugging/diagnosing cluster issues (eg i just noticed that a client had hung, took me a while to figure out that i had a region that was repeatedly failing to open with an npe due to hbase-2729) ",
        "label": 453
    },
    {
        "text": "race between regionopenedhandler and assignmentmanager  when the master is processing a zk event for region_opened, it calls delete() on the znode before it removes the node from regionsintransition. if the notification of that delete comes back into assignmentmanager before the region is removed from rit, you see an error like: 2011-08-30 17:43:29,537 warn [main-eventthread] master.assignmentmanager(861): node deleted but still in rit: .meta.,,1.1028785192 state=open, ts=1314751409532, server=todd-w510,55655,1314751396840 not certain if it causes issues, but it's a concerning log message. ",
        "label": 544
    },
    {
        "text": "optimise the time spent holding the updatelock under log roll  log roll entails syncing the old log, closing it and creating a new log file. we currently do all the 3 steps while holding the updatelock. this causes latency spikes for puts during this time. we only need to sync the old log under the lock. creating the new file, can be done before grabbing the lock. closing the old file can be done after we release the lock. ",
        "label": 34
    },
    {
        "text": "abstract wal splitting from zk  hm side: splitlogmanager rs side: splitlogworker hlogsplitter and a few handler classes. this jira may need to be split further apart into smaller ones. ",
        "label": 407
    },
    {
        "text": "ipcutil produces a lot of warn log spew  i was running some integration tests on trunk and noticed that it log (which uses loadtesttool with 16k records) is overflowing with this: 13/03/21 23:02:15 warn ipc.ipcutil: buffer grew from 16384 to 16971 13/03/21 23:02:15 warn ipc.ipcutil: buffer grew from 16384 to 18906 13/03/21 23:02:15 warn ipc.ipcutil: buffer grew from 16384 to 18486 13/03/21 23:02:15 warn ipc.ipcutil: buffer grew from 16384 to 22896 13/03/21 23:02:15 warn ipc.ipcutil: buffer grew from 16384 to 22253 so much in fact, that reznor-mbp:stripe sergey$ grep -a -c \"buffer grew\" it.log  2769498 reznor-mbp:stripe sergey$ grep -a -v \"buffer grew\" it.log > it2.log reznor-mbp:stripe sergey$ ll it* -rw-r--r--  1 sergey  staff  189440541 mar 22 11:22 it.log -rw-r--r--  1 sergey  staff    1114677 mar 22 11:33 it2.log there are two questions.  1) should this log be trace level, or there at all? it happens a lot.  2) is this condition normal? i am assuming the log level was set to warn for a reason ",
        "label": 314
    },
    {
        "text": "change foreignexception receive string  fe  to only be  receive fe   this was suggested but not completely finished before hbase-7206 got committed. this finishes the job. ",
        "label": 248
    },
    {
        "text": "port hbase 'auto detect data block encoding in hfileoutputformat' to    this issue is to backport auto detection of data block encoding in hfileoutputformat to 0.94 and 0.96 branches. ",
        "label": 269
    },
    {
        "text": " fb  print the detail exceptions info from the retriesexhaustedexception  the hbase client only prints the name of exception for the retriesexhaustedexception logging purpose, which failed to provide any useful debug information. so this jira is to enhance the logging to print the entire stack track of the exception to help on issue investigation. ",
        "label": 371
    },
    {
        "text": "make hbase works with jdk1  jdk1.7 is out for a while. hbase should support it. ",
        "label": 242
    },
    {
        "text": "test to check replication log znodes move is done correctly  replicationzookeeper#copyqueuesfromrsusingmulti moves the znodes under a regionserver failover environment. this jira is to add that the move is done correctly. ",
        "label": 199
    },
    {
        "text": " hbck  fix should be able to fill info regioninfo if matching region in fs  on mozilla cluster, hbck reported empty info:regioninfo but then also that there were regions in fs that were not deployed. at least one of these regions w/ an empty info:regioninfo matches to the region in fs that is not in the .meta. hbck should be able to pick up the region from ms and fix the .meta. entry on --fix. version: 0.90.1-cdh3u0 ................................................... number of tables: 14 number of live region servers: 29 number of dead region servers: 27 ..number of empty regioninfo_qualifier rows in .meta.: 10 error: region hdfs://hp-admin01.phx1.mozilla.com:8020/hbase/crash_reports/10111f37472811e5e86534790bb10e3c on hdfs, b ut not listed in meta or deployed on any region server. error: region hdfs://hp-admin01.phx1.mozilla.com:8020/hbase/crash_reports/1bcaf00897a749ea6a0d0bf1ce709116 on hdfs, b ut not listed in meta or deployed on any region server. error: region hdfs://hp-admin01.phx1.mozilla.com:8020/hbase/crash_reports/375913d5c0f5ed4180c0d4506c53fd1d on hdfs, b ut not listed in meta or deployed on any region server. error: region hdfs://hp-admin01.phx1.mozilla.com:8020/hbase/crash_reports/5a1fa81ddf4bac6c7f6483d803d5cc30 on hdfs, b ut not listed in meta or deployed on any region server. error: region hdfs://hp-admin01.phx1.mozilla.com:8020/hbase/crash_reports/6240f00ac370c186e44d189d0a52c8e7 on hdfs, b ut not listed in meta or deployed on any region server. error: region hdfs://hp-admin01.phx1.mozilla.com:8020/hbase/crash_reports/6bd89ea69b8a4886fed3dfe93ab5e5aa on hdfs, b ut not listed in meta or deployed on any region server. error: region hdfs://hp-admin01.phx1.mozilla.com:8020/hbase/crash_reports/716695118671df66d9d1b883f1aeae56 on hdfs, b ut not listed in meta or deployed on any region server. error: region hdfs://hp-admin01.phx1.mozilla.com:8020/hbase/crash_reports/805ce44ef7e6aa7fa1603c422f808a3a on hdfs, b ut not listed in meta or deployed on any region server. error: region hdfs://hp-admin01.phx1.mozilla.com:8020/hbase/crash_reports/8ed41d06b2c8e937cf460ce5e41ecbf9 on hdfs, b ut not listed in meta or deployed on any region server. error: region hdfs://hp-admin01.phx1.mozilla.com:8020/hbase/crash_reports/8faa71d5e90aa82570df036515f752e4 on hdfs, b ut not listed in meta or deployed on any region server. error: region hdfs://hp-admin01.phx1.mozilla.com:8020/hbase/crash_reports/938f334ca6399ce5a17d33dc1a045d8d on hdfs, b ut not listed in meta or deployed on any region server. error: region hdfs://hp-admin01.phx1.mozilla.com:8020/hbase/crash_reports/cd673fbac6f8f88f87c81f3bdd3a1ed8 on hdfs, b ut not listed in meta or deployed on any region server. ",
        "label": 248
    },
    {
        "text": "once replication sees an error it slows down forever  sleepmultiplier inside of hbaseinterclusterreplicationendpoint and replicationsource never gets reset to zero. ",
        "label": 154
    },
    {
        "text": "always cache index and bloom blocks  this would add a new boolean config option: hfile.block.cache.datablocks  default would be true. setting this to false allows hbase in a mode where only index blocks are cached, which is useful for analytical scenarios where a useful working set of the data cannot be expected to fit into the (aggregate) cache.  this is the equivalent of setting cacheblocks to false on all scans (including scans on behalf of gets). i would like to get a general feeling about what folks think about this.  the change itself would be simple. update (mikhail): we probably don't need a new conf option. instead, we will make index blocks cached by default. ",
        "label": 324
    },
    {
        "text": "can't scan ' meta ' from new shell  need scan of .meta. debugging. ",
        "label": 314
    },
    {
        "text": "make the compaction logging less confusing  1) one of the most popular question from hbase users has got to be \"i have scheduled major compactions to run once per week, why are there so many\".  we need to somehow tell the user, wherever we log that there is a \"major\" compaction, whether it's a major compaction because that's what was in the request (from regular major compaction or user request), or was it just promoted because it took all files. esp. the latter should be clear.  2) small vs large compaction threads and minor vs major compactions is confusing. maybe the threads can be named short and long compactions. we ",
        "label": 406
    },
    {
        "text": "remove fragmentation indicator for  fix in   hbase-2165 is about working on fragmentation indicator to make it less intrusive. currently it can get in way of displaying ui on big cluster. ",
        "label": 229
    },
    {
        "text": "does not compile with hadoop and  0.94 is supposed to work with 0.20.205 and 0.22 if i am not wrong. we should document this. ",
        "label": 314
    },
    {
        "text": "do not allow user to disable or drop acl table  currently htabledescriptor.islegaltablename api doesn't check for the acl table name, due to this user can able to disable/enable/drop/create the acl table. ",
        "label": 184
    },
    {
        "text": "hbase regionserver checksum verify default  true or false  hregionserver: default to false  hbase-common/hbase-default.xml: true ",
        "label": 340
    },
    {
        "text": "master ui should check against known bad jdk versions and warn the user  we know that jdk 1.6.0u18 is broken and unstable with hbase. we should add a quick check to master web ui and display a warning when running under an unstable jdk. ",
        "label": 453
    },
    {
        "text": "remove dead code in halfstorefilereader getscanner seekbefore   here is related code:           cell fk = new keyvalue.keyonlykeyvalue(getfirstkey(), 0, getfirstkey().length);           // this will be null when the file is empty in which we can not           // seekbefore to any key           if (fk == null)             return false; fk wouldn't be null. ",
        "label": 191
    },
    {
        "text": "columncountgetfilter   pagefilter not working with filterlist  thanks to anoop and ramkrishna, here's what we found with filterlist if i use filterlist to include columncountgetfilter among other filters, the returning result has no keyvalues. this problem seems to occur when specified column count is less then actual number of existing columns. also same problem arises with pagefilter following is the code of the problem: configuration conf = hbaseconfiguration.create(); htable table = new htable(conf, \"test\"); get get = new get(bytes.tobytes(\"test00001\")); filterlist filterlist = new filterlist(); filterlist.addfilter(new columncountgetfilter(100));            get.setfilter(filterlist); result r = table.get(get); system.out.println(r.size()); // prints zero ",
        "label": 46
    },
    {
        "text": "tof doesn't take zk client port for remote clusters  currently we are only able to specify the zk ensemble and root znode for the remote cluster in tof, we should also be able to give the client port (like in replication). this will require a change in copytable's command line arguments too. ",
        "label": 229
    },
    {
        "text": "ensure region state error messages include server making report  branch   this message is near useless. a rs is carrying a region that is not known to master but we don't know which server has it because message doesn't say who is complaining (this is fixed in 2.2.x). 2019-10-14 20:06:50,347 warn org.apache.hadoop.hbase.master.assignment.assignmentmanager: failed to checkonlineregionsreport, maybe due to network lag, if this message continues, be careful of double assign org.apache.hadoop.hbase.exceptions.unexpectedstateexception: not online: xxxx,ced91598,1570663084277_0001.c727b4ed71a3a29a44cce3a917f753f4. at org.apache.hadoop.hbase.master.assignment.assignmentmanager.checkonlineregionsreport(assignmentmanager.java:1014) at org.apache.hadoop.hbase.master.assignment.assignmentmanager.reportonlineregions(assignmentmanager.java:973) at org.apache.hadoop.hbase.master.masterrpcservices.regionserverreport(masterrpcservices.java:491) at org.apache.hadoop.hbase.shaded.protobuf.generated.regionserverstatusprotos$regionserverstatusservice$2.callblockingmethod(regionserverstatusprotos.java:13139) at org.apache.hadoop.hbase.ipc.rpcserver.call(rpcserver.java:413) at org.apache.hadoop.hbase.ipc.callrunner.run(callrunner.java:130) at org.apache.hadoop.hbase.ipc.rpcexecutor$handler.run(rpcexecutor.java:324) at org.apache.hadoop.hbase.ipc.rpcexecutor$handler.run(rpcexecutor.java:304) ",
        "label": 402
    },
    {
        "text": "minor typo in replicationsource sockettimeoutexception error handling  the user gets an error message on socket timeout exception: the words \"the\" and \"call\" need a space between them. fix is trivial. 2012-10-11 11:09:06,154 debug org.apache.hadoop.hbase.replication.regionserver.replicationsource: encountered a sockettimeoutexception. since thecall to the remote cluster timed out, which is usually caused by a machine failure or a massive slowdown, sleeping 1000 times 100 the error is present in .92 and onward all the way through to the trunk. fix should go into all those branches. ",
        "label": 15
    },
    {
        "text": "testcreatetablehandler testmasterrestartafterenablingnodeiscreated failed  https://builds.apache.org/job/hbase-trunk/4258/testreport/org.apache.hadoop.hbase.master.handler/testcreatetablehandler/testmasterrestartafterenablingnodeiscreated/ timed out after 5 seconds. looked to be making progress. timeout seems too short. ",
        "label": 314
    },
    {
        "text": "don't use bulk assigner if assigning just several regions  if just assign one region, bulk assigner may be slower. ",
        "label": 242
    },
    {
        "text": "hbase preamble of add increment tests  add the tests that were added by parent issue hbase-15158; adds incrementperformancetest, testregionincrement, and moves increment testing 'from client side' out into own test suite. this stuff is mostly forward-post of tests committed to branch-1 to test increment regressions 'narorow' fix (see hbase-15031). we are adding the tests separately here in an effort at making the hbase-15158 patch smaller. this is preamble 2 of 2. preamble 1 was hbase-15186 ",
        "label": 314
    },
    {
        "text": "provide a put api that uses the provided row without coping  the current available put api always makes a copy of the rowkey.  let's provide an api that accepts an immutable byte array as rowkey without making a copy.  there are cases where the caller of put has created the immutable byte array (e.g from a serializer) and will not change it for the put duration. we can avoid making a copy again. ",
        "label": 490
    },
    {
        "text": "fix filtercellbystore in walsplitter is awful for performance  testing the latest 1.2 i see this when there is a regionserver that crashes. thread 921 (rs_log_replay_ops-hbase2698:16020-0-writer-1):   state: runnable   blocked count: 6354   waited count: 6249   stack:     org.apache.hadoop.hbase.keyvalue.equals(keyvalue.java:1128)     java.util.arraylist.indexof(arraylist.java:317)     java.util.arraylist.contains(arraylist.java:300)     java.util.arraylist.batchremove(arraylist.java:720)     java.util.arraylist.removeall(arraylist.java:690)     org.apache.hadoop.hbase.wal.walsplitter$logrecoverededitsoutputsink.filtercellbystore(walsplitter.java:1529)     org.apache.hadoop.hbase.wal.walsplitter$logrecoverededitsoutputsink.append(walsplitter.java:1557)     org.apache.hadoop.hbase.wal.walsplitter$writerthread.writebuffer(walsplitter.java:1113)     org.apache.hadoop.hbase.wal.walsplitter$writerthread.dorun(walsplitter.java:1105)     org.apache.hadoop.hbase.wal.walsplitter$writerthread.run(walsplitter.java:1075) thread 920 (rs_log_replay_ops-hbase2698:16020-0-writer-0):   state: timed_waiting   blocked count: 17560   waited count: 19695   stack:     java.lang.object.wait(native method)     org.apache.hadoop.hbase.wal.walsplitter$writerthread.dorun(walsplitter.java:1093)     org.apache.hadoop.hbase.wal.walsplitter$writerthread.run(walsplitter.java:1075) thread 919 (rs_log_replay_ops-hbase2698:16020-0):   state: timed_waiting   blocked count: 115   waited count: 976   stack:     java.lang.object.wait(native method)     org.apache.hadoop.hbase.wal.walsplitter$entrybuffers.appendentry(walsplitter.java:944)     org.apache.hadoop.hbase.wal.walsplitter.splitlogfile(walsplitter.java:365)     org.apache.hadoop.hbase.wal.walsplitter.splitlogfile(walsplitter.java:236)     org.apache.hadoop.hbase.regionserver.splitlogworker$1.exec(splitlogworker.java:104)     org.apache.hadoop.hbase.regionserver.handler.walsplitterhandler.process(walsplitterhandler.java:72)     org.apache.hadoop.hbase.executor.eventhandler.run(eventhandler.java:128)     java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1142)     java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:617)     java.lang.thread.run(thread.java:745) this has been going on for >10 mins. ",
        "label": 154
    },
    {
        "text": "port hbase to thrift  hbase-5428 adds loading filters at start up. needs to be added in thrift 2 as well. ",
        "label": 285
    },
    {
        "text": "testmasteradmin fails throwing regionofflineexception when we're expecting illegalstateexception  ",
        "label": 314
    },
    {
        "text": "support more than one slave cluster  currently replication supports only 1 slave cluster, need to ability to add more. ",
        "label": 286
    },
    {
        "text": "users should be able to choose custom tableinputformats without modifying tablemapreduceutil inittablemapperjob   currently, org.apache.hadoop.hbase.mapreduce.tablemapreduceutil.inittablemapperjob() forces any hbase job to use the default tableinputformat.class as the job's input format class.  \"job.setinputformatclass(tableinputformat.class);\" ==> this line is included in inittablemapperjob().  this restriction causes users to modify inittablemapperjob() in addition to implementing their own tableinputformat.   it would be nicer if users can use custom tableinputformats without additionally tampering with hbase source code. ",
        "label": 82
    },
    {
        "text": "upgrade thrift lib to  ",
        "label": 223
    },
    {
        "text": "remove slabcache  per title. ",
        "label": 339
    },
    {
        "text": "add an option of using round robin assignment for enabling table  under some scenarios, we use the function of disable/enable htable. but currently, enable htable uses the random-assignment. we hope all the regions show a better distribution, no matter how many regions and how many regionservers. so i suggest to add an option of using round-robin assignment on enable-table. ",
        "label": 240
    },
    {
        "text": "pre commit zombie finder is overly broad  zombie detector is flagging processes from builds that aren't ours. ex from hbase-14337: -1 core zombie tests. there are 4 zombie test(s): at org.apache.reef.io.network.deprecatednetworkconnectionservicetest.testmultithreadedsharedconnmessagingnetworkconnservicerate(deprecatednetworkconnectionservicetest.java:343) ",
        "label": 314
    },
    {
        "text": " hbase  when a table haven't disable  shell could response in a  user friendly  way   currently, 0.2.0's hbase shell will throw raw exception if user execute a 'delete' command before 'disable' the table. compare to 0.1.2's shell script, we would like to have a more friendly message instead of dumping the exception. ",
        "label": 229
    },
    {
        "text": "testsecureloadinc  tests hang repeatedly getting unsupportedoperationexception in hadoop2 profile  these two unit tests fail by hanging under the hadoop2 profile.  running org.apache.hadoop.hbase.mapreduce.testsecureloadincrementalhfilessplitrecovery  running org.apache.hadoop.hbase.mapreduce.testsecureloadincrementalhfiles 2013-04-15 14:03:50,311 error [ipc server handler 0 on 53755] access.securebulkloadendpoint$1(240): failed to complete bulk load java.lang.unsupportedoperationexception: immutable configuration         at org.apache.hadoop.hbase.compoundconfiguration.setclass(compoundconfiguration.java:511)         at org.apache.hadoop.ipc.rpc.setprotocolengine(rpc.java:193)         at org.apache.hadoop.hdfs.namenodeproxies.creatennproxywithclientprotocol(namenodeproxies.java:249)         at org.apache.hadoop.hdfs.namenodeproxies.createnonhaproxy(namenodeproxies.java:168)         at org.apache.hadoop.hdfs.namenodeproxies.createproxy(namenodeproxies.java:129)         at org.apache.hadoop.hdfs.dfsclient.<init>(dfsclient.java:409)         at org.apache.hadoop.hdfs.dfsclient.<init>(dfsclient.java:376)         at org.apache.hadoop.hdfs.distributedfilesystem.initialize(distributedfilesystem.java:123)         at org.apache.hadoop.fs.filesystem.createfilesystem(filesystem.java:2296)         at org.apache.hadoop.fs.filesystem.access$200(filesystem.java:85)         at org.apache.hadoop.fs.filesystem$cache.getinternal(filesystem.java:2330)         at org.apache.hadoop.fs.filesystem$cache.get(filesystem.java:2312)         at org.apache.hadoop.fs.filesystem.get(filesystem.java:316)         at org.apache.hadoop.fs.filesystem.get(filesystem.java:162)         at org.apache.hadoop.hbase.security.access.securebulkloadendpoint$1.run(securebulkloadendpoint.java:224)         at org.apache.hadoop.hbase.security.access.securebulkloadendpoint$1.run(securebulkloadendpoint.java:218)         at java.security.accesscontroller.doprivileged(native method)         at javax.security.auth.subject.doas(subject.java:337)         at org.apache.hadoop.security.usergroupinformation.doas(usergroupinformation.java:1347)         at org.apache.hadoop.hbase.security.access.securebulkloadendpoint.securebulkloadhfiles(securebulkloadendpoint.java:218)         at org.apache.hadoop.hbase.protobuf.generated.securebulkloadprotos$securebulkloadservice.callmethod(securebulkloadprotos.java:3654)         at org.apache.hadoop.hbase.regionserver.hregion.execservice(hregion.java:5024)         at org.apache.hadoop.hbase.regionserver.hregionserver.execservice(hregionserver.java:3076)         at sun.reflect.nativemethodaccessorimpl.invoke0(native method)         at sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:39)         at sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:25)         at java.lang.reflect.method.invoke(method.java:597)         at org.apache.hadoop.hbase.ipc.protobufrpcserverengine$server.call(protobufrpcserverengine.java:174)         at org.apache.hadoop.hbase.ipc.hbaseserver$handler.run(hbaseserver.java:1871) there has been some discussion from ted and andrew about an acceptable approaches to fix the problem here :  https://issues.apache.org/jira/browse/hbase-8258?focusedcommentid=13623091&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13623091 ",
        "label": 248
    },
    {
        "text": "write documentation for configuring managing zookeeper with hbase  ",
        "label": 342
    },
    {
        "text": " unit tests  testreplication queuefailover occasionally fails  part   the failure is in testreplication.queuefailover (fails due to unreplicated rows). i have come across two problems:  1. the sleepmultiplier is not properly reset when the currentpath is changed (in replicationsource.java).  2. replicationexecutor sometime removes files to replicate from the queue too early, resulting in corresponding edits missing. here the problem is due to the fact the log-file length that the replication executor finds is not the most updated one, and hence it doesn't read anything from there, and ultimately, when there is a log roll, the replication-queue gets a new entry, and the executor drops the old entry out of the queue. ",
        "label": 139
    },
    {
        "text": "remove deprecated hconnection for thus removing all pb references for  this is sub-task for hbase-15174. ",
        "label": 258
    },
    {
        "text": "testcatalogtracker testservernotrunningioexception fails occasionally  i would like to remove this method. it micro-tests a single method and poorly at that. ",
        "label": 441
    },
    {
        "text": "ineffective config check in backuplogcleaner getdeletablefiles   here is related code:     if (this.getconf() == null || !backupmanager.isbackupenabled(getconf())) {       log.warn(\"backup is not enabled. check your \" + backuprestoreconstants.backup_enable_key           + \" setting\");       return files;     } however, in setconf() we don't store the configuration where backup is disabled:   public void setconf(configuration config) {     // if backup is disabled, keep all members null     if (!config.getboolean(backuprestoreconstants.backup_enable_key,       backuprestoreconstants.backup_enable_default)) {       log.warn(\"backup is disabled - allowing all wals to be deleted\");       return;     } this means that once config with backup enabled is remembered, it won't go to disabled state. ",
        "label": 370
    },
    {
        "text": "ant javadoc complains about missing classes  something to do with cp - javadoc target not happy with cp ( in trunk). placeholder ticket to revisit it. ",
        "label": 266
    },
    {
        "text": " hbase thirdparty  upgrade to netty  netty has a few newer versions that what we're on. specifically, there have been some changes to the native library loading that i think might make our current relocated usage less terrible. https://github.com/netty/netty/pull/6884  https://github.com/netty/netty/pull/7102 ",
        "label": 320
    },
    {
        "text": "flakey tests make ci unreliable  most precommit and postcommit builds are failing these days. keeping an eye on usual suspects reveals them to be mostly longer-running tests. either the tests need to me made more rigorous or the erroneous jenkins configuration needs addressed. the usual suspects: org.apache.hadoop.hbase.client.testmultiparallel org.apache.hadoop.hbase.testdrainingserver org.apache.hadoop.hbase.regionserver.testsplittransaction org.apache.hadoop.hbase.client.testmultiparallel.testflushcommitsnoabort org.apache.hadoop.hbase.replication.testreplication org.apache.hadoop.hbase.util.testhbasefsck ",
        "label": 340
    },
    {
        "text": "change hbasemapwritable and rowresult to implement sortedmap instead of map  hbasemapwritable and rowresult currently implement map. however, it would be trivial (and highly useful) for them to implement sortedmap since hbasemapwritable already uses a treemap for the map. ",
        "label": 247
    },
    {
        "text": "testhbasefsck testregionshouldnotbedeployed seems to be flaky  i ran the entire test suite many times and always failed on, at least, testregionshouldnotbedeployed. results below. i will attached more result when current tests are done. failed tests:  testdeleteexpiredstorefiles(org.apache.hadoop.hbase.regionserver.teststore):  expected:<2> but was:<4>  testacquiretaskatstartup(org.apache.hadoop.hbase.regionserver.testsplitlogworker):  waiting timed out after [1 000] msec  testregionshouldnotbedeployed(org.apache.hadoop.hbase.util.testhbasefsck):  expected:<[should_not_be_deployed]> but was:<[]>  testpermissionswatcher(org.apache.hadoop.hbase.security.access.testzkpermissionswatcher) ",
        "label": 242
    },
    {
        "text": "htable checkandput delete doesn't handle null values  from john beatty on the ml: thanks ryan, but i seem to be missing something then. it npes for me.  when running against 0.89.20100726 and providing a null expected value  i get the below stack trace (and works like a champ when i provide a  byte[0]. i also don't see the transformation you're referring to in  htable. (for reference,  http://svn.apache.org/viewvc/hbase/branches/0.89.20100726/src/main/java/org/apache/hadoop/hbase/regionserver/hregion.java?view=markup) java.io.ioexception: java.io.ioexception: java.lang.nullpointerexception  at org.apache.hadoop.hbase.regionserver.hregionserver.convertthrowabletoioe(hregionserver.java:845)  at org.apache.hadoop.hbase.regionserver.hregionserver.convertthrowabletoioe(hregionserver.java:835)  at org.apache.hadoop.hbase.regionserver.hregionserver.checkandmutate(hregionserver.java:1754)  at org.apache.hadoop.hbase.regionserver.hregionserver.checkandput(hregionserver.java:1773)  at sun.reflect.generatedmethodaccessor8.invoke(unknown source)  at sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:25)  at org.apache.hadoop.hbase.ipc.hbaserpc$server.call(hbaserpc.java:576)  at org.apache.hadoop.hbase.ipc.hbaseserver$handler.run(hbaseserver.java:919)  caused by: java.lang.nullpointerexception  at org.apache.hadoop.hbase.regionserver.hregion.checkandmutate(hregion.java:1616)  at org.apache.hadoop.hbase.regionserver.hregionserver.checkandmutate(hregionserver.java:1751)  ... 6 more looking in the code, i'm not sure either where the null conversion is done, even worse is that we don't even have unit tests! it should be put intotestfromclientside. ",
        "label": 229
    },
    {
        "text": "assignmentmanager's handleregion should respect the single threaded nature of the processing  while debugging a case where a region was getting opened on a regionserver and then closed soon after (and then never re-opened anywhere thereafter), it seemed like the processing in handleregion to do with deletion of zk nodes should be non-asynchronous. this achieves two things:  1. the synchronous deletion prevents more than one processing on the same event data twice. assuming that we do get more than one notification (on let's say, region opened event), the subsequent processing(s) in handleregion for the same znode would end up with a zookeeper node not found exception. the return value of the data read would be null and that's already handled. if it is asynchronous, it leads to issues like - master opens a region on a certain regionserver and soon after it sends that regionserver a close for the same region, and then the znode is deleted. 2. the deletion is currently handled in an executor service. this is problematic since by design the events for a given region should be processed in order. by delegating a part of the processing to executor service we are somewhat violating this contract since there is no guarantee of the ordering in the executor service executions... thanks to jeffrey zhong and enis soztutar for the discussions on this issue. ",
        "label": 139
    },
    {
        "text": "procedure v2   reimplement split  use the proc-v2 state machine for split. also update the logic to have a single meta-writer. ",
        "label": 426
    },
    {
        "text": "per cell ttls  now that we have cell tags, we can optionally store ttls per cell. ",
        "label": 38
    },
    {
        "text": "small inconsistency in the  example api usage   the example uses \"mylittlerow\" but refers to \"myrow\" in one of the comments. ",
        "label": 70
    },
    {
        "text": "fix failed ut testclusterrestartfailover  ",
        "label": 187
    },
    {
        "text": "improve verifyreplication to compute badrows more accurately  verifyreplicaiton could compare the source table with its peer table and compute badrows. however, the current badrows computing method might not be accurate enough. for example, if source table contains rows as {r1, r2, r3, r4} and peer table contains rows as {r1, r3, r4} badrows will be 3 because 'r2' in source table will make all the later row comparisons fail. will it be better if the badrows is computed to 1 in this situation? maybe, we can compute the badrows more accurately in merge comparison? ",
        "label": 238
    },
    {
        "text": "push entries to peer clusters serially  when region-move or rs failure occurs in master cluster, the hlog entries that are not pushed before region-move or rs-failure will be pushed by original rs(for region move) or another rs which takes over the remained hlog of dead rs(for rs failure), and the new entries for the same region(s) will be pushed by the rs which now serves the region(s), but they push the hlog entries of a same region concurrently without coordination. this treatment can possibly lead to data inconsistency between master and peer clusters:  1. there are put and then delete written to master cluster  2. due to region-move / rs-failure, they are pushed by different replication-source threads to peer cluster  3. if delete is pushed to peer cluster before put, and flush and major-compact occurs in peer cluster before put is pushed to peer cluster, the delete is collected and the put remains in peer cluster in this scenario, the put remains in peer cluster, but in master cluster the put is masked by the delete, hence data inconsistency between master and peer clusters ",
        "label": 353
    },
    {
        "text": "backport  replication  the replication executor should make sure the file that it is replicating is closed before declaring success on that file  to  ",
        "label": 139
    },
    {
        "text": "catalogtracker has an identity crisis  needs to be cut back in scope  ct needs a good reworking. i'd suggest its scope be cut way down to only deal in zk transactions rather than zk and reading meta location in hbase (over an hconnection) and being a purveyor of hregioninterfaces on meta and root servers and being an abortable and a verifier of catalog locations. once this is done, i would suggest it then better belongs over under the zk package and that the meta* classes then move to client package. here's some messy notes i added to head of ct class in hbase-3446 where i spent some time trying to make out what it was ct did.   // todo: this class needs a rethink.  the original intent was that it would be   // the one-stop-shop for root and meta locations and that it would get this   // info from reading and watching zk state.  the class was to be used by   // servers when they needed to know of root and meta movement but also by   // client-side (inside in htable) so rather than figure root and meta   // locations on fault, the client would instead get notifications out of zk.   //    // but this original intent is frustrated by the fact that this class has to   // read an hbase table, the -root- table, to figure out the .meta. region   // location which means we depend on an hconnection.  hconnection will do   // retrying but also, it has its own mechanism for finding root and meta   // locations (and for 'verifying'; it tries the location and if it fails, does   // new lookup, etc.).  so, at least for now, hconnection (or htable) can't   // have a ct since ct needs a hconnection (even then, do want ht to have a ct?   // for ht keep up a session with zk?  rather, shouldn't we do like asynchbase   // where we'd open a connection to zk, read what we need then let the   // connection go?).  the 'fix' is make it so both root and meta addresses   // are wholey up in zk -- not in zk (root) -- and in an hbase table (meta).   //   // but even then, this class does 'verification' of the location and it does   // this by making a call over an hconnection (which will do its own root   // and meta lookups).  isn't this verification 'useless' since when we   // return, whatever is dependent on the result of this call then needs to   // use hconnection; what we have verified may change in meantime (hconnection   // uses the ct primitives, the root and meta trackers finding root locations).   //   // when meta is moved to zk, this class may make more sense.  in the   // meantime, it does not cohere.  it should just watch meta and root and   // not do verification -- let that be out in hconnection since its going to   // be done there ultimately anyways.   //   // this class has spread throughout the codebase.  it needs to be reigned in.   // this class should be used server-side only, even if we move meta location   // up into zk.  currently its used over in the client package. its used in   // metareader and metaeditor classes usually just to get the configuration   // its using (it does this indirectly by asking its hconnection for its   // configuration and even then this is just used to get an hconnection out on   // the other end). st.ack 10/23/2011.   // ",
        "label": 323
    },
    {
        "text": "be consistent in use of qualified unqualified mapfile paths  a store that was made up in hdfs can't be examined using local filesystem because we \u2013 or hadoop \u2013 is inconsistent. ",
        "label": 314
    },
    {
        "text": "commonfsutils streamlackscapabilityexception  hflush when running test against hadoop3 beta1  as of commit d8fb10c8329b19223c91d3cda6ef149382ad4ea0 , i encountered the following exception when running unit test against hadoop3 beta1: testrefreshstorefiles(org.apache.hadoop.hbase.regionserver.testhstore)  time elapsed: 0.061 sec  <<< error! java.io.ioexception: cannot get log writer at org.apache.hadoop.hbase.regionserver.testhstore.inithregion(testhstore.java:215) at org.apache.hadoop.hbase.regionserver.testhstore.init(testhstore.java:220) at org.apache.hadoop.hbase.regionserver.testhstore.init(testhstore.java:195) at org.apache.hadoop.hbase.regionserver.testhstore.init(testhstore.java:190) at org.apache.hadoop.hbase.regionserver.testhstore.init(testhstore.java:185) at org.apache.hadoop.hbase.regionserver.testhstore.init(testhstore.java:179) at org.apache.hadoop.hbase.regionserver.testhstore.init(testhstore.java:173) at org.apache.hadoop.hbase.regionserver.testhstore.testrefreshstorefiles(testhstore.java:962) caused by: org.apache.hadoop.hbase.util.commonfsutils$streamlackscapabilityexception: hflush at org.apache.hadoop.hbase.regionserver.testhstore.inithregion(testhstore.java:215) at org.apache.hadoop.hbase.regionserver.testhstore.init(testhstore.java:220) at org.apache.hadoop.hbase.regionserver.testhstore.init(testhstore.java:195) at org.apache.hadoop.hbase.regionserver.testhstore.init(testhstore.java:190) at org.apache.hadoop.hbase.regionserver.testhstore.init(testhstore.java:185) at org.apache.hadoop.hbase.regionserver.testhstore.init(testhstore.java:179) at org.apache.hadoop.hbase.regionserver.testhstore.init(testhstore.java:173) at org.apache.hadoop.hbase.regionserver.testhstore.testrefreshstorefiles(testhstore.java:962) ",
        "label": 320
    },
    {
        "text": "faster hbase bulk loader  we can get a 3x to 4x gain based on a prototype demonstrating this approach in effect (hackily) over the mr bulk loader for very large data sets by doing the following: 1. do direct multi-puts from hbase client using gzip compressed rpc's  2. turn off wal (we will ensure no data loss in another way)  3. for each bulk load client, we need to:  3.1 do a put  3.2 get back a tracking cookie (memstorets or hlogsequenceid) per put  3.3 be able to ask the rs if the tracking cookie has been flushed to disk  4. for each client, we can succeed it if the tracking cookie for the last put it did (for every rs) makes it to disk. otherwise the map task fails and is retried.  5. if the last put did not make it to disk for a timeout (say a second or so) we issue a manual flush. enhancements: increase the memstore size so that we flush larger files decrease the compaction ratios (say increase the number of files to compact) quick background: the bottlenecks in the multiput approach are that the data is transferred uncompressed twice over the top-of-rack: once from the client to the rs (on the multi put call) and again because of wal (hdfs replication). we reduced the former with rpc compression and eliminated the latter above while still guaranteeing that data wont be lost. this is better than the mr bulk loader at a high level because we dont need to merge sort all the files for a given region and then make it a hfile - thats the equivalent of bulk loading and majorcompacting in one shot. also there is much more disk involved in the mr method (sort/spill). ",
        "label": 34
    },
    {
        "text": "thrift server  deletes in mutaterow s don't delete   simple bugs:  in mutaterow we don't check the isdelete flag, it always assumes a put.  in mutaterows we don't check if the delete has only the family specified. ",
        "label": 547
    },
    {
        "text": "deleting a table kills client rpc  no subsequent communication if shell or thrift server  etc   in shell, create a table, drop it, then try recreate. will get: nativeexception: java.io.ioexception: the client is stopped ",
        "label": 247
    },
    {
        "text": "the update of  tableinfo is not atomic  we remove then rename  this comes of hbase-4547. the rename in 0.20 hdfs fails if file exists already. in 0.20+ its better but still 'some' issues if existing reader when file is renamed. this issue is about fixing this (though we depend on fix first being in hdfs). ",
        "label": 314
    },
    {
        "text": "testsnapshotcloneindependence testonlinesnapshotmetadatachangesindependent fails  https://builds.apache.org/job/hbase-trunk/4270/testreport/org.apache.hadoop.hbase.client/testsnapshotcloneindependence/testonlinesnapshotmetadatachangesindependent/ error message org.apache.hadoop.hbase.exceptions.hbasesnapshotexception: snapshot { ss=snapshot_test1374188869207 table=test1374188869207 type=flush } had an error.  procedure snapshot_test1374188869207 { waiting=[vesta.apache.org,37857,1374188841025] done=[] } stacktrace org.apache.hadoop.hbase.exceptions.hbasesnapshotexception: org.apache.hadoop.hbase.exceptions.hbasesnapshotexception: snapshot { ss=snapshot_test1374188869207 table=test1374188869207 type=flush } had an error.  procedure snapshot_test1374188869207 { waiting=[vesta.apache.org,37857,1374188841025] done=[] } at sun.reflect.nativeconstructoraccessorimpl.newinstance0(native method) at sun.reflect.nativeconstructoraccessorimpl.newinstance(nativeconstructoraccessorimpl.java:39) at sun.reflect.delegatingconstructoraccessorimpl.newinstance(delegatingconstructoraccessorimpl.java:27) at java.lang.reflect.constructor.newinstance(constructor.java:513) at org.apache.hadoop.ipc.remoteexception.instantiateexception(remoteexception.java:95) at org.apache.hadoop.ipc.remoteexception.unwrapremoteexception(remoteexception.java:79) at org.apache.hadoop.hbase.protobuf.protobufutil.getremoteexception(protobufutil.java:232) at org.apache.hadoop.hbase.client.hbaseadmin.executecallable(hbaseadmin.java:2701) at org.apache.hadoop.hbase.client.hbaseadmin.execute(hbaseadmin.java:2670) at org.apache.hadoop.hbase.client.hbaseadmin.snapshot(hbaseadmin.java:2304) at org.apache.hadoop.hbase.client.hbaseadmin.snapshot(hbaseadmin.java:2251) at org.apache.hadoop.hbase.client.hbaseadmin.snapshot(hbaseadmin.java:2203) at org.apache.hadoop.hbase.snapshot.snapshottestingutils.createsnapshotandvalidate(snapshottestingutils.java:379) at org.apache.hadoop.hbase.snapshot.snapshottestingutils.createsnapshotandvalidate(snapshottestingutils.java:410) at org.apache.hadoop.hbase.client.testsnapshotcloneindependence.runtestsnapshotmetadatachangesindependent(testsnapshotcloneindependence.java:341) at org.apache.hadoop.hbase.client.testsnapshotcloneindependence.testonlinesnapshotmetadatachangesindependent(testsnapshotcloneindependence.java:145) at sun.reflect.nativemethodaccessorimpl.invoke0(native method) at sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:39) at sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:25) at java.lang.reflect.method.invoke(method.java:597) at org.junit.runners.model.frameworkmethod$1.runreflectivecall(frameworkmethod.java:47) at org.junit.internal.runners.model.reflectivecallable.run(reflectivecallable.java:12) at org.junit.runners.model.frameworkmethod.invokeexplosively(frameworkmethod.java:44) at org.junit.internal.runners.statements.invokemethod.evaluate(invokemethod.java:17) at org.junit.internal.runners.statements.runbefores.evaluate(runbefores.java:26) at org.junit.internal.runners.statements.runafters.evaluate(runafters.java:27) at org.junit.runners.parentrunner.runleaf(parentrunner.java:271) at org.junit.runners.blockjunit4classrunner.runchild(blockjunit4classrunner.java:70) ... mighty matteo bertozzi? want to take a look at this failure? thanks boss. ",
        "label": 309
    },
    {
        "text": "hcm shutdownhook causes data loss with hbase client write buffer    in my application i set hbase.client.write.buffer to a reasonably small value (roughly 64 edits) in order to try to batch a few put together before talking to hbase. when my application does a graceful shutdown, i call htable#flushcommits in order to flush any pending change to hbase. i want to do the same thing when i get a sigterm by using runtime#addshutdownhook but this is impossible since hconnectionmanager already registers a shutdown hook that invokes hconnectionmanager#deleteallconnections. this static method closes all the connections to hbase and then all connections to zookeeper. because all shutdown hooks run in parallel, my hook will attempt to flush edits while connections are getting closed. there is no way to guarantee the order in which the hooks will execute, so i propose that we remove the hook in the hcm altogether and provide some user-visible api they call in their own hook after they're done flushing their stuff, if they really want to do a graceful shutdown. i expect that a lot of users won't use a hook though, otherwise this issue would have cropped up already. for those users, connections won't get \"gracefully\" terminated, but i don't think that would be a problem since the underlying tcp socket will get closed by the os anyway, so things like zookeeper and such should realize that the connection has been terminated and assume the client is gone, and do the necessary clean-up on their side. an alternate fix would be to leave the hook in place by default but keep a reference to it and add a user-visible api to be able to un-register the hook. i find this ugly. thoughts? ",
        "label": 314
    },
    {
        "text": "baseloadbalancer wouldloweravailability should consider region replicas  found this issue when try to fix the flaky unit test  testregionreplicasplit. it may fail as  java.lang.assertionerror: splitted regions should not be assigned to same region server. see https://builds.apache.org/job/hbase-flaky-tests/job/master/5227/testreport/junit/org.apache.hadoop.hbase.master.assignment/testregionreplicasplit/testregionreplicasplitregionassignment/.   now  wouldloweravailability method only consider the primary regions. the replica region can't assign to same server with primary region. but can be assigned to same server with other replica regions.    ",
        "label": 187
    },
    {
        "text": "revise zookeeper session timeout setting  current zk session timeout is set to 90sec., and the comment in the doc says: \"this setting becomes zookeeper's 'maxsessiontimeout'\". however, this comment is misleading - it doesn't always become maxsessiontimeout, min(our timeout, maxsessiontimeout) is chosen. moreover, the default maxsessiontimeout in zk that i'm looking at is 40s, so this setting doesn't do anything.  additionally, 40s. seems like a lot of time. 1) should the comment be changed to tell the user to change zk config if they want higher timeout?  2) should the setting be revised down? ",
        "label": 229
    },
    {
        "text": "testdistributedlogsplitting testlogreplayfordisablingtable fails on hadoop  the test failed with: testlogreplayfordisablingtable(org.apache.hadoop.hbase.master.testdistributedlogsplitting)  time elapsed: 0.144 sec  <<< error! java.io.filenotfoundexception: file hdfs://localhost:56794/user/hortonzy/hbase/disabletable/6676df27ed855d9c61ad20ed650700e7/recovered.edits does not exist.         at org.apache.hadoop.hdfs.distributedfilesystem.liststatus(distributedfilesystem.java:405)         at org.apache.hadoop.hbase.master.testdistributedlogsplitting.testlogreplayfordisablingtable(testdistributedlogsplitting.java:774) this was due to filenotfoundexception being thrown out of liststatus() for non-existent directory in hadoop 2.0. ",
        "label": 233
    },
    {
        "text": "remove confusing log message of how  basescanner get got different address startcode than scan   seeing some of these errors in the hbase master's logs: 2010-03-24 16:52:17,003 debug org.apache.hadoop.hbase.master.basescanner: get on test1,8947030000,1269474720493 got different address than scan: sa=10.18.34.217:60020, serveraddress= 2010-03-24 16:52:17,003 debug org.apache.hadoop.hbase.master.basescanner: get on test1,8947030000,1269474720493 got different startcode than scan: sc=1269456397807, serveraddress=0 2010-03-24 16:52:17,018 debug org.apache.hadoop.hbase.master.basescanner: get on test1,8953040000,1269474720493 got different address than scan: sa=10.18.34.215:60020, serveraddress= 2010-03-24 16:52:17,018 debug org.apache.hadoop.hbase.master.basescanner: get on test1,8953040000,1269474720493 got different startcode than scan: sc=1269456397735, serveraddress=0 ideas? ",
        "label": 314
    },
    {
        "text": "up the versions kept by catalog tables  currently  make it   the .meta. and root tables currently only keep a single version of a cell. debugging, would be good to have access to previous version of a cell. i can change the defaults so new installs get the upped version. should we do a migration to up versions in established tables?   /** table descriptor for <core>-root-</code> catalog table */   public static final htabledescriptor root_tabledesc = new htabledescriptor(       hconstants.root_table_name,       new hcolumndescriptor[] { new hcolumndescriptor(hconstants.column_family,           1, hcolumndescriptor.compressiontype.none, false, false,           integer.max_value, hconstants.forever, false) });      /** table descriptor for <code>.meta.</code> catalog table */   public static final htabledescriptor meta_tabledesc = new htabledescriptor(       hconstants.meta_table_name, new hcolumndescriptor[] {           new hcolumndescriptor(hconstants.column_family, 1,               hcolumndescriptor.compressiontype.none, false, false,               integer.max_value, hconstants.forever, false),           new hcolumndescriptor(hconstants.column_family_historian,               hconstants.all_versions, hcolumndescriptor.compressiontype.none,               false, false, integer.max_value, hconstants.forever, false) }); ",
        "label": 314
    },
    {
        "text": " rest  spnego based authentication  currently the rest gateway can authenticate to a hbase cluster using a preconfigured principal. this provides a limited form of secure operation where one or more gateways can be deployed with distinct principals granting appropriate levels of privilege, but the service ports must be protected through network acls. this is at best a stopgap. spnego is the standard mechanism for kerberos authentication over http. enhance the rest gateway such that it provides this option, and issues requests to the hbase cluster with the established context. ",
        "label": 242
    },
    {
        "text": "meta remains unassigned when the meta server crashes with the clusterstatuslistener set  while running tests described in hbase-9338, ran into this problem. the hbase.status.listener.class was set to org.apache.hadoop.hbase.client.clusterstatuslistener$multicastlistener.  1. i had the meta server coming down  2. the metassh got triggered. the call chain:  2.1 verifyandassignmetawithretries  2.2 verifymetaregionlocation  2.3 waitformetaserverconnection  2.4 getmetaserverconnection  2.5 getcachedconnection  2.6 hconnectionmanager.getadmin(servername, false)  2.7 isdeadserver(servername) -> this is hardcoded to return 'false' when the clusterstatuslistener field is null. if clusterstatuslistener is not null (in my test), then it could return true in certain cases (and in this case, indeed it should return true since the server is down). i am trying to understand why it's hardcoded to 'false' for former case.  3. when isdeadserver returns true, the method hconnectionmanager.getadmin(servername, boolean) throws regionserverstoppedexception.  4. finally, after the retries are over verifyandassignmetawithretries gives up and the master aborts. the methods in the above call chain don't handle regionserverstoppedexception. maybe something to look at... ",
        "label": 340
    },
    {
        "text": " refguide  improvements to new contributor docs  developer.xml expanded explanation around git & svn, and mentioning the egit plugin expanded explanation of setting up the eclipse project extra section about basic compilation using maven and eclipse fix to tarball command that makes it maven2 compatible greatly expanded section about contributing docs, and clarification that pushing generated site is only for those with permissions ",
        "label": 209
    },
    {
        "text": "add ability to have multiple zk servers in a quorum in minizookeepercluster for test writing  interesting things can happen when you have a zk quorum of multiple servers and one of them dies. doing testing here on clusters, this has turned up some bugs with hbase interaction with zk. would be good to add the ability to have multiple zk servers in unit tests and be able to kill them individually. ",
        "label": 294
    },
    {
        "text": "remove the kv copy of every kv in scan  introduced by hbase  here is offending code from inside in storescanner#next:       // kv is no longer immutable due to keyonlyfilter! use copy for safety       keyvalue copykv = new keyvalue(kv.getbuffer(), kv.getoffset(), kv.getlength()); this looks wrong given philosophy up to this has been avoidance of garbage-making copies. maybe this has been looked into before and this is the only thing to be done but why is keyonlyfilter not making copies rather than mutating originals? making this critical against 0.92. ",
        "label": 286
    },
    {
        "text": "replication code logs like crazy if a target table cannot be found   one of our rs/dn machines ran out of diskspace on the partition to which we write the log files. it turns out we still had a table in our source cluster with replication_scope=>1 that did not have a matching table in the remote cluster. in then logged a long stack trace every 50ms or so, over a few days that filled up our log partition. since replicationsource cannot make any progress in this case anyway, it should probably sleep a bit before retrying (or at least limit the rate at which it spews out these exceptions to the log). ",
        "label": 286
    },
    {
        "text": "read meta location from zk  ",
        "label": 154
    },
    {
        "text": "remove rs from deadserver when new instance checks in  keeping the servers in deadserver until it reaches some maximum isn't super friendly, it confuses even the best of our users: 09:27 < gbowyer> hi all, i have apparently three dead rs in my cluster, i cannot find references to them in hdfs or in zk, how do i still report dead rs  09:27 < gbowyer> also the same nodes are reported as live region servers the subtil startcode difference can be hard to catch, also this behavior differs from 0.20 (so old users get confused, like i did when debugging this problem) and it also differs from hadoop's handling of dead datanodes. it was introduced in hbase-3282. i think this should be improved by doing like hadoop does, removing the rs from deadservers when a new instance with the same hostname+port checks in. stack says we should do it in servermanager.checkisdead ",
        "label": 229
    },
    {
        "text": "scaling compaction with multiple threads  was thinking we should build in support to be able to handle more then one thread for compactions this will allow us to keep up with compactions when we get to the point where we store tb's of data per node and may regions  maybe a configurable setting to set how many threads a region server can use for compactions. with compression turned on my compactions are limited by cpu speed with multi cores then it would be nice to be able to scale compactions to 2 or more cores. ",
        "label": 341
    },
    {
        "text": "reduce unnecessary getfilestatus hdfs calls in ttl hfile and hlog cleanners  for each in file in archive dir, the timetolivehfilecleaner need call getfilestatus to get the modify time of file. actually the cleanerchore have had the file status when listing its parent dir. when we set the ttl to 7 days in our cluster for data security, the number of files left in archive dir is up to 65 thousands. in each clean period, timetolivehfilecleaner will generate ten thousand getfilestatus call in a short time, which is very heavy for hdfs namenode. fix: change the path param to filestatus in isfiledeletable method and reduce unnecessary getfilestatus hdfs calls in ttl cleaners. ",
        "label": 411
    },
    {
        "text": "logging cleanups  emit regionname when regiontoobusyexception inside retriesexhausted  make netty connect disconnect trace level  in mr failures, i see this:  error: org.apache.hadoop.hbase.client.retriesexhaustedwithdetailsexception: failed 365 actions: regiontoobusyexception: 365 times, servers with issues: ve0534.halxg.cloudera.com,16020,1514392912363 at org.apache.hadoop.hbase.client.batcherrors.makeexception(batcherrors.java:54) at org.apache.hadoop.hbase.client.asyncprocess.waitforallpreviousopsandreset(asyncprocess.java:491) at org.apache.hadoop.hbase.client.bufferedmutatorimpl.backgroundflushcommits(bufferedmutatorimpl.java:268) at org.apache.hadoop.hbase.client.bufferedmutatorimpl.flush(bufferedmutatorimpl.java:225) at org.apache.hadoop.hbase.test.integrationtestbiglinkedlist$generator$generatormapper.persist(integrationtestbiglinkedlist.java:541) at org.apache.hadoop.hbase.test.integrationtestbiglinkedlist$generator$generatormapper.map(integrationtestbiglinkedlist.java:464) at org.apache.hadoop.hbase.test.integrationtestbiglinkedlist$generator$generatormapper.map(integrationtestbiglinkedlist.java:399) at org.apache.hadoop.mapreduce.mapper.run(mapper.java:146) at org.apache.hadoop.mapred.maptask.runnewmapper(maptask.java:787) at org.apache.hadoop.mapred.maptask.run(maptask.java:341) at org.apache.hadoop.mapred.yarnchild$2.run(yarnchild.java:164) at java.security.accesscontroller.doprivileged(native method) at javax.security.auth.subject.doas(subject.java:422) at org.apache.hadoop.security.usergroupinformation.doas(usergroupinformation.java:1746) at org.apache.hadoop.mapred.yarnchild.main(yarnchild.java:158) [2017-12-27 09:09:11.570]container killed by the applicationmaster. [2017-12-27 09:09:11.586]container killed on request. exit code is 143 [2017-12-27 09:09:11.600]container exited with a non-zero exit code 143. its missing the region name which is in the root exception, regiontoobusyexception \u2013 we just skip it. ",
        "label": 314
    },
    {
        "text": "print gc option in hbase env sh affects hbase zkcli  i un-commented the -verbose:gc option in hbase-env.sh, which print out the gc info.  but when i use hbase zkcli to check zk, it can not connect to the server.  the problem is zkcli uses \"hbase org.apache.hadoop.hbase.zookeeper.zookeepermainserverarg\" to get the server_arg in the script hbase. when gc verbose option is open, the output of zookeepermainserverarg is with gc info, which masses up with server_arg. and this is the reason stop zkcli working.  i think the easiest way to fix this is to trim the gc info out of server_arg in the hbase script. ",
        "label": 125
    },
    {
        "text": "convert  meta  and  root  content to pb  ",
        "label": 155
    },
    {
        "text": "hadoopqa doing false positives  https://builds.apache.org/job/precommit-hbase-build/16930/consoletext says:  +1 core tests. the patch passed unit tests in . ...but here is what happened: ... results : tests in error:  org.apache.hadoop.hbase.regionserver.testrsstatusservlet.testbasic(org.apache.hadoop.hbase.regionserver.testrsstatusservlet)   run 1: testrsstatusservlet.testbasic:105 \ufffd nullpointer   run 2: testrsstatusservlet.testbasic:105 \ufffd nullpointer   run 3: testrsstatusservlet.testbasic:105 \ufffd nullpointer org.apache.hadoop.hbase.regionserver.testrsstatusservlet.testwithregions(org.apache.hadoop.hbase.regionserver.testrsstatusservlet)   run 1: testrsstatusservlet.testwithregions:119 \ufffd nullpointer   run 2: testrsstatusservlet.testwithregions:119 \ufffd nullpointer   run 3: testrsstatusservlet.testwithregions:119 \ufffd nullpointer tests run: 1033, failures: 0, errors: 2, skipped: 21 ... [info] apache hbase - server ............................. failure [17:54.559s] ... why we reporting pass when it failed? ",
        "label": 314
    },
    {
        "text": "testipv6nioserversocketchannel testserversocketfromlocalhostresolution can hang indefinetly  should have a timeout on this test at least. stuck here: \"main\" #1 prio=5 os_prio=0 tid=0x00007f3f9c008000 nid=0xca97 runnable [0x00007f3fa2e8c000]    java.lang.thread.state: runnable         at org.apache.hadoop.hbase.hbasetestingutility$portallocator.randomfreeport(hbasetestingutility.java:3500)         at org.apache.hadoop.hbase.hbasetestingutility.randomfreeport(hbasetestingutility.java:3450)         at org.apache.hadoop.hbase.testipv6nioserversocketchannel.bindserversocket(testipv6nioserversocketchannel.java:57)         at org.apache.hadoop.hbase.testipv6nioserversocketchannel.testserversocketfromlocalhostresolution(testipv6nioserversocketchannel.java:151)         at sun.reflect.nativemethodaccessorimpl.invoke0(native method)         at sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:62)         at sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43)         at java.lang.reflect.method.invoke(method.java:497)         at org.junit.runners.model.frameworkmethod$1.runreflectivecall(frameworkmethod.java:50)         at org.junit.internal.runners.model.reflectivecallable.run(reflectivecallable.java:12)         at org.junit.internal.runners.statements.invokemethod.evaluate(invokemethod.java:17)         at org.junit.runners.parentrunner.runleaf(parentrunner.java:325)         at org.junit.runners.blockjunit4classrunner.runchild(blockjunit4classrunner.java:78)         at org.junit.runners.blockjunit4classrunner.runchild(blockjunit4classrunner.java:57)         at org.junit.runners.parentrunner$3.run(parentrunner.java:290)         at org.junit.runners.parentrunner$1.schedule(parentrunner.java:71)         at org.junit.runners.parentrunner.runchildren(parentrunner.java:288)         at org.junit.runners.parentrunner.access$000(parentrunner.java:58)         at org.junit.runners.parentrunner$2.evaluate(parentrunner.java:268)         at org.junit.runners.parentrunner.run(parentrunner.java:363)         at org.junit.runners.suite.runchild(suite.java:128)         at org.junit.runners.suite.runchild(suite.java:27)         at org.junit.runners.parentrunner$3.run(parentrunner.java:290)         at org.junit.runners.parentrunner$1.schedule(parentrunner.java:71)         at org.junit.runners.parentrunner.runchildren(parentrunner.java:288)         at org.junit.runners.parentrunner.access$000(parentrunner.java:58)         at org.junit.runners.parentrunner$2.evaluate(parentrunner.java:268)         at org.junit.runners.parentrunner.run(parentrunner.java:363)         at org.junit.runner.junitcore.run(junitcore.java:137)         at org.junit.runner.junitcore.run(junitcore.java:115)         at org.apache.maven.surefire.junitcore.junitcorewrapper.createrequestandrun(junitcorewrapper.java:108)         at org.apache.maven.surefire.junitcore.junitcorewrapper.executeeager(junitcorewrapper.java:78)         at org.apache.maven.surefire.junitcore.junitcorewrapper.execute(junitcorewrapper.java:54)         at org.apache.maven.surefire.junitcore.junitcoreprovider.invoke(junitcoreprovider.java:144)         at org.apache.maven.surefire.booter.forkedbooter.invokeproviderinsameclassloader(forkedbooter.java:203)         at org.apache.maven.surefire.booter.forkedbooter.runsuitesinprocess(forkedbooter.java:155)         at org.apache.maven.surefire.booter.forkedbooter.main(forkedbooter.java:103) ",
        "label": 198
    },
    {
        "text": "hbck for amv2  a k a hbck2   we don't have an hbck for the new am. old hbck may actually do damage going against amv2. fix. ",
        "label": 459
    },
    {
        "text": "oldwals not cleared in a replication slave cluster  cyclic replication bw clusters   when a cluster is passive (receiving edits only via replication) in a cyclic replication setup of 2 clusters, oldwals size keeps on growing. on analysing, we observed the following behaviour. 1. new entry is added to wal (edit replicated from other cluster). 2. replicationsourcewalreaderthread(rswalrt) reads and applies the configured filters (due to cyclic replication setup, clustermarkingentryfilter discards new entry from other cluster). 3. entry is null, rswalrt neither updates the batch stats (walentrybatch.lastwalposition) nor puts it in the entrybatchqueue. 4. replicationsource thread is blocked in entrybachqueue.take(). 5. so replicationsource#updatelogposition has never invoked and wal file is never cleared from replicationqueue. 6. hence logcleaner on the master, doesn't deletes the oldwal files from hadoop. note: when a new edit is added via hbase-client, replicationsource thread process and clears the oldwal files from replication queues and hence master cleans up the wals please provide us a solution   ",
        "label": 486
    },
    {
        "text": "last flushed sequence id is ignored by servermanager  i got lots of error messages like this: 2014-05-22 08:58:59,793 debug [rpcserver.handler=1,port=20020] master.servermanager: regionserver a2428.halxg.cloudera.com,20020,1400742071109 indicates a last flushed sequence id (numberofstores=9, numberofstorefiles=2, storefileuncompressedsizemb=517, storefilesizemb=517, compressionratio=1.0000, memstoresizemb=0, storefileindexsizemb=0, readrequestscount=0, writerequestscount=0, rootindexsizekb=34, totalstaticindexsizekb=381, totalstaticbloomsizekb=0, totalcompactingkvs=0, currentcompactedkvs=0, compactionprogresspct=nan) that is less than the previous last flushed sequence id (605446) for region integrationtestbiglinkedlist, \ufffda\ufffd\ufffd*t\ufffd^fu\ufffd2\ufffd\ufffd0,1400740489477.a44d3e309b5a7e29355f6faa0d3a4095. ignoring. regionload.tostring doesn't print out the last flushed sequence id passed in. why is it less than the previous one? ",
        "label": 98
    },
    {
        "text": "incorrect warning in splitlogmanager  because of recently added behavior - where the splitlogmanager timeout thread get's data from zk node just to check that the zk node is there ... we might have multiple watches firing without the task znode expiring. remove the poor warning message. (internally, there was an assert that failed in mikhail's tests) ",
        "label": 356
    },
    {
        "text": "move hstore key java into o a h h store  per jim's suggestions on hbase-419, let's move all the store-related files into a subpackage. it should either be o.a.h.h.store or o.a.h.h.regionserver.store. if we push it down another level, i think that we should make sure we never use any of those files outside of o.a.h.h.regionserver. ",
        "label": 241
    },
    {
        "text": "add per column family data block cache hit ratios  in addition to the overall block cache hit ratio it would be extremely useful to have per-column-family data block cache hit ratio metrics. ",
        "label": 155
    },
    {
        "text": "heap fragmentation in region server  stop-the-world gc pauses have long been a problem in hbase. \"concurrent mode failures\" can usually be tuned around by setting the initiating occupancy fraction low, but eventually the heap becomes fragmented and a promotion failure occurs. this jira is to do research/experiments about the heap fragmentation issue and possible solutions. ",
        "label": 453
    },
    {
        "text": "doubly assigned regions redux  testing, i see doubly assigned regions. below is from master log for testtable,0000135598,1230761605500. 2008-12-31 22:13:35,528 [ipc server handler 2 on 60000] info org.apache.hadoop.hbase.master.servermanager: received msg_report_split: testtable,0000116170,1230761152219: testtable,0000116170,1230761152219 split; daughters: testtable,0000116170,1230761605500, testtable,0000135598,1230761605500 from xx.xx.xx.142:60020 2008-12-31 22:13:35,528 [ipc server handler 2 on 60000] info org.apache.hadoop.hbase.master.regionmanager: assigning region testtable,0000135598,1230761605500 to server xx.xx.xx.142:60020 2008-12-31 22:13:38,561 [ipc server handler 6 on 60000] info org.apache.hadoop.hbase.master.servermanager: received msg_report_open: testtable,0000135598,1230761605500 from xx.xx.xx.142:60020 2008-12-31 22:13:38,562 [hmaster] info org.apache.hadoop.hbase.master.processregionopen$1: testtable,0000135598,1230761605500 open on xx.xx.xx.142:60020 2008-12-31 22:13:38,562 [hmaster] info org.apache.hadoop.hbase.master.processregionopen$1: updating row testtable,0000135598,1230761605500 in region .meta.,,1 with startcode 1230759988953 and server xx.xx.xx.142:60020 2008-12-31 22:13:44,640 [ipc server handler 4 on 60000] debug org.apache.hadoop.hbase.master.regionmanager: going to close region testtable,0000135598,1230761605500 2008-12-31 22:13:50,441 [ipc server handler 9 on 60000] info org.apache.hadoop.hbase.master.regionmanager: assigning region testtable,0000135598,1230761605500 to server xx.xx.xx.139:60020 2008-12-31 22:13:53,457 [ipc server handler 5 on 60000] info org.apache.hadoop.hbase.master.servermanager: received msg_report_process_open: testtable,0000135598,1230761605500 from xx.xx.xx.139:60020 2008-12-31 22:13:53,458 [ipc server handler 5 on 60000] info org.apache.hadoop.hbase.master.servermanager: received msg_report_open: testtable,0000135598,1230761605500 from xx.xx.xx.139:60020 2008-12-31 22:13:53,458 [hmaster] info org.apache.hadoop.hbase.master.processregionopen$1: testtable,0000135598,1230761605500 open on xx.xx.xx.139:60020 2008-12-31 22:13:53,458 [hmaster] info org.apache.hadoop.hbase.master.processregionopen$1: updating row testtable,0000135598,1230761605500 in region .meta.,,1 with startcode 1230759988788 and server xx.xx.xx.139:60020 2008-12-31 22:13:53,688 [ipc server handler 6 on 60000] info org.apache.hadoop.hbase.master.servermanager: received msg_report_close: testtable,0000135598,1230761605500 from xx.xx.xx.142:60020 2008-12-31 22:13:53,688 [hmaster] debug org.apache.hadoop.hbase.master.hmaster: processing todo: processregionclose of testtable,0000135598,1230761605500, false 2008-12-31 22:13:54,263 [ipc server handler 7 on 60000] info org.apache.hadoop.hbase.master.regionmanager: assigning region testtable,0000135598,1230761605500 to server xx.xx.xx.141:60020 2008-12-31 22:13:57,273 [ipc server handler 9 on 60000] info org.apache.hadoop.hbase.master.servermanager: received msg_report_process_open: testtable,0000135598,1230761605500 from xx.xx.xx.141:60020 2008-12-31 22:14:03,917 [ipc server handler 0 on 60000] info org.apache.hadoop.hbase.master.servermanager: received msg_report_open: testtable,0000135598,1230761605500 from xx.xx.xx.141:60020 2008-12-31 22:14:03,917 [hmaster] info org.apache.hadoop.hbase.master.processregionopen$1: testtable,0000135598,1230761605500 open on xx.xx.xx.141:60020 2008-12-31 22:14:03,918 [hmaster] info org.apache.hadoop.hbase.master.processregionopen$1: updating row testtable,0000135598,1230761605500 in region .meta.,,1 with startcode 1230759989031 and server xx.xx.xx.141:60020 2008-12-31 22:14:29,350 [regionmanager.metascanner] debug org.apache.hadoop.hbase.master.basescanner: testtable,0000135598,1230761605500 no longer has references to testtable,0000116170,1230761152219 see how we choose to assign before we get the close back from the regionserver. ",
        "label": 241
    },
    {
        "text": "won't when storefile   2g  was   won't split under load   looks like a new bug where we won't split when under load. some recent refactoring seems to have dropped our split provoker. ",
        "label": 314
    },
    {
        "text": "add support for scan filters in thrift2  with hbase 0.94 a new thrift api was added (thrift2). this api is more akin to the java hbase api. thrift (version1) had added filterstring to the tscan struct as part of hbase release 0.92 . thrift2 tscan object doesn't have filterstring parameter. hence executing server side filters using thrift2 api is currently not possible. it would be great to have filtering capabilities added to tscan struct in thrift2 as well to maintain feature compatibility between two thrift versions. ",
        "label": 285
    },
    {
        "text": "make use of clusterstatuslistener for async client  ",
        "label": 149
    },
    {
        "text": "import tools should use a combiner to merge puts  multiple puts to the same row should be combined into a single mutation object. this can be done with a combiner. import.importer#writeresult appears to do this manually. ",
        "label": 339
    },
    {
        "text": "when split doing offlineparentinmeta encounters error  it'll cause data loss  follow below steps to replay the problem:  1. change the splittransaction.java as below,just like mock the timeout error. splittransaction.java       if (!testing) {         metaeditor.offlineparentinmeta(server.getcatalogtracker(),            this.parent.getregioninfo(), a.getregioninfo(), b.getregioninfo());         throw new ioexception(\"some unexpected error in split\");       }     2. update the regionserver code,restart;  3. create a table & put some data to the table;  4. split the table;  5. kill the regionserver hosted the table;  6. wait some time after master servershutdownhandler.process execute,then scan the table,u'll find the data wrote before lost. we can fix the bug just use the patch. ",
        "label": 519
    },
    {
        "text": "hbase breaks builtingzipdecompressor on hadoop   x  from some friends of ours at dropbox: index: src/main/java/org/apache/hadoop/hbase/io/hfile/compression.java  ===================================================================  \u2014 src/main/java/org/apache/hadoop/hbase/io/hfile/compression.java (revision 1425723)  +++ src/main/java/org/apache/hadoop/hbase/io/hfile/compression.java (working copy)  @@ -33,6 +33,7 @@  import org.apache.hadoop.io.compress.compressionoutputstream;  import org.apache.hadoop.io.compress.compressor;  import org.apache.hadoop.io.compress.decompressor;  +import org.apache.hadoop.io.compress.donotpool;  import org.apache.hadoop.io.compress.gzipcodec;  import org.apache.hadoop.io.compress.defaultcodec;  import org.apache.hadoop.util.reflectionutils;  @@ -308,6 +309,9 @@  public void returndecompressor(decompressor decompressor) {  if (decompressor != null) {  codecpool.returndecompressor(decompressor);  + if (decompressor.getclass().isannotationpresent(donotpool.class)) { + decompressor.end(); + } }  } breaks compatibility with hadoop-0.20.2-cdh3u2.   +import org.apache.hadoop.io.compress.donotpool;  does not exist in that version of hadoop. ",
        "label": 441
    },
    {
        "text": "region server not exiting after failing  if a region server was overloaded, the process never exists. also, this causes an hbase shutdown to wait indefinitely (as called from the shell script). this is the thread dump from the regionserver:  --------------------------------------------  full thread dump java hotspot(tm) 64-bit server vm (1.5.0_14-b03 mixed mode): \"ipc server handler 9 on 60020\" daemon prio=1 tid=0x00002aab1c29eb40 nid=0x45db waiting on condition [0x0000000042835000..0x0000000042835c80]  at sun.misc.unsafe.park(native method)  at java.util.concurrent.locks.locksupport.park(locksupport.java:118)  at java.util.concurrent.locks.abstractqueuedsynchronizer.parkandcheckinterrupt(abstractqueuedsynchronizer.java:716)  at java.util.concurrent.locks.abstractqueuedsynchronizer.acquirequeued(abstractqueuedsynchronizer.java:746)  at java.util.concurrent.locks.abstractqueuedsynchronizer.acquire(abstractqueuedsynchronizer.java:1076)  at java.util.concurrent.locks.reentrantlock$nonfairsync.lock(reentrantlock.java:184)  at java.util.concurrent.locks.reentrantlock.lock(reentrantlock.java:256)  at org.apache.hadoop.hbase.hlog.rollwriter(hlog.java:219)  at org.apache.hadoop.hbase.hlog.append(hlog.java:390) locked <0x00002aaab70634d0> (a java.lang.integer)  at org.apache.hadoop.hbase.hregion.update(hregion.java:1602)  at org.apache.hadoop.hbase.hregion.batchupdate(hregion.java:1405)  at org.apache.hadoop.hbase.hregionserver.batchupdate(hregionserver.java:1544)  at sun.reflect.generatedmethodaccessor5.invoke(unknown source)  at sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:25)  at java.lang.reflect.method.invoke(method.java:585)  at org.apache.hadoop.hbase.ipc.hbaserpc$server.call(hbaserpc.java:413)  at org.apache.hadoop.ipc.server$handler.run(server.java:901) \"regionserver/0:0:0:0:0:0:0:0:60020.cacheflusher\" daemon prio=1 tid=0x00002aab1c1cb800 nid=0x45c8 waiting for monitor entry [0x0000000041522000..0x0000000041522b00]  at org.apache.hadoop.hbase.hlog.completecacheflush(hlog.java:481) waiting to lock <0x00002aaab70634d0> (a java.lang.integer)  at org.apache.hadoop.hbase.hregion.internalflushcache(hregion.java:1103)  at org.apache.hadoop.hbase.hregion.flushcache(hregion.java:998)  at org.apache.hadoop.hbase.hregionserver$flusher.flushregion(hregionserver.java:447) locked <0x00002aaab70681f8> (a java.util.hashset)  at org.apache.hadoop.hbase.hregionserver$flusher.run(hregionserver.java:390) \"regionserver/0:0:0:0:0:0:0:0:60020.logroller\" daemon prio=1 tid=0x00002aab1c1cc2b0 nid=0x45c7 waiting on condition [0x0000000041421000..0x0000000041421a80]  at sun.misc.unsafe.park(native method)  at java.util.concurrent.locks.locksupport.park(locksupport.java:118)  at java.util.concurrent.locks.abstractqueuedsynchronizer.parkandcheckinterrupt(abstractqueuedsynchronizer.java:716)  at java.util.concurrent.locks.abstractqueuedsynchronizer.acquirequeued(abstractqueuedsynchronizer.java:746)  at java.util.concurrent.locks.abstractqueuedsynchronizer.acquire(abstractqueuedsynchronizer.java:1076)  at java.util.concurrent.locks.reentrantlock$nonfairsync.lock(reentrantlock.java:184)  at java.util.concurrent.locks.reentrantlock.lock(reentrantlock.java:256)  at org.apache.hadoop.hbase.hlog.rollwriter(hlog.java:219)  at org.apache.hadoop.hbase.hregionserver$logroller.run(hregionserver.java:618) locked <0x00002aaab70632b8> (a java.lang.integer) \"org.apache.hadoop.dfs.dfsclient$leasechecker@353c375\" daemon prio=1 tid=0x00002aab1c0893c0 nid=0x45c5 waiting on condition [0x000000004121f000..0x000000004121fd80]  at java.lang.thread.sleep(native method)  at org.apache.hadoop.dfs.dfsclient$leasechecker.run(dfsclient.java:605)  at java.lang.thread.run(thread.java:595) \"org.apache.hadoop.io.objectwritable connection culler\" daemon prio=1 tid=0x00002aab1c10ad00 nid=0x45c3 waiting on condition [0x000000004101d000..0x000000004101dc80]  at java.lang.thread.sleep(native method)  at org.apache.hadoop.ipc.client$connectionculler.run(client.java:423) \"org.apache.hadoop.hbase.io.hbaseobjectwritable connection culler\" daemon prio=1 tid=0x000000005093f200 nid=0x45b5 waiting on condition [0x0000000040e1b000..0x0000000040e1bc80]  at java.lang.thread.sleep(native method)  at org.apache.hadoop.ipc.client$connectionculler.run(client.java:423) \"destroyjavavm\" prio=1 tid=0x00002aab1c00d930 nid=0x458f waiting on condition [0x0000000000000000..0x00007fff1680e7f0] \"regionserver/0:0:0:0:0:0:0:0:60020\" prio=1 tid=0x00002aab1c00dfe0 nid=0x45b4 waiting for monitor entry [0x0000000040d1a000..0x0000000040d1ac00]  at org.apache.hadoop.hbase.hregionserver.run(hregionserver.java:867) waiting to lock <0x00002aaab70632b8> (a java.lang.integer)  at java.lang.thread.run(thread.java:595) \"low memory detector\" daemon prio=1 tid=0x00000000505e9c90 nid=0x45b2 runnable [0x0000000000000000..0x0000000000000000] \"compilerthread1\" daemon prio=1 tid=0x00000000505e8060 nid=0x45b1 waiting on condition [0x0000000000000000..0x0000000040a16360] \"compilerthread0\" daemon prio=1 tid=0x00000000505e6ab0 nid=0x45b0 waiting on condition [0x0000000000000000..0x00000000409156e0] \"adapterthread\" daemon prio=1 tid=0x00000000505e5350 nid=0x45af waiting on condition [0x0000000000000000..0x0000000000000000] \"signal dispatcher\" daemon prio=1 tid=0x00000000505e4070 nid=0x45ae runnable [0x0000000000000000..0x0000000000000000] \"finalizer\" daemon prio=1 tid=0x00000000505cfef0 nid=0x45ad in object.wait() [0x0000000040613000..0x0000000040613c80]  at java.lang.object.wait(native method) waiting on <0x00002aaab70bc3d8> (a java.lang.ref.referencequeue$lock)  at java.lang.ref.referencequeue.remove(referencequeue.java:120) locked <0x00002aaab70bc3d8> (a java.lang.ref.referencequeue$lock)  at java.lang.ref.referencequeue.remove(referencequeue.java:136)  at java.lang.ref.finalizer$finalizerthread.run(finalizer.java:159) \"reference handler\" daemon prio=1 tid=0x00000000505cf6c0 nid=0x45ac in object.wait() [0x0000000040512000..0x0000000040512c00]  at java.lang.object.wait(native method) waiting on <0x00002aaab70b3ac8> (a java.lang.ref.reference$lock)  at java.lang.object.wait(object.java:474)  at java.lang.ref.reference$referencehandler.run(reference.java:116) locked <0x00002aaab70b3ac8> (a java.lang.ref.reference$lock) \"vm thread\" prio=1 tid=0x00000000505cb1d0 nid=0x45ab runnable \"gc task thread#0 (parallelgc)\" prio=1 tid=0x000000005051e4d0 nid=0x45a9 runnable \"gc task thread#1 (parallelgc)\" prio=1 tid=0x000000005051f350 nid=0x45aa runnable \"vm periodic task thread\" prio=1 tid=0x0000000050515430 nid=0x45b3 waiting on condition ",
        "label": 241
    },
    {
        "text": "meta migration from to trunk fails  i started a trunk cluster as an upgrade from 0.90.4ish, and now i can't scan my .meta. table, etc, and other operations fail. ",
        "label": 428
    },
    {
        "text": "race in tablename cache  testing 0.96.1rc1. with one process incrementing a row in a table, we increment single col. we flush or do kills/kill-9 and data is lost. flush and kill are likely the same problem (kill would flush), kill -9 may or may not have the same root cause. 5 nodes  hadoop 2.1.0 (a pre cdh5b1 hdfs).  hbase 0.96.1 rc1 test: 250000 increments on a single row an single col with various number of client threads (incrementblaster). verify we have a count of 250000 after the run (incrementverifier). run 1: no fault injection. 5 runs. count = 250000. on multiple runs. correctness verified. 1638 inc/s throughput.  run 2: flushes table with incrementing row. count = 246875 !=250000. correctness failed. 1517 inc/s throughput.   run 3: kill of rs hosting incremented row. count = 243750 != 250000. correctness failed. 1451 inc/s throughput.  run 4: one kill -9 of rs hosting incremented row. 246878.!= 250000. correctness failed. 1395 inc/s (including recovery) ",
        "label": 248
    },
    {
        "text": "make sure we clean up scannerreadpoints upon any exceptions  if there is an exception in the creation of regionscanner (for example, exception while opening store files) the scanner read points is not cleaned up. having an unused old entry in the scannerreadpoints means that flushes and compactions cannot garbage-collect older versions. ",
        "label": 34
    },
    {
        "text": "if rs can't talk to master  pause  more importantly  don't split  currently we do and splits are lost and table is wounded   what i saw was master shutting itself down because it had lost zk lease. fine. the rs though doesn't look like it can deal with this situation. we'll see stuff like this: ...failed on connection exception: java.net.connectexception: connection refused     at org.apache.hadoop.hbase.ipc.hbaseclient.wrapexception(hbaseclient.java:744)     at org.apache.hadoop.hbase.ipc.hbaseclient.call(hbaseclient.java:722)     at org.apache.hadoop.hbase.ipc.hbaserpc$invoker.invoke(hbaserpc.java:328)     at $proxy0.regionserverreport(unknown source)     at org.apache.hadoop.hbase.regionserver.hregionserver.run(hregionserver.java:470)     at java.lang.thread.run(unknown source) caused by: java.net.connectexception: connection refused     at sun.nio.ch.socketchannelimpl.checkconnect(native method)     at sun.nio.ch.socketchannelimpl.finishconnect(unknown source)     at org.apache.hadoop.net.socketiowithtimeout.connect(socketiowithtimeout.java:206)     at org.apache.hadoop.net.netutils.connect(netutils.java:404)     at org.apache.hadoop.hbase.ipc.hbaseclient$connection.setupiostreams(hbaseclient.java:305)     at org.apache.hadoop.hbase.ipc.hbaseclient.getconnection(hbaseclient.java:826)     at org.apache.hadoop.hbase.ipc.hbaseclient.call(hbaseclient.java:707)     ... 4 more ... all over the regionserver as it tries to send heartbeat to master on this broken connection. on split, we close parent, add children to the catalog but then when we try to tell the master about the split, it fails. means the children never get deployed. meantime the parent is offline. this issue is about going through the regionserver and anytime it has a connection to master, make sure on fault that no damage is done the table and then that the regionserver puts a pause on splitting. ",
        "label": 314
    },
    {
        "text": "reenable testmultiparallel testactivethreadscount  it was disabled in hbase-14642, this issue should reenable it. ",
        "label": 198
    },
    {
        "text": "upgrade jaxws ri dependency to  the 2.3.1 depends on some legacy libraries so let's upgrade it. ",
        "label": 391
    },
    {
        "text": "remove bypass method in observercontext and implement the 'bypass' logic case by case  http://search-hadoop.com/m/hbase/ygbbxd0rdcihsc1 ",
        "label": 314
    },
    {
        "text": "regionservermetricswrapperrunnable misused the 'period' parameter  the 'period' parameter in regionservermetricswrapperrunnable is in millisecond. when initializing the 'lastran' parameter, the original code misused the 'period' as in second. ",
        "label": 466
    },
    {
        "text": "set 'hbase bulkload retries number' to as hbase claims  hbase-8450 claimes 'hbase.bulkload.retries.number' is set to 10 when its still 0 (jeffrey zhong noticed). fix. ",
        "label": 314
    },
    {
        "text": "forward port hbase 'region was hijacked and remained in transition when rs failed to open a region and later regionplan changed to new rs on retry'  hbase-14207 was integrated to 0.98 however, for hbase 1.x where zookeeper is involved in region assignment, the fix from hbase-14207 applies. hbase-14207 has been closed. so opening a new jira for forward porting. ",
        "label": 441
    },
    {
        "text": "htable coprocessorexec  and possibly coprocessorproxy  does not work with dynamically loaded coprocessors  from hdfs or local system  because the rpc system tries to deserialize an unknown class   loading coprocessors jars from hdfs works fine. i load it from the shell, after setting the attribute, and it gets loaded: info org.apache.hadoop.hbase.regionserver.hregion: setting up tabledescriptor config now ... info org.apache.hadoop.hbase.coprocessor.coprocessorhost: class com.mycoprocessorclass needs to be loaded from a file - hdfs://localhost:9000/coproc/rt-      >0.0.1-snapshot.jar. info org.apache.hadoop.hbase.coprocessor.coprocessorhost: loadinstance: com.mycoprocessorclass info org.apache.hadoop.hbase.regionserver.regioncoprocessorhost: regionenvironment createenvironment debug org.apache.hadoop.hbase.regionserver.hregion: registered protocol handler: region=t1,,1322572939753.6409aee1726d31f5e5671a59fe6e384f. protocol=com.mycoprocessorclassprotocol info org.apache.hadoop.hbase.regionserver.regioncoprocessorhost: load coprocessor com.mycoprocessorclass from htd of t1 successfully. the problem is that this coprocessors simply extends baseendpointcoprocessor, with a dynamic method. when calling this method from the client with htable.coprocessorexec, i get errors on the hregionserver, because the call cannot be deserialized from writables. the problem is that exec tries to do an \"early\" resolve of the coprocessor class. the coprocessor class is loaded, but it is in the context of the hregionserver / hregion. so, the call fails: 2011-12-02 00:34:17,348 error org.apache.hadoop.hbase.io.hbaseobjectwritable: error in readfields java.io.ioexception: protocol class com.mycoprocessorclassprotocol not found   at org.apache.hadoop.hbase.client.coprocessor.exec.readfields(exec.java:125)   at org.apache.hadoop.hbase.io.hbaseobjectwritable.readobject(hbaseobjectwritable.java:575)   at org.apache.hadoop.hbase.ipc.invocation.readfields(invocation.java:105)   at org.apache.hadoop.hbase.ipc.hbaseserver$connection.processdata(hbaseserver.java:1237)   at org.apache.hadoop.hbase.ipc.hbaseserver$connection.readandprocess(hbaseserver.java:1167)   at org.apache.hadoop.hbase.ipc.hbaseserver$listener.doread(hbaseserver.java:703)   at org.apache.hadoop.hbase.ipc.hbaseserver$listener$reader.dorunloop(hbaseserver.java:495)   at org.apache.hadoop.hbase.ipc.hbaseserver$listener$reader.run(hbaseserver.java:470)   at java.util.concurrent.threadpoolexecutor$worker.runtask(threadpoolexecutor.java:886)   at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:908)   at java.lang.thread.run(thread.java:680) caused by: java.lang.classnotfoundexception: com.mycoprocessorclassprotocol   at java.net.urlclassloader$1.run(urlclassloader.java:202)   at java.security.accesscontroller.doprivileged(native method)   at java.net.urlclassloader.findclass(urlclassloader.java:190)   at java.lang.classloader.loadclass(classloader.java:306)   at sun.misc.launcher$appclassloader.loadclass(launcher.java:301)   at java.lang.classloader.loadclass(classloader.java:247)   at java.lang.class.forname0(native method)   at java.lang.class.forname(class.java:247)   at org.apache.hadoop.conf.configuration.getclassbyname(configuration.java:943)   at org.apache.hadoop.hbase.client.coprocessor.exec.readfields(exec.java:122)   ... 10 more probably the correct way to fix this is to make exec really smart, so that it knows all the class definitions loaded in coprocessorhost(s). i created a small patch that simply doesn't resolve the class definition in the exec, instead passing it as string down to the hregion layer. this layer knows all the definitions, and simply loads it by name. ",
        "label": 37
    },
    {
        "text": "fix licenses on the branch   there are a handful of empty files and several files missing apache licenses on the 0.90 branch. this patch will fixes all of them and in conjunction with hbase-5363 will allow it to pass rat tests. ",
        "label": 248
    },
    {
        "text": "alter table operation and also related changes in rest interface  i have made some changes to the alter operation on the hbase shell.  now we can add, update, delete the column families. also, make the  changes to the tablehandler in rest interface. changes to the hbase shell: > alter 'table', {name => 'cf', versions => 3} this command will try to find the column family named 'cf' at first.  if has, it will modifycolumn, if not, add the column > alter 'table', {name => 'cf', 'method' => 'delete'} this command will delete the column family named 'cf'. to achieve this goal, i also add a method to the hbaseadmin.java public tabledescriptor gettabledescriptor(byte[] tablename); changes to the tablehandler in rest interface. > curl -x put -t - http://localhost:60050/api/tablename <?xml version=\"1.0\" encoding=\"utf-8\"?>  <table>  <name>tables</name>  <columnfamilies>  <columnfamily>  <name>cf1</name>  <max-versions>2</max-versions>  <compression>none</compression>  <in-memory>false</in-memory>  <block-cache>true</block-cache>  </columnfamily>  </columnfamilies>  </table> it will check the column family 'cf1'. if exists, modifycolumn, if  not, addcolumn > curl -x delete http://localhost:60050/api/tablename?column=cf1 it will deletecolumn 'cf1'. ",
        "label": 549
    },
    {
        "text": "remove the hstorefile 'info' file  and index and bloomfilter if possible   hstorefiles comprise a mapfile of data and index and then a companion info file that has the sequence id for the edits that comprise the file. lets remove this info file. put the sequence id into the filename of the mapfile or into the metadata in a tfile. ",
        "label": 314
    },
    {
        "text": "expose per region request rate metrics  we currently export metrics on request rates for each region server, and this can help with identifying uneven load at a high level. but once you see a given server under high load, you're forced to extrapolate based on your application patterns and the data it's serving what the likely culprit is. this can and should be much easier if we just exported request rate metrics per-region on each server. dynamically updating the metrics keys based on assigned regions may pose some minor challenges, but this seems a very valuable diagnostic tool to have available. ",
        "label": 154
    },
    {
        "text": "integrate rwcc with append and increment operations  currently increment and append operations do not work with rwcc and hence a client could see the results of multiple such operation mixed in the same get/scan.  the semantics might be a bit more interesting here as upsert adds and removes to and from the memstore. ",
        "label": 286
    },
    {
        "text": "wal unflushed seqid tracking may wrong when durability async wal is used  durability.async_wal do not wait wal sync and commit mvcc ahead. so when region start flush may get a large flushedseqid and later wal process buffer entry and put a small unflushedsequenceids for this region again. ",
        "label": 149
    },
    {
        "text": "verify the files when regionserver is starting and bucketcache is in file mode  we use fileioengine in bucketcache and have configured <hbase.bucketcache.persistent.path>.  if the regionserver is stopped, and the cache data file or the backingmap persistence file is deleted or changed before the regionserver is restarted. when restart regionserver, the backingmap and cache data are inconsistent, and get or scan command will get ioexception like follows: bucket.bucketcache: failed reading block 18951416e2ca4e8bbc11523f4f5ea576_1125745279 from bucket cache  java.io.ioexception: invalid hfile block magic: \\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00  at org.apache.hadoop.hbase.io.hfile.blocktype.parse(blocktype.java:154)  at org.apache.hadoop.hbase.io.hfile.blocktype.read(blocktype.java:167)  at org.apache.hadoop.hbase.io.hfile.hfileblock.<init>(hfileblock.java:347)  at org.apache.hadoop.hbase.io.hfile.hfileblock$1.deserialize(hfileblock.java:247)  at org.apache.hadoop.hbase.io.hfile.hfileblock$1.deserialize(hfileblock.java:226)  at org.apache.hadoop.hbase.io.hfile.bucket.bucketcache.getblock(bucketcache.java:514) ...... ",
        "label": 59
    },
    {
        "text": "close hlog  and open new one  if there hasnt been edits in n minutes hours  this will help narrow the write hole on clusters with periods of light load. ",
        "label": 314
    },
    {
        "text": "testmastermetrics fails occasionally  latest occurrence was in https://builds.apache.org/job/hbase-trunk/4970 java.io.ioexception: shutting down at org.apache.hadoop.hbase.minihbasecluster.init(minihbasecluster.java:231) at org.apache.hadoop.hbase.minihbasecluster.<init>(minihbasecluster.java:93) at org.apache.hadoop.hbase.hbasetestingutility.startminihbasecluster(hbasetestingutility.java:875) at org.apache.hadoop.hbase.hbasetestingutility.startminicluster(hbasetestingutility.java:839) at org.apache.hadoop.hbase.hbasetestingutility.startminicluster(hbasetestingutility.java:756) at org.apache.hadoop.hbase.hbasetestingutility.startminicluster(hbasetestingutility.java:727) at org.apache.hadoop.hbase.master.testmastermetrics.startcluster(testmastermetrics.java:56) at sun.reflect.nativemethodaccessorimpl.invoke0(native method) at sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:57) at sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43) at java.lang.reflect.method.invoke(method.java:606) at org.junit.runners.model.frameworkmethod$1.runreflectivecall(frameworkmethod.java:47) at org.junit.internal.runners.model.reflectivecallable.run(reflectivecallable.java:12) at org.junit.runners.model.frameworkmethod.invokeexplosively(frameworkmethod.java:44) at org.junit.internal.runners.statements.runbefores.evaluate(runbefores.java:24) at org.junit.internal.runners.statements.runafters.evaluate(runafters.java:27) at org.junit.runners.parentrunner.run(parentrunner.java:309) at org.junit.runners.suite.runchild(suite.java:127) at org.junit.runners.suite.runchild(suite.java:26) at org.junit.runners.parentrunner$3.run(parentrunner.java:238) at java.util.concurrent.executors$runnableadapter.call(executors.java:471) at java.util.concurrent.futuretask$sync.innerrun(futuretask.java:334) at java.util.concurrent.futuretask.run(futuretask.java:166) at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1145) at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:615) at java.lang.thread.run(thread.java:724) caused by: java.lang.runtimeexception: master not initialized after 200000ms seconds at org.apache.hadoop.hbase.util.jvmclusterutil.startup(jvmclusterutil.java:221) at org.apache.hadoop.hbase.localhbasecluster.startup(localhbasecluster.java:425) at org.apache.hadoop.hbase.minihbasecluster.init(minihbasecluster.java:224) ... 25 more ",
        "label": 242
    },
    {
        "text": "rest client  remotehtable  doesn't support binary row keys  the rest server doesn't seem to support using binary (md5 for example) row keys. i believe the root cause of this is the use of bytes.tobytes() in the rowspec.parserowkeys() method. based on the use of bytes.tostringbinary() within remotehtable.buildrowspec(), i believe the converse function bytes.tobytesbinary() should be used for row key parsing in rowspec.parserowkeys(). i also noticed that the remotehtable.buildrowspec() method isn't url encoding the row key, which is a mismatch to the logic in rowspec.parserowkeys() which performs url decoding for both the start and stop row keys. ",
        "label": 271
    },
    {
        "text": "intermittent testiofencing testfencingaroundcompaction failure due to region getting stuck in compaction  from http://54.241.6.143/job/hbase-trunk/org.apache.hbase$hbase-server/348/testreport/junit/org.apache.hadoop.hbase/testiofencing/testfencingaroundcompaction/ (the underlying region is tabletest,,1369855507443.c251a1d71e75fed8e490db63419edcf1.): 2013-05-29 19:25:20,363 debug [pool-1-thread-1] catalog.catalogtracker(208): stopping catalog tracker org.apache.hadoop.hbase.catalog.catalogtracker@6280d069 2013-05-29 19:25:20,366 info  [pool-1-thread-1] hbase.testiofencing(255): waiting for compaction to be about to start 2013-05-29 19:25:20,367 debug [pool-1-thread-1] hbase.testiofencing$compactionblockerregion(107): waiting for compaction to block 2013-05-29 19:25:20,367 debug [pool-1-thread-1] hbase.testiofencing$compactionblockerregion(109): compaction block reached 2013-05-29 19:25:20,367 info  [pool-1-thread-1] hbase.testiofencing(257): starting a new server 2013-05-29 19:25:20,424 debug [pool-1-thread-1] client.hconnectionmanager(2811): regionserver/ip-10-197-74-184.us-west-1.compute.internal/10.197.74.184:0 hconnection server-to-server retries=100 ... 2013-05-29 19:25:20,861 info  [pool-1-thread-1] hbase.testiofencing(260): killing region server zk lease ... 2013-05-29 19:25:21,030 debug [rs_close_region-ip-10-197-74-184.us-west-1.compute.internal,37836,1369855503920-0] handler.closeregionhandler(125): processing close of tabletest,,1369855507443.c251a1d71e75fed8e490db63419edcf1. 2013-05-29 19:25:21,031 debug [rs_close_region-ip-10-197-74-184.us-west-1.compute.internal,37836,1369855503920-0] regionserver.hregion(928): closing tabletest,,1369855507443.c251a1d71e75fed8e490db63419edcf1.: disabling compactions & flushes 2013-05-29 19:25:21,031 debug [rs_close_region-ip-10-197-74-184.us-west-1.compute.internal,37836,1369855503920-0] regionserver.hregion(1022): waiting for 1 compactions to complete for region tabletest,,1369855507443.c251a1d71e75fed8e490db63419edcf1. ... 2013-05-29 19:25:27,037 info  [pool-1-thread-1] hbase.testiofencing(265): waiting for the new server to pick up the region tabletest,,1369855507443.c251a1d71e75fed8e490db63419edcf1. the test started new region server. however, the region got stuck in:   public void waitforflushesandcompactions() {     synchronized (writestate) {       while (writestate.compacting > 0 || writestate.flushing) {         log.debug(\"waiting for \" + writestate.compacting + \" compactions\"             + (writestate.flushing ? \" & cache flush\" : \"\") + \" to complete for region \" + this);         try {           writestate.wait(); this led to the timeout:         asserttrue(\"timed out waiting for new server to open region\",           system.currenttimemillis() - startwaittime < 60000); ",
        "label": 155
    },
    {
        "text": " forward port  verify the file integrity in persistent ioengine  verify the persistent cache file integrity before retrieve from persistence file. ",
        "label": 59
    },
    {
        "text": "hbase common module's class  org apache hadoop hbase io encoding rowindexcodecv1  dataoutputstream is not closed     public bytebuffer decodekeyvalues(datainputstream source,  hfileblockdecodingcontext decodingctx) throws ioexception{...} dataoutputstream is not close after use. //\u4ee3\u7801\u5360\u4f4d\u7b26 else {   rowindexseekerv1 seeker = new rowindexseekerv1(cellcomparatorimpl.comparator,       decodingctx);   seeker.setcurrentbuffer(new singlebytebuff(sourceasbuffer));   list<cell> kvs = new arraylist<>();   kvs.add(seeker.getcell());   while (seeker.next()) {     kvs.add(seeker.getcell());   }   boolean includesmvcc = decodingctx.gethfilecontext().isincludesmvcc();   bytearrayoutputstream baos = new bytearrayoutputstream();   dataoutputstream out = new dataoutputstream(baos);   for (cell cell : kvs) {     keyvalue currentcell = keyvalueutil.copytonewkeyvalue(cell);     out.write(currentcell.getbuffer(), currentcell.getoffset(),         currentcell.getlength());     if (includesmvcc) {       writableutils.writevlong(out, cell.getsequenceid());     }   }   out.flush();   return bytebuffer.wrap(baos.getbuffer(), 0, baos.size()); }     ",
        "label": 559
    },
    {
        "text": "running walperformanceevaluation against asyncfswal throws exceptions  was trying to do a perf eval on asyncfswal. i ran w/ these args:  performance counter stats for '/home/stack/hbase/bin/hbase --config /home/stack/conf_hbase org.apache.hadoop.hbase.wal.walperformanceevaluation -path /user/stack/logs/ -verify -threads 25 -iterations 1000000 -keysize 50 -valuesize 100 -syncinterval 10': the verify fails on all runs: exception in thread \"main\" java.lang.illegalstateexception: counted=12390228, expected=25000000  at org.apache.hadoop.hbase.wal.walperformanceevaluation.run(walperformanceevaluation.java:368) at org.apache.hadoop.util.toolrunner.run(toolrunner.java:76)  at org.apache.hadoop.hbase.wal.walperformanceevaluation.innermain(walperformanceevaluation.java:597) at org.apache.hadoop.hbase.wal.walperformanceevaluation.main(walperformanceevaluation.java:601) i need to fix test or figure what is wrong in asyncfswal. also seeing these when i run w/ one thread only: 2017-11-28 21:25:49,952 warn [asyncfswal-1-1] wal.asyncfswal: ringbuffertruck with unexpected type: empty log has a spew of them. has stuff like this too: 2017-11-28 21:25:40,065 warn [close-wal-writer-3] wal.asyncprotobuflogwriter: normal close failed, try recover java.io.ioexception: stream already broken at org.apache.hadoop.hbase.io.asyncfs.fanoutoneblockasyncdfsoutput.endblock(fanoutoneblockasyncdfsoutput.java:510) at org.apache.hadoop.hbase.io.asyncfs.fanoutoneblockasyncdfsoutput.lambda$close$12(fanoutoneblockasyncdfsoutput.java:550) at org.apache.hadoop.hbase.shaded.io.netty.util.concurrent.abstracteventexecutor.safeexecute(abstracteventexecutor.java:163)  at org.apache.hadoop.hbase.shaded.io.netty.util.concurrent.singlethreadeventexecutor.runalltasks(singlethreadeventexecutor.java:403) at org.apache.hadoop.hbase.shaded.io.netty.channel.nio.nioeventloop.run(nioeventloop.java:462)  at org.apache.hadoop.hbase.shaded.io.netty.util.concurrent.singlethreadeventexecutor$5.run(singlethreadeventexecutor.java:858) at org.apache.hadoop.hbase.shaded.io.netty.util.concurrent.defaultthreadfactory$defaultrunnabledecorator.run(defaultthreadfactory.java:138)  at java.lang.thread.run(thread.java:748) starts out spewing empty here: 2017-11-28 21:16:52,051 info [main] regionserver.hregion: setting flushnonsloppystoresfirstpolicy for the region=walperformanceevaluation:0,,1511932610787.deca03e0ca447fa25d02fe9cd6e31aa4.  2017-11-28 21:16:52,058 debug [main] regionserver.hregion: found 0 recovered edits file(s) under hdfs://ve0524.halxg.cloudera.com:8020/user/stack/logs/data/walperformanceevaluation/0/deca03e0ca447fa25d02fe9cd6e31aa4  2017-11-28 21:16:52,068 debug [main] regionserver.flushlargestorespolicy: no hbase.hregion.percolumnfamilyflush.size.lower.bound set in description of table walperformanceevaluation:0, use config (134217728) instead  2017-11-28 21:16:52,084 debug [main] wal.walsplitter: wrote file=hdfs://ve0524.halxg.cloudera.com:8020/user/stack/logs/data/walperformanceevaluation/0/deca03e0ca447fa25d02fe9cd6e31aa4/recovered.edits/2.seqid, newseqid=2, maxseqid=0  2017-11-28 21:16:52,084 info [main] regionserver.hregion: onlined deca03e0ca447fa25d02fe9cd6e31aa4; next sequenceid=2  2017-11-28 21:16:52,185 warn [asyncfswal-1-1] wal.asyncfswal: ringbuffertruck with unexpected type: empty  2017-11-28 21:16:52,185 warn [asyncfswal-1-1] wal.asyncfswal: ringbuffertruck with unexpected type: empty  2017-11-28 21:16:52,185 warn [asyncfswal-1-1] wal.asyncfswal: ringbuffertruck with unexpected type: empty  2017-11-28 21:16:52,185 warn [asyncfswal-1-1] wal.asyncfswal: ringbuffertruck with unexpected type: empty  2017-11-28 21:16:52,185 warn [asyncfswal-1-1] wal.asyncfswal: ringbuffertruck with unexpected type: empty  2017-11-28 21:16:52,185 warn [asyncfswal-1-1] wal.asyncfswal: ringbuffertruck with unexpected type: empty  2017-11-28 21:16:52,185 warn [asyncfswal-1-1] wal.asyncfswal: ringbuffertruck with unexpected type: empty  ... this is tip of branch-2 minus the commit of the change to the ringbuffer (i'd not pulled in that change). [~apache9] in case you've seen it before else i'll dig in sir. ",
        "label": 149
    },
    {
        "text": " replication  replicationsource's uncaughtexceptionhandler shouldn't join  from jeff whiting on the ml: \"regionserver60020.replicationsource,dev2\" daemon prio=10 tid=0x00002aaaf0312800 nid=0x69f8 in object.wait() [0x000000004533e000]  java.lang.thread.state: timed_waiting (on object monitor)  at java.lang.object.wait(native method) waiting on <0x00002aaab12464c0> (a org.apache.hadoop.hbase.replication.regionserver.replicationsource)  at java.lang.thread.join(thread.java:1151) locked <0x00002aaab12464c0> (a org.apache.hadoop.hbase.replication.regionserver.replicationsource)  at org.apache.hadoop.hbase.util.threads.shutdown(threads.java:91)  at org.apache.hadoop.hbase.replication.regionserver.replicationsource.terminate(replicationsource.java:649)  at org.apache.hadoop.hbase.replication.regionserver.replicationsource$1.uncaughtexception(replicationsource.java:628)  at java.lang.thread.dispatchuncaughtexception(thread.java:1831) that's pretty dumb, the thread is trying to join itself. uncaughtexceptionhandler shouldn't try to terminate() but just clear resources and then return. ",
        "label": 229
    },
    {
        "text": "hbase changed hregion size  testheapsize broke  fix it   both trunk and branch are broke at mo. ",
        "label": 314
    },
    {
        "text": "avoided to call job waitforcompletion true  two times  import.java, job output is printing two times. after job completed, job.waitforcompletion(true) is calling two times. job job = createsubmittablejob(conf, otherargs);     boolean isjobsuccessful = job.waitforcompletion(true);     if(isjobsuccessful){       // flush all the regions of the table       flushregionsifnecessary(conf);     }     long inputrecords = job.getcounters().findcounter(taskcounter.map_input_records).getvalue();     long outputrecords = job.getcounters().findcounter(taskcounter.map_output_records).getvalue();     if (outputrecords < inputrecords) {       system.err.println(\"warning, not all records were imported (maybe filtered out).\");       if (outputrecords == 0) {         system.err.println(\"if the data was exported from hbase 0.94 \"+             \"consider using -dhbase.import.version=0.94.\");       }     }     system.exit(job.waitforcompletion(true) ? 0 : 1); ",
        "label": 226
    },
    {
        "text": "audit of hbase client  interfaceaudience public apis  similar to hbase-9523, let's do an audit of the hbase-client public api. this is easier to do now that the we can publish only the public api javadoc http://hbase.apache.org/apidocs/ (notice it only has public apis now!) ",
        "label": 248
    },
    {
        "text": "and  using filterlist  of two columnprefixfilters broken  [notice this in 89 branch. possibly an issue in trunk also.] a test which does a columnprefixfilter(\"tag0\") and columnprefixfilter(\"tag1\") should return 0 kvs; instead it returns kvs with prefix \"tag0\". table = htable.new(conf, tablename) put = put.new(bytes.tobytes(\"row\")) put.add(cf1name, bytes.tobytes(\"tag0\"), bytes.tobytes(\"value0\")) put.add(cf1name, bytes.tobytes(\"tag1\"), bytes.tobytes(\"value1\")) put.add(cf1name, bytes.tobytes(\"tag2\"), bytes.tobytes(\"value2\")) table.put(put) # test for and two column prefix filters                                                                                                                                                    filter1 = columnprefixfilter.new(bytes.tobytes(\"tag0\")); filter2 = columnprefixfilter.new(bytes.tobytes(\"tag2\")); filters = filterlist.new(filterlist::operator::must_pass_all); filters.addfilter(filter1); filters.addfilter(filter2); get = get.new(bytes.tobytes(\"row\")) get.setfilter(filters) get.setmaxversions(); keyvalues = table.get(get).raw() keyvalues.each do |keyvalue|   puts \"key=#{bytes.tostringbinary(keyvalue.getqualifier())}; value=#{bytes.tostringbinary(keyvalue.getvalue())}; timestamp=#{keyvalue.gettimestamp()}\"  end outputs: key=tag0; value=value0; timestamp=1325719223523 ",
        "label": 300
    },
    {
        "text": "getrow does not always work when specifying number of versions  when a cell that exists is updated, getrow specifying number of versions does not work.  what is returned is the original value at that timestamp, instead of the updated value. note that this only applies when more than one version is specified. getrow with (implied) timestamp = latest does work. ",
        "label": 241
    },
    {
        "text": "mutation getfamilymap  return type change between hbase and breaks downstream apps  in hbase-94, mutation#getfamilymap() had signature:  public map<byte[],list<keyvalue>> getfamilymap() in hbase-96 it is:  public navigablemap<byte[],list<? extends cell>> getfamilymap() i understand this might not be an easy fix or even a possible one - but it breaks downstream apps in a nasty way. if the app needs to process the individual columns, then the whole logic is now different. is there a way to work around this, if this cannot be fixed? ",
        "label": 248
    },
    {
        "text": "add proper privilege check for rsgroup commands  currently list_rsgroups command can be executed by any user. this is inconsistent with other list commands such as list_peers and list_peer_configs. we should add proper privilege check for list_rsgroups command. privilege check should be added for get_table_rsgroup / get_server_rsgroup / get_rsgroup commands. ",
        "label": 188
    },
    {
        "text": "testlocalhbasecluster hangs with hadoop builds   trunk: mvn clean test -dhadoop.profile=2.0 -dtest=testlocalhbasecluster 0.94: mvn clean test -dhadoop.profile=23 -dtest=testlocalhbasecluster testlocalhbasecluster(org.apache.hadoop.hbase.testlocalhbasecluster)  time elapsed: 0.022 sec  <<< error! java.lang.runtimeexception: master not initialized after 200 seconds         at org.apache.hadoop.hbase.util.jvmclusterutil.startup(jvmclusterutil.java:208)         at org.apache.hadoop.hbase.localhbasecluster.startup(localhbasecluster.java:424)         at org.apache.hadoop.hbase.testlocalhbasecluster.testlocalhbasecluster(testlocalhbasecluster.java:66) ... ",
        "label": 199
    },
    {
        "text": "show the table state when we encounter exception while disabling   enabling table  this patch is a advice for good user experience  reason:  when we disable a table and the table is not enabled,we receive a exception,but the exception is too brief,some time we want to know what state is the table in,so that we can know why the table can't be disable.for example,i once encountered a problem the table is neither disable nor enable when my region server crash down,if we give the table state,i will find the problem more quickly . ",
        "label": 523
    },
    {
        "text": "revisit thrust of paragraph on splitting  see the thread 'md5 hash key and splits' for the confusion our paragraph on splitting seems to bring on (as well as good input on when manual splitting might be favored). the user is under the impression that he needs to manually split though his keys have md5 salt. the paragraph needs to make sure it does not bring on such confusion as it would seem to in this case. ",
        "label": 330
    },
    {
        "text": "complain if clock skew across the cluster is badly out of sync  hbase-710 and hbase-609 are issues where the system has broken in presence of clock skew over the cluster. would be a nice service if master could flag very bad clock skew. regionservers could report their local time when they ping the master. it could do a compare. ",
        "label": 241
    },
    {
        "text": "a corrupt hfile could cause endless attempts to assign the region without a chance of success  as described in hbase-9737, a corrupt hfile in a region could lead to an assignment storm in the cluster since the master will keep trying to assign the region to each region server one after another and obviously none will succeed. the region server, upon detecting such a scenario should mark the region as \"rs_zk_region_failed_error\" (or something to the effect) in the zookeeper which should indicate the master to stop assigning the region until the error has been resolved (via an hbase shell command, probably \"assign\"?) ",
        "label": 355
    },
    {
        "text": "hbase shell docs for scan command does not reference versions  hbase(main):046:0> help 'scan'  scan a table; pass table name and optionally a dictionary of scanner  specifications. scanner specifications may include one or more of:  timerange, filter, limit, startrow, stoprow, timestamp, maxlength,  or columns, cache versions should be mentioned somewhere here. ",
        "label": 31
    },
    {
        "text": "align check and mutate operations in table and asynctable  check and mutate methods are way different. table has checkandx methods (some of them are deprecated), but asynctable has an interface called checkandmutatebuilder and these kind of operations are handled through that. ",
        "label": 352
    },
    {
        "text": " fb  force to generate the hostaddress port as stringvalue in hserveraddress  there is a serious bug in hserveraddress, who depends on the stringvalue [class variable] for comparison. this variable is supposed to be host_ip_address:port. however, there is one constructor which allows user to pass a string as host_ip_address directly. this constructor is buggy because some caller may pass the host name instead of host ip address. and we found out one case in the hbase client. the fix is to normalize the stringvalue generation by calling the existing function gethostaddresswithport. for example:  this.stringvalue = gethostaddresswithport(); ",
        "label": 378
    },
    {
        "text": "improve shell help to reflect all possible options  the shell is not consistent in its help texts. for example: scan a table; pass table name and optionally a dictionary of scanner specifications.  scanner specifications may include one or more of the following: limit, startrow, stoprow, timestamp, or columns.  if no columns are specified, all columns will be scanned. but in the code you have  filter = args[\"filter\"]  startrow = args[\"startrow\"] || ''  stoprow = args[\"stoprow\"]  timestamp = args[\"timestamp\"]  columns = args[\"columns\"] || args[\"column\"] || get_all_columns  cache = args[\"cache_blocks\"] || true  versions = args[\"versions\"] || 1 versions is missing from the help. check all commands and make sure all options are stated and examples given. ",
        "label": 194
    },
    {
        "text": "move coprocessors set out of regionload  when i worked on hbase-5256, i revisited the code related to ser/de of coprocessors set in regionload. i think the rationale for embedding coprocessors set is for maximum flexibility where each region can load different coprocessors.  this flexibility is causing extra cost in the region server to master communication and increasing the footprint of master heap. would hserverload be a better place for this set ? if required, region server should calculate disparity of loaded coprocessors among regions and send report through hserverload ",
        "label": 406
    },
    {
        "text": "edit of  proto files moving classes to better homes  a client wants to hook up to hbase and make use of our .proto files. on review, our .proto files are a little messy: the filter proto is in the hbase.proto file rather than in filter.protos, the server/regionload stuff is in hbase.proto rather than in cluster.status, etc. ",
        "label": 314
    },
    {
        "text": "disable frag display in trunk  let hbase replace it  hbase-2165 is about working on fragmentation indicator to make it less intrusive. currently it can get in way of displaying ui on big cluster. ",
        "label": 285
    },
    {
        "text": "use top level apache pom for shared configuration  lars francke suggested this one to me offline and i think it's an excellent idea, so just raising it here for posterity. see https://repository.apache.org/content/repositories/releases/org/apache/apache/7/apache-7.pom if we changed the hbase top-level pom to have a parent of the asf one we can share some configuration love here, take advantage of 'known good' plugins, slim down the hbase pom definition even more (i love removing code, it's my favourite task) and abide by standard apache release artifact signing and packaging processes. this should be simple. lars or i will work up a patch when one of us has some time. (nice thinking lars!) ",
        "label": 284
    },
    {
        "text": "hfileprettyprinter should print out nicely formatted tags  when i was using hfile to print out a rows with tags, the output is like: hsun-mbp:hbase-2.0.0-snapshot hsun$ hbase org.apache.hadoop.hbase.io.hfile.hfile -f /tmp/71afa45b1cb94ea1858a99f31197274f -p 2016-04-25 11:40:40,409 warn  [main] util.nativecodeloader: unable to load native-hadoop library for your platform... using builtin-java classes where applicable 2016-04-25 11:40:40,580 info  [main] hfile.cacheconfig: cacheconfig:disabled k: b/b:b/1461608231279/maximum/vlen=0/seqid=0 v:  k: b/b:b/1461608231278/put/vlen=1/seqid=0 v: b t[0]: \ufffd scanned kv count -> 2 with attached patch, the print is now like: 2016-04-25 11:57:05,849 info  [main] hfile.cacheconfig: cacheconfig:disabled k: b/b:b/1461609876838/maximum/vlen=0/seqid=0 v:  k: b/b:b/1461609876837/put/vlen=1/seqid=0 v: b t[0]: [tag type : 8, value : \\x00\\x0e\\xee\\xee] scanned kv count -> 2 ",
        "label": 205
    },
    {
        "text": "make blockcache eviction thresholds configurable  some of our customers found that tuning the blockcache eviction thresholds made test results different in their test environment. however, those thresholds are not configurable in the current implementation. the only way to change those values is to re-compile the hbase source code. we wonder if it is possible to make them configurable. ",
        "label": 239
    },
    {
        "text": "hooks for hbase tracing  includes the hooks that use htrace library to add dapper-like tracing to hbase. ",
        "label": 250
    },
    {
        "text": "optimize some code  set capacity on arraylist when possible  use isempty  reduce allocations  1. set capacity on arraylist when possible  2. use isempty instead of size() == 0 when possible  3. reduce some unnecessary allocation ",
        "label": 226
    },
    {
        "text": "make region balancing sloppier  the region load balancer is exacting. here's the logic:         if (avgload > 2.0 && thisserversload.getnumberofregions() > avgload) {           if (log.isdebugenabled()) {             log.debug(\"server \" + servername + \" is overloaded. server load: \" +               thisserversload.getnumberofregions() + \" avg: \" + avgload);           } ... on a cluster of thousands of regions, especially around startup or if there's been a crash, the above makes for a bunch of churn as load balancer closes and opens nodes to achieve an exact balance (all nodes must be <= to average). i'd suggest that nodes should be left alone if they are within some percentage of the average \u2013 say 10% (should be configurable). ",
        "label": 314
    },
    {
        "text": "treat checksumexception as we would a parseexception splitting logs  else we replay split on every restart  in short, a checksumexception will fail log processing for a server so we skip out w/o archiving logs. on restart, we'll then reprocess the logs \u2013 hit the checksumexception anew, usually \u2013 and so on. here is the splitlog method (edited):   private list<path> splitlog(final filestatus[] logfiles) throws ioexception {     ....     outputsink.startwriterthreads(entrybuffers);          try {       int i = 0;       for (filestatus log : logfiles) {        path logpath = log.getpath();         long loglength = log.getlen();         splitsize += loglength;         log.debug(\"splitting hlog \" + (i++ + 1) + \" of \" + logfiles.length             + \": \" + logpath + \", length=\" + loglength);         try {           recoverfilelease(fs, logpath, conf);           parsehlog(log, entrybuffers, fs, conf);           processedlogs.add(logpath);         } catch (eofexception eof) {           // truncated files are expected if a rs crashes (see hbase-2643)           log.info(\"eof from hlog \" + logpath + \". continuing\");           processedlogs.add(logpath);         } catch (filenotfoundexception fnfe) {           // a file may be missing if the region server was able to archive it           // before shutting down. this means the edits were persisted already           log.info(\"a log was missing \" + logpath +               \", probably because it was moved by the\" +               \" now dead region server. continuing\");           processedlogs.add(logpath);         } catch (ioexception e) {           // if the ioe resulted from bad file format,           // then this problem is idempotent and retrying won't help           if (e.getcause() instanceof parseexception ||               e.getcause() instanceof checksumexception) {             log.warn(\"parseexception from hlog \" + logpath + \".  continuing\");             processedlogs.add(logpath);           } else {             if (skiperrors) {               log.info(\"got while parsing hlog \" + logpath +                 \". marking as corrupted\", e);               corruptedlogs.add(logpath);             } else {               throw e;             }           }         }       }       if (fs.liststatus(srcdir).length > processedlogs.size()           + corruptedlogs.size()) {         throw new orphanhlogaftersplitexception(             \"discovered orphan hlog after split. maybe the \"             + \"hregionserver was not dead when we started\");       }       archivelogs(srcdir, corruptedlogs, processedlogs, oldlogdir, fs, conf);           } finally {       splits = outputsink.finishwritingandclose();     }     return splits;   } notice how we'll only archive logs only if we successfully split all logs. we won't archive 31 of 35 files if we happen to get a checksum exception on file 32. i think we should treat a checksumexception the same as a parseexception; a retry will not fix it if hdfs could not get around the checksumexception (seems like in our case all replicas were corrupt). here is a play-by-play from the logs: 813572 2011-03-18 20:31:44,687 debug org.apache.hadoop.hbase.regionserver.wal.hlogsplitter: splitting hlog 34 of 35: hdfs://sv2borg170:9000/hbase/.logs/sv2borg182,60020,1300384550664/sv2borg182%3a60020.1300461329481, length=150       65662813573 2011-03-18 20:31:44,687 info org.apache.hadoop.hbase.util.fsutils: recovering file hdfs://sv2borg170:9000/hbase/.logs/sv2borg182,60020,1300384550664/sv2borg182%3a60020.1300461329481 .... 813617 2011-03-18 20:31:46,238 info org.apache.hadoop.fs.fsinputchecker: found checksum error: b[0, 512]=000000cd000000502037383661376439656265643938636463343433386132343631323633303239371d6170695f6163636573735f746f6b656e5f7374       6174735f6275636b65740000000d9fa4d5dc0000012ec9c7cbaf00ffffffff000000010000006d0000005d00000008002337626262663764626431616561366234616130656334383436653732333132643a32390764656661756c746170695f616e64726f69645f6c6f67676564       696e5f73686172655f70656e64696e675f696e69740000012ec956b02804000000000000000100000000ffffffff4e128eca0eb078d0652b0abac467fd09000000cd000000502034663166613763666165333930666332653138346233393931303132623366331d6170695f6163       636573735f746f6b656e5f73746174735f6275636b65740000000d9fa4d5dd0000012ec9c7cbaf00ffffffff000000010000006d0000005d00000008002366303734323966643036323862636530336238333938356239316237386633353a32390764656661756c746170695f61       6e64726f69645f6c6f67676564696e5f73686172655f70656e64696e675f696e69740000012ec9569f1804000000000000000100000000000000d30000004e2066663763393964303633343339666531666461633761616632613964643631331b6170695f6163636573735f746f       6b656e5f73746174735f68 813618 org.apache.hadoop.fs.checksumexception: checksum error: /blk_7781725413191608261:of:/hbase/.logs/sv2borg182,60020,1300384550664/sv2borg182%3a60020.1300461329481 at 15064576 813619         at org.apache.hadoop.fs.fsinputchecker.verifysum(fsinputchecker.java:277) 813620         at org.apache.hadoop.fs.fsinputchecker.readchecksumchunk(fsinputchecker.java:241) 813621         at org.apache.hadoop.fs.fsinputchecker.fill(fsinputchecker.java:176) 813622         at org.apache.hadoop.fs.fsinputchecker.read1(fsinputchecker.java:193) 813623         at org.apache.hadoop.fs.fsinputchecker.read(fsinputchecker.java:158) 813624         at org.apache.hadoop.hdfs.dfsclient$blockreader.read(dfsclient.java:1175) 813625         at org.apache.hadoop.hdfs.dfsclient$dfsinputstream.readbuffer(dfsclient.java:1807) 813626         at org.apache.hadoop.hdfs.dfsclient$dfsinputstream.read(dfsclient.java:1859) 813627         at java.io.datainputstream.read(datainputstream.java:132) 813628         at java.io.datainputstream.readfully(datainputstream.java:178) 813629         at org.apache.hadoop.io.dataoutputbuffer$buffer.write(dataoutputbuffer.java:63) 813630         at org.apache.hadoop.io.dataoutputbuffer.write(dataoutputbuffer.java:101) 813631         at org.apache.hadoop.io.sequencefile$reader.next(sequencefile.java:1937) 813632         at org.apache.hadoop.io.sequencefile$reader.next(sequencefile.java:1837) 813633         at org.apache.hadoop.io.sequencefile$reader.next(sequencefile.java:1883) 813634         at org.apache.hadoop.hbase.regionserver.wal.sequencefilelogreader.next(sequencefilelogreader.java:198) 813635         at org.apache.hadoop.hbase.regionserver.wal.sequencefilelogreader.next(sequencefilelogreader.java:172) 813636         at org.apache.hadoop.hbase.regionserver.wal.hlogsplitter.parsehlog(hlogsplitter.java:429) 813637         at org.apache.hadoop.hbase.regionserver.wal.hlogsplitter.splitlog(hlogsplitter.java:262) 813638         at org.apache.hadoop.hbase.regionserver.wal.hlogsplitter.splitlog(hlogsplitter.java:188) 813639         at org.apache.hadoop.hbase.master.masterfilesystem.splitlog(masterfilesystem.java:197) 813640         at org.apache.hadoop.hbase.master.masterfilesystem.splitlogafterstartup(masterfilesystem.java:181) 813641         at org.apache.hadoop.hbase.master.hmaster.finishinitialization(hmaster.java:384) 813642         at org.apache.hadoop.hbase.master.hmaster.run(hmaster.java:283) 813643 2011-03-18 20:31:46,239 warn org.apache.hadoop.hdfs.dfsclient: found checksum error for blk_7781725413191608261_14589573 from 10.20.20.182:50010 at 15064576 813644 2011-03-18 20:31:46,240 info org.apache.hadoop.hdfs.dfsclient: could not obtain block blk_7781725413191608261_14589573 from any node: java.io.ioexception: no live nodes contain current block. will get new block locations        from namenode and retry... 813645 2011-03-18 20:31:49,243 debug org.apache.hadoop.hbase.regionserver.wal.hlogsplitter: pushed=80624 entries from hdfs://sv2borg170:9000/hbase/.logs/sv2borg182,60020,1300384550664/sv2borg182%3a60020.1300461329481 .... see code above. on exception we'll dump edits read so far from this block, close out all writers tying off recovered.edits so far written. we'll skip archiving these files because we only archive if all files are processed; we won't archive files 30 of 35 if we failed splitting on file 31. i think checksumexception should be treated same as a parseexception ",
        "label": 314
    },
    {
        "text": "use new hadoop shutdown flag  hadoop-4829 was just committed. in 0.21 we should change how we do shutdown to make use of the newly added flag. ",
        "label": 314
    },
    {
        "text": "make use of metricsconnection in async client  ",
        "label": 149
    },
    {
        "text": "infinite loop possible in master master replication  we just discovered the following scenario: 1. cluster a and b are setup in master/master replication 2. by accident we had cluster c replicate to cluster a. now all edit originating from c will be bouncing between a and b. forever!  the reason is that when the edit come in from c the cluster id is already set and won't be reset. we have a couple of options here: 1. optionally only support master/master (not cycles of more than two clusters). in that case we can always reset the cluster id in the replicationsource. that means that now cycles > 2 will have the data cycle forever. this is the only option that requires no changes in the hlog format. 2. instead of a single cluster id per edit maintain a (unordered) set of cluster id that have seen this edit. then in replicationsource we drop any edit that the sink has seen already. the is the cleanest approach, but it might need a lot of data stored per edit if there are many clusters involved. 3. maintain a configurable counter of the maximum cycle side we want to support. could default to 10 (even maybe even just). store a hop-count in the wal and the replicationsource increases that hop-count on each hop. if we're over the max, just drop the edit. ",
        "label": 464
    },
    {
        "text": "improve snapshot name error message  the output for snapshots when you enter an invalid snapshot name talks about \"user-space table names\" instead of \"snapshot names\". the error message should say \"snapshot names can only contain...\". here is an example of the output: hbase(main):001:0> snapshot 'user', 'asdf asdf' error: java.lang.illegalargumentexception: illegal character <32> at 4. user-space table names can only contain 'word characters': i.e. [a-za-z_0-9-.]: asdf asdf here is some help for this command: take a snapshot of specified table. examples:   hbase> snapshot 'sourcetable', 'snapshotname' ",
        "label": 309
    },
    {
        "text": "testsplittransactiononcluster testfailedsplit flakey  only in branch-1 and branch-1.2. fails look like this: https://builds.apache.org/view/h-l/view/hbase/job/hbase-1.3/jdk=latest1.8,label=hadoop/397/ test-org.apache.hadoop.hbase.regionserver.testsplittransactiononcluster.xml.<init> if i look in the xml, i see this:   <testcase name=\"testfailedsplit\" classname=\"org.apache.hadoop.hbase.regionserver.testsplittransactiononcluster\" time=\"8.275\">     <flakyfailure type=\"java.lang.assertionerror:\">java.lang.assertionerror: null at org.junit.assert.fail(assert.java:86) at org.junit.assert.asserttrue(assert.java:41) at org.junit.assert.asserttrue(assert.java:52) at org.apache.hadoop.hbase.regionserver.testsplittransactiononcluster.testfailedsplit(testsplittransactiononcluster.java:1339)       <system-err><![cdata[ ... the xml is cut off. testfailedsplit seems to be the culprit. if i look in the -output.txt i see: .... 2015-11-25 09:00:37,816 debug [asf905.gq1.ygridcore.net,48894,1448441976062_choreservice_1] balancer.baseloadbalancer$cluster(838):  lowest locality region index is 0 and its region server contains 3 regions 2015-11-25 09:00:37,816 debug [asf905.gq1.ygridcore.net,48894,1448441976062_choreservice_1] balancer.baseloadbalancer$cluster(813): lowest locality region server with non zero regions is asf905.gq1.ygridcore.net with locality 0.0 2015-11-25 09:00:37,816 debug [asf905.gq1.ygridcore.net,48894,1448441976062_choreservice_1] balancer.baseloadbalancer$cluster(838):  lowest locality region index is 0 and its region server contains 3 regions 2015-11-25 09:00:37,817 debug [asf905.gq1.ygridcore.net,48894,1448441976062_choreservice_1] balancer.baseloadbalancer$cluster(813): lowest locality region server with non zero regions is asf905.gq1.ygridcore.net with locality 0.0 ... spewing... this test was added here: kalashnikov:hbase.git.commit stack$ git log -s testfailedsplit  ./hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/testsplittransactiononcluster.java commit 871444cb0a733b82af843952253b4545a407979a author: andrew purtell <apurtell@apache.org> date:   mon dec 15 17:31:33 2014 -0800     hbase-12686 failures in split before ponr not clearing the daughter regions from regions in transition during rollback (vandana ayyalasomayajula) the balancer is not coming back true (line #1339 assert is null according to above) ... 1337       regions = testing_util.gethbaseadmin().gettableregions(tablename); 1338       asserttrue(regions.size() == 1); 1339       asserttrue(admin.balancer()); ... line #1339 was not in original test. it was added later: commit 46f993b19fa11d1a8880d08045be43e38017b46a author: virag kothari <virag@yahoo-inc.com> date:   wed jan 7 10:58:32 2015 -0800     hbase-12694 testtableexistsifthespecifiedtableregionissplitparent in testsplittransactiononcluster class leaves regions in transition (vandana ayyalasomayajula) we are having trouble achieving a balance.... let me see. ",
        "label": 314
    },
    {
        "text": "throw tablenotfoundexception if table not exists in asyncadmin compact  now we will return successfully, which is not the same with the hbaseadmin. for normal compaction, we should throw tablenotfoundexception if the locations is empty. ",
        "label": 391
    },
    {
        "text": "nightly test should make junit reports optional rather than attempt archive after reporting   hbase-19030 \"nightly runs should attempt to log tests results after archiving\" was reopened because its fix was causing failures (reported by our @busbey). this issue is about fixing the new failures (originally to be done against reopened hbase-19030 but time passed). ",
        "label": 402
    },
    {
        "text": " tools  tool to kick region out of intransistion  it seems fairly easy getting a region stuck \"intransitions\" (see recent filings of mine). also, with addition to clusterstatus of intransitions content, you can see this state now when you do analysis. i want to roll rc2. 0.20.0 still has issues and we even know now what the worst of them are but the fixes can wait till 0.20.1. meantime, i need a means of bumping stuff that is stuck from the intransistions.... for 0.20.0 release in case we trip over this scenario for then we can effect a repair at least. otherwise, requires restart of cluster. ",
        "label": 314
    },
    {
        "text": "fix new findbugs warnings introduced by hbase  inconsistent synchronization of org.apache.hadoop.hbase.regionserver.timerangetracker.maximumtimestamp; locked 66% of time in class org.apache.hadoop.hbase.regionserver.timerangetracker field org.apache.hadoop.hbase.regionserver.timerangetracker.maximumtimestamp synchronized 66% of the time inconsistent synchronization of org.apache.hadoop.hbase.regionserver.timerangetracker.minimumtimestamp; locked 62% of time in class org.apache.hadoop.hbase.regionserver.timerangetracker field org.apache.hadoop.hbase.regionserver.timerangetracker.minimumtimestamp synchronized 62% of the time ",
        "label": 441
    },
    {
        "text": "testadmin hangs randomly in trunk  fom the logs in my env 2011-11-01 15:48:40,744 warn  [master:0;localhost,39664,1320187706355] master.assignmentmanager(1471): failed assignment of -root-,,0.70236052 to localhost,44046,1320187706849, trying to assign elsewhere instead; retry=1 org.apache.hadoop.hbase.ipc.hbaserpc$versionmismatch: protocol org.apache.hadoop.hbase.ipc.hregioninterface version mismatch. (client = 28, server = 29) at org.apache.hadoop.hbase.ipc.writablerpcengine.getproxy(writablerpcengine.java:185) at org.apache.hadoop.hbase.ipc.hbaserpc.getproxy(hbaserpc.java:300) anyway, after this the logs finishes with: 2011-11-01 15:54:35,132 info  [master:0;localhost,39664,1320187706355.oldlogcleaner] hbase.chore(80): master:0;localhost,39664,1320187706355.oldlogcleaner exiting process thread dump: automatic stack trace every 60 seconds waiting on master:0;localhost,39664,1320187706355 it's in     sun.management.threadimpl.getthreadinfo1(native method)     sun.management.threadimpl.getthreadinfo(threadimpl.java:156)     sun.management.threadimpl.getthreadinfo(threadimpl.java:121)     org.apache.hadoop.util.reflectionutils.printthreadinfo(reflectionutils.java:149)     org.apache.hadoop.hbase.util.threads.threaddumpingisalive(threads.java:113)     org.apache.hadoop.hbase.localhbasecluster.join(localhbasecluster.java:405)     org.apache.hadoop.hbase.minihbasecluster.join(minihbasecluster.java:408)     org.apache.hadoop.hbase.hbasetestingutility.shutdownminihbasecluster(hbasetestingutility.java:616)     org.apache.hadoop.hbase.hbasetestingutility.shutdownminicluster(hbasetestingutility.java:590)     org.apache.hadoop.hbase.client.testadmin.teardownafterclass(testadmin.java:89) so that's at least why adding a timeout wont help and may be why it does not end at all. adding a maximum retry to threads#threaddumpingisalive could help. i also wonder if the root cause of the non ending is my modif on the wal, with some threads surprised to have updates that were not written in the wal. here is the full stack dump: thread 354 (ipc client (47) connection to localhost/127.0.0.1:52227 from nkeywal):   state: timed_waiting   blocked count: 360   waited count: 359   stack:     java.lang.object.wait(native method)     org.apache.hadoop.ipc.client$connection.waitforwork(client.java:702)     org.apache.hadoop.ipc.client$connection.run(client.java:744) thread 272 (master:0;localhost,39664,1320187706355-eventthread):   state: waiting   blocked count: 0   waited count: 4   waiting on java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject@107b954b   stack:     sun.misc.unsafe.park(native method)     java.util.concurrent.locks.locksupport.park(locksupport.java:158)     java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject.await(abstractqueuedsynchronizer.java:1987)     java.util.concurrent.linkedblockingqueue.take(linkedblockingqueue.java:399)     org.apache.zookeeper.clientcnxn$eventthread.run(clientcnxn.java:502) thread 271 (master:0;localhost,39664,1320187706355-sendthread(localhost:21819)):   state: runnable   blocked count: 2   waited count: 0   stack:     sun.nio.ch.epollarraywrapper.epollwait(native method)     sun.nio.ch.epollarraywrapper.poll(epollarraywrapper.java:210)     sun.nio.ch.epollselectorimpl.doselect(epollselectorimpl.java:65)     sun.nio.ch.selectorimpl.lockanddoselect(selectorimpl.java:69)     sun.nio.ch.selectorimpl.select(selectorimpl.java:80)     org.apache.zookeeper.clientcnxn$sendthread.run(clientcnxn.java:1107) thread 152 (master:0;localhost,39664,1320187706355):   state: waiting   blocked count: 217   waited count: 174   waiting on org.apache.hadoop.hbase.zookeeper.rootregiontracker@6621477c   stack:     java.lang.object.wait(native method)     java.lang.object.wait(object.java:485)     org.apache.hadoop.hbase.zookeeper.zookeepernodetracker.blockuntilavailable(zookeepernodetracker.java:131)     org.apache.hadoop.hbase.zookeeper.zookeepernodetracker.blockuntilavailable(zookeepernodetracker.java:104)     org.apache.hadoop.hbase.catalog.catalogtracker.waitforroot(catalogtracker.java:277)     org.apache.hadoop.hbase.master.hmaster.assignrootandmeta(hmaster.java:523)     org.apache.hadoop.hbase.master.hmaster.finishinitialization(hmaster.java:468)     org.apache.hadoop.hbase.master.hmaster.run(hmaster.java:309)     java.lang.thread.run(thread.java:662) thread 165 (lrublockcache.evictionthread):   state: waiting   blocked count: 0   waited count: 1   waiting on org.apache.hadoop.hbase.io.hfile.lrublockcache$evictionthread@3e9d7b56   stack:     java.lang.object.wait(native method)     java.lang.object.wait(object.java:485)     org.apache.hadoop.hbase.io.hfile.lrublockcache$evictionthread.run(lrublockcache.java:593)     java.lang.thread.run(thread.java:662) thread 151 (main-eventthread):   state: waiting   blocked count: 40   waited count: 39   waiting on java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject@22531380   stack:     sun.misc.unsafe.park(native method)     java.util.concurrent.locks.locksupport.park(locksupport.java:158)     java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject.await(abstractqueuedsynchronizer.java:1987)     java.util.concurrent.linkedblockingqueue.take(linkedblockingqueue.java:399)     org.apache.zookeeper.clientcnxn$eventthread.run(clientcnxn.java:502) thread 150 (main-sendthread(localhost:21819)):   state: runnable   blocked count: 55   waited count: 0   stack:     sun.nio.ch.epollarraywrapper.epollwait(native method)     sun.nio.ch.epollarraywrapper.poll(epollarraywrapper.java:210)     sun.nio.ch.epollselectorimpl.doselect(epollselectorimpl.java:65)     sun.nio.ch.selectorimpl.lockanddoselect(selectorimpl.java:69)     sun.nio.ch.selectorimpl.select(selectorimpl.java:80)     org.apache.zookeeper.clientcnxn$sendthread.run(clientcnxn.java:1107) thread 149 (ipc server handler 4 on 39664):   state: waiting   blocked count: 3   waited count: 1968   waiting on java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject@73f5173f   stack:     sun.misc.unsafe.park(native method)     java.util.concurrent.locks.locksupport.park(locksupport.java:158)     java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject.await(abstractqueuedsynchronizer.java:1987)     java.util.concurrent.linkedblockingqueue.take(linkedblockingqueue.java:399)     org.apache.hadoop.hbase.ipc.hbaseserver$handler.run(hbaseserver.java:1224) thread 148 (ipc server handler 3 on 39664):   state: waiting   blocked count: 7   waited count: 1969   waiting on java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject@73f5173f   stack:     sun.misc.unsafe.park(native method)     java.util.concurrent.locks.locksupport.park(locksupport.java:158)     java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject.await(abstractqueuedsynchronizer.java:1987)     java.util.concurrent.linkedblockingqueue.take(linkedblockingqueue.java:399)     org.apache.hadoop.hbase.ipc.hbaseserver$handler.run(hbaseserver.java:1224) thread 147 (ipc server handler 2 on 39664):   state: waiting   blocked count: 11   waited count: 1968   waiting on java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject@73f5173f   stack:     sun.misc.unsafe.park(native method)     java.util.concurrent.locks.locksupport.park(locksupport.java:158)     java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject.await(abstractqueuedsynchronizer.java:1987)     java.util.concurrent.linkedblockingqueue.take(linkedblockingqueue.java:399)     org.apache.hadoop.hbase.ipc.hbaseserver$handler.run(hbaseserver.java:1224) thread 146 (ipc server handler 1 on 39664):   state: waiting   blocked count: 6   waited count: 1969   waiting on java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject@73f5173f   stack:     sun.misc.unsafe.park(native method)     java.util.concurrent.locks.locksupport.park(locksupport.java:158)     java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject.await(abstractqueuedsynchronizer.java:1987)     java.util.concurrent.linkedblockingqueue.take(linkedblockingqueue.java:399)     org.apache.hadoop.hbase.ipc.hbaseserver$handler.run(hbaseserver.java:1224) thread 145 (ipc server handler 0 on 39664):   state: waiting   blocked count: 3   waited count: 1970   waiting on java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject@73f5173f   stack:     sun.misc.unsafe.park(native method)     java.util.concurrent.locks.locksupport.park(locksupport.java:158)     java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject.await(abstractqueuedsynchronizer.java:1987)     java.util.concurrent.linkedblockingqueue.take(linkedblockingqueue.java:399)     org.apache.hadoop.hbase.ipc.hbaseserver$handler.run(hbaseserver.java:1224) thread 133 (ipc server listener on 39664):   state: runnable   blocked count: 1   waited count: 0   stack:     sun.nio.ch.epollarraywrapper.epollwait(native method)     sun.nio.ch.epollarraywrapper.poll(epollarraywrapper.java:210)     sun.nio.ch.epollselectorimpl.doselect(epollselectorimpl.java:65)     sun.nio.ch.selectorimpl.lockanddoselect(selectorimpl.java:69)     sun.nio.ch.selectorimpl.select(selectorimpl.java:80)     sun.nio.ch.selectorimpl.select(selectorimpl.java:84)     org.apache.hadoop.hbase.ipc.hbaseserver$listener.run(hbaseserver.java:580) thread 144 (ipc server responder):   state: runnable   blocked count: 0   waited count: 0   stack:     sun.nio.ch.epollarraywrapper.epollwait(native method)     sun.nio.ch.epollarraywrapper.poll(epollarraywrapper.java:210)     sun.nio.ch.epollselectorimpl.doselect(epollselectorimpl.java:65)     sun.nio.ch.selectorimpl.lockanddoselect(selectorimpl.java:69)     sun.nio.ch.selectorimpl.select(selectorimpl.java:80)     org.apache.hadoop.hbase.ipc.hbaseserver$responder.run(hbaseserver.java:754) thread 143 (ipc reader 9 on port 39664):   state: runnable   blocked count: 0   waited count: 0   stack:     sun.nio.ch.epollarraywrapper.epollwait(native method)     sun.nio.ch.epollarraywrapper.poll(epollarraywrapper.java:210)     sun.nio.ch.epollselectorimpl.doselect(epollselectorimpl.java:65)     sun.nio.ch.selectorimpl.lockanddoselect(selectorimpl.java:69)     sun.nio.ch.selectorimpl.select(selectorimpl.java:80)     sun.nio.ch.selectorimpl.select(selectorimpl.java:84)     org.apache.hadoop.hbase.ipc.hbaseserver$listener$reader.run(hbaseserver.java:471)     java.util.concurrent.threadpoolexecutor$worker.runtask(threadpoolexecutor.java:886)     java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:908)     java.lang.thread.run(thread.java:662) thread 142 (ipc reader 8 on port 39664):   state: runnable   blocked count: 0   waited count: 0   stack:     sun.nio.ch.epollarraywrapper.epollwait(native method)     sun.nio.ch.epollarraywrapper.poll(epollarraywrapper.java:210)     sun.nio.ch.epollselectorimpl.doselect(epollselectorimpl.java:65)     sun.nio.ch.selectorimpl.lockanddoselect(selectorimpl.java:69)     sun.nio.ch.selectorimpl.select(selectorimpl.java:80)     sun.nio.ch.selectorimpl.select(selectorimpl.java:84)     org.apache.hadoop.hbase.ipc.hbaseserver$listener$reader.run(hbaseserver.java:471)     java.util.concurrent.threadpoolexecutor$worker.runtask(threadpoolexecutor.java:886)     java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:908)     java.lang.thread.run(thread.java:662) thread 141 (ipc reader 7 on port 39664):   state: runnable   blocked count: 0   waited count: 0   stack:     sun.nio.ch.epollarraywrapper.epollwait(native method)     sun.nio.ch.epollarraywrapper.poll(epollarraywrapper.java:210)     sun.nio.ch.epollselectorimpl.doselect(epollselectorimpl.java:65)     sun.nio.ch.selectorimpl.lockanddoselect(selectorimpl.java:69)     sun.nio.ch.selectorimpl.select(selectorimpl.java:80)     sun.nio.ch.selectorimpl.select(selectorimpl.java:84)     org.apache.hadoop.hbase.ipc.hbaseserver$listener$reader.run(hbaseserver.java:471)     java.util.concurrent.threadpoolexecutor$worker.runtask(threadpoolexecutor.java:886)     java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:908)     java.lang.thread.run(thread.java:662) thread 140 (ipc reader 6 on port 39664):   state: runnable   blocked count: 0   waited count: 0   stack:     sun.nio.ch.epollarraywrapper.epollwait(native method)     sun.nio.ch.epollarraywrapper.poll(epollarraywrapper.java:210)     sun.nio.ch.epollselectorimpl.doselect(epollselectorimpl.java:65)     sun.nio.ch.selectorimpl.lockanddoselect(selectorimpl.java:69)     sun.nio.ch.selectorimpl.select(selectorimpl.java:80)     sun.nio.ch.selectorimpl.select(selectorimpl.java:84)     org.apache.hadoop.hbase.ipc.hbaseserver$listener$reader.run(hbaseserver.java:471)     java.util.concurrent.threadpoolexecutor$worker.runtask(threadpoolexecutor.java:886)     java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:908)     java.lang.thread.run(thread.java:662) thread 139 (ipc reader 5 on port 39664):   state: runnable   blocked count: 0   waited count: 0   stack:     sun.nio.ch.epollarraywrapper.epollwait(native method)     sun.nio.ch.epollarraywrapper.poll(epollarraywrapper.java:210)     sun.nio.ch.epollselectorimpl.doselect(epollselectorimpl.java:65)     sun.nio.ch.selectorimpl.lockanddoselect(selectorimpl.java:69)     sun.nio.ch.selectorimpl.select(selectorimpl.java:80)     sun.nio.ch.selectorimpl.select(selectorimpl.java:84)     org.apache.hadoop.hbase.ipc.hbaseserver$listener$reader.run(hbaseserver.java:471)     java.util.concurrent.threadpoolexecutor$worker.runtask(threadpoolexecutor.java:886)     java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:908)     java.lang.thread.run(thread.java:662) thread 138 (ipc reader 4 on port 39664):   state: runnable   blocked count: 0   waited count: 0   stack:     sun.nio.ch.epollarraywrapper.epollwait(native method)     sun.nio.ch.epollarraywrapper.poll(epollarraywrapper.java:210)     sun.nio.ch.epollselectorimpl.doselect(epollselectorimpl.java:65)     sun.nio.ch.selectorimpl.lockanddoselect(selectorimpl.java:69)     sun.nio.ch.selectorimpl.select(selectorimpl.java:80)     sun.nio.ch.selectorimpl.select(selectorimpl.java:84)     org.apache.hadoop.hbase.ipc.hbaseserver$listener$reader.run(hbaseserver.java:471)     java.util.concurrent.threadpoolexecutor$worker.runtask(threadpoolexecutor.java:886)     java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:908)     java.lang.thread.run(thread.java:662) thread 137 (ipc reader 3 on port 39664):   state: runnable   blocked count: 0   waited count: 0   stack:     sun.nio.ch.epollarraywrapper.epollwait(native method)     sun.nio.ch.epollarraywrapper.poll(epollarraywrapper.java:210)     sun.nio.ch.epollselectorimpl.doselect(epollselectorimpl.java:65)     sun.nio.ch.selectorimpl.lockanddoselect(selectorimpl.java:69)     sun.nio.ch.selectorimpl.select(selectorimpl.java:80)     sun.nio.ch.selectorimpl.select(selectorimpl.java:84)     org.apache.hadoop.hbase.ipc.hbaseserver$listener$reader.run(hbaseserver.java:471)     java.util.concurrent.threadpoolexecutor$worker.runtask(threadpoolexecutor.java:886)     java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:908)     java.lang.thread.run(thread.java:662) thread 136 (ipc reader 2 on port 39664):   state: runnable   blocked count: 1   waited count: 1   stack:     sun.nio.ch.epollarraywrapper.epollwait(native method)     sun.nio.ch.epollarraywrapper.poll(epollarraywrapper.java:210)     sun.nio.ch.epollselectorimpl.doselect(epollselectorimpl.java:65)     sun.nio.ch.selectorimpl.lockanddoselect(selectorimpl.java:69)     sun.nio.ch.selectorimpl.select(selectorimpl.java:80)     sun.nio.ch.selectorimpl.select(selectorimpl.java:84)     org.apache.hadoop.hbase.ipc.hbaseserver$listener$reader.run(hbaseserver.java:471)     java.util.concurrent.threadpoolexecutor$worker.runtask(threadpoolexecutor.java:886)     java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:908)     java.lang.thread.run(thread.java:662) thread 135 (ipc reader 1 on port 39664):   state: runnable   blocked count: 1   waited count: 1   stack:     sun.nio.ch.epollarraywrapper.epollwait(native method)     sun.nio.ch.epollarraywrapper.poll(epollarraywrapper.java:210)     sun.nio.ch.epollselectorimpl.doselect(epollselectorimpl.java:65)     sun.nio.ch.selectorimpl.lockanddoselect(selectorimpl.java:69)     sun.nio.ch.selectorimpl.select(selectorimpl.java:80)     sun.nio.ch.selectorimpl.select(selectorimpl.java:84)     org.apache.hadoop.hbase.ipc.hbaseserver$listener$reader.run(hbaseserver.java:471)     java.util.concurrent.threadpoolexecutor$worker.runtask(threadpoolexecutor.java:886)     java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:908)     java.lang.thread.run(thread.java:662) thread 134 (ipc reader 0 on port 39664):   state: runnable   blocked count: 0   waited count: 0   stack:     sun.nio.ch.epollarraywrapper.epollwait(native method)     sun.nio.ch.epollarraywrapper.poll(epollarraywrapper.java:210)     sun.nio.ch.epollselectorimpl.doselect(epollselectorimpl.java:65)     sun.nio.ch.selectorimpl.lockanddoselect(selectorimpl.java:69)     sun.nio.ch.selectorimpl.select(selectorimpl.java:80)     sun.nio.ch.selectorimpl.select(selectorimpl.java:84)     org.apache.hadoop.hbase.ipc.hbaseserver$listener$reader.run(hbaseserver.java:471)     java.util.concurrent.threadpoolexecutor$worker.runtask(threadpoolexecutor.java:886)     java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:908)     java.lang.thread.run(thread.java:662) thread 124 (leasechecker):   state: timed_waiting   blocked count: 0   waited count: 407   stack:     java.lang.thread.sleep(native method)     org.apache.hadoop.hdfs.dfsclient$leasechecker.run(dfsclient.java:1252)     java.lang.thread.run(thread.java:662) thread 121 (processthread:-1):   state: waiting   blocked count: 0   waited count: 269   waiting on java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject@7f5d84e0   stack:     sun.misc.unsafe.park(native method)     java.util.concurrent.locks.locksupport.park(locksupport.java:158)     java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject.await(abstractqueuedsynchronizer.java:1987)     java.util.concurrent.linkedblockingqueue.take(linkedblockingqueue.java:399)     org.apache.zookeeper.server.preprequestprocessor.run(preprequestprocessor.java:103) thread 120 (syncthread:0):   state: waiting   blocked count: 2   waited count: 252   waiting on java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject@3b25b27c   stack:     sun.misc.unsafe.park(native method)     java.util.concurrent.locks.locksupport.park(locksupport.java:158)     java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject.await(abstractqueuedsynchronizer.java:1987)     java.util.concurrent.linkedblockingqueue.take(linkedblockingqueue.java:399)     org.apache.zookeeper.server.syncrequestprocessor.run(syncrequestprocessor.java:94) thread 119 (sessiontracker):   state: timed_waiting   blocked count: 0   waited count: 207   stack:     java.lang.object.wait(native method)     org.apache.zookeeper.server.sessiontrackerimpl.run(sessiontrackerimpl.java:142) thread 118 (nioservercxn.factory:0.0.0.0/0.0.0.0:21819):   state: runnable   blocked count: 38   waited count: 0   stack:     sun.nio.ch.epollarraywrapper.epollwait(native method)     sun.nio.ch.epollarraywrapper.poll(epollarraywrapper.java:210)     sun.nio.ch.epollselectorimpl.doselect(epollselectorimpl.java:65)     sun.nio.ch.selectorimpl.lockanddoselect(selectorimpl.java:69)     sun.nio.ch.selectorimpl.select(selectorimpl.java:80)     org.apache.zookeeper.server.nioservercnxn$factory.run(nioservercnxn.java:232) thread 116 (org.apache.hadoop.hdfs.server.datanode.datablockscanner@2e6f947b):   state: timed_waiting   blocked count: 0   waited count: 407   stack:     java.lang.thread.sleep(native method)     org.apache.hadoop.hdfs.server.datanode.datablockscanner.run(datablockscanner.java:620)     java.lang.thread.run(thread.java:662) thread 113 (ipc server handler 2 on 39899):   state: waiting   blocked count: 0   waited count: 1   waiting on java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject@1b4c72c8   stack:     sun.misc.unsafe.park(native method)     java.util.concurrent.locks.locksupport.park(locksupport.java:158)     java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject.await(abstractqueuedsynchronizer.java:1987)     java.util.concurrent.linkedblockingqueue.take(linkedblockingqueue.java:399)     org.apache.hadoop.ipc.server$handler.run(server.java:1364) thread 112 (ipc server handler 1 on 39899):   state: waiting   blocked count: 0   waited count: 1   waiting on java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject@1b4c72c8   stack:     sun.misc.unsafe.park(native method)     java.util.concurrent.locks.locksupport.park(locksupport.java:158)     java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject.await(abstractqueuedsynchronizer.java:1987)     java.util.concurrent.linkedblockingqueue.take(linkedblockingqueue.java:399)     org.apache.hadoop.ipc.server$handler.run(server.java:1364) thread 111 (ipc server handler 0 on 39899):   state: waiting   blocked count: 0   waited count: 1   waiting on java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject@1b4c72c8   stack:     sun.misc.unsafe.park(native method)     java.util.concurrent.locks.locksupport.park(locksupport.java:158)     java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject.await(abstractqueuedsynchronizer.java:1987)     java.util.concurrent.linkedblockingqueue.take(linkedblockingqueue.java:399)     org.apache.hadoop.ipc.server$handler.run(server.java:1364) thread 106 (ipc server listener on 39899):   state: runnable   blocked count: 0   waited count: 0   stack:     sun.nio.ch.epollarraywrapper.epollwait(native method)     sun.nio.ch.epollarraywrapper.poll(epollarraywrapper.java:210)     sun.nio.ch.epollselectorimpl.doselect(epollselectorimpl.java:65)     sun.nio.ch.selectorimpl.lockanddoselect(selectorimpl.java:69)     sun.nio.ch.selectorimpl.select(selectorimpl.java:80)     sun.nio.ch.selectorimpl.select(selectorimpl.java:84)     org.apache.hadoop.ipc.server$listener.run(server.java:439) thread 108 (ipc server responder):   state: runnable   blocked count: 0   waited count: 0   stack:     sun.nio.ch.epollarraywrapper.epollwait(native method)     sun.nio.ch.epollarraywrapper.poll(epollarraywrapper.java:210)     sun.nio.ch.epollselectorimpl.doselect(epollselectorimpl.java:65)     sun.nio.ch.selectorimpl.lockanddoselect(selectorimpl.java:69)     sun.nio.ch.selectorimpl.select(selectorimpl.java:80)     org.apache.hadoop.ipc.server$responder.run(server.java:605) thread 102 (org.apache.hadoop.hdfs.server.datanode.dataxceiverserver@45d1c3cd):   state: runnable   blocked count: 0   waited count: 0   stack:     sun.nio.ch.serversocketchannelimpl.accept0(native method)     sun.nio.ch.serversocketchannelimpl.accept(serversocketchannelimpl.java:152)     sun.nio.ch.serversocketadaptor.accept(serversocketadaptor.java:84)     org.apache.hadoop.hdfs.server.datanode.dataxceiverserver.run(dataxceiverserver.java:131)     java.lang.thread.run(thread.java:662) thread 109 (datanode: [/tmp/d846d12d-19f3-439a-8cab-e05db67ae60b/dfscluster_2773516a-bc5a-4029-9ee0-fc499eee6ca8/dfs/data/data5,/tmp/d846d12d-19f3-439a-8cab-e05db67ae60b/dfscluster_2773516a-bc5a-4029-9ee0-fc499eee6ca8/dfs/data/data6]):   state: timed_waiting   blocked count: 137   waited count: 283   stack:     java.lang.object.wait(native method)     org.apache.hadoop.hdfs.server.datanode.datanode.offerservice(datanode.java:986)     org.apache.hadoop.hdfs.server.datanode.datanode.run(datanode.java:1421)     java.lang.thread.run(thread.java:662) thread 107 (pool-4-thread-1):   state: runnable   blocked count: 0   waited count: 0   stack:     sun.nio.ch.epollarraywrapper.epollwait(native method)     sun.nio.ch.epollarraywrapper.poll(epollarraywrapper.java:210)     sun.nio.ch.epollselectorimpl.doselect(epollselectorimpl.java:65)     sun.nio.ch.selectorimpl.lockanddoselect(selectorimpl.java:69)     sun.nio.ch.selectorimpl.select(selectorimpl.java:80)     sun.nio.ch.selectorimpl.select(selectorimpl.java:84)     org.apache.hadoop.ipc.server$listener$reader.run(server.java:333)     java.util.concurrent.threadpoolexecutor$worker.runtask(threadpoolexecutor.java:886)     java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:908)     java.lang.thread.run(thread.java:662) thread 105 (timer-3):   state: timed_waiting   blocked count: 0   waited count: 15   stack:     java.lang.object.wait(native method)     java.util.timerthread.mainloop(timer.java:509)     java.util.timerthread.run(timer.java:462) thread 104 (1353906974@qtp-1197660496-1 - acceptor0 selectchannelconnector@localhost:59858):   state: runnable   blocked count: 1   waited count: 1   stack:     sun.nio.ch.epollarraywrapper.epollwait(native method)     sun.nio.ch.epollarraywrapper.poll(epollarraywrapper.java:210)     sun.nio.ch.epollselectorimpl.doselect(epollselectorimpl.java:65)     sun.nio.ch.selectorimpl.lockanddoselect(selectorimpl.java:69)     sun.nio.ch.selectorimpl.select(selectorimpl.java:80)     org.mortbay.io.nio.selectormanager$selectset.doselect(selectormanager.java:498)     org.mortbay.io.nio.selectormanager.doselect(selectormanager.java:192)     org.mortbay.jetty.nio.selectchannelconnector.accept(selectchannelconnector.java:124)     org.mortbay.jetty.abstractconnector$acceptor.run(abstractconnector.java:708)     org.mortbay.thread.queuedthreadpool$poolthread.run(queuedthreadpool.java:582) thread 103 (1185716172@qtp-1197660496-0):   state: timed_waiting   blocked count: 0   waited count: 8   stack:     java.lang.object.wait(native method)     org.mortbay.thread.queuedthreadpool$poolthread.run(queuedthreadpool.java:626) thread 101 (refreshused-/tmp/d846d12d-19f3-439a-8cab-e05db67ae60b/dfscluster_2773516a-bc5a-4029-9ee0-fc499eee6ca8/dfs/data/data6):   state: timed_waiting   blocked count: 0   waited count: 1   stack:     java.lang.thread.sleep(native method)     org.apache.hadoop.fs.du$durefreshthread.run(du.java:80)     java.lang.thread.run(thread.java:662) thread 98 (refreshused-/tmp/d846d12d-19f3-439a-8cab-e05db67ae60b/dfscluster_2773516a-bc5a-4029-9ee0-fc499eee6ca8/dfs/data/data5):   state: timed_waiting   blocked count: 0   waited count: 1   stack:     java.lang.thread.sleep(native method)     org.apache.hadoop.fs.du$durefreshthread.run(du.java:80)     java.lang.thread.run(thread.java:662) thread 90 (org.apache.hadoop.hdfs.server.datanode.datablockscanner@605b28c9):   state: timed_waiting   blocked count: 0   waited count: 408   stack:     java.lang.thread.sleep(native method)     org.apache.hadoop.hdfs.server.datanode.datablockscanner.run(datablockscanner.java:620)     java.lang.thread.run(thread.java:662) thread 86 (ipc server handler 2 on 56098):   state: waiting   blocked count: 0   waited count: 1   waiting on java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject@78ff22ed   stack:     sun.misc.unsafe.park(native method)     java.util.concurrent.locks.locksupport.park(locksupport.java:158)     java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject.await(abstractqueuedsynchronizer.java:1987)     java.util.concurrent.linkedblockingqueue.take(linkedblockingqueue.java:399)     org.apache.hadoop.ipc.server$handler.run(server.java:1364) thread 85 (ipc server handler 1 on 56098):   state: waiting   blocked count: 0   waited count: 1   waiting on java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject@78ff22ed   stack:     sun.misc.unsafe.park(native method)     java.util.concurrent.locks.locksupport.park(locksupport.java:158)     java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject.await(abstractqueuedsynchronizer.java:1987)     java.util.concurrent.linkedblockingqueue.take(linkedblockingqueue.java:399)     org.apache.hadoop.ipc.server$handler.run(server.java:1364) thread 84 (ipc server handler 0 on 56098):   state: waiting   blocked count: 0   waited count: 1   waiting on java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject@78ff22ed   stack:     sun.misc.unsafe.park(native method)     java.util.concurrent.locks.locksupport.park(locksupport.java:158)     java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject.await(abstractqueuedsynchronizer.java:1987)     java.util.concurrent.linkedblockingqueue.take(linkedblockingqueue.java:399)     org.apache.hadoop.ipc.server$handler.run(server.java:1364) thread 80 (ipc server listener on 56098):   state: runnable   blocked count: 0   waited count: 0   stack:     sun.nio.ch.epollarraywrapper.epollwait(native method)     sun.nio.ch.epollarraywrapper.poll(epollarraywrapper.java:210)     sun.nio.ch.epollselectorimpl.doselect(epollselectorimpl.java:65)     sun.nio.ch.selectorimpl.lockanddoselect(selectorimpl.java:69)     sun.nio.ch.selectorimpl.select(selectorimpl.java:80)     sun.nio.ch.selectorimpl.select(selectorimpl.java:84)     org.apache.hadoop.ipc.server$listener.run(server.java:439) thread 82 (ipc server responder):   state: runnable   blocked count: 0   waited count: 0   stack:     sun.nio.ch.epollarraywrapper.epollwait(native method)     sun.nio.ch.epollarraywrapper.poll(epollarraywrapper.java:210)     sun.nio.ch.epollselectorimpl.doselect(epollselectorimpl.java:65)     sun.nio.ch.selectorimpl.lockanddoselect(selectorimpl.java:69)     sun.nio.ch.selectorimpl.select(selectorimpl.java:80)     org.apache.hadoop.ipc.server$responder.run(server.java:605) thread 76 (org.apache.hadoop.hdfs.server.datanode.dataxceiverserver@2b68989e):   state: runnable   blocked count: 0   waited count: 0   stack:     sun.nio.ch.serversocketchannelimpl.accept0(native method)     sun.nio.ch.serversocketchannelimpl.accept(serversocketchannelimpl.java:152)     sun.nio.ch.serversocketadaptor.accept(serversocketadaptor.java:84)     org.apache.hadoop.hdfs.server.datanode.dataxceiverserver.run(dataxceiverserver.java:131)     java.lang.thread.run(thread.java:662) thread 83 (datanode: [/tmp/d846d12d-19f3-439a-8cab-e05db67ae60b/dfscluster_2773516a-bc5a-4029-9ee0-fc499eee6ca8/dfs/data/data3,/tmp/d846d12d-19f3-439a-8cab-e05db67ae60b/dfscluster_2773516a-bc5a-4029-9ee0-fc499eee6ca8/dfs/data/data4]):   state: timed_waiting   blocked count: 149   waited count: 290   stack:     java.lang.object.wait(native method)     org.apache.hadoop.hdfs.server.datanode.datanode.offerservice(datanode.java:986)     org.apache.hadoop.hdfs.server.datanode.datanode.run(datanode.java:1421)     java.lang.thread.run(thread.java:662) thread 81 (pool-3-thread-1):   state: runnable   blocked count: 0   waited count: 0   stack:     sun.nio.ch.epollarraywrapper.epollwait(native method)     sun.nio.ch.epollarraywrapper.poll(epollarraywrapper.java:210)     sun.nio.ch.epollselectorimpl.doselect(epollselectorimpl.java:65)     sun.nio.ch.selectorimpl.lockanddoselect(selectorimpl.java:69)     sun.nio.ch.selectorimpl.select(selectorimpl.java:80)     sun.nio.ch.selectorimpl.select(selectorimpl.java:84)     org.apache.hadoop.ipc.server$listener$reader.run(server.java:333)     java.util.concurrent.threadpoolexecutor$worker.runtask(threadpoolexecutor.java:886)     java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:908)     java.lang.thread.run(thread.java:662) thread 79 (timer-2):   state: timed_waiting   blocked count: 0   waited count: 15   stack:     java.lang.object.wait(native method)     java.util.timerthread.mainloop(timer.java:509)     java.util.timerthread.run(timer.java:462) thread 78 (348878159@qtp-164967086-1 - acceptor0 selectchannelconnector@localhost:36427):   state: runnable   blocked count: 2   waited count: 1   stack:     sun.nio.ch.epollarraywrapper.epollwait(native method)     sun.nio.ch.epollarraywrapper.poll(epollarraywrapper.java:210)     sun.nio.ch.epollselectorimpl.doselect(epollselectorimpl.java:65)     sun.nio.ch.selectorimpl.lockanddoselect(selectorimpl.java:69)     sun.nio.ch.selectorimpl.select(selectorimpl.java:80)     org.mortbay.io.nio.selectormanager$selectset.doselect(selectormanager.java:498)     org.mortbay.io.nio.selectormanager.doselect(selectormanager.java:192)     org.mortbay.jetty.nio.selectchannelconnector.accept(selectchannelconnector.java:124)     org.mortbay.jetty.abstractconnector$acceptor.run(abstractconnector.java:708)     org.mortbay.thread.queuedthreadpool$poolthread.run(queuedthreadpool.java:582) thread 77 (1905729203@qtp-164967086-0):   state: timed_waiting   blocked count: 0   waited count: 8   stack:     java.lang.object.wait(native method)     org.mortbay.thread.queuedthreadpool$poolthread.run(queuedthreadpool.java:626) thread 75 (refreshused-/tmp/d846d12d-19f3-439a-8cab-e05db67ae60b/dfscluster_2773516a-bc5a-4029-9ee0-fc499eee6ca8/dfs/data/data4):   state: timed_waiting   blocked count: 0   waited count: 1   stack:     java.lang.thread.sleep(native method)     org.apache.hadoop.fs.du$durefreshthread.run(du.java:80)     java.lang.thread.run(thread.java:662) thread 72 (refreshused-/tmp/d846d12d-19f3-439a-8cab-e05db67ae60b/dfscluster_2773516a-bc5a-4029-9ee0-fc499eee6ca8/dfs/data/data3):   state: timed_waiting   blocked count: 0   waited count: 1   stack:     java.lang.thread.sleep(native method)     org.apache.hadoop.fs.du$durefreshthread.run(du.java:80)     java.lang.thread.run(thread.java:662) thread 61 (org.apache.hadoop.hdfs.server.datanode.datablockscanner@6709da93):   state: timed_waiting   blocked count: 0   waited count: 408   stack:     java.lang.thread.sleep(native method)     org.apache.hadoop.hdfs.server.datanode.datablockscanner.run(datablockscanner.java:620)     java.lang.thread.run(thread.java:662) thread 60 (ipc server handler 2 on 40388):   state: waiting   blocked count: 0   waited count: 1   waiting on java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject@56afd9e3   stack:     sun.misc.unsafe.park(native method)     java.util.concurrent.locks.locksupport.park(locksupport.java:158)     java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject.await(abstractqueuedsynchronizer.java:1987)     java.util.concurrent.linkedblockingqueue.take(linkedblockingqueue.java:399)     org.apache.hadoop.ipc.server$handler.run(server.java:1364) thread 59 (ipc server handler 1 on 40388):   state: waiting   blocked count: 0   waited count: 1   waiting on java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject@56afd9e3   stack:     sun.misc.unsafe.park(native method)     java.util.concurrent.locks.locksupport.park(locksupport.java:158)     java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject.await(abstractqueuedsynchronizer.java:1987)     java.util.concurrent.linkedblockingqueue.take(linkedblockingqueue.java:399)     org.apache.hadoop.ipc.server$handler.run(server.java:1364) thread 58 (ipc server handler 0 on 40388):   state: waiting   blocked count: 0   waited count: 1   waiting on java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject@56afd9e3   stack:     sun.misc.unsafe.park(native method)     java.util.concurrent.locks.locksupport.park(locksupport.java:158)     java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject.await(abstractqueuedsynchronizer.java:1987)     java.util.concurrent.linkedblockingqueue.take(linkedblockingqueue.java:399)     org.apache.hadoop.ipc.server$handler.run(server.java:1364) thread 53 (ipc server listener on 40388):   state: runnable   blocked count: 0   waited count: 0   stack:     sun.nio.ch.epollarraywrapper.epollwait(native method)     sun.nio.ch.epollarraywrapper.poll(epollarraywrapper.java:210)     sun.nio.ch.epollselectorimpl.doselect(epollselectorimpl.java:65)     sun.nio.ch.selectorimpl.lockanddoselect(selectorimpl.java:69)     sun.nio.ch.selectorimpl.select(selectorimpl.java:80)     sun.nio.ch.selectorimpl.select(selectorimpl.java:84)     org.apache.hadoop.ipc.server$listener.run(server.java:439) thread 55 (ipc server responder):   state: runnable   blocked count: 0   waited count: 0   stack:     sun.nio.ch.epollarraywrapper.epollwait(native method)     sun.nio.ch.epollarraywrapper.poll(epollarraywrapper.java:210)     sun.nio.ch.epollselectorimpl.doselect(epollselectorimpl.java:65)     sun.nio.ch.selectorimpl.lockanddoselect(selectorimpl.java:69)     sun.nio.ch.selectorimpl.select(selectorimpl.java:80)     org.apache.hadoop.ipc.server$responder.run(server.java:605) thread 49 (org.apache.hadoop.hdfs.server.datanode.dataxceiverserver@48baa31b):   state: runnable   blocked count: 0   waited count: 0   stack:     sun.nio.ch.serversocketchannelimpl.accept0(native method)     sun.nio.ch.serversocketchannelimpl.accept(serversocketchannelimpl.java:152)     sun.nio.ch.serversocketadaptor.accept(serversocketadaptor.java:84)     org.apache.hadoop.hdfs.server.datanode.dataxceiverserver.run(dataxceiverserver.java:131)     java.lang.thread.run(thread.java:662) thread 57 (datanode: [/tmp/d846d12d-19f3-439a-8cab-e05db67ae60b/dfscluster_2773516a-bc5a-4029-9ee0-fc499eee6ca8/dfs/data/data1,/tmp/d846d12d-19f3-439a-8cab-e05db67ae60b/dfscluster_2773516a-bc5a-4029-9ee0-fc499eee6ca8/dfs/data/data2]):   state: timed_waiting   blocked count: 148   waited count: 283   stack:     java.lang.object.wait(native method)     org.apache.hadoop.hdfs.server.datanode.datanode.offerservice(datanode.java:986)     org.apache.hadoop.hdfs.server.datanode.datanode.run(datanode.java:1421)     java.lang.thread.run(thread.java:662) thread 54 (pool-2-thread-1):   state: runnable   blocked count: 0   waited count: 0   stack:     sun.nio.ch.epollarraywrapper.epollwait(native method)     sun.nio.ch.epollarraywrapper.poll(epollarraywrapper.java:210)     sun.nio.ch.epollselectorimpl.doselect(epollselectorimpl.java:65)     sun.nio.ch.selectorimpl.lockanddoselect(selectorimpl.java:69)     sun.nio.ch.selectorimpl.select(selectorimpl.java:80)     sun.nio.ch.selectorimpl.select(selectorimpl.java:84)     org.apache.hadoop.ipc.server$listener$reader.run(server.java:333)     java.util.concurrent.threadpoolexecutor$worker.runtask(threadpoolexecutor.java:886)     java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:908)     java.lang.thread.run(thread.java:662) thread 52 (timer-1):   state: timed_waiting   blocked count: 0   waited count: 15   stack:     java.lang.object.wait(native method)     java.util.timerthread.mainloop(timer.java:509)     java.util.timerthread.run(timer.java:462) thread 51 (1031841975@qtp-1068922666-1 - acceptor0 selectchannelconnector@localhost:56535):   state: runnable   blocked count: 1   waited count: 1   stack:     sun.nio.ch.epollarraywrapper.epollwait(native method)     sun.nio.ch.epollarraywrapper.poll(epollarraywrapper.java:210)     sun.nio.ch.epollselectorimpl.doselect(epollselectorimpl.java:65)     sun.nio.ch.selectorimpl.lockanddoselect(selectorimpl.java:69)     sun.nio.ch.selectorimpl.select(selectorimpl.java:80)     org.mortbay.io.nio.selectormanager$selectset.doselect(selectormanager.java:498)     org.mortbay.io.nio.selectormanager.doselect(selectormanager.java:192)     org.mortbay.jetty.nio.selectchannelconnector.accept(selectchannelconnector.java:124)     org.mortbay.jetty.abstractconnector$acceptor.run(abstractconnector.java:708)     org.mortbay.thread.queuedthreadpool$poolthread.run(queuedthreadpool.java:582) thread 50 (1191055321@qtp-1068922666-0):   state: timed_waiting   blocked count: 0   waited count: 8   stack:     java.lang.object.wait(native method)     org.mortbay.thread.queuedthreadpool$poolthread.run(queuedthreadpool.java:626) thread 48 (refreshused-/tmp/d846d12d-19f3-439a-8cab-e05db67ae60b/dfscluster_2773516a-bc5a-4029-9ee0-fc499eee6ca8/dfs/data/data2):   state: timed_waiting   blocked count: 0   waited count: 1   stack:     java.lang.thread.sleep(native method)     org.apache.hadoop.fs.du$durefreshthread.run(du.java:80)     java.lang.thread.run(thread.java:662) thread 45 (refreshused-/tmp/d846d12d-19f3-439a-8cab-e05db67ae60b/dfscluster_2773516a-bc5a-4029-9ee0-fc499eee6ca8/dfs/data/data1):   state: timed_waiting   blocked count: 0   waited count: 1   stack:     java.lang.thread.sleep(native method)     org.apache.hadoop.fs.du$durefreshthread.run(du.java:80)     java.lang.thread.run(thread.java:662) thread 31 (ipc server handler 9 on 52227):   state: waiting   blocked count: 0   waited count: 64   waiting on java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject@64473a14   stack:     sun.misc.unsafe.park(native method)     java.util.concurrent.locks.locksupport.park(locksupport.java:158)     java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject.await(abstractqueuedsynchronizer.java:1987)     java.util.concurrent.linkedblockingqueue.take(linkedblockingqueue.java:399)     org.apache.hadoop.ipc.server$handler.run(server.java:1364) thread 30 (ipc server handler 8 on 52227):   state: waiting   blocked count: 3   waited count: 65   waiting on java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject@64473a14   stack:     sun.misc.unsafe.park(native method)     java.util.concurrent.locks.locksupport.park(locksupport.java:158)     java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject.await(abstractqueuedsynchronizer.java:1987)     java.util.concurrent.linkedblockingqueue.take(linkedblockingqueue.java:399)     org.apache.hadoop.ipc.server$handler.run(server.java:1364) thread 29 (ipc server handler 7 on 52227):   state: waiting   blocked count: 2   waited count: 66   waiting on java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject@64473a14   stack:     sun.misc.unsafe.park(native method)     java.util.concurrent.locks.locksupport.park(locksupport.java:158)     java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject.await(abstractqueuedsynchronizer.java:1987)     java.util.concurrent.linkedblockingqueue.take(linkedblockingqueue.java:399)     org.apache.hadoop.ipc.server$handler.run(server.java:1364) thread 28 (ipc server handler 6 on 52227):   state: waiting   blocked count: 1   waited count: 64   waiting on java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject@64473a14   stack:     sun.misc.unsafe.park(native method)     java.util.concurrent.locks.locksupport.park(locksupport.java:158)     java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject.await(abstractqueuedsynchronizer.java:1987)     java.util.concurrent.linkedblockingqueue.take(linkedblockingqueue.java:399)     org.apache.hadoop.ipc.server$handler.run(server.java:1364) thread 27 (ipc server handler 5 on 52227):   state: waiting   blocked count: 4   waited count: 68   waiting on java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject@64473a14   stack:     sun.misc.unsafe.park(native method)     java.util.concurrent.locks.locksupport.park(locksupport.java:158)     java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject.await(abstractqueuedsynchronizer.java:1987)     java.util.concurrent.linkedblockingqueue.take(linkedblockingqueue.java:399)     org.apache.hadoop.ipc.server$handler.run(server.java:1364) thread 26 (ipc server handler 4 on 52227):   state: waiting   blocked count: 0   waited count: 64   waiting on java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject@64473a14   stack:     sun.misc.unsafe.park(native method)     java.util.concurrent.locks.locksupport.park(locksupport.java:158)     java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject.await(abstractqueuedsynchronizer.java:1987)     java.util.concurrent.linkedblockingqueue.take(linkedblockingqueue.java:399)     org.apache.hadoop.ipc.server$handler.run(server.java:1364) thread 25 (ipc server handler 3 on 52227):   state: waiting   blocked count: 0   waited count: 65   waiting on java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject@64473a14   stack:     sun.misc.unsafe.park(native method)     java.util.concurrent.locks.locksupport.park(locksupport.java:158)     java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject.await(abstractqueuedsynchronizer.java:1987)     java.util.concurrent.linkedblockingqueue.take(linkedblockingqueue.java:399)     org.apache.hadoop.ipc.server$handler.run(server.java:1364) thread 24 (ipc server handler 2 on 52227):   state: waiting   blocked count: 1   waited count: 66   waiting on java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject@64473a14   stack:     sun.misc.unsafe.park(native method)     java.util.concurrent.locks.locksupport.park(locksupport.java:158)     java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject.await(abstractqueuedsynchronizer.java:1987)     java.util.concurrent.linkedblockingqueue.take(linkedblockingqueue.java:399)     org.apache.hadoop.ipc.server$handler.run(server.java:1364) thread 23 (ipc server handler 1 on 52227):   state: waiting   blocked count: 0   waited count: 64   waiting on java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject@64473a14   stack:     sun.misc.unsafe.park(native method)     java.util.concurrent.locks.locksupport.park(locksupport.java:158)     java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject.await(abstractqueuedsynchronizer.java:1987)     java.util.concurrent.linkedblockingqueue.take(linkedblockingqueue.java:399)     org.apache.hadoop.ipc.server$handler.run(server.java:1364) thread 22 (ipc server handler 0 on 52227):   state: waiting   blocked count: 3   waited count: 65   waiting on java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject@64473a14   stack:     sun.misc.unsafe.park(native method)     java.util.concurrent.locks.locksupport.park(locksupport.java:158)     java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject.await(abstractqueuedsynchronizer.java:1987)     java.util.concurrent.linkedblockingqueue.take(linkedblockingqueue.java:399)     org.apache.hadoop.ipc.server$handler.run(server.java:1364) thread 15 (ipc server listener on 52227):   state: runnable   blocked count: 43   waited count: 0   stack:     sun.nio.ch.epollarraywrapper.epollwait(native method)     sun.nio.ch.epollarraywrapper.poll(epollarraywrapper.java:210)     sun.nio.ch.epollselectorimpl.doselect(epollselectorimpl.java:65)     sun.nio.ch.selectorimpl.lockanddoselect(selectorimpl.java:69)     sun.nio.ch.selectorimpl.select(selectorimpl.java:80)     sun.nio.ch.selectorimpl.select(selectorimpl.java:84)     org.apache.hadoop.ipc.server$listener.run(server.java:439) thread 17 (ipc server responder):   state: runnable   blocked count: 0   waited count: 0   stack:     sun.nio.ch.epollarraywrapper.epollwait(native method)     sun.nio.ch.epollarraywrapper.poll(epollarraywrapper.java:210)     sun.nio.ch.epollselectorimpl.doselect(epollselectorimpl.java:65)     sun.nio.ch.selectorimpl.lockanddoselect(selectorimpl.java:69)     sun.nio.ch.selectorimpl.select(selectorimpl.java:80)     org.apache.hadoop.ipc.server$responder.run(server.java:605) thread 21 (timer-0):   state: timed_waiting   blocked count: 1   waited count: 17   stack:     java.lang.object.wait(native method)     java.util.timerthread.mainloop(timer.java:509)     java.util.timerthread.run(timer.java:462) thread 20 (245022965@qtp-589734556-1 - acceptor0 selectchannelconnector@localhost:33079):   state: runnable   blocked count: 2   waited count: 1   stack:     sun.nio.ch.epollarraywrapper.epollwait(native method)     sun.nio.ch.epollarraywrapper.poll(epollarraywrapper.java:210)     sun.nio.ch.epollselectorimpl.doselect(epollselectorimpl.java:65)     sun.nio.ch.selectorimpl.lockanddoselect(selectorimpl.java:69)     sun.nio.ch.selectorimpl.select(selectorimpl.java:80)     org.mortbay.io.nio.selectormanager$selectset.doselect(selectormanager.java:498)     org.mortbay.io.nio.selectormanager.doselect(selectormanager.java:192)     org.mortbay.jetty.nio.selectchannelconnector.accept(selectchannelconnector.java:124)     org.mortbay.jetty.abstractconnector$acceptor.run(abstractconnector.java:708)     org.mortbay.thread.queuedthreadpool$poolthread.run(queuedthreadpool.java:582) thread 19 (1821050251@qtp-589734556-0):   state: timed_waiting   blocked count: 0   waited count: 8   stack:     java.lang.object.wait(native method)     org.mortbay.thread.queuedthreadpool$poolthread.run(queuedthreadpool.java:626) thread 16 (pool-1-thread-1):   state: runnable   blocked count: 45   waited count: 44   stack:     sun.nio.ch.epollarraywrapper.epollwait(native method)     sun.nio.ch.epollarraywrapper.poll(epollarraywrapper.java:210)     sun.nio.ch.epollselectorimpl.doselect(epollselectorimpl.java:65)     sun.nio.ch.selectorimpl.lockanddoselect(selectorimpl.java:69)     sun.nio.ch.selectorimpl.select(selectorimpl.java:80)     sun.nio.ch.selectorimpl.select(selectorimpl.java:84)     org.apache.hadoop.ipc.server$listener$reader.run(server.java:333)     java.util.concurrent.threadpoolexecutor$worker.runtask(threadpoolexecutor.java:886)     java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:908)     java.lang.thread.run(thread.java:662) thread 14 (org.apache.hadoop.hdfs.server.namenode.decommissionmanager$monitor@620fa83):   state: timed_waiting   blocked count: 1   waited count: 147   stack:     java.lang.thread.sleep(native method)     org.apache.hadoop.hdfs.server.namenode.decommissionmanager$monitor.run(decommissionmanager.java:65)     java.lang.thread.run(thread.java:662) thread 13 (org.apache.hadoop.hdfs.server.namenode.fsnamesystem$replicationmonitor@d5d4de6):   state: timed_waiting   blocked count: 2   waited count: 147   stack:     java.lang.thread.sleep(native method)     org.apache.hadoop.hdfs.server.namenode.fsnamesystem$replicationmonitor.run(fsnamesystem.java:2689)     java.lang.thread.run(thread.java:662) thread 12 (org.apache.hadoop.hdfs.server.namenode.leasemanager$monitor@73d32e45):   state: timed_waiting   blocked count: 0   waited count: 220   stack:     java.lang.thread.sleep(native method)     org.apache.hadoop.hdfs.server.namenode.leasemanager$monitor.run(leasemanager.java:368)     java.lang.thread.run(thread.java:662) thread 11 (org.apache.hadoop.hdfs.server.namenode.fsnamesystem$heartbeatmonitor@19be4777):   state: timed_waiting   blocked count: 0   waited count: 89   stack:     java.lang.thread.sleep(native method)     org.apache.hadoop.hdfs.server.namenode.fsnamesystem$heartbeatmonitor.run(fsnamesystem.java:2666)     java.lang.thread.run(thread.java:662) thread 10 (org.apache.hadoop.hdfs.server.namenode.pendingreplicationblocks$pendingreplicationmonitor@658f7386):   state: timed_waiting   blocked count: 0   waited count: 2   stack:     java.lang.thread.sleep(native method)     org.apache.hadoop.hdfs.server.namenode.pendingreplicationblocks$pendingreplicationmonitor.run(pendingreplicationblocks.java:186)     java.lang.thread.run(thread.java:662) thread 4 (signal dispatcher):   state: runnable   blocked count: 0   waited count: 0   stack: thread 3 (finalizer):   state: waiting   blocked count: 9   waited count: 10   waiting on java.lang.ref.referencequeue$lock@3d1a70a7   stack:     java.lang.object.wait(native method)     java.lang.ref.referencequeue.remove(referencequeue.java:118)     java.lang.ref.referencequeue.remove(referencequeue.java:134)     java.lang.ref.finalizer$finalizerthread.run(finalizer.java:159) thread 2 (reference handler):   state: waiting   blocked count: 11   waited count: 12   waiting on java.lang.ref.reference$lock@270d75a3   stack:     java.lang.object.wait(native method)     java.lang.object.wait(object.java:485)     java.lang.ref.reference$referencehandler.run(reference.java:116) thread 1 (main):   state: runnable   blocked count: 104   waited count: 97   stack:     sun.management.threadimpl.getthreadinfo1(native method)     sun.management.threadimpl.getthreadinfo(threadimpl.java:156)     sun.management.threadimpl.getthreadinfo(threadimpl.java:121)     org.apache.hadoop.util.reflectionutils.printthreadinfo(reflectionutils.java:149)     org.apache.hadoop.hbase.util.threads.threaddumpingisalive(threads.java:113)     org.apache.hadoop.hbase.localhbasecluster.join(localhbasecluster.java:405)     org.apache.hadoop.hbase.minihbasecluster.join(minihbasecluster.java:408)     org.apache.hadoop.hbase.hbasetestingutility.shutdownminihbasecluster(hbasetestingutility.java:616)     org.apache.hadoop.hbase.hbasetestingutility.shutdownminicluster(hbasetestingutility.java:590)     org.apache.hadoop.hbase.client.testadmin.teardownafterclass(testadmin.java:89)     sun.reflect.nativemethodaccessorimpl.invoke0(native method)     sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:39)     sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:25)     java.lang.reflect.method.invoke(method.java:597)     org.junit.runners.model.frameworkmethod$1.runreflectivecall(frameworkmethod.java:44)     org.junit.internal.runners.model.reflectivecallable.run(reflectivecallable.java:15)     org.junit.runners.model.frameworkmethod.invokeexplosively(frameworkmethod.java:41)     org.junit.internal.runners.statements.runafters.evaluate(runafters.java:37)     org.junit.runners.parentrunner.run(parentrunner.java:236)     org.apache.maven.surefire.junit4.junit4testset.execute(junit4testset.java:53) ",
        "label": 340
    },
    {
        "text": "tune hconnectionmanager getcachedlocation method  about 75% improvement in execution time.  1. add the following method in softvaluesortedmap: public synchronized <k, v> entry<k, v> lowerentry(k key) {   return ((treemap) this.internalmap).lowerentry(key); } 2. modify getcachedlocation:   map.entry<byte[], hregionlocation> tentry = tablelocations.lowerentry(row);   if (tentry != null) {   hregionlocation possibleregion = tentry.getvalue();   //other code } ",
        "label": 546
    },
    {
        "text": "don't block on reader threads queueing to a scheduler queue  blocking on the epoll thread is awful. the new rpc scheduler can have lots of different queues. those queues have different capacity limits. currently the dispatch method can block trying to add the the blocking queue in any of the schedulers. this causes readers to block, tcp acks are delayed, and everything slows down. ",
        "label": 154
    },
    {
        "text": "fix javadoc warnings  from https://builds.apache.org/job/precommit-hbase-build/6211/artifact/trunk/patchprocess/patchjavadocwarnings.txt : [warning] /home/jenkins/jenkins-slave/workspace/precommit-hbase-build/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/replicationsink.java:123: warning - tag @link: can't find replicateentries(org.apache.hadoop.hbase.regionserver.wal.hlog.entry[]) in org.apache.hadoop.hbase.replication.regionserver.replicationsink [info]                                                                          ... [warning] /home/jenkins/jenkins-slave/workspace/precommit-hbase-build/trunk/hbase-client/src/main/java/org/apache/hadoop/hbase/client/put.java:73: warning - @param argument \"ts\" is not a parameter name. the above appeared in other precommit builds as well. ",
        "label": 441
    },
    {
        "text": "move hmasterinterface  hregioninterface  and hmasterregioninterface into o a h h ipc  ",
        "label": 86
    },
    {
        "text": "add disabling block cache scanner flag to the shell  option for scan and count  hbase-1823 added an option for individual scans to not cache blocks. expose this as an option in the shell for scan and count. ",
        "label": 38
    },
    {
        "text": "starting a localhbasecluster when is occupied results in  too many open files   this bug was introduced via hbase-6677 \"random zookeeper port in test can overrun max port\". if 2181 is occupied but you start a localhbasecluster (let's say you untar hbase and start it right away) you'll get this: 13/09/03 10:38:13 info server.nioservercnxnfactory: binding to port 0.0.0.0/0.0.0.0:2181 13/09/03 10:38:13 info server.nioservercnxnfactory: binding to port 0.0.0.0/0.0.0.0:2181 13/09/03 10:38:13 info server.nioservercnxnfactory: binding to port 0.0.0.0/0.0.0.0:2181 ... 13/09/03 10:38:44 info server.nioservercnxnfactory: binding to port 0.0.0.0/0.0.0.0:2181 13/09/03 10:38:44 info server.nioservercnxnfactory: binding to port 0.0.0.0/0.0.0.0:2181 13/09/03 10:38:44 error master.hmastercommandline: master exiting java.io.ioexception: too many open files         at sun.nio.ch.epollarraywrapper.epollcreate(native method)         at sun.nio.ch.epollarraywrapper.<init>(epollarraywrapper.java:87)         at sun.nio.ch.epollselectorimpl.<init>(epollselectorimpl.java:68)         at sun.nio.ch.epollselectorprovider.openselector(epollselectorprovider.java:36)         at java.nio.channels.selector.open(selector.java:227)         at org.apache.zookeeper.server.nioservercnxnfactory.<init>(nioservercnxnfactory.java:61)         at org.apache.hadoop.hbase.zookeeper.minizookeepercluster.startup(minizookeepercluster.java:165)         at org.apache.hadoop.hbase.zookeeper.minizookeepercluster.startup(minizookeepercluster.java:131)         at org.apache.hadoop.hbase.master.hmastercommandline.startmaster(hmastercommandline.java:164)         at org.apache.hadoop.hbase.master.hmastercommandline.run(hmastercommandline.java:134)         at org.apache.hadoop.util.toolrunner.run(toolrunner.java:70)         at org.apache.hadoop.hbase.util.servercommandline.domain(servercommandline.java:78)         at org.apache.hadoop.hbase.master.hmaster.main(hmaster.java:2812) the reason is that minizookeepercluster.selectclientport returns 2181 if defaultclientport is greater than 0, which it always is when starting a localhbasecluster. ",
        "label": 229
    },
    {
        "text": " bucketcache  rename  hbase offheapcache minblocksize     /**    * the target block size used by blockcache instances. defaults to    * {@link hconstants#default_blocksize}.    * todo: this config point is completely wrong, as it's used to determine the    * target block size of blockcache instances. rename.    */   public static final string blockcache_blocksize_key = \"hbase.offheapcache.minblocksize\"; ",
        "label": 334
    },
    {
        "text": "add read log size per second metrics for replication source  the current metrics of replication source contain logeditsreadrate, shippedbatchesrate, etc, which could indicate how fast the data replicated to peer cluster to some extent. however, it is not clear enough to know how many bytes replicating to peer cluster from these metrics. in production environment, it may be important to know the size of replicating data per second because the services may be affected if the network become busy. ",
        "label": 238
    },
    {
        "text": "after a large truncating table hbase becomes unresponsive  if you see **** i removed and ip or something for security reasons once i truncate the table, hbase freaks out for about 10 seconds and all the thrift servers die. thrift server log:  2009-04-02 12:09:08,971 info org.apache.hadoop.ipc.hbaseclass: retrying connect   to server: /*****:60020. already tried 0 time(s).  you see this a bunch of times and then it times out the hbase shell  nhbase(main):001:0> truncate 't2'  09/04/30 13:01:08 info zookeeper.zookeeperwrapper: quorum servers:   ****  truncating t2; it may take a while  disabling table...  09/04/30 13:01:19 info client.hbaseadmin: disabled t2  0 row(s) in 10.3417 seconds  dropping table...  09/04/30 13:01:19 info client.hbaseadmin: deleted t2  0 row(s) in 0.1592 seconds  creating table...  0 row(s) in 14.7567 seconds  hbase(main):002:0> lsit  nameerror: undefined local variable or method `lsit' for #<object:0x3bbe9a50>  from (hbase):3  hbase(main):003:0> lsit  nameerror: undefined local variable or method `lsit' for #<object:0x3bbe9a50>  from (hbase):4  hbase(main):004:0> list  nativeexception: java.lang.nullpointerexception: null  from org/apache/hadoop/hbase/client/hconnectionmanager.java:344:in `proc  essrow'   from org/apache/hadoop/hbase/client/metascanner.java:64:in `metascan'  from org/apache/hadoop/hbase/client/metascanner.java:29:in `metascan'  from org/apache/hadoop/hbase/client/hconnectionmanager.java:351:in `list  tables'   from org/apache/hadoop/hbase/client/hbaseadmin.java:121:in `listtables'  from sun/reflect/nativemethodaccessorimpl.java:-2:in `invoke0'  from sun/reflect/nativemethodaccessorimpl.java:39:in `invoke'  from sun/reflect/delegatingmethodaccessorimpl.java:25:in `invoke'  from java/lang/reflect/method.java:597:in `invoke'  from org/jruby/javasupport/javamethod.java:298:in `invokewithexceptionha  ndling'   from org/jruby/javasupport/javamethod.java:259:in `invoke'  from org/jruby/java/invokers/instancemethodinvoker.java:36:in `call'  from org/jruby/runtime/callsite/cachingcallsite.java:260:in `cacheandcal  l'  from org/jruby/runtime/callsite/cachingcallsite.java:75:in `call'  from org/jruby/ast/callnoargnode.java:61:in `interpret'  from org/jruby/ast/fornode.java:101:in `interpret'  ... 113 levels...  from org/jruby/internal/runtime/methods/dynamicmethod.java:226:in `call'  from org/jruby/internal/runtime/methods/compiledmethod.java:216:in `call  '  from org/jruby/internal/runtime/methods/compiledmethod.java:71:in `call'  from org/jruby/runtime/callsite/cachingcallsite.java:260:in `cacheandcal  l'  from org/jruby/runtime/callsite/cachingcallsite.java:75:in `call'  from home/fds/ts/hadoop/hbase/bin/$dot_dot/bin/hirb.rb:441:in `_file  _'  from home/fds/ts/hadoop/hbase/bin/$dot_dot/bin/hirb.rb:-1:in `_file_  '  from home/fds/ts/hadoop/hbase/bin/$dot_dot/bin/hirb.rb:-1:in `load'  from org/jruby/ruby.java:564:in `runscript'  from org/jruby/ruby.java:467:in `runnormally'  from org/jruby/ruby.java:340:in `runfrommain'  from org/jruby/main.java:214:in `run'  from org/jruby/main.java:100:in `run'  from org/jruby/main.java:84:in `main'  from /home/fds/ts/hadoop/hbase/bin/../bin/hirb.rb:300:in `list'  from (hbase):5hbase(main):005:0>  hbase(main):006:0* ",
        "label": 21
    },
    {
        "text": "ref guide needs upgrade update  our ref guide has lots of references in the upgrade section to obsolete versions and no references to the 2.0.0-* releases. we should correct this for beta-1 ",
        "label": 402
    },
    {
        "text": "flooding the cluster with administrative actions leads to collapse  steps to reproduce:  1. start a cluster.  2. start an ingest process.  3. in the hbase shell, do this: while true do    flush 'table' end we should reject abuse via administrative requests like this. what happens on the cluster is the requests back up, leading to lots of these: 2014-01-10 18:55:55,293 warn  [priority.rpcserver.handler=2,port=8120] monitoring.taskmonitor: too many actions in action monitor! purging some. at this point we could lower a gate on further requests for actions until the backlog clears. continuing, all of the regionservers will eventually die with a stackoverflowerror of unknown origin because, stack overflow: 2014-01-10 19:02:02,783 error [priority.rpcserver.handler=3,port=8120] ipc.rpcserver: unexpected throwable object java.lang.stackoverflowerror         at java.util.arraylist$sublist.add(arraylist.java:965) [...] ",
        "label": 229
    },
    {
        "text": "root region does not get assigned after doing kill  on all daemons and restarting hbase  when doing a kill -9 on all hbase processes and attempting to re-start hbase, the master does not properly assign the root region. the /hbase/root-region-server znode still contains the old regionserver, but the regionserver referenced in it does not get assigned the root region. this might get resolved after the znode expires, though, but some testing is required. ",
        "label": 324
    },
    {
        "text": "rpc retries non recoverable error  i'm recently working with hbase/trunk + hive/trunk. i had a hive command eventually timeout with the following exception (stacktrace truncated). caused by: java.io.ioexception: could not set up io streams         at org.apache.hadoop.hbase.ipc.rpcclient$connection.setupiostreams(rpcclient.java:922)         at org.apache.hadoop.hbase.ipc.rpcclient.getconnection(rpcclient.java:1536)         at org.apache.hadoop.hbase.ipc.rpcclient.call(rpcclient.java:1425)         at org.apache.hadoop.hbase.ipc.rpcclient.callblockingmethod(rpcclient.java:1654)         at org.apache.hadoop.hbase.ipc.rpcclient$blockingrpcchannelimplementation.callblockingmethod(rpcclient.java:1712)         at org.apache.hadoop.hbase.protobuf.generated.clientprotos$clientservice$blockingstub.scan(clientprotos.java:28857)         at org.apache.hadoop.hbase.client.scannercallable.openscanner(scannercallable.java:302)         at org.apache.hadoop.hbase.client.scannercallable.call(scannercallable.java:157)         at org.apache.hadoop.hbase.client.scannercallable.call(scannercallable.java:57)         at org.apache.hadoop.hbase.client.rpcretryingcaller.callwithretries(rpcretryingcaller.java:120)         ... 43 more caused by: java.lang.nosuchmethoderror: org.apache.hadoop.net.netutils.getinputstream(ljava/net/socket;)lorg/apache/hadoop/net/socketinputwrapper;         at org.apache.hadoop.hbase.ipc.rpcclient$connection.setupiostreams(rpcclient.java:861)         ... 52 more the root cause looks like a dependency version missmatch (hive compiled vs hadoop1, hbase vs hadoop2). however, we still retry this exception, even though it'll never actually complete. we should be more careful where we blindly catch throwables. ",
        "label": 339
    },
    {
        "text": "mapred package docs don't say zookeeper jar is a dependency   in:  http://hadoop.apache.org/hbase/docs/r0.20.3/api/org/apache/hadoop/hbase/mapred/package-summary.html we dont say the classpath needs zookeeper-x.y.z.jar - which it does. but this package does say so:  http://hadoop.apache.org/hbase/docs/r0.20.3/api/org/apache/hadoop/hbase/mapreduce/package-summary.html ",
        "label": 314
    },
    {
        "text": "hadoop requirements section needs to be recast  mention of clusterbomb release  and cleanup of confusion around where to get apache prebuilt append version  make a matrix of hadoop versions and of what and what does not work with what version of hbase. also, address the misunderstanding our doc. is causing here: http://search-hadoop.com/m/e80zczrpl51/hadoop+not+working+after+replacing+hadoop-core.jar+with+hadoop-core-append.jar&subj=re+hadoop+not+working+after+replacing+hadoop+core+jar+with+hadoop+core+append+jar in particular see joe pallas paraphrasing of what our manual says. address. ",
        "label": 314
    },
    {
        "text": "deadlock running 'flushsomeregions'  playing with mr uploading no a regionserver with 60+ regions, i ran into a deadlock: found one java-level deadlock: ============================= \"ipc server handler 19 on 60020\":   waiting to lock monitor 0x084be38c (object 0xb6f69a70, a org.apache.hadoop.hbase.regionserver.flusher),   which is held by \"ipc server handler 16 on 60020\" \"ipc server handler 16 on 60020\":   waiting to lock monitor 0x080f8dec (object 0xb73610c0, a org.apache.hadoop.hbase.regionserver.hregion$writestate),   which is held by \"ipc server handler 2 on 60020\" \"ipc server handler 2 on 60020\":   waiting to lock monitor 0x086e8fe8 (object 0xb6f69cf0, a java.util.hashset),   which is held by \"ipc server handler 16 on 60020\" java stack information for the threads listed above: =================================================== \"ipc server handler 19 on 60020\":         at org.apache.hadoop.hbase.regionserver.flusher.flushsomeregions(flusher.java:261)         - waiting to lock <0xb6f69a70> (a org.apache.hadoop.hbase.regionserver.flusher)         at org.apache.hadoop.hbase.regionserver.flusher.reclaimmemcachememory(flusher.java:252)         at org.apache.hadoop.hbase.regionserver.hregionserver.batchupdate(hregionserver.java:1136)         at sun.reflect.generatedmethodaccessor3.invoke(unknown source)         at sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43)         at java.lang.reflect.method.invoke(method.java:623)         at org.apache.hadoop.hbase.ipc.hbaserpc$server.call(hbaserpc.java:473)         at org.apache.hadoop.ipc.server$handler.run(server.java:896) \"ipc server handler 16 on 60020\":         at org.apache.hadoop.hbase.regionserver.hregion.flushcache(hregion.java:948)         - waiting to lock <0xb73610c0> (a org.apache.hadoop.hbase.regionserver.hregion$writestate)         at org.apache.hadoop.hbase.regionserver.flusher.flushregion(flusher.java:173)         - locked <0xb6f69cf0> (a java.util.hashset)         at org.apache.hadoop.hbase.regionserver.flusher.flushsomeregions(flusher.java:267)         - locked <0xb6f69a70> (a org.apache.hadoop.hbase.regionserver.flusher)         at org.apache.hadoop.hbase.regionserver.flusher.reclaimmemcachememory(flusher.java:252)         at org.apache.hadoop.hbase.regionserver.hregionserver.batchupdate(hregionserver.java:1136)         at sun.reflect.generatedmethodaccessor3.invoke(unknown source)         at sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43)         at java.lang.reflect.method.invoke(method.java:623)         at org.apache.hadoop.hbase.ipc.hbaserpc$server.call(hbaserpc.java:473)         at org.apache.hadoop.ipc.server$handler.run(server.java:896) \"ipc server handler 2 on 60020\":         at org.apache.hadoop.hbase.regionserver.flusher.addregion(flusher.java:237)         - waiting to lock <0xb6f69cf0> (a java.util.hashset)         at org.apache.hadoop.hbase.regionserver.flusher.request(flusher.java:114)         at org.apache.hadoop.hbase.regionserver.hregion.requestflush(hregion.java:1627)         - locked <0xb73610c0> (a org.apache.hadoop.hbase.regionserver.hregion$writestate)         at org.apache.hadoop.hbase.regionserver.hregion.update(hregion.java:1614)         at org.apache.hadoop.hbase.regionserver.hregion.batchupdate(hregion.java:1398)         at org.apache.hadoop.hbase.regionserver.hregionserver.batchupdate(hregionserver.java:1137)         at sun.reflect.generatedmethodaccessor3.invoke(unknown source)         at sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43)         at java.lang.reflect.method.invoke(method.java:623)         at org.apache.hadoop.hbase.ipc.hbaserpc$server.call(hbaserpc.java:473)         at org.apache.hadoop.ipc.server$handler.run(server.java:896) found 1 deadlock. regionserver is hosed. ",
        "label": 38
    },
    {
        "text": "remove  xx heapdumponoutofmemoryerror autodump of heap option on oome  by default the -xx:+heapdumponoutofmemoryerror option is set for hbase. means we'll dump heap when we oome. in the heaps we run with 8g, 16g, etc., these can make for hefty files. no one really looks at these things other than a few weirdos and even then, the interesting ones are too big to ship easily. meantime, they can cause headache. e.g. you are on ec2, root is but a small partition, and you set up hbase on root partition... a heap dump could cause your root partition to fill and make the machine unapproachable. ",
        "label": 314
    },
    {
        "text": "master stuck splitting server logs in shutdown loop  on each iteration  edits are aggregated up into the millions  lars cluster is sick with master trying to split logs. the logs its replaying have millions of edits in them. here is sample from log. first we get the shutdown and then in the shutdown process, we start to split up the shutdown servers log: 2008-03-28 16:29:45,305 info org.apache.hadoop.hbase.hmaster: process shutdown of server 192.168.105.37:60020: logsplit: false, rootres canned: false, numberofmetaregions: 1, onlinemetaregions.size(): 1 2008-03-28 16:29:45,310 info org.apache.hadoop.hbase.hlog: splitting 3 log(s) in hdfs://lv1-xen-pdc-2.worldlingo.com:9000/hbase/log_192 .168.105.37_1206741382563_60020 2008-03-28 16:29:45,311 debug org.apache.hadoop.hbase.hlog: splitting 0 of 3: hdfs://lv1-xen-pdc-2.worldlingo.com:9000/hbase/log_192.16 8.105.37_1206741382563_60020/hlog.dat.002 2008-03-28 16:29:45,380 debug org.apache.hadoop.hbase.hlog: creating new log file writer for path hdfs://lv1-xen-pdc-2.worldlingo.com:9 000/hbase/pdc-docs/488338803/oldlogfile.log and region pdc-docs,ep01108687nwa2,1205739919655 2008-03-28 16:29:45,390 debug org.apache.hadoop.hbase.hlog: creating new log file writer for path hdfs://lv1-xen-pdc-2.worldlingo.com:9 000/hbase/pdc-docs/447465883/oldlogfile.log and region pdc-docs,ep01900680nwa1,1205754584444 2008-03-28 16:29:45,403 debug org.apache.hadoop.hbase.hlog: creating new log file writer for path hdfs://lv1-xen-pdc-2.worldlingo.com:9 000/hbase/pdc-docs/2035706226/oldlogfile.log and region pdc-docs,ep01119588nwa2,1205754281917 2008-03-28 16:29:45,428 debug org.apache.hadoop.hbase.hlog: creating new log file writer for path hdfs://lv1-xen-pdc-2.worldlingo.com:9 000/hbase/pdc-docs/437772136/oldlogfile.log and region pdc-docs,ep00200190nwa2,120576451593 ... we open a file in each region to take edits. we then start replaying the 3 wal files from the regionserver. on the second one, we get exception... 2008-03-28 16:40:36,537 warn org.apache.hadoop.hbase.hlog: old log file hdfs://lv1-xen-pdc-2.worldlingo.com:9000/hbase/pdc-docs/1045858 46/oldlogfile.log already exists. copying existing file to new file 2008-03-28 16:40:36,545 debug org.apache.hadoop.hbase.hlog: creating new log file writer for path hdfs://lv1-xen-pdc-2.worldlingo.com:9 000/hbase/pdc-docs/104585846/oldlogfile.log and region pdc-docs,ep96104830nwa1,1205768785572 2008-03-28 16:40:36,979 debug org.apache.hadoop.hbase.hlog: copied 220000 edits 2008-03-28 16:40:38,853 debug org.apache.hadoop.hbase.hlog: applied 222812 total edits 2008-03-28 16:40:38,853 debug org.apache.hadoop.hbase.hlog: splitting 1 of 3: hdfs://lv1-xen-pdc-2.worldlingo.com:9000/hbase/log_192.16 8.105.37_1206741382563_60020/hlog.dat.003 2008-03-28 16:40:56,883 warn org.apache.hadoop.hbase.hlog: old log file hdfs://lv1-xen-pdc-2.worldlingo.com:9000/hbase/pdc-docs/2118067 194/oldlogfile.log already exists. copying existing file to new file 2008-03-28 16:40:56,891 debug org.apache.hadoop.hbase.hlog: creating new log file writer for path hdfs://lv1-xen-pdc-2.worldlingo.com:9 000/hbase/pdc-docs/2118067194/oldlogfile.log and region pdc-docs,ep97302517nwa2,1205726201776 2008-03-28 16:41:12,910 debug org.apache.hadoop.hbase.hlog: applied 36638 total edits 2008-03-28 16:41:12,910 debug org.apache.hadoop.hbase.hlog: splitting 2 of 3: hdfs://lv1-xen-pdc-2.worldlingo.com:9000/hbase/log_192.16 8.105.37_1206741382563_60020/hlog.dat.004 2008-03-28 16:41:18,684 warn org.apache.hadoop.hbase.hmaster: processing pending operations: processservershutdown of 192.168.105.37:60 020 java.io.eofexception         at java.io.datainputstream.readfully(datainputstream.java:178)         at org.apache.hadoop.io.dataoutputbuffer$buffer.write(dataoutputbuffer.java:56)         at org.apache.hadoop.io.dataoutputbuffer.write(dataoutputbuffer.java:90)         at org.apache.hadoop.io.sequencefile$reader.next(sequencefile.java:1829)         at org.apache.hadoop.io.sequencefile$reader.next(sequencefile.java:1729)         at org.apache.hadoop.io.sequencefile$reader.next(sequencefile.java:1775)         at org.apache.hadoop.hbase.hlog.splitlog(hlog.java:540)         at org.apache.hadoop.hbase.hmaster$processservershutdown.process(hmaster.java:2167)         at org.apache.hadoop.hbase.hmaster.run(hmaster.java:1085) a finally clause makes sure we close up all the new files we've made in all regions. these new files have accumulated some edits from the splitting of the first file. because we got an exception, the shutdown processing runs again. because regions have files in place with edits, we won't overwrite them second time through. we instead copy the old into a new file to which we start appending until the exception happens again. after a couple of hours, we're up into the millions of edits. ",
        "label": 314
    },
    {
        "text": "remove getregionserverwithoutretries and getregionserverwithretries from hconnection interface  its broke having these meta methods in hconnection. they take servercallables which themselves have hconnections inevitably. it makes for a tangle in the model and frustrates being able to do mocked implemenations of hconnection. these methods better belong in something like hconnectionmanager, or elsewhere altogether. ",
        "label": 314
    },
    {
        "text": "nullpointerexception in clientscanner  the following stack trace was observed whilst loading a large volume of data into hbase: caused by: java.lang.nullpointerexception  at org.apache.hadoop.hbase.client.htable$clientscanner.next(htable.java:2008)  at org.apache.hadoop.hbase.client.htable$clientscanner$1.hasnext(htable.java:2089) it appears that lastresult is initialized to be null, however in the exception handling code there isn't any null checking before the field is accessed for get row:  this.scan.setstartrow(this.lastresult.getrow()); there should be some additional null checking logic here. ",
        "label": 38
    },
    {
        "text": "shell code should create a binding   irb workspace instead of polluting the root namespace  right now, the shell builds a list of commands and then injects them into the root exectution's context bin/hirb.rb # add commands to this namespace @shell.export_commands(self) hbase-shell/src/main/ruby/shell.rb     def export_commands(where)       ::shell.commands.keys.each do |cmd|         # here where is the irb namespace         # this method just adds the call to the specified command         # which just references back to 'this' shell object         # a decently extensible way to add commands         where.send :instance_eval, <<-eof           def #{cmd}(*args)             ret = @shell.command('#{cmd}', *args)             puts             return ret           end         eof       end     end this is an unclean abstraction. for one, it requires that there be an instance variable in the main namespace called '@shell' without making that clear in the docs. additionally, it complicates maintenance by breaking isolation. we should update things so that shell can provide a binding for eval or a workspace for irb execution and then use it directly when we construct our irb session. ",
        "label": 153
    },
    {
        "text": "remove namenode uri from zk splitlogs  when moving to hdfs ha or removing ha we end up changing the nn namespace. this can cause the hmaster not to start up fully due to trying to split phantom hlogs pointing to the wrong fs - java.lang.illegalargumentexception: wrong fs: error messages. the hlogs in question might not even be on hdfs anymore. you have to go in a manually clear out the zk splitlogs directory to get hbase to properly boot up. ",
        "label": 199
    },
    {
        "text": "define a public interface for canary and move existing implementation to limitedprivate  it can be marked as ia.limitedprivate(tools). ",
        "label": 387
    },
    {
        "text": "fix testasyncdecommissionadminapi  ",
        "label": 149
    },
    {
        "text": "bundle ruby files for hbase shell into a jar   we currently package all the ruby scripts for the hbase shell by placing them in a directory within lib/. we should be able to put these in a jar file since we rely on jruby. ",
        "label": 402
    },
    {
        "text": "implement updateconfiguration stopmaster stopregionserver shutdown methods  ",
        "label": 187
    },
    {
        "text": "testshell visibility tests failing  this is after hbase-14105 but we've seen this earlier where adding ruby units to the shell tests can cause the visibility tests to fail inexplicably. we can't just avoid adding ruby units to testshell in 0.98 so figure out the root cause and fix or disable these.   1) error: test_the_get/put_methods_should_work_for_data_written_with_visibility(hbase::visibilitylabelsadminmethodstest): nativeexception: junit.framework.assertionfailederror: waiting timed out after [10,000] msec     junit/framework/assert.java:57:in `fail'     org/apache/hadoop/hbase/waiter.java:193:in `waitfor'     org/apache/hadoop/hbase/waiter.java:128:in `waitfor'     org/apache/hadoop/hbase/hbasetestingutility.java:3514:in `waitfor'     org/apache/hadoop/hbase/hbasetestingutility.java:3576:in `waitlabelavailable'     ./src/test/ruby/hbase/visibility_labels_admin_test.rb:73:in `test_the_get/put_methods_should_work_for_data_written_with_visibility'     org/jruby/rubyproc.java:270:in `call'     org/jruby/rubykernel.java:2105:in `send'     org/jruby/rubyarray.java:1620:in `each'     org/jruby/rubyarray.java:1620:in `each'   2) error: test_the_set/clear_methods_should_work_with_authorizations(hbase::visibilitylabelsadminmethodstest): nativeexception: junit.framework.assertionfailederror: waiting timed out after [10,000] msec     junit/framework/assert.java:57:in `fail'     org/apache/hadoop/hbase/waiter.java:193:in `waitfor'     org/apache/hadoop/hbase/waiter.java:128:in `waitfor'     org/apache/hadoop/hbase/hbasetestingutility.java:3514:in `waitfor'     org/apache/hadoop/hbase/hbasetestingutility.java:3576:in `waitlabelavailable'     ./src/test/ruby/hbase/visibility_labels_admin_test.rb:52:in `test_the_set/clear_methods_should_work_with_authorizations'     org/jruby/rubyproc.java:270:in `call'     org/jruby/rubykernel.java:2105:in `send'     org/jruby/rubyarray.java:1620:in `each'     org/jruby/rubyarray.java:1620:in `each' ",
        "label": 38
    },
    {
        "text": "operational concerns for replication should call out zookeeper  our design invariants state that zookeeper data is safe to delete. however, replication only stores its data in zookeeper.   this can lead to operators accidentally disabling their replication set up while attempting to recover from an unrelated issue by clearing the zk state. we should update the operational concerns section on replication to call out that the /hbase/replication tree should not be deleted. we should probably also add a warning to the set up steps. ",
        "label": 330
    },
    {
        "text": "use builder pattern to remove nullable parameters for coprocessor methods in rawasynctable interface  ",
        "label": 149
    },
    {
        "text": "make the number of flush thread be updated in an online fashion  hbase regionserver flusher count   in order to achieve online configurable, some of key hbase configuration knobs needed to be updated on the fly.   currently, hbase can be configured to flush multiple region's memstore in parallel. and this task is to make the number of flush thread be updated in an online fashion (hbase.regionserver.flusher.count). ",
        "label": 154
    },
    {
        "text": "export hdfs read and write latency as a metric  hdfs write latency spikes especially are an indicator of general cluster overloading. we see this where the wal writer complains about writes taking > 1 second, sometimes > 4, etc. if for example the average write latency over the monitoring period is exported as a metric, then this can feed into alerting for or automatic provisioning of additional cluster hardware. while we're at it, export read side metrics as well. ",
        "label": 38
    },
    {
        "text": "fix testfsutils creating dirs under top level dir  ",
        "label": 314
    },
    {
        "text": "testregionservercoprocessorexceptionwithabort fails if the region server stops too fast  the current implementation of hregionserver#stop is   public void stop(final string msg) {     this.stopped = true;     log.info(\"stopped: \" + msg);     synchronized (this) {       // wakes run() if it is sleeping       notifyall(); // findbugs nn_naked_notify     }   } the notification is sent on the wrong object and does nothing. as a consequence, the region server continues to sleep instead of waking up and stopping immediately. a correct implementation is:   public void stop(final string msg) {     this.stopped = true;     log.info(\"stopped: \" + msg);     // wakes run() if it is sleeping     sleeper.skipsleepcycle();   } then the region server stops immediately. this makes the region server stops 0,5s faster on average, which is quite useful for unit tests. however, with this fix, testregionservercoprocessorexceptionwithabort does not work.  it likely because the code does no expect the region server to stop that fast. the exception is: testexceptionfromcoprocessorduringput(org.apache.hadoop.hbase.coprocessor.testregionservercoprocessorexceptionwithabort)  time elapsed: 30.06 sec  <<< error! java.lang.exception: test timed out after 30000 milliseconds at java.lang.throwable.fillinstacktrace(native method) at java.lang.throwable.<init>(throwable.java:196) at java.lang.exception.<init>(exception.java:41) at java.lang.interruptedexception.<init>(interruptedexception.java:48) at java.lang.thread.sleep(native method) at org.apache.hadoop.hbase.client.hconnectionmanager$hconnectionimplementation.locateregioninmeta(hconnectionmanager.java:1019) at org.apache.hadoop.hbase.client.hconnectionmanager$hconnectionimplementation.locateregion(hconnectionmanager.java:804) at org.apache.hadoop.hbase.client.hconnectionmanager$hconnectionimplementation.relocateregion(hconnectionmanager.java:778) at org.apache.hadoop.hbase.client.hconnectionmanager$hconnectionimplementation.getregionlocation(hconnectionmanager.java:697) at org.apache.hadoop.hbase.client.servercallable.connect(servercallable.java:75) at org.apache.hadoop.hbase.client.hconnectionmanager$hconnectionimplementation.getregionserverwithretries(hconnectionmanager.java:1280) at org.apache.hadoop.hbase.client.htable.getroworbefore(htable.java:585) at org.apache.hadoop.hbase.client.metascanner.metascan(metascanner.java:154) at org.apache.hadoop.hbase.client.metascanner.access$000(metascanner.java:52) at org.apache.hadoop.hbase.client.metascanner$1.connect(metascanner.java:130) at org.apache.hadoop.hbase.client.metascanner$1.connect(metascanner.java:127) at org.apache.hadoop.hbase.client.hconnectionmanager.execute(hconnectionmanager.java:357) at org.apache.hadoop.hbase.client.metascanner.metascan(metascanner.java:127) at org.apache.hadoop.hbase.client.metascanner.metascan(metascanner.java:103) at org.apache.hadoop.hbase.client.hconnectionmanager$hconnectionimplementation.prefetchregioncache(hconnectionmanager.java:866) at org.apache.hadoop.hbase.client.hconnectionmanager$hconnectionimplementation.locateregioninmeta(hconnectionmanager.java:920) at org.apache.hadoop.hbase.client.hconnectionmanager$hconnectionimplementation.locateregion(hconnectionmanager.java:808) at org.apache.hadoop.hbase.client.hconnectionmanager$hconnectionimplementation.processbatchcallback(hconnectionmanager.java:1469) at org.apache.hadoop.hbase.client.hconnectionmanager$hconnectionimplementation.processbatch(hconnectionmanager.java:1354) at org.apache.hadoop.hbase.client.htable.flushcommits(htable.java:892) at org.apache.hadoop.hbase.client.htable.doput(htable.java:750) at org.apache.hadoop.hbase.client.htable.put(htable.java:725) at org.apache.hadoop.hbase.coprocessor.testregionservercoprocessorexceptionwithabort.testexceptionfromcoprocessorduringput(testregionservercoprocessorexceptionwithabort.java:84) at sun.reflect.nativemethodaccessorimpl.invoke0(native method) at sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:39) at sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:25) at java.lang.reflect.method.invoke(method.java:597) at org.junit.runners.model.frameworkmethod$1.runreflectivecall(frameworkmethod.java:45) at org.junit.internal.runners.model.reflectivecallable.run(reflectivecallable.java:15) at org.junit.runners.model.frameworkmethod.invokeexplosively(frameworkmethod.java:42) at org.junit.internal.runners.statements.invokemethod.evaluate(invokemethod.java:20) at org.junit.internal.runners.statements.failontimeout$statementthread.run(failontimeout.java:62) we have this exception because we entered a loop of retries. ",
        "label": 164
    },
    {
        "text": "testimportexport has been failing against hadoop profile  testimportexport has been failing against hadoop 0.23 profile ",
        "label": 248
    },
    {
        "text": "too aggressive task resubmission from the distributed log manager  with default settings for \"hbase.splitlog.manager.timeout\" => 25s and \"hbase.splitlog.max.resubmit\" => 3. on tests mentionned on hbase-5843, i have variations around this scenario, 0.94 + hdfs 1.0.3: the regionserver in charge of the split does not answer in less than 25s, so it gets interrupted but actually continues. sometimes, we go out of the number of retry, sometimes not, sometimes we're out of retry, but the as the interrupts were ignored we finish nicely. in the mean time, the same single task is executed in parallel by multiple nodes, increasing the probability to get into race conditions. details:  t0: unplug a box with dn+rs  t + x: other boxes are already connected, to their connection starts to dies. nevertheless, they don't consider this node as suspect.  t + 180s: zookeeper -> master detects the node as dead. recovery start. it can be less than 180s sometimes it around 150s.  t + 180s: distributed split starts. there is only 1 task, it's immediately acquired by a one rs.  t + 205s: the rs has multiple errors when splitting, because a datanode is missing as well. the master decides to give the task to someone else. but often the task continues in the first rs. interrupts are often ignored, as it's well stated in the code (\"// todo interrupt often gets swallowed, do what else?\")    2012-09-04 18:27:30,404 info org.apache.hadoop.hbase.regionserver.splitlogworker: sending interrupt to stop the worker thread t + 211s: two regionsservers are processing the same task. they fight for the leases: 2012-09-04 18:27:32,004 warn org.apache.hadoop.hdfs.dfsclient: datastreamer exception: org.apache.hadoop.ipc.remoteexception:          org.apache.hadoop.hdfs.server.namenode.leaseexpiredexception: lease mismatch on    /hbase/table/4d1c1a4695b1df8c58d13382b834332e/recovered.edits/0000000000000000037.temp owned by dfsclient_hb_rs_box2,60020,1346775882980 but is accessed by dfsclient_hb_rs_box1,60020,1346775719125 they can fight like this for many files, until the tasks finally get interrupted or finished.  the taks on the second box can be cancelled as well. in this case, the task is created again for a new box.  the master seems to stop after 3 attemps. it can as well renounce to split the files. sometimes the tasks were not cancelled on the rs side, so the split is finished despites what the master thinks and logs. in this case, the assignement starts. in the other, it's \"we've got a problem\"). 2012-09-04 18:43:52,724 info org.apache.hadoop.hbase.master.splitlogmanager: skipping resubmissions of task /hbase/splitlog/hdfs%3a%2f%2fbox1%3a9000%2fhbase%2f.logs%2fbox0%2c60020%2c1346776587640-splitting%2fbox0%252c60020%252c1346776587640.1346776587832 because threshold 3 reached      t + 300s: split is finished. assignement starts  t + 330s: assignement is finished, regions are available again. there are a lot of subcases possible depending on the number of logs files, of region server and so on. the issues are:  1) it's difficult, especially in hbase but not only, to interrupt a task. the pattern is often  void f() throws ioexception{   try {      // whatever throw interruptedexception   }catch(interruptedexception){     throw new interruptedioexception();   } }  boolean g(){    int nbretry= 0;      for(;;)       try{          f();          return true;       }catch(ioexception e){          nbretry++;          if ( nbretry > maxretry) return false;       }    }   } this tyically shallows the interrupt. there are other variation, but this one seems to be the standard.  even if we fix this in hbase, we need the other layers to be interrupteble as well. that's not proven. 2) 25s is very aggressive, considering that we have a default timeout of 180s for zookeeper. in other words, we give 180s to a regionserver before acting, but when it comes to split, it's 25s only. there may be reasons for this, but it seems dangerous, as during a failure the cluster is less available than during normal operations. we could do stuff around this, for example:  => obvious option: increase the timeout at each try. something like *2.  => also possible: increase the initial timeout  => check for an update instead of blindly cancelling + resubmitting. 3) globally, it seems that this retry mechanism duplicates the failure detection already in place with zk. would it not make sense to just hook into this existing detection mechanism, and resubmit a task if and only if we detect that the regionserver in charge died? during a failure scenario we should be much more gentle than during normal operation, not the opposite. ",
        "label": 340
    },
    {
        "text": "hbase master log grows very fast after stopped hadoop  due to connection exception   hbase 96.0(probably the same issue on 94.x) on single node cluster. at some point, we stopped hadoop, but keep hbase running. as expected, hbase began to throw connection errors. p.s., later testing shows that this problem doesn't limit to single node cluster. for the first hour, the regionserver log grows by ~10mb, and master log doesn't grow much, which is ok. log size after one hour -rw-rw-r-- 1 biadmin biadmin  497959 feb  5 10:36 hbase-biadmin-master-hdtest014.svl.ibm.com.log ... -rw-rw-r-- 1 biadmin biadmin 8865371 feb  5 10:37 hbase-biadmin-regionserver-hdtest014.svl.ibm.com.log however, within 4 hours, the master log grows to 13gb. and it only stops due to out of disk space. log size after 4 hour -rw-rw-r-- 1 biadmin biadmin  3521880064 feb  5 14:10 hbase-biadmin-master-hdtest014.svl.ibm.com.log -rw-rw-r-- 1 biadmin biadmin 10737418582 feb  5 11:25 hbase-biadmin-master-hdtest014.svl.ibm.com.log.1 ... -rw-rw-r-- 1 biadmin biadmin    11222365 feb  5 10:49 hbase-biadmin-regionserver-hdtest014.svl.ibm.com.log the exception/error message filled out master log is error message filling up master log 2014-02-05 11:37:48,688 info org.apache.hadoop.hbase.master.handler.metaservershutdownhandler: splitting hbase:meta logs for hdtest014.svl.ibm.com,60020,1391622549030 2014-02-05 11:37:48,689 error org.apache.hadoop.hbase.executor.eventhandler: caught throwable while processing event m_meta_server_shutdown java.io.ioexception: failed log splitting for hdtest014.svl.ibm.com,60020,1391622549030, will retry     at org.apache.hadoop.hbase.master.handler.metaservershutdownhandler.process(metaservershutdownhandler.java:70)     at org.apache.hadoop.hbase.executor.eventhandler.run(eventhandler.java:128)     at java.util.concurrent.threadpoolexecutor$worker.runtask(threadpoolexecutor.java:906)     at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:929)     at java.lang.thread.run(thread.java:738) caused by: java.net.connectexception: call from hdtest014.svl.ibm.com/9.30.194.23 to hdtest014.svl.ibm.com:9000 failed on connection exception: java.net.connectexception: connection refused; for more details see:  http://wiki.apache.org/hadoop/connectionrefused     at sun.reflect.generatedconstructoraccessor5.newinstance(unknown source)     at sun.reflect.delegatingconstructoraccessorimpl.newinstance(delegatingconstructoraccessorimpl.java:39)     at java.lang.reflect.constructor.newinstance(constructor.java:527)     at org.apache.hadoop.net.netutils.wrapwithmessage(netutils.java:783)     at org.apache.hadoop.net.netutils.wrapexception(netutils.java:730)     at org.apache.hadoop.ipc.client.call(client.java:1351)     at org.apache.hadoop.ipc.client.call(client.java:1300)     at org.apache.hadoop.ipc.protobufrpcengine$invoker.invoke(protobufrpcengine.java:206)     at com.sun.proxy.$proxy8.getfileinfo(unknown source)     at sun.reflect.generatedmethodaccessor8.invoke(unknown source)     at sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:37)     at java.lang.reflect.method.invoke(method.java:611)     at org.apache.hadoop.io.retry.retryinvocationhandler.invokemethod(retryinvocationhandler.java:186)     at org.apache.hadoop.io.retry.retryinvocationhandler.invoke(retryinvocationhandler.java:102)     at com.sun.proxy.$proxy8.getfileinfo(unknown source)     at org.apache.hadoop.hdfs.protocolpb.clientnamenodeprotocoltranslatorpb.getfileinfo(clientnamenodeprotocoltranslatorpb.java:651)     at sun.reflect.generatedmethodaccessor9.invoke(unknown source)     at sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:37)     at java.lang.reflect.method.invoke(method.java:611)     at org.apache.hadoop.hbase.fs.hfilesystem$1.invoke(hfilesystem.java:266)     at com.sun.proxy.$proxy11.getfileinfo(unknown source)     at org.apache.hadoop.hdfs.dfsclient.getfileinfo(dfsclient.java:1679)     at org.apache.hadoop.hdfs.distributedfilesystem$17.docall(distributedfilesystem.java:1106)     at org.apache.hadoop.hdfs.distributedfilesystem$17.docall(distributedfilesystem.java:1102)     at org.apache.hadoop.fs.filesystemlinkresolver.resolve(filesystemlinkresolver.java:81)     at org.apache.hadoop.hdfs.distributedfilesystem.getfilestatus(distributedfilesystem.java:1102)     at org.apache.hadoop.fs.filesystem.exists(filesystem.java:1406)     at org.apache.hadoop.hbase.master.masterfilesystem.getlogdirs(masterfilesystem.java:317)     at org.apache.hadoop.hbase.master.masterfilesystem.splitlog(masterfilesystem.java:405)     at org.apache.hadoop.hbase.master.masterfilesystem.splitmetalog(masterfilesystem.java:301)     at org.apache.hadoop.hbase.master.masterfilesystem.splitmetalog(masterfilesystem.java:292)     at org.apache.hadoop.hbase.master.handler.metaservershutdownhandler.process(metaservershutdownhandler.java:63)     ... 4 more caused by: java.net.connectexception: connection refused     at sun.nio.ch.socketchannelimpl.checkconnect(native method)     at sun.nio.ch.socketchannelimpl.finishconnect(socketchannelimpl.java:614)     at org.apache.hadoop.net.socketiowithtimeout.connect(socketiowithtimeout.java:206)     at org.apache.hadoop.net.netutils.connect(netutils.java:529)     at org.apache.hadoop.net.netutils.connect(netutils.java:493)     at org.apache.hadoop.ipc.client$connection.setupconnection(client.java:547)     at org.apache.hadoop.ipc.client$connection.setupiostreams(client.java:642)     at org.apache.hadoop.ipc.client$connection.access$2600(client.java:314)     at org.apache.hadoop.ipc.client.getconnection(client.java:1399)     at org.apache.hadoop.ipc.client.call(client.java:1318) ",
        "label": 134
    },
    {
        "text": "purge the logs when we reach the eof for the last wal file when replication  now there will be strange a warn log 2019-05-30 14:59:38,426 warn  [rs:1;zhangduo-ubuntu:39885.replicationsource.wal-reader.zhangduo-ubuntu%2c39885%2c1559199556433,2] wal.protobuflogreader(422): encountered a malformed edit, seeking back to last good position in file, from 2459 to 2459 java.io.eofexception: first byte is negative at offset 2459 at org.apache.hadoop.hbase.regionserver.wal.protobuflogreader.readnext(protobuflogreader.java:347) at org.apache.hadoop.hbase.regionserver.wal.readerbase.next(readerbase.java:98) at org.apache.hadoop.hbase.regionserver.wal.readerbase.next(readerbase.java:86) at org.apache.hadoop.hbase.replication.regionserver.walentrystream.readnextentryandrecordreaderposition(walentrystream.java:263) at org.apache.hadoop.hbase.replication.regionserver.walentrystream.tryadvanceentry(walentrystream.java:176) at org.apache.hadoop.hbase.replication.regionserver.walentrystream.hasnext(walentrystream.java:101) at org.apache.hadoop.hbase.replication.regionserver.replicationsourcewalreader.readwalentries(replicationsourcewalreader.java:195) at org.apache.hadoop.hbase.replication.regionserver.replicationsourcewalreader.run(replicationsourcewalreader.java:138) and in testreplicationstatus* uts, we set the retry interval to 100ms, so the logs are flooded with these useless warns... ",
        "label": 149
    },
    {
        "text": "merge rawasynctable and asynctable  as discussed in hbase-18978. ",
        "label": 149
    },
    {
        "text": "hbase does not load hadoop native libs  after moving out from hadoop/contrib, the standalone release does not include hadoop native libs in hbase/lib/native while it still includes hadoop-core.jar. i think they should be included as well to improve speed for compression and decompression. ",
        "label": 314
    },
    {
        "text": " compat  bytebufferutils copyfrombuffertobuffer goes from void to int  ramkrishna.s.vasudevan you need this change? bbutils was public back in 1.0 and bytebufferutils.copyfrombuffertobuffer returned a void. hbase-12213 hfileblock backed by array of bytebuffers (ram) changed it to return an int. you think we need this? i can try undoing it. thanks. ",
        "label": 314
    },
    {
        "text": "hbase canary fails with tablenotfoundexception when table deleted during canary run  in 1.3.2 branch-1, we saw a drastic increase in tablenotfoundexceptions thrown by hbase canary. we traced the issue back to canary trying to call istableenabled() on temporary tables that were deleted in the middle of the canary run. in this version of hbase canary, canary throws tablenotfoundexception (and then fails) if a table is deleted between admin.listtables() and admin.tableenabled() function calls in regionmonitor's sniff() method. following the goal of regionmonitor.sniff(), which is to query all existing tables, in order to reduce noise we should skip over a table (i.e. don't check if it was enabled, or do anything else with it at all) if it was returned in listtables() but deleted before canary can query it. temporary tables which are not meant to be kept should not throw tablenotfoundexceptions which fail the canary. patch in progress: add a call to admin.tableexists() before tableenabled() on line 1244 in regionmonitor.sniff(). ",
        "label": 89
    },
    {
        "text": "document how to use bash with hbase shell  ",
        "label": 248
    },
    {
        "text": "create checkandput variant that exposes timestamp   uuid  michael checked the checkandput which doesn't expose timestamp. a variant of checkandput should be created to expose timestamp which is written into a column specified by additional parameters. ",
        "label": 314
    },
    {
        "text": "make max versions work like ttl  in scans and gets  check max versions setting and return that many only rather than wait on compaction  hbase-47 added specification of ttl on cells. the implementation checks cell timestamp against configured ttl before returning results scanning or getting. you can also set the maximum versions of a cell to keep. the maximum versions is not checked scanning or getting, only when we compact (we'll drop cells that are beyond the maximum version at compaction time). this issue is about adding check for maximum versions to gets and scans so that if you ask for all versions but have configured the store to only keep 3 versions, though 4 may have been inserted, you'll currently get 4 returned (if compactions have not had a chance to run). ",
        "label": 229
    },
    {
        "text": "remove  ea from all but tests  enable it if you need it testing  follows on from discussion on the tail of hbase-2753 ",
        "label": 314
    },
    {
        "text": "fix the incorrect badversion checking in the recoverable zookeeper  thanks for stack and kaka's reporting that there is a bug in the recoverable zookeeper when handling badversion exception for setdata(). it shall compare the id payload of the data in zk with its own identifier. ",
        "label": 294
    },
    {
        "text": "move entirely to spotbugs  we've been relying on spotbugs definitions with findbugs tooling for awhile now. i think spotbugs now provides its own versions of everything we need (and yetus supports spotbugs directly). do a pass removing findbugs tooling from all branches in favor of spotbugs. ",
        "label": 149
    },
    {
        "text": "possible over catch of exceptions  there are a few cases found by a tool that are possibly over-catch of exceptions, especially those that will abort the server. over-catching these exceptions may unexpectedly abort the server, and may cause problems in the future when code in the try-block evolves. i am attaching a patch against trunk that constrains the catch blocks to the exact exceptions that were thrown. my tool actually found one more case in 0.96.1, but i found it has already been fixed in trunk: line: 1175, file: \"org/apache/hadoop/hbase/master/splitlogmanager.java\" 1173:             try { 1174:               thread.sleep(20); 1175:-            } catch (exception ignoree) { 1175:+           } catch (interruptedexception e) { 1176:               // ignore 1177:             } any feedbacks are much appreciated! ",
        "label": 142
    },
    {
        "text": "regionserver memory leak causing oome during relatively modest bulk importing  i have recreated this issue several times and it appears to have been introduced in 0.2. during an import to a single table, memory usage of individual region servers grows w/o bounds and when set to the default 1gb it will eventually die with oome. this has happened to me as well as daniel ploeg on the mailing list. in my case, i have 10 rs nodes and oome happens w/ 1gb heap at only about 30-35 regions per rs. in previous versions, i have imported to several hundred regions per rs with default heap size. i am able to get past this by increasing the max heap to 2gb. however, the appearance of this in newer versions leads me to believe there is now some kind of memory leak happening in the region servers during import. ",
        "label": 314
    },
    {
        "text": "convert keyvalue to cell in hbase client module   result put delete  columninterpreter  this path is the second half of eliminating keyvalue from the client interfaces. this percolated through quite a bit. ",
        "label": 248
    },
    {
        "text": "add of the offline call to the master interface  hbck from hbase-5128 requires an offline method on the master to properly cleanup state during certain assignment repair operations. this will this method will be added to recent and older versions of hbase. ",
        "label": 248
    },
    {
        "text": "refactoring qos levels convention  current naming convention about qos is confusing. for first, there is no high or low priority, rather it works based on whether the operation is a root/meta lookup or a pure client side one.   with addition of replicationhandlers, we introduced a new level of qos.   i think we should standarized qos levels that reflects how they actually works. ",
        "label": 199
    },
    {
        "text": "add document for async admin  ",
        "label": 187
    },
    {
        "text": "description for hbase acl table is wrong on master status catalogtables  on master-status#catalogtables, i see: hbase:acl the .namespace. table holds information about namespaces. in masterstatustmpl.jamon, we have:         if (tablename.equals(tablename.meta_table_name)){             description = \"the hbase:meta table holds references to all user table regions\";         } else {             description = \"the .namespace. table holds information about namespaces.\";         } the above check doesn't cover hbase:acl table. ",
        "label": 371
    },
    {
        "text": "book should have individual disqus comment per page  instead of one blob of comments for the whole thing, each page in the book should be it's own \"article\", or whatever disqus uses it uniquely identify an comment-able entity. ",
        "label": 330
    },
    {
        "text": "splitting log in a hostile environment   bad hdfs   we drop write ahead log edits  the master has noticed that the regionserver that was carrying the .meta. region among others has died and it goes to split its logs: 2008-05-18 19:58:01,292 debug org.apache.hadoop.hbase.hlog: splitting 0 of 2: hdfs://domu-12-31-38-00-d4-21:9000/hbase/log_10.254.30.79_1210899434766_60020/hlog.dat.017 2008-05-18 19:58:01,408 debug org.apache.hadoop.hbase.hlog: creating new log file writer for path hdfs://domu-12-31-38-00-d4-21:9000/hbase/categories/1060231198/oldlogfile.log and region categories,2864153,1211005494348 2008-05-18 19:58:01,573 debug org.apache.hadoop.hbase.hlog: creating new log file writer for path hdfs://domu-12-31-38-00-d4-21:9000/hbase/categories/297165731/oldlogfile.log and region categories,5992242,1211005494349 master can't write hdfs for some reason so can't do the log split: 2008-05-18 19:59:15,265 info org.apache.hadoop.dfs.dfsclient: exception in createblockoutputstream java.net.sockettimeoutexception: read timed out 2008-05-18 19:59:15,266 info org.apache.hadoop.dfs.dfsclient: abandoning block blk_7852777250062244002 2008-05-18 19:59:15,268 info org.apache.hadoop.dfs.dfsclient: waiting to find target node: 10.252.219.207:50010 2008-05-18 19:59:39,945 info org.apache.hadoop.ipc.client: retrying connect to server: /10.254.30.79:60020. already tried 6 time(s). 2008-05-18 20:00:21,274 info org.apache.hadoop.dfs.dfsclient: exception in createblockoutputstream java.io.ioexception: bad connect ack with firstbadlink 10.254.30.79:50010 2008-05-18 20:00:21,275 info org.apache.hadoop.dfs.dfsclient: abandoning block blk_7007215478628265924 2008-05-18 20:00:21,277 info org.apache.hadoop.dfs.dfsclient: waiting to find target node: 10.252.219.207:50010 2008-05-18 20:00:40,955 info org.apache.hadoop.ipc.client: retrying connect to server: /10.254.30.79:60020. already tried 7 time(s). 2008-05-18 20:01:31,178 info org.apache.hadoop.dfs.dfsclient: exception in createblockoutputstream java.io.ioexception: bad connect ack with firstbadlink 10.254.30.79:50010 2008-05-18 20:01:31,178 info org.apache.hadoop.dfs.dfsclient: abandoning block blk_2374125514769088471 2008-05-18 20:01:31,180 info org.apache.hadoop.dfs.dfsclient: waiting to find target node: 10.252.219.207:50010 2008-05-18 20:01:40,145 info org.apache.hadoop.dfs.dfsclient: exception in createblockoutputstream java.net.sockettimeoutexception: read timed out 2008-05-18 20:01:40,145 info org.apache.hadoop.dfs.dfsclient: abandoning block blk_-621042589816139684 2008-05-18 20:01:40,148 info org.apache.hadoop.dfs.dfsclient: waiting to find target node: 10.252.219.207:50010 .. weirdly, the above is complaining can't connect to the datanode running on same host as master. eventually the split fails with: 2008-05-18 20:24:28,393 warn org.apache.hadoop.hbase.hmaster: processing pending operations: processservershutdown of 10.254.30.79:60020 java.io.ioexception: java.io.ioexception: could not complete write to file /hbase/categories/1060231198/oldlogfile.log by dfsclient_520078809     at org.apache.hadoop.dfs.namenode.complete(namenode.java:343)     at sun.reflect.generatedmethodaccessor44.invoke(unknown source)     at sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:25)     at java.lang.reflect.method.invoke(method.java:597)     at org.apache.hadoop.ipc.rpc$server.call(rpc.java:409)     at org.apache.hadoop.ipc.server$handler.run(server.java:901)     at sun.reflect.nativeconstructoraccessorimpl.newinstance0(native method)     at sun.reflect.nativeconstructoraccessorimpl.newinstance(nativeconstructoraccessorimpl.java:39)     at sun.reflect.delegatingconstructoraccessorimpl.newinstance(delegatingconstructoraccessorimpl.java:27)     at java.lang.reflect.constructor.newinstance(constructor.java:513)     at org.apache.hadoop.hbase.remoteexceptionhandler.decoderemoteexception(remoteexceptionhandler.java:82)     at org.apache.hadoop.hbase.hmaster.run(hmaster.java:1116) 2008-05-18 20:24:28,394 debug org.apache.hadoop.hbase.hmaster: main processing loop: processservershutdown of 10.254.30.79:60020 2008-05-18 20:24:28,394 info org.apache.hadoop.hbase.hmaster: process shutdown of server 10.254.30.79:60020: logsplit: false, rootrescanned: false, numberofmetaregions: 1, onlinemetaregions.size(): 1 2008-05-18 20:24:28,395 info org.apache.hadoop.hbase.hlog: splitting 1 log(s) in hdfs://domu-12-31-38-00-d4-21:9000/hbase/log_10.254.30.79_1210899434766_60020 2008-05-18 20:24:28,395 debug org.apache.hadoop.hbase.hlog: splitting 0 of 1: hdfs://domu-12-31-38-00-d4-21:9000/hbase/log_10.254.30.79_1210899434766_60020/hlog.dat.018 2008-05-18 20:24:28,399 warn org.apache.hadoop.hbase.hlog: old log file hdfs://domu-12-31-38-00-d4-21:9000/hbase/categories/297165731/oldlogfile.log already exists. copying existing file to new file 2008-05-18 20:25:03,105 info org.apache.hadoop.ipc.client: retrying connect to server: /10.254.30.79:60020. already tried 9 time(s). 2008-05-18 20:25:28,401 warn org.apache.hadoop.hbase.hlog: exception processing hdfs://domu-12-31-38-00-d4-21:9000/hbase/log_10.254.30.79_1210899434766_60020/hlog.dat.018 -- continuing. possible data loss! java.net.sockettimeoutexception: timed out waiting for rpc response ... and we just move on to the next log \u2013 we notice the earlier attempt at distributing the edits and try to pick them up (though in this case, the file is likely empty) \u2013 but the split of new log also fails. though log says 'possible data loss!', we keep going . the .meta. and other regions are reassigned and deployed though they are likely missing edits. in this catastrophic case, i'd say master should not move and if it has to, go down rather than reassign regions and try to keep going. ",
        "label": 314
    },
    {
        "text": "list command in shell seems broken  hbase(main):007:0> list error: wrong number of arguments (1 for 2) ",
        "label": 314
    },
    {
        "text": "joinedheap for non essential column families should reseek instead of seek  this was raised by the phoenix team. during a profiling session we noticed that catching the joinedheap up to the current rows via seek causes a performance regression, which makes the joinedheap only efficient when either a high or low percentage is matched by the filter.  (high is fine, because the joinedheap will not get behind as often and does not need to be caught up, low is fine, because the seek isn't happening frequently). in our tests we found that the solution is quite simple: replace seek with reseek. patch coming soon. ",
        "label": 286
    },
    {
        "text": "namespacejanitor chore is not used  currently namespacejanitor chore is not started by hmaster. jimmy identified some race conditions around the janitor. francis said the janitor can do the cleanup for some failure scenarios. this jira is to solicit discussion on how the cleanup should be properly done. ",
        "label": 323
    },
    {
        "text": "move non mr parts of tokenutil into hbase client  hbase-14208 moved tokenutil from hbase-client to hbase-server. i have a project depending on hbase-client 1.4.4, which i'd like to upgrade to 2.1.3. my project uses tokenutil (specifically obtainandcachetoken), which is included in hbase-client 1.4.4. at the same time i also have a dependency on jetty 9.4, which is incompatible with the current version used by hadoop. i can fix this for hbase-client by using hbase-shaded-client instead, since jetty is shaded in this jar, but tokenutil is only present in hbase-server as of 2.0.0. since there is no hbase-shaded-server, i can't use tokenutil and jetty 9.4 at the same time. tokenutil can be split into server-only parts, and a client relevant part that can go back to hbase-client. the tokenutil in hbase-server can retain the moved methods, and delegate to the util in hbase-client if backward compatibility is a concern. ",
        "label": 427
    },
    {
        "text": "split testadmin1  it is too large and easy to timeout. ",
        "label": 149
    },
    {
        "text": "rejectedexecutionexception could be thrown from tableoverasynctable coprocessor service if the connection has been shutown  this breaks testmasterabortwhilemergingtable i believe. https://builds.apache.org/job/hbase-flaky-tests/job/hbase-21512/1151/artifact/hbase-server/target/surefire-reports/org.apache.hadoop.hbase.master.assignment.testmasterabortwhilemergingtable-output.txt/*view*/ 2019-06-01 00:40:09,104 error [peworker-13] procedure2.procedureexecutor(1667): code-bug: uncaught runtime exception: pid=9, state=runnable:merge_table_regions_update_meta, haslock=true; mergetableregionsprocedure table=test, regions=[048d06685b8e1df26516884c41b59c9b, 9f7c60e69f7144b32deb828e3a60c8a8], forcibly=false java.util.concurrent.rejectedexecutionexception: task java.util.concurrent.futuretask@4ba1959e rejected from java.util.concurrent.threadpoolexecutor@67913a08[terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 0] at java.util.concurrent.threadpoolexecutor$abortpolicy.rejectedexecution(threadpoolexecutor.java:2063) at java.util.concurrent.threadpoolexecutor.reject(threadpoolexecutor.java:830) at java.util.concurrent.threadpoolexecutor.execute(threadpoolexecutor.java:1379) at java.util.concurrent.abstractexecutorservice.submit(abstractexecutorservice.java:134) at org.apache.hadoop.hbase.client.tableoverasynctable.coprocssorservice(tableoverasynctable.java:427) at org.apache.hadoop.hbase.client.tableoverasynctable.coprocessorservice(tableoverasynctable.java:457) at org.apache.hadoop.hbase.client.table.coprocessorservice(table.java:527) at org.apache.hadoop.hbase.metatableaccessor.multimutate(metatableaccessor.java:1768) at org.apache.hadoop.hbase.metatableaccessor.mergeregions(metatableaccessor.java:1634) at org.apache.hadoop.hbase.master.assignment.regionstatestore.mergeregions(regionstatestore.java:253) at org.apache.hadoop.hbase.master.assignment.assignmentmanager.markregionasmerged(assignmentmanager.java:1665) at org.apache.hadoop.hbase.master.assignment.mergetableregionsprocedure.updatemetaformergedregions(mergetableregionsprocedure.java:731) at org.apache.hadoop.hbase.master.assignment.mergetableregionsprocedure.executefromstate(mergetableregionsprocedure.java:276) at org.apache.hadoop.hbase.master.assignment.mergetableregionsprocedure.executefromstate(mergetableregionsprocedure.java:84) at org.apache.hadoop.hbase.procedure2.statemachineprocedure.execute(statemachineprocedure.java:194) at org.apache.hadoop.hbase.procedure2.procedure.doexecute(procedure.java:959) at org.apache.hadoop.hbase.procedure2.procedureexecutor.execprocedure(procedureexecutor.java:1648) at org.apache.hadoop.hbase.procedure2.procedureexecutor.executeprocedure(procedureexecutor.java:1395) at org.apache.hadoop.hbase.procedure2.procedureexecutor.access$1100(procedureexecutor.java:78) at org.apache.hadoop.hbase.procedure2.procedureexecutor$workerthread.run(procedureexecutor.java:1964) ",
        "label": 149
    },
    {
        "text": "simpleregionnormalizer needs to have better heuristics to trigger merge operation  simpleregionnormalizer needs to have better heuristics to trigger merge operation. simpleregionnormalizer is not able to trigger a merge action if the table's smallest region has neighboring regions that are larger than table's average region size, whereas there are other smaller regions whose combined size is less than the average region size. for example, consider a table with six region, say r1 to r6. keep r1 as empty and create some data say, 100k rows of data for each of the regions r2, r3 and r4. create smaller amount of data for regions r5 and r6, say about 27k rows of data. run the normalizer. verify the number the regions for that table and also check the master log to see if any merge action was triggered as a result of normalization. in such scenario, it would be better to have a merge action triggered for those two smaller regions r5 and r6 even though either of them is not the smallest one ",
        "label": 441
    },
    {
        "text": "tableinputformat should handle as many errors as possible  prior to hbase-4196 there was different handling of ioexceptions thrown from scanner in mapred and mapreduce api. the patch to hbase-4196 unified this handling so that if exception is caught a reconnect is attempted (without bothering the mapred client). after that, hbase-4269 changed this behavior back, but in both mapred and mapreduce apis. the question is, is there any reason not to handle all errors that the input format can handle? in other words, why not try to reissue the request after any ioexception? i see the following disadvantages of current approach the client may see exceptions like leaseexception and scannertimeoutexception if he fails to process all fetched data in timeout to avoid scannertimeoutexception the client must raise hbase.regionserver.lease.period timeouts for tasks is aready configured in mapred.task.timeout, so this seems to me a bit redundant, because typically one needs to update both these parameters i don't see any possibility to get rid of leaseexception (this is configured on server side) i think all of these issues would be gone, if the donotretryioexception would not be rethrown. on the other hand, handling errors in inputformat has disadvantage, that it may hide from the user some inefficiency. eg. if i have very big scanner.caching, and i manage to process only a few rows in timeout, i will end up with single row being fetched many times (and will not be explicitly notified about this). could we solve this problem by adding some counter to the inputformat? ",
        "label": 227
    },
    {
        "text": "fix two findbugs warnings to get our count down to the tolerated number again  ",
        "label": 314
    },
    {
        "text": "remove meta and root memcache size bandaid  in 0.19 i introduced a bandaid to limit the damage done to losing the rs holding meta or root by drastically lowering the memstore size. example:   protected htabledescriptor(final byte [] name, hcolumndescriptor[] families) {     this.name = name.clone();     this.nameasstring = bytes.tostring(this.name);     setmetaflags(name);     for(hcolumndescriptor descriptor : families) {       this.families.put(descriptor.getname(), descriptor);     }     setmemstoreflushsize(16 * 1024);   } we can remove it from 0.21 since we force sync everything catalog. ",
        "label": 229
    },
    {
        "text": "itbll can't go big because regiontoobusyexception  above memstore limit  running itblls, the basic link generator keeps failing because i run into exceptions like below: 2017-12-26 19:23:45,284 info [main] org.apache.hadoop.hbase.test.integrationtestbiglinkedlist$generator: persisting current.length=1000000, count=1000000, id=job: job_1513025868268_0062 task: attempt_1513025868268_0062_m_000006_2, current=\\x8b\\xdb25\\xa7*\\x9a\\xf5\\xdex\\x83\\xdf\\xdc?\\x94\\x92, i=1000000 2017-12-26 19:24:18,982 info [htable-pool3-t6] org.apache.hadoop.hbase.client.asyncrequestfutureimpl: #2, table=integrationtestbiglinkedlist, attempt=10/11 failed=524ops, last exception: org.apache.hadoop.hbase.regiontoobusyexception: org.apache.hadoop.hbase.regiontoobusyexception: above memstore limit, regionname=integrationtestbiglinkedlist,q\\xc7\\x1cq\\xc7\\x1cq\\xc0,1514342757438.71ef1fbab1576588955f45796e95c08b., server=ve0538.halxg.cloudera.com,16020,1514343549993, memstoresize=538084641, blockingmemstoresize=536870912 at org.apache.hadoop.hbase.regionserver.hregion.checkresources(hregion.java:4178) at org.apache.hadoop.hbase.regionserver.hregion.batchmutate(hregion.java:3799) at org.apache.hadoop.hbase.regionserver.hregion.batchmutate(hregion.java:3739) at org.apache.hadoop.hbase.regionserver.rsrpcservices.dobatchop(rsrpcservices.java:975) at org.apache.hadoop.hbase.regionserver.rsrpcservices.dononatomicregionmutation(rsrpcservices.java:894) at org.apache.hadoop.hbase.regionserver.rsrpcservices.multi(rsrpcservices.java:2587) at org.apache.hadoop.hbase.shaded.protobuf.generated.clientprotos$clientservice$2.callblockingmethod(clientprotos.java:41560) at org.apache.hadoop.hbase.ipc.rpcserver.call(rpcserver.java:404) at org.apache.hadoop.hbase.ipc.callrunner.run(callrunner.java:130) at org.apache.hadoop.hbase.ipc.rpcexecutor$handler.run(rpcexecutor.java:324) at org.apache.hadoop.hbase.ipc.rpcexecutor$handler.run(rpcexecutor.java:304)  on ve0538.halxg.cloudera.com,16020,1514343549993, tracking started null, retrying after=10050ms, replay=524ops 2017-12-26 19:24:29,061 info [htable-pool3-t6] org.apache.hadoop.hbase.client.asyncrequestfutureimpl: #2, table=integrationtestbiglinkedlist, attempt=11/11 failed=524ops, last exception: org.apache.hadoop.hbase.regiontoobusyexception: org.apache.hadoop.hbase.regiontoobusyexception: above memstore limit, regionname=integrationtestbiglinkedlist,q\\xc7\\x1cq\\xc7\\x1cq\\xc0,1514342757438.71ef1fbab1576588955f45796e95c08b., server=ve0538.halxg.cloudera.com,16020,1514343549993, memstoresize=538084641, blockingmemstoresize=536870912 at org.apache.hadoop.hbase.regionserver.hregion.checkresources(hregion.java:4178) at org.apache.hadoop.hbase.regionserver.hregion.batchmutate(hregion.java:3799) at org.apache.hadoop.hbase.regionserver.hregion.batchmutate(hregion.java:3739) at org.apache.hadoop.hbase.regionserver.rsrpcservices.dobatchop(rsrpcservices.java:975) at org.apache.hadoop.hbase.regionserver.rsrpcservices.dononatomicregionmutation(rsrpcservices.java:894) at org.apache.hadoop.hbase.regionserver.rsrpcservices.multi(rsrpcservices.java:2587) at org.apache.hadoop.hbase.shaded.protobuf.generated.clientprotos$clientservice$2.callblockingmethod(clientprotos.java:41560) at org.apache.hadoop.hbase.ipc.rpcserver.call(rpcserver.java:404) at org.apache.hadoop.hbase.ipc.callrunner.run(callrunner.java:130) at org.apache.hadoop.hbase.ipc.rpcexecutor$handler.run(rpcexecutor.java:324) at org.apache.hadoop.hbase.ipc.rpcexecutor$handler.run(rpcexecutor.java:304)  on ve0538.halxg.cloudera.com,16020,1514343549993, tracking started null, retrying after=10033ms, replay=524ops 2017-12-26 19:24:37,183 info [readonlyzkclient] org.apache.hadoop.hbase.zookeeper.readonlyzkclient: 0x015051a0 no activities for 60000 ms, close active connection. will reconnect next time when there are new requests. 2017-12-26 19:24:39,122 warn [htable-pool3-t6] org.apache.hadoop.hbase.client.asyncrequestfutureimpl: #2, table=integrationtestbiglinkedlist, attempt=12/11 failed=524ops, last exception: org.apache.hadoop.hbase.regiontoobusyexception: org.apache.hadoop.hbase.regiontoobusyexception: above memstore limit, regionname=integrationtestbiglinkedlist,q\\xc7\\x1cq\\xc7\\x1cq\\xc0,1514342757438.71ef1fbab1576588955f45796e95c08b., server=ve0538.halxg.cloudera.com,16020,1514343549993, memstoresize=538084641, blockingmemstoresize=536870912 at org.apache.hadoop.hbase.regionserver.hregion.checkresources(hregion.java:4178) at org.apache.hadoop.hbase.regionserver.hregion.batchmutate(hregion.java:3799) at org.apache.hadoop.hbase.regionserver.hregion.batchmutate(hregion.java:3739) at org.apache.hadoop.hbase.regionserver.rsrpcservices.dobatchop(rsrpcservices.java:975) at org.apache.hadoop.hbase.regionserver.rsrpcservices.dononatomicregionmutation(rsrpcservices.java:894) at org.apache.hadoop.hbase.regionserver.rsrpcservices.multi(rsrpcservices.java:2587) at org.apache.hadoop.hbase.shaded.protobuf.generated.clientprotos$clientservice$2.callblockingmethod(clientprotos.java:41560) at org.apache.hadoop.hbase.ipc.rpcserver.call(rpcserver.java:404) at org.apache.hadoop.hbase.ipc.callrunner.run(callrunner.java:130) at org.apache.hadoop.hbase.ipc.rpcexecutor$handler.run(rpcexecutor.java:324) at org.apache.hadoop.hbase.ipc.rpcexecutor$handler.run(rpcexecutor.java:304) ... fails task over and over. with server-killing monkeys. 24gs which should be more than enough. had just finished a big compaction. whats shutting us out? why taking so long to flush? we seen stuck at limit so job fails. ",
        "label": 314
    },
    {
        "text": "add publish of a snapshot to apache repo to our pom  see here http://www.apache.org/dev/publishing-maven-artifacts.html#publish-snapshot ",
        "label": 314
    },
    {
        "text": "incorrect snapshot version is used for beta  maven complains that used snapshot version is incorrect. dot is used instead of hyphen. [warning] some problems were encountered while building the effective model for org.apache.hbase:hbase-error-prone:jar:2.0.0-beta-1.snapshot  [warning] 'version' uses an unsupported snapshot version format, should be '*-snapshot' instead. @ line 30, column 12 ",
        "label": 352
    },
    {
        "text": "wrong warning in logs warn org apache hadoop ipc hbaseserver  methods length    from protobufrpcengine.java     static method getmethod(class<? extends versionedprotocol> protocol,         string methodname) {       method method = methodinstances.get(methodname);       if (method != null) {         return method;       }       method[] methods = protocol.getmethods();       log.warn(\"methods length : \" + methods.length); <=========       for (method m : methods) {         if (m.getname().equals(methodname)) {           m.setaccessible(true);           methodinstances.put(methodname, m);           return m;         }       }       return null;     } ",
        "label": 139
    },
    {
        "text": "upgrade slf4j to  we need to upgrade slf4j to 1.6.1 since other hadoop components use 1.6.1 now. ",
        "label": 242
    },
    {
        "text": " fb  assign sequence number to bulk loaded data  currently bulk loaded files are not assigned a sequence number. thus, they can only be used to import historical data, dating to the past. there are cases where we want to bulk load \"current data\"; but the bulk load mechanism does not support this, as the bulk loaded files are always sorted behind the non-bulkloaded hfiles. assigning sequence id to bulk loaded files should solve this issue. storefiles within a store are sorted based on the sequenceid. sequenceid is a monotonically increasing number that accompanies every edit written to the wal. for entries that update the same cell, we would like the latter edit to win. this comparision is accomplished using memstorets, at the kv level; and sequenceid at the storefile level (to order scanners in the keyvalueheap). bulkloaded files are generated outside of hbase/regionserver, so they do not have a sequenceid written in the file. this causes hbase to lose track of the point in time, when the bulkloaded file was imported to hbase. resulting in a behavior, that *only* supports viewing bulkloaded files as files back-filling data from the begining of time. by assigning a sequence number to the file, we can allow the bulk loaded file to fit in where we want. either at the \"current time\" or the \"begining of time\". the latter is the default, to maintain backward compatibility. design approach:  store files keep track of the sequence id in the trailer. since we do not wish to edit/rewrite the bulk loaded file upon import, we will encode the assigned sequenceid into the filename. the filename regex is updated for this regard. if the sequenceid is encoded in the filename, the sequenceid will be used as the sequenceid for the file. if none is found, the sequenceid will be considered 0 (as per the default, backward-compatible behavior).  to enable clients to request pre-existing behavior, the command line utility allows for 2 ways to import bulkloaded files: to assign or not assign a sequence number. if a sequence number is assigned, the imporeted file will be imported with the \"current sequence id\". if the sequence number is not assigned, it will be as if it was backfilling old data, from the begining of time. compaction behavior: with the current compaction algorithm, bulk loaded files \u2013 that backfill data, to the begining of time \u2013 can cause a compaction storm, converting every minor compaction to a major compaction. to address this, these files are excluded from minor compaction, based on a config param. (enabled for the messages use case). since, bulk loaded files that are not back-filling data do not cause this issue, they will not be ignored during minor compactions based on the config parameter. this is also required to ensure that there are no holes in the set of files selected for compaction \u2013 this is necessary to preserve the order of kv's comparision before and after compaction. ",
        "label": 34
    },
    {
        "text": "generate hadoopx poms sh expects the version to have one extra ' '  this change is in 0.96 branch, but missing in 0.98.  including the commit that made this change ",
        "label": 364
    },
    {
        "text": "explore different queuing behaviors while busy  http://queue.acm.org/detail.cfm?id=2839461 ",
        "label": 323
    },
    {
        "text": "tableoutputformat could not assign a timestamp  when i use the tableoutputformat, it is impossible to assign an specified timestamp to the row.  we may want to assign an specified timestamp. ",
        "label": 314
    },
    {
        "text": "add retries around action server stop start  these can fail on occasion (my upping connectiontimeout is not enough). lets just retry a few times at least rather than fail at least for server start. losing a server makes tests run for longer and there is also the danger we could lose all servers and the long-running test would then outright fail. ",
        "label": 155
    },
    {
        "text": "region server throw notservingregionexception when batchupdate during compaction spliting and then shutdown  2008-12-13 21:30:58,184 info org.apache.hadoop.hbase.regionserver.logroller: rolling hlog. number of entries: 30015  2008-12-13 21:30:58,595 info org.apache.hadoop.hbase.regionserver.hregion: starting compaction on region gdr,138884579261228161625885,1229166027688  2008-12-13 21:31:00,162 info org.apache.hadoop.hbase.regionserver.hlog: new log writer created at /hbase/log_10.24.1.12_1229150189049_60020/hlog.dat.1229175060158  2008-12-13 21:31:00,162 info org.apache.hadoop.hbase.regionserver.hlog: removing old log file /hbase/log_10.24.1.12_1229150189049_60020/hlog.dat.1229173244235 whose highest sequence/edit id is 145008256  2008-12-13 21:31:00,165 info org.apache.hadoop.hbase.regionserver.hlog: removing old log file /hbase/log_10.24.1.12_1229150189049_60020/hlog.dat.1229173248573 whose highest sequence/edit id is 145038271  2008-12-13 21:31:05,571 info org.apache.hadoop.hbase.regionserver.hregion: compaction completed on region gdr,138884579261228161625885,1229166027688 in 6sec  2008-12-13 21:31:05,571 info org.apache.hadoop.hbase.regionserver.hregion: starting split of region gdr,138884579261228161625885,1229166027688  2008-12-13 21:31:05,735 info org.apache.hadoop.hbase.regionserver.hregion: closed gdr,138884579261228161625885,1229166027688  2008-12-13 21:31:05,863 info org.apache.hadoop.ipc.server: ipc server handler 4 on 60020, call batchupdate([b@4df611bd, row => 138884603141228853661885, {column => gdr:start_time, value => '...', column => gdr:imsi, value => '...', column => gdr:msisdn, value => '...', column => gdr:sourceip, value => '...', column => gdr:destip, value => '...', column => gdr:gdrtype, value => '...', column => gdr:req_num, value => '...', column => gdr:apn, value => '...', column => gdr:gdrtime, value => '...', column => gdr:result, value => '...', column => gdr:gtpver, value => '...', column => gdr:remoteno, value => '...', column => gdr:frontno, value => '...', column => gdr:offset, value => '...', column => gdr:url, value => '...'} , -1) from 10.24.1.10:39000: error: org.apache.hadoop.hbase.notservingregionexception: region gdr,138884579261228161625885,1229166027688 closed  org.apache.hadoop.hbase.notservingregionexception: region gdr,138884579261228161625885,1229166027688 closed  at org.apache.hadoop.hbase.regionserver.hregion.obtainrowlock(hregion.java:1836)  at org.apache.hadoop.hbase.regionserver.hregion.getlock(hregion.java:1901)  at org.apache.hadoop.hbase.regionserver.hregion.batchupdate(hregion.java:1432)  at org.apache.hadoop.hbase.regionserver.hregion.batchupdate(hregion.java:1406)  at org.apache.hadoop.hbase.regionserver.hregionserver.batchupdate(hregionserver.java:1415)  at sun.reflect.generatedmethodaccessor7.invoke(unknown source)  at sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:25)  at java.lang.reflect.method.invoke(method.java:597)  at org.apache.hadoop.hbase.ipc.hbaserpc$server.call(hbaserpc.java:554)  at org.apache.hadoop.ipc.server$handler.run(server.java:888)  2008-12-13 21:31:07,594 info org.apache.hadoop.hbase.regionserver.hregion: region gdr,138884579261228161625885,1229175065574/642186371 available  2008-12-13 21:31:07,594 info org.apache.hadoop.hbase.regionserver.hregion: closed gdr,138884579261228161625885,1229175065574  2008-12-13 21:31:07,885 info org.apache.hadoop.ipc.server: ipc server handler 9 on 60020, call batchupdate([b@7792b8d, row => 138884603141228853661885, {column => gdr:start_time, value => '...', column => gdr:imsi, value => '...', column => gdr:msisdn, value => '...', column => gdr:sourceip, value => '...', column => gdr:destip, value => '...', column => gdr:gdrtype, value => '...', column => gdr:req_num, value => '...', column => gdr:apn, value => '...', column => gdr:gdrtime, value => '...', column => gdr:result, value => '...', column => gdr:gtpver, value => '...', column => gdr:remoteno, value => '...', column => gdr:frontno, value => '...', column => gdr:offset, value => '...', column => gdr:url, value => '...'} , -1) from 10.24.1.10:39000: error: org.apache.hadoop.hbase.notservingregionexception: region gdr,138884579261228161625885,1229166027688 closed  org.apache.hadoop.hbase.notservingregionexception: region gdr,138884579261228161625885,1229166027688 closed  at org.apache.hadoop.hbase.regionserver.hregion.obtainrowlock(hregion.java:1836)  at org.apache.hadoop.hbase.regionserver.hregion.getlock(hregion.java:1901)  at org.apache.hadoop.hbase.regionserver.hregion.batchupdate(hregion.java:1432)  at org.apache.hadoop.hbase.regionserver.hregion.batchupdate(hregion.java:1406)  at org.apache.hadoop.hbase.regionserver.hregionserver.batchupdate(hregionserver.java:1415)  at sun.reflect.generatedmethodaccessor7.invoke(unknown source)  at sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:25)  at java.lang.reflect.method.invoke(method.java:597)  at org.apache.hadoop.hbase.ipc.hbaserpc$server.call(hbaserpc.java:554)  at org.apache.hadoop.ipc.server$handler.run(server.java:888)  2008-12-13 21:31:08,346 info org.apache.hadoop.hbase.regionserver.hregion: region gdr,138884596811227665528885,1229175065574/1240335718 available the many region throw such exception. and then the region server shutdown 2008-12-13 22:01:46,700 warn org.apache.hadoop.dfs.dfsclient: datastreamer exception: java.io.ioexception: unable to create new block.  at org.apache.hadoop.dfs.dfsclient$dfsoutputstream.nextblockoutputstream(dfsclient.java:2349)  at org.apache.hadoop.dfs.dfsclient$dfsoutputstream.access$1800(dfsclient.java:1735)  at org.apache.hadoop.dfs.dfsclient$dfsoutputstream$datastreamer.run(dfsclient.java:1912) 2008-12-13 22:01:46,701 warn org.apache.hadoop.dfs.dfsclient: error recovery for block blk_-1991134958879829135_36755 bad datanode[1]  2008-12-13 22:01:46,701 fatal org.apache.hadoop.hbase.regionserver.flusher: replay of hlog required. forcing server shutdown and at last:  008-12-13 22:04:53,414 info org.apache.hadoop.ipc.client: retrying connect to server: /10.24.1.18:60020. already tried 6 time(s).  2008-12-13 22:04:54,417 info org.apache.hadoop.ipc.client: retrying connect to server: /10.24.1.18:60020. already tried 7 time(s).  2008-12-13 22:04:55,420 info org.apache.hadoop.ipc.client: retrying connect to server: /10.24.1.18:60020. already tried 8 time(s).  2008-12-13 22:04:56,423 info org.apache.hadoop.ipc.client: retrying connect to server: /10.24.1.18:60020. already tried 9 time(s).  2008-12-13 22:07:04,556 error org.apache.hadoop.hbase.regionserver.compactsplitthread: compaction failed for region gdr,138883452271227827193885,1229167157710  java.lang.nullpointerexception  at org.apache.hadoop.hbase.client.servercallable.getregionname(servercallable.java:71)  at org.apache.hadoop.hbase.client.hconnectionmanager$tableservers.getregionserverwithretries(hconnectionmanager.java:863)  at org.apache.hadoop.hbase.client.htable.commit(htable.java:964)  at org.apache.hadoop.hbase.client.htable.commit(htable.java:950)  at org.apache.hadoop.hbase.regionserver.compactsplitthread.split(compactsplitthread.java:167)  at org.apache.hadoop.hbase.regionserver.compactsplitthread.run(compactsplitthread.java:85)  2008-12-13 22:07:04,558 info org.apache.hadoop.hbase.regionserver.compactsplitthread: regionserver/0:0:0:0:0:0:0:0:60020.compactor exiting  2008-12-13 22:07:04,558 info org.apache.hadoop.hbase.regionserver.hregionserver: regionserver/0:0:0:0:0:0:0:0:60020 exiting  2008-12-13 22:07:04,627 info org.apache.hadoop.hbase.regionserver.hregionserver: starting shutdown thread.  2008-12-13 22:07:04,627 info org.apache.hadoop.hbase.regionserver.hregionserver: shutdown thread complete ",
        "label": 399
    },
    {
        "text": "maven doesn't like duplicate dependencies in hbase pom xml  an install of the latest maven plugin resolves dependencies with maven 3.  maven 3 does not like the fact that several dependencies in the main pom.xml are duplicated. below is the error message which can be fixed by removing: the 2nd com.google.guava dependency from the \"test dependencies\" section both org.slf4j dependencies from the \"avro dependencies\" section 9/10/10 11:15:50 am pdt: build errors for hbase; org.apache.maven.project.projectbuildingexception: some problems were encountered while processing the poms:  [warning] 'version' contains an expression but should be a constant. @ org.apache.hbase:hbase:${hbase.version}, /opt/eclipse/troove/hbase/pom.xml  [error] 'dependencies.dependency.(groupid:artifactid:type:classifier)' must be unique: org.slf4j:slf4j-log4j12:jar -> duplicate declaration of version ${slf4j.version} @ org.apache.hbase:hbase:${hbase.version}, /opt/eclipse/troove/hbase/pom.xml  [error] 'dependencies.dependency.(groupid:artifactid:type:classifier)' must be unique: org.slf4j:slf4j-api:jar -> duplicate declaration of version ${slf4j.version} @ org.apache.hbase:hbase:${hbase.version}, /opt/eclipse/troove/hbase/pom.xml  [error] 'dependencies.dependency.(groupid:artifactid:type:classifier)' must be unique: com.google.guava:guava:jar -> duplicate declaration of version ${guava.version} @ org.apache.hbase:hbase:${hbase.version}, /opt/eclipse/troove/hbase/pom.xml  [warning] 'build.plugins.plugin.version' is missing for org.codehaus.mojo:build-helper-maven-plugin @ org.apache.hbase:hbase:0.89-snapshot-withhlogsplit, /opt/eclipse/troove/hbase/pom.xml ",
        "label": 284
    },
    {
        "text": "building against hadoop uses out of date mapreduce artifacts  the \"hadoop-mapred\" artifacts have been replaced by \"hadoop-mapreduce-*\" artifacts in 0.23 onwards. ",
        "label": 447
    },
    {
        "text": " hbase thirdparty  remove changes  update notices  from mike drob on vote thread for hbase-thirdparty 1.0.1rc0: \"license question... do we actually bundle jquery, asciidoctor, and the orca  logo here? i didn't see them anywhere.  changes is mostly blank... if we don't use it, get rid of it in the next  version.\" let me fix in next release. ",
        "label": 320
    },
    {
        "text": "asyncadmin can not deal with non default meta replica  in asyncadmin we support passing both encodedregionname and regionname as a parameter so we have a getregioninfo method to get the regioninfo first. in general we will scan the meta table to get the region info, but for meta region itself, the problem is that, we only check for the first replica, so for the non default replicas, we will still go to the meta region and then get an unknownregionexception. we should find a way to deal with this. ",
        "label": 149
    },
    {
        "text": "add cellcounter to count multiple versions of rows  currently rowcounter only retrieves latest version for each row.  some applications would store multiple versions for the same row. rowcounter should accept a new parameter for the number of versions to return.  scan object would be configured with version parameter (for scan.maxversions).  then the following api should be called:   public keyvalue[] raw() { ",
        "label": 428
    },
    {
        "text": "reused waledits in replication may cause regionservers to go oom  waledit.heapsize() is incorrect in certain replication scenarios which may cause regionservers to go oom. a little background on this issue. we noticed that our source replication regionservers would get into gc storms and sometimes even oom.   we noticed a case where it showed that there were around 25k waledits to replicate, each one with an arraylist of keyvalues. the array list had a capacity of around 90k (using 350kb of heap memory) but had around 6 non null entries. when the replicationsource.readallentriestoreplicateornextfile() gets a waledit it removes all kv's that are scoped other than local. but in doing so we don't account for the capacity of the arraylist when determining heapsize for a waledit. the logic for shipping a batch is whether you have hit a size capacity or number of entries capacity. therefore if have a waledit with 25k entries and suppose all are removed:   the size of the arraylist is 0 (we don't even count the collection's heap size currently) but the capacity is ignored.  this will yield a heapsize() of 0 bytes while in the best case it would be at least 100000 bytes (provided you pass initialcapacity and you have 32 bit jvm) i have some ideas on how to address this problem and want to know everyone's thoughts: 1. we use a probabalistic counter such as hyperloglog and create something like: class capacityestimatearraylist implements arraylist this class overrides all additive methods to update the probabalistic counts it includes one additional method called estimatecapacity (we would take estimatecapacity - size() and fill in sizes for all references) then we can do something like this in waledit.heapsize:   public long heapsize() {     long ret = classsize.arraylist;     for (keyvalue kv : kvs) {       ret += kv.heapsize();     }     long nullentriesestimate = kvs.getcapacityestimate() - kvs.size();     ret += classsize.align(nullentriesestimate * classsize.reference);     if (scopes != null) {       ret += classsize.treemap;       ret += classsize.align(scopes.size() * classsize.map_entry);       // todo this isn't quite right, need help here     }     return ret;   } 2. in replicationsource.removenonreplicableedits() we know the size of the array originally, and we provide some percentage threshold. when that threshold is met (50% of the entries have been removed) we can call kvs.trimtosize() 3. in the heapsize() method for waledit we could use reflection (please don't shoot me for this) to grab the actual capacity of the list. doing something like this: public int getarraylistcapacity()  {     try {       field f = arraylist.class.getdeclaredfield(\"elementdata\");       f.setaccessible(true);       return ((object[]) f.get(kvs)).length;     } catch (exception e) {       log.warn(\"exception in trying to get capacity on arraylist\", e);       return kvs.size();     } i am partial to (1) using hyperloglog and creating a capacityestimatearraylist, this is reusable throughout the code for other classes that implement heapsize which contains arraylists. the memory footprint is very small and it is very fast. the issue is that this is an estimate, although we can configure the precision we most likely always be conservative. the estimatecapacity will always be less than the actualcapacity, but it will be close. i think that putting the logic in removenonreplicableedits will work, but this only solves the heapsize problem in this particular scenario. solution 3 is slow and horrible but that gives us the exact answer. i would love to hear if anyone else has any other ideas on how to remedy this problem? i have code for trunk and 0.94 for all 3 ideas and can provide a patch if the community thinks any of these approaches is a viable one. ",
        "label": 286
    },
    {
        "text": "inconsistent behavior for prebatchmutate in dominibatchmutate and processrowswithlocks  in dominibatchmutate, the prebatchmutate is called before building wal, but in processrowswithlocks, we suggest the rowprocessor implementation to build wal in process method, which is ahead of prebatchmutate. if a cp modifies the mutations, especially if it removes some cells from the mutations, then the behavior of processrowswithlocks is broken. the changes applied to memstore and wal will be different. and there is no way to remove entries from a waledit through cp. ",
        "label": 459
    },
    {
        "text": "improve master webui snapshot information  on the master webui, we currently show lots of information about the space used by individual snapshots. we should also give a total space used. ",
        "label": 205
    },
    {
        "text": "regionplan should correctly implement equals and hashcode  error-prone identified dodgy code in assignmentmanager where we are relying on reference (object) equality to do the right thing, and are getting lucky, because if we properly used equals() the result is wrong, because regionplan does not correctly implement equals and hashcode according to the jdk contracts for same. ",
        "label": 314
    },
    {
        "text": "optimize flushing of the store cache for max versions and  new  min versions  as discussed with with jon, there is room for improvement in how the memstore is flushed to disk.  currently only expired kvs are pruned before flushing, but we can also prune versions if we find at least maxversions versions in the memstore.  the same holds for the new minversion feature: if we find at least minversion versions in the store we can remove all further versions that are expired. generally we should use the same mechanism here that is used for compaction. i.e. storescanner. we only need to add a scanner to memstore that can scan along the current snapshot. ",
        "label": 286
    },
    {
        "text": "invalid hfile block magic on local file system  error: java.lang.runtimeexception: org.apache.hadoop.hbase.client.retriesexhaustedexception: failed after attempts=7, exceptions:  thu apr 26 11:19:18 pdt 2012, org.apache.hadoop.hbase.client.scannercallable@190a621a, java.io.ioexception: java.io.ioexception: could not iterate storefilescanner[hfilescanner for reader reader=file:/tmp/hbase-eclark/hbase/testtable/e2d1c846363c75262cbfd85ea278b342/info/bae2681d63734066957b58fe791a0268, compression=none, cacheconf=cacheconfig:enabled [cachedataonread=true] [cachedataonwrite=false] [cacheindexesonwrite=false] [cachebloomsonwrite=false] [cacheevictonclose=false] [cachecompressed=false], firstkey=0000000001/info:data/1335463981520/put, lastkey=0002588100/info:data/1335463902296/put, avgkeylen=30, avgvaluelen=1000, entries=1215085, length=1264354417, cur=0000000248/info:data/1335463994457/put/vlen=1000/ts=0]  at org.apache.hadoop.hbase.regionserver.storefilescanner.next(storefilescanner.java:135)  at org.apache.hadoop.hbase.regionserver.keyvalueheap.next(keyvalueheap.java:95)  at org.apache.hadoop.hbase.regionserver.storescanner.next(storescanner.java:368)  at org.apache.hadoop.hbase.regionserver.keyvalueheap.next(keyvalueheap.java:127)  at org.apache.hadoop.hbase.regionserver.hregion$regionscannerimpl.nextinternal(hregion.java:3323)  at org.apache.hadoop.hbase.regionserver.hregion$regionscannerimpl.next(hregion.java:3279)  at org.apache.hadoop.hbase.regionserver.hregion$regionscannerimpl.next(hregion.java:3296)  at org.apache.hadoop.hbase.regionserver.hregionserver.next(hregionserver.java:2393)  at sun.reflect.generatedmethodaccessor15.invoke(unknown source)  at sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:25)  at java.lang.reflect.method.invoke(method.java:597)  at org.apache.hadoop.hbase.ipc.writablerpcengine$server.call(writablerpcengine.java:364)  at org.apache.hadoop.hbase.ipc.hbaseserver$handler.run(hbaseserver.java:1376)  caused by: java.io.ioexception: invalid hfile block magic: \\xec\\xd5\\x9d\\xb4\\xc2bfo  at org.apache.hadoop.hbase.io.hfile.blocktype.parse(blocktype.java:153)  at org.apache.hadoop.hbase.io.hfile.blocktype.read(blocktype.java:164)  at org.apache.hadoop.hbase.io.hfile.hfileblock.<init>(hfileblock.java:254)  at org.apache.hadoop.hbase.io.hfile.hfileblock$fsreaderv2.readblockdatainternal(hfileblock.java:1779)  at org.apache.hadoop.hbase.io.hfile.hfileblock$fsreaderv2.readblockdata(hfileblock.java:1637)  at org.apache.hadoop.hbase.io.hfile.hfilereaderv2.readblock(hfilereaderv2.java:327)  at org.apache.hadoop.hbase.io.hfile.hfilereaderv2$abstractscannerv2.readnextdatablock(hfilereaderv2.java:555)  at org.apache.hadoop.hbase.io.hfile.hfilereaderv2$scannerv2.next(hfilereaderv2.java:651)  at org.apache.hadoop.hbase.regionserver.storefilescanner.next(storefilescanner.java:130)  ... 12 more thu apr 26 11:19:19 pdt 2012, org.apache.hadoop.hbase.client.scannercallable@190a621a, java.io.ioexception: java.io.ioexception: java.lang.illegalargumentexception  at org.apache.hadoop.hbase.regionserver.hregionserver.convertthrowabletoioe(hregionserver.java:1132)  at org.apache.hadoop.hbase.regionserver.hregionserver.convertthrowabletoioe(hregionserver.java:1121)  at org.apache.hadoop.hbase.regionserver.hregionserver.next(hregionserver.java:2420)  at sun.reflect.generatedmethodaccessor15.invoke(unknown source)  at sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:25)  at java.lang.reflect.method.invoke(method.java:597)  at org.apache.hadoop.hbase.ipc.writablerpcengine$server.call(writablerpcengine.java:364)  at org.apache.hadoop.hbase.ipc.hbaseserver$handler.run(hbaseserver.java:1376)  caused by: java.lang.illegalargumentexception  at java.nio.buffer.position(buffer.java:216)  at org.apache.hadoop.hbase.io.hfile.hfilereaderv2$scannerv2.next(hfilereaderv2.java:630)  at org.apache.hadoop.hbase.regionserver.storefilescanner.next(storefilescanner.java:130)  at org.apache.hadoop.hbase.regionserver.keyvalueheap.next(keyvalueheap.java:95)  at org.apache.hadoop.hbase.regionserver.storescanner.next(storescanner.java:406)  at org.apache.hadoop.hbase.regionserver.keyvalueheap.next(keyvalueheap.java:127)  at org.apache.hadoop.hbase.regionserver.hregion$regionscannerimpl.nextinternal(hregion.java:3323)  at org.apache.hadoop.hbase.regionserver.hregion$regionscannerimpl.next(hregion.java:3279)  at org.apache.hadoop.hbase.regionserver.hregion$regionscannerimpl.next(hregion.java:3296)  at org.apache.hadoop.hbase.regionserver.hregionserver.next(hregionserver.java:2393)  ... 5 more on latest 0.94 branch i spun up a new standalone hbase. then i started a performance evaluation run hbase/bin/hbase org.apache.hadoop.hbase.performanceevaluation --nomapred randomwrite 10  after that completed i tried a scan of testtable. the scan got the above error. ",
        "label": 154
    },
    {
        "text": "retrytime log is confusing  in the log we have this:  (rpcretryingcaller.java:callwithretries(122)) - call exception, tries=5, retries=35, retrytime=-21839ms it looks like the retrytime is negative. look the code, it is actually a warning message error. we also should use environmentedgemanager to be consistent. ",
        "label": 242
    },
    {
        "text": "latest timestamp not replaced by current timestamp in keyvalue  i was trying to bulk load using the new hfileoutputformat. when using a mapreduce in which map generates {{keyvalue}}s and reduce is equal to keyvaluesortreducer, and using the constructor using (byte[] row, byte[] family, byte[] qualifier, byte[] value), the (undefined) timestamp was inserted as hconstants.latest_timestamp/long.max_value into hbase. this causes all kinds of troubles, but most importantly, while the records were in the table, other mapreduces (using tableinputformat) and hbase shell's 'get'-command did not fetch them. guess there is some sort of filtering of future dates. as i understood from st.ack, the lastest_timestamp is supposed to be replaced by system.currenttimemillis(), but i don't see this reflected in the code of keyvalue, and apparently it did not happen elsewhere; perhaps because there is no actual hbase connection? ",
        "label": 314
    },
    {
        "text": "do exponential backoff in clients on nsre  wre  ise  etc   jim firby suggestion is that we do expotential backoff retrying locating regions, committing edits, etc. ",
        "label": 38
    },
    {
        "text": "javadoc  document that hbaseadmin flush  is synchronous  currently the javadoc in hbaseadmin.flush(...) says that this is an asynchronous operation. looking at the, however, it is in fact not. having this as a synchronous operation open ups some use cases we're interested in. for example doing some ingest via the high level api with wal disabled and then issue a flush through the hbaseadmin. when the flush succeeded we know the data is securely in hbase.  (this should work even with intermediary splits, as they also force a flush, but that needs to be verified as well. so this is just for a trivial javadoc change. ",
        "label": 286
    },
    {
        "text": "inifinite retries on failed server in rsproceduredispatcher  we observed this recently on some cluster, i'm still investigating the root cause however seems like the retries should have special handling for this exception; and separately probably a cap on number of retries 2019-04-20 04:24:27,093 warn  [rsproceduredispatcher-pool4-t1285] procedure.rsproceduredispatcher: request to server ,17020,1555742560432 failed due to java.io.ioexception: call to :17020 failed on local exception: org.apache.hadoop.hbase.ipc.failedserverexception: this server is in the failed servers list: :17020, try=26603, retrying... the corresponding worker is stuck ",
        "label": 314
    },
    {
        "text": " shell  should be able to copy paste table description to create new table  i want to create a new table based off the description of an old. you'd think i could just copy the description of the old in the shell but it doesn't work. our 'describe' emission cannot be used as input on a subsequent create. below i copied the output that describes one table and tried to create a new table named 'x' with it: hbase shell; enter 'help<return>' for list of supported commands.                                                                                                                                                                                                                                                           version: 0.2.1, r49040, mon sep  8 11:29:45 pdt 2008hbase(main):001:0> create 'x', {name => 'alternate_title', bloomfilter => 'false', versions => '2147483647', compression => 'none', length => '2147483647', ttl => '-1', in_memory => 'false', blockcache => 'false'}, {name => 'anchor', bloomfilter => 'false', versions => '2147483647', compression => 'none', length => '2147483647', ttl => '-1', in_memory => 'false', blockcache => 'false'}, {name => 'inlink', bloomfilter => 'false', versions => '2147483647', compression => 'none', length => '2147483647', ttl => '-1', in_memory => 'false', blockcache => 'false'}, {name => 'alternate_url', bloomfilter => 'false', versions => '2147483647', compression => 'none', length => '2147483647', ttl => '-1', in_memory => 'false', blockcache => 'false'}, {name => 'page', bloomfilter => 'false', versions => '2147483647', compression => 'none', length => '2147483647', ttl => '-1', in_memory => 'false', blockcache => 'false'}, {name => 'misc', bloomfilter => 'false', versions => '2147483647', compression => 'none', length => '2147483647', ttl => '-1', in_memory => 'false', blockcache => 'false'}nameerror: no constructor with arguments matching [class [b, class java.lang.string, class org.apache.hadoop.hbase.hcolumndescriptor$compressiontype, class java.lang.string, class java.lang.string, class java.lang.string, class java.lang.string, class java.lang.string] on object javautilities         from file:/p/share/hbase/lib/jruby-complete-1.1.2.jar!/builtin/javasupport/proxy/concrete.rb:23:in `__jcreate!'         from file:/p/share/hbase/lib/jruby-complete-1.1.2.jar!/builtin/javasupport/proxy/concrete.rb:23:in `initialize'         from file:/p/share/hbase/lib/jruby-complete-1.1.2.jar!/builtin/javasupport/proxy/concrete.rb:6:in `new'         from file:/p/share/hbase/lib/jruby-complete-1.1.2.jar!/builtin/javasupport/proxy/concrete.rb:6:in `new'         from /p/share/hbase/bin/../bin/hbase.rb:161:in `hcd'         from /p/share/hbase/bin/../bin/hbase.rb:117:in `create'         from /p/share/hbase/bin/../bin/hbase.rb:111:in `each'         from /p/share/hbase/bin/../bin/hbase.rb:111:in `create'         from /p/share/hbase/bin/../bin/hirb.rb:228:in `create'         from (hbase):2:in `binding' ",
        "label": 549
    },
    {
        "text": "split testscp  it is time consuming. ",
        "label": 149
    },
    {
        "text": "checkandput should properly read mvcc  see, for example: // todo: use mvcc to make this set of increments atomic to reads here's an example of what i can happen (would probably be good to write up a test case for each read/update):  concurrent update via increment and put. the put grabs the row lock first and updates the memstore, but releases the row lock before the mvcc is advanced. then, the increment grabs the row lock and reads right away, reading the old value and incrementing based on that. there are a few options here:  1) waiting for the mvcc to advance for read/updates: the downside is that you have to wait for updates on other rows. 2) have an mvcc per-row (table configuration): this avoids the unnecessary contention of 1) 3) transform the read/updates to write-only with rollup on read.. e.g. an increment would just have the number of values to increment. ",
        "label": 286
    },
    {
        "text": " hadoop2  testtableinputformatscan  fails intermittently with privilegedactionexception  in the test we see the following log messages which indicate an authentication problem and then some sort of recovery problem. 2013-04-16 23:27:04,469 error [ipc server handler 0 on 45600] security.usergroupinformation(1370): priviledgedactionexception as:ec2-user.hfs.2 (auth:simple) cause:org.apache.hadoop.security.accesscontrolexception: can't continue with getblocklocalpathinfo() authorization. the user ec2-user.hfs.2 is not allowed to call getblocklocalpathinfo 2013-04-16 23:27:04,501 warn  [pri ipc server handler 4 on 33892] hdfs.dfsinputstream(489): failed to connect to /127.0.0.1:55547 for block, add to deadnodes and continue. org.apache.hadoop.security.accesscontrolexception: can't continue with getblocklocalpathinfo() authorization. the user ec2-user.hfs.2 is not allowed to call getblocklocalpathinfo at org.apache.hadoop.hdfs.server.datanode.datanode.checkblocklocalpathaccess(datanode.java:1016) at org.apache.hadoop.hdfs.server.datanode.datanode.getblocklocalpathinfo(datanode.java:1026) at org.apache.hadoop.hdfs.protocolpb.clientdatanodeprotocolserversidetranslatorpb.getblocklocalpathinfo(clientdatanodeprotocolserversidetranslatorpb.java:112) at org.apache.hadoop.hdfs.protocol.proto.clientdatanodeprotocolprotos$clientdatanodeprotocolservice$2.callblockingmethod(clientdatanodeprotocolprotos.java:5104) at org.apache.hadoop.ipc.protobufrpcengine$server$protobufrpcinvoker.call(protobufrpcengine.java:454) at org.apache.hadoop.ipc.rpc$server.call(rpc.java:910) at org.apache.hadoop.ipc.server$handler$1.run(server.java:1694) at org.apache.hadoop.ipc.server$handler$1.run(server.java:1690) at java.security.accesscontroller.doprivileged(native method) at javax.security.auth.subject.doas(subject.java:396) at org.apache.hadoop.security.usergroupinformation.doas(usergroupinformation.java:1367) at org.apache.hadoop.ipc.server$handler.run(server.java:1688) org.apache.hadoop.security.accesscontrolexception: can't continue with getblocklocalpathinfo() authorization. the user ec2-user.hfs.2 is not allowed to call getblocklocalpathinfo at org.apache.hadoop.hdfs.server.datanode.datanode.checkblocklocalpathaccess(datanode.java:1016) at org.apache.hadoop.hdfs.server.datanode.datanode.getblocklocalpathinfo(datanode.java:1026) at org.apache.hadoop.hdfs.protocolpb.clientdatanodeprotocolserversidetranslatorpb.getblocklocalpathinfo(clientdatanodeprotocolserversidetranslatorpb.java:112) at org.apache.hadoop.hdfs.protocol.proto.clientdatanodeprotocolprotos$clientdatanodeprotocolservice$2.callblockingmethod(clientdatanodeprotocolprotos.java:5104) at org.apache.hadoop.ipc.protobufrpcengine$server$protobufrpcinvoker.call(protobufrpcengine.java:454) at org.apache.hadoop.ipc.rpc$server.call(rpc.java:910) at org.apache.hadoop.ipc.server$handler$1.run(server.java:1694) at org.apache.hadoop.ipc.server$handler$1.run(server.java:1690) at java.security.accesscontroller.doprivileged(native method) at javax.security.auth.subject.doas(subject.java:396) at org.apache.hadoop.security.usergroupinformation.doas(usergroupinformation.java:1367) at org.apache.hadoop.ipc.server$handler.run(server.java:1688) at sun.reflect.nativeconstructoraccessorimpl.newinstance0(native method) at sun.reflect.nativeconstructoraccessorimpl.newinstance(nativeconstructoraccessorimpl.java:39) at sun.reflect.delegatingconstructoraccessorimpl.newinstance(delegatingconstructoraccessorimpl.java:27) at java.lang.reflect.constructor.newinstance(constructor.java:513) at org.apache.hadoop.ipc.remoteexception.instantiateexception(remoteexception.java:90) at org.apache.hadoop.ipc.remoteexception.unwrapremoteexception(remoteexception.java:57) at org.apache.hadoop.hdfs.dfsclient.getlocalblockreader(dfsclient.java:790) at org.apache.hadoop.hdfs.dfsinputstream.getblockreader(dfsinputstream.java:888) at org.apache.hadoop.hdfs.dfsinputstream.blockseekto(dfsinputstream.java:455) at org.apache.hadoop.hdfs.dfsinputstream.readwithstrategy(dfsinputstream.java:645) at org.apache.hadoop.hdfs.dfsinputstream.read(dfsinputstream.java:689) at java.io.datainputstream.readfully(datainputstream.java:178) at java.io.datainputstream.readfully(datainputstream.java:152) at org.apache.hadoop.hbase.util.fstabledescriptors.gettabledescriptormodtime(fstabledescriptors.java:429) at org.apache.hadoop.hbase.util.fstabledescriptors.gettabledescriptormodtime(fstabledescriptors.java:414) at org.apache.hadoop.hbase.util.fstabledescriptors.get(fstabledescriptors.java:169) at org.apache.hadoop.hbase.util.fstabledescriptors.get(fstabledescriptors.java:132) at org.apache.hadoop.hbase.regionserver.hregionserver.openregion(hregionserver.java:3350) at sun.reflect.nativemethodaccessorimpl.invoke0(native method) at sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:39) at sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:25) at java.lang.reflect.method.invoke(method.java:597) at org.apache.hadoop.hbase.ipc.protobufrpcserverengine$server.call(protobufrpcserverengine.java:174) at org.apache.hadoop.hbase.ipc.hbaseserver$handler.run(hbaseserver.java:1871) caused by: org.apache.hadoop.ipc.remoteexception(org.apache.hadoop.security.accesscontrolexception): can't continue with getblocklocalpathinfo() authorization. the user ec2-user.hfs.2 is not allowed to call getblocklocalpathinfo at org.apache.hadoop.hdfs.server.datanode.datanode.checkblocklocalpathaccess(datanode.java:1016) at org.apache.hadoop.hdfs.server.datanode.datanode.getblocklocalpathinfo(datanode.java:1026) at org.apache.hadoop.hdfs.protocolpb.clientdatanodeprotocolserversidetranslatorpb.getblocklocalpathinfo(clientdatanodeprotocolserversidetranslatorpb.java:112) at org.apache.hadoop.hdfs.protocol.proto.clientdatanodeprotocolprotos$clientdatanodeprotocolservice$2.callblockingmethod(clientdatanodeprotocolprotos.java:5104) at org.apache.hadoop.ipc.protobufrpcengine$server$protobufrpcinvoker.call(protobufrpcengine.java:454) at org.apache.hadoop.ipc.rpc$server.call(rpc.java:910) at org.apache.hadoop.ipc.server$handler$1.run(server.java:1694) at org.apache.hadoop.ipc.server$handler$1.run(server.java:1690) at java.security.accesscontroller.doprivileged(native method) at javax.security.auth.subject.doas(subject.java:396) at org.apache.hadoop.security.usergroupinformation.doas(usergroupinformation.java:1367) at org.apache.hadoop.ipc.server$handler.run(server.java:1688) at org.apache.hadoop.ipc.client.call(client.java:1164) at org.apache.hadoop.ipc.protobufrpcengine$invoker.invoke(protobufrpcengine.java:202) at com.sun.proxy.$proxy20.getblocklocalpathinfo(unknown source) at org.apache.hadoop.hdfs.protocolpb.clientdatanodeprotocoltranslatorpb.getblocklocalpathinfo(clientdatanodeprotocoltranslatorpb.java:199) at org.apache.hadoop.hdfs.blockreaderlocal.getblockpathinfo(blockreaderlocal.java:254) at org.apache.hadoop.hdfs.blockreaderlocal.newblockreader(blockreaderlocal.java:167) at org.apache.hadoop.hdfs.dfsclient.getlocalblockreader(dfsclient.java:786) ... 17 more this seems similar to the other short-circuit-read hadoop2 related failures ",
        "label": 248
    },
    {
        "text": "always flush region based on memstore size could hold hlog files from archiving  currently, memstore flusher always chooses the biggest memstore region to flush. suppose i have two tables: one is very actively updated, while the other is periodically updated. the active one has biggest memstore all the time and is flushed all the time. but the in-active one never gets a chance to flush. since it is not flushed, the hlog file can't be archived, although there are lots of hlog files. if the active table happens to have big updates all the time, the hlog files could cause huge disk space pressure. other than the memstore size, periodically flushing regions based on hlog roll time is helpful in hlog archiving/replication. ",
        "label": 242
    },
    {
        "text": " hbase dynamic schema config  broke build  missing change to hregion heapsize  ",
        "label": 314
    },
    {
        "text": "documentation for the usage of hbase dataframe user api  json  avro  etc   ",
        "label": 485
    },
    {
        "text": "testtokenauthentication fails with the ibm jdk  \"digest-md5: digest response format violation. mismatched response.\" the failure trace: 2014-02-13 15:41:00,449 warn  [rpcserver.reader=1,port=54751] ipc.rpcserver$listener(794): rpcserver.listener,port=54751: count of bytes read: 0 javax.security.sasl.saslexception: digest-md5: digest response format violation. mismatched response.         at com.ibm.security.sasl.digest.digestmd5server.validateclientresponse(digestmd5server.java:614)         at com.ibm.security.sasl.digest.digestmd5server.evaluateresponse(digestmd5server.java:234)         at org.apache.hadoop.hbase.ipc.rpcserver$connection.saslreadandprocess(rpcserver.java:1315)         at org.apache.hadoop.hbase.ipc.rpcserver$connection.readandprocess(rpcserver.java:1501)         at org.apache.hadoop.hbase.ipc.rpcserver$listener.doread(rpcserver.java:790)         at org.apache.hadoop.hbase.ipc.rpcserver$listener$reader.dorunloop(rpcserver.java:581)         at org.apache.hadoop.hbase.ipc.rpcserver$listener$reader.run(rpcserver.java:556)         at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1170)         at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:640)         at java.lang.thread.run(thread.java:853) ",
        "label": 180
    },
    {
        "text": "allow round robin distribution for table created with multiple regions  we can distribute the initial regions created for a new table in round-robin fashion. ",
        "label": 441
    },
    {
        "text": "hconnectionmanager can't find cached hregioninterface which makes client very slow  hregioninterface gethregionconnection(final string hostname,  final int port, final inetsocketaddress isa, final boolean master)  throws ioexception /////////////////////////  string rsname = isa != null ? isa.tostring() : addressing  .createhostandportstr(hostname, port); ////here,if isa is null, the addressing created a address like \"node41:60010\"  ////should use \"isa.tostring():new inetsocketaddress(hostname, port).tostring();\"   ////instead of \"addressing.createhostandportstr(hostname, port);\"  server = this.servers.get(rsname);   if (server == null) {  // create a unique lock for this rs (if necessary)  this.connectionlock.putifabsent(rsname, rsname);  // get the rs lock  synchronized (this.connectionlock.get(rsname)) {  // do one more lookup in case we were stalled above  server = this.servers.get(rsname);  if (server == null) {  try {  if (clusterid.hasid()) { conf.set(hconstants.cluster_id, clusterid.getid()); } // only create isa when we need to.  inetsocketaddress address = isa != null ? isa  : new inetsocketaddress(hostname, port);  // definitely a cache miss. establish an rpc for this rs  server = (hregioninterface) hbaserpc.waitforproxy(  serverinterfaceclass, hregioninterface.version, address,  this.conf, this.maxrpcattempts, this.rpctimeout,  this.rpctimeout);  this.servers.put(address.tostring(), server); ////but here address.tostring() send an address like \"node41/10.61.2l.171:60010  ////so this method can never get cached address and make client request very slow due to it's synchronized.  } catch (remoteexception e) { log.warn(\"remoteexception connecting to rs\", e); // throw what the remoteexception was carrying. throw remoteexceptionhandler.decoderemoteexception(e); } }  }  /////////////////////// ",
        "label": 293
    },
    {
        "text": "bloom filters will not work if enabled after table is created and contains data  currently it is possible to enable a bloom filter after a table is created and data has been stored in it by disabling the table and modifying the column. while this correctly sets the attribute in the column descriptor, it does not create bloom filters for existing data so that on the first compaction, an npe will be thrown because the hstore expects each hstorefile to have a bloom filter. ",
        "label": 241
    },
    {
        "text": "fix order of parameters after hbase  the order of the parameters are not proper in hbase-daemon.sh. here is a simple change that fixes it: --- bin/hbase-daemon.sh (revision 1101351) +++ bin/hbase-daemon.sh (working copy) @@ -143,7 +143,7 @@     echo \"`ulimit -a`\" >> $loglog 2>&1     nohup nice -n $hbase_niceness \"$hbase_home\"/bin/hbase \\         --config \"${hbase_conf_dir}\" \\ -        $command $startstop \"$@\" > \"$logout\" 2>&1 < /dev/null & +        $command \"$@\" $startstop > \"$logout\" 2>&1 < /dev/null &     echo $! > $pid     sleep 1; head \"$logout\"     ;; also see https://issues.apache.org/jira/browse/hbase-3833?page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel&focusedcommentid=13028332#comment-13028332 i think this is an oversight and should have been part of the patch. currently the local-regionservers.sh simply prints out the usage and exits, because the -d are not before the command as expected. ",
        "label": 285
    },
    {
        "text": "backport zk less region assignment to  discuss concerns about backporting hbase-11059 to 0.98 ",
        "label": 472
    },
    {
        "text": "running an hbase job jar  illegalaccesserror  class com google protobuf zerocopyliteralbytestring cannot access its superclass com google protobuf literalbytestring  (jimmy has been working on this one internally. i'm just the messenger raising this critical issue upstream). so, if you make job jar and bundle up hbase inside in it because you want to access hbase from your mapreduce task, the deploy of the job jar to the cluster fails with: 14/01/05 08:59:19 info configuration.deprecation: topology.node.switch.mapping.impl is deprecated. instead, use net.topology.node.switch.mapping.impl 14/01/05 08:59:19 info configuration.deprecation: io.bytes.per.checksum is deprecated. instead, use dfs.bytes-per-checksum exception in thread \"main\" java.lang.illegalaccesserror: class com.google.protobuf.zerocopyliteralbytestring cannot access its superclass com.google.protobuf.literalbytestring at java.lang.classloader.defineclass1(native method) at java.lang.classloader.defineclass(classloader.java:792) at java.security.secureclassloader.defineclass(secureclassloader.java:142) at java.net.urlclassloader.defineclass(urlclassloader.java:449) at java.net.urlclassloader.access$100(urlclassloader.java:71) at java.net.urlclassloader$1.run(urlclassloader.java:361) at java.net.urlclassloader$1.run(urlclassloader.java:355) at java.security.accesscontroller.doprivileged(native method) at java.net.urlclassloader.findclass(urlclassloader.java:354) at java.lang.classloader.loadclass(classloader.java:424) at java.lang.classloader.loadclass(classloader.java:357) at org.apache.hadoop.hbase.protobuf.protobufutil.toscan(protobufutil.java:818) at org.apache.hadoop.hbase.mapreduce.tablemapreduceutil.convertscantostring(tablemapreduceutil.java:433) at org.apache.hadoop.hbase.mapreduce.tablemapreduceutil.inittablemapperjob(tablemapreduceutil.java:186) at org.apache.hadoop.hbase.mapreduce.tablemapreduceutil.inittablemapperjob(tablemapreduceutil.java:147) at org.apache.hadoop.hbase.mapreduce.tablemapreduceutil.inittablemapperjob(tablemapreduceutil.java:270) at org.apache.hadoop.hbase.mapreduce.tablemapreduceutil.inittablemapperjob(tablemapreduceutil.java:100) at com.ngdata.hbaseindexer.mr.hbasemapreduceindexertool.run(hbasemapreduceindexertool.java:124) at com.ngdata.hbaseindexer.mr.hbasemapreduceindexertool.run(hbasemapreduceindexertool.java:64) at org.apache.hadoop.util.toolrunner.run(toolrunner.java:70) at com.ngdata.hbaseindexer.mr.hbasemapreduceindexertool.main(hbasemapreduceindexertool.java:51) at sun.reflect.nativemethodaccessorimpl.invoke0(native method) at sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:57) at sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43) at java.lang.reflect.method.invoke(method.java:606) at org.apache.hadoop.util.runjar.main(runjar.java:212) so, zclbs is a hack. this class is in the hbase-protocol module. it is \"in\" the com.google.protobuf package. all is well and good usually. but when we make a job jar and bundle up hbase inside it, our 'trick' breaks. runjar makes a new class loader to run the job jar. this urlclassloader 'attaches' all the jars and classes that are in jobjar so they can be found when it does to do a lookup only classloaders work by always delegating to their parent first (unless you are a war file in a container where delegation is 'off' for the most part) and in this case, the parent classloader will have access to a pb jar since pb is in the hadoop classpath. so, the parent loads the pb classes. we then load zclbs only this is done in the claslsloader made by runjar; zkclbs has a different classloader from its superclass and we get the above illegalaccesserror. now (jimmy's work comes in here), this can't be fixed by reflection \u2013 you can't setaccess on a 'class' \u2013 and though it probably could be fixed by hacking runjar so it was somehow made configurable so we could put in place our own classloader to do something like containers do for war files (probably not a bad idea), there would be some fierce hackery involved and besides, this won't show up in hadoop anytime too soon leaving hadoop 2.2ers out in the cold. so, the alternatives are: 1. undo the zclsb hack. we'd lose a lot of nice perf improvement but i'd say this is preferable to crazy classpath hacks.  2. require folks put hbase-protocol \u2013 thats all you'd need \u2013 on the hadoop classpath. this is kinda crazy.  3. we could try shading the pb jar content or probably better, just pull pb into hbase altogether only under a different package. if it was in our code base, we could do more zclsb-like speedups. i was going to experiment with #3 above unless anyone else has a better idea. ",
        "label": 339
    },
    {
        "text": "metrics refresh task is not canceled when regions are closed  leaking hregion objects  while investigating hbase-7205 by repeatedly enabling and disabling one table having 100 regions i noticed that closed hregion objects are kept forever in memory.   the memory analyzer tool indicates a reference to hregion object in metrics refresh-task (metricsregionwrapperimpl.hregionmetricswrapperrunnable) that prevents the hregion object to be collected. ",
        "label": 9
    },
    {
        "text": "npe from compactionchecker  i recently updated production data to use hbase 0.90.0.  now i'm periodically seeing: [10/02/11 17:23:27] 30076066 [mpactionchecker] error nserver$majorcompactionchecker - caught exception  java.lang.nullpointerexception  at org.apache.hadoop.hbase.regionserver.store.ismajorcompaction(store.java:832)  at org.apache.hadoop.hbase.regionserver.store.ismajorcompaction(store.java:810)  at org.apache.hadoop.hbase.regionserver.hregion.ismajorcompaction(hregion.java:2800)  at org.apache.hadoop.hbase.regionserver.hregionserver$majorcompactionchecker.chore(hregionserver.java:1047)  at org.apache.hadoop.hbase.chore.run(chore.java:66) the only negative effect is that this is interrupting compactions from happening. but that is pretty serious and this might be a sign of data corruption? maybe it's just my data, but this task should at least involve improving the handling to catch the npe and still iterate through the other onlineregions that might compact without error. the majorcompactionchecker.chore() method only catches ioexceptions and so this npe breaks out of that loop. ",
        "label": 547
    },
    {
        "text": "after full backup passed on hdfs root and incremental failed  full backup cannot be cleaned  >>  ./bin/hbase backup create full hdfs://localhost:8020/ -t test1 2017-09-27 10:19:38,885 info [main] impl.backupmanifest: manifest file stored to hdfs://localhost:8020/backup_1506487766386/.backup.manifest  2017-09-27 10:19:38,937 info [main] impl.tablebackupclient: backup backup_1506487766386 completed.  backup session backup_1506487766386 finished. status: success >> 2017-09-27 10:20:48,211 info [main] mapreduce.jobsubmitter: cleaning up the staging area /tmp/hadoop-yarn/staging/vkhandelwal/.staging/job_1506419443344_0045  2017-09-27 10:20:48,215 error [main] impl.tablebackupclient: unexpected exception in incremental-backup: incremental copy backup_1506487845361can not convert from directory (check hadoop, hbase and walplayer m/r job logs)   java.io.ioexception: can not convert from directory (check hadoop, hbase and walplayer m/r job logs)   at org.apache.hadoop.hbase.backup.impl.incrementaltablebackupclient.waltohfiles(incrementaltablebackupclient.java:363)  at  ./bin/hbase backup create full hdfs://localhost:8020/ -t test1  2017-09-27 10:19:38,885 info [main] impl.backupmanifest: manifest file stored to hdfs://localhost:8020/backup_1506487766386/.backup.manifest  2017-09-27 10:19:38,937 info [main] impl.tablebackupclient: backup backup_1506487766386 completed.  backup session backup_1506487766386 finished. status: success  ./bin/hbase backup create incremental hdfs://localhost:8020/ -t test1  2017-09-27 10:20:48,215 error [main] impl.tablebackupclient: unexpected exception in incremental-backup: incremental copy backup_1506487845361can not convert from directory (check hadoop, hbase and walplayer m/r job logs)   java.io.ioexception: can not convert from directory (check hadoop, hbase and walplayer m/r job logs)   at org.apache.hadoop.hbase.backup.impl.incrementaltablebackupclient.waltohfiles(incrementaltablebackupclient.java:363)  at org.apache.hadoop.hbase.backup.impl.incrementaltablebackupclient.convertwalstohfiles(incrementaltablebackupclient.java:322)  at org.apache.hadoop.hbase.backup.impl.incrementaltablebackupclient.execute(incrementaltablebackupclient.java:232)  at org.apache.hadoop.hbase.backup.impl.backupadminimpl.backuptables(backupadminimpl.java:601)  at org.apache.hadoop.hbase.backup.impl.backupcommands$createcommand.execute(backupcommands.java:336)  at org.apache.hadoop.hbase.backup.backupdriver.parseandrun(backupdriver.java:137)  at org.apache.hadoop.hbase.backup.backupdriver.dowork(backupdriver.java:170)  at org.apache.hadoop.hbase.backup.backupdriver.run(backupdriver.java:203)  at org.apache.hadoop.util.toolrunner.run(toolrunner.java:70)  at org.apache.hadoop.hbase.backup.backupdriver.main(backupdriver.java:178)  caused by: java.lang.illegalargumentexception: can not create a path from an empty string  at org.apache.hadoop.fs.path.checkpatharg(path.java:126)  at org.apache.hadoop.fs.path.<init>(path.java:134)  at org.apache.hadoop.util.stringutils.stringtopath(stringutils.java:245)  at org.apache.hadoop.hbase.mapreduce.walinputformat.getinputpaths(walinputformat.java:301)  at org.apache.hadoop.hbase.mapreduce.walinputformat.getsplits(walinputformat.java:274)  at org.apache.hadoop.hbase.mapreduce.walinputformat.getsplits(walinputformat.java:264)  at org.apache.hadoop.mapreduce.jobsubmitter.writenewsplits(jobsubmitter.java:301)  at org.apache.hadoop.mapreduce.jobsubmitter.writesplits(jobsubmitter.java:318)  at org.apache.hadoop.mapreduce.jobsubmitter.submitjobinternal(jobsubmitter.java:196)  at org.apache.hadoop.mapreduce.job$10.run(job.java:1290)  at org.apache.hadoop.mapreduce.job$10.run(job.java:1287)  at java.security.accesscontroller.doprivileged(native method)  at javax.security.auth.subject.doas(subject.java:422)  at org.apache.hadoop.security.usergroupinformation.doas(usergroupinformation.java:1657)  at org.apache.hadoop.mapreduce.job.submit(job.java:1287)  at org.apache.hadoop.mapreduce.job.waitforcompletion(job.java:1308)  at org.apache.hadoop.hbase.mapreduce.walplayer.run(walplayer.java:380)  at org.apache.hadoop.hbase.backup.impl.incrementaltablebackupclient.waltohfiles(incrementaltablebackupclient.java:354)  ... 9 more  2017-09-27 10:20:48,216 error [main] impl.tablebackupclient: backupid=backup_1506487845361,startts=1506487846725,failedts=1506487848216,failedphase=prepare_incremental,failedmessage=can not convert from directory (check hadoop, hbase and walplayer m/r job logs)   2017-09-27 10:20:49,919 error [main] impl.tablebackupclient: backup backup_1506487845361 failed.  backup session backup_1506487845361 finished. status: success  ~/desktop/backup-open-source/hbase-2.0.0-alpha3$ ./bin/hbase backup delete backup_150648776638  please make sure that backup is enabled on the cluster. to enable backup, in hbase-site.xml, set:  hbase.backup.enable=true  hbase.master.logcleaner.plugins=your_plugins,org.apache.hadoop.hbase.backup.master.backuplogcleaner  hbase.procedure.master.classes=your_classes,org.apache.hadoop.hbase.backup.master.logrollmasterproceduremanager  hbase.procedure.regionserver.classes=your_classes,org.apache.hadoop.hbase.backup.regionserver.logrollregionserverproceduremanager  and restart the cluster  2017-09-27 10:22:37,043 info [main] metrics.metricregistries: loaded metricregistries class org.apache.hadoop.hbase.metrics.impl.metricregistriesimpl  deleted 0 backups. total requested: 2  ./bin/hbase backup history | grep backup_150648776638  2017-09-27 10:22:18,600 info [main] metrics.metricregistries: loaded metricregistries class org.apache.hadoop.hbase.metrics.impl.metricregistriesimpl  {id=backup_1506487766386,type=full,tables= {test1},state=complete,start time=wed sep 27 10:19:27 ist 2017,end time=wed sep 27 10:19:38 ist 2017,progress=100%}      org.apache.hadoop.hbase.backup.impl.incrementaltablebackupclient.convertwalstohfiles(incrementaltablebackupclient.java:322)  at org.apache.hadoop.hbase.backup.impl.incrementaltablebackupclient.execute(incrementaltablebackupclient.java:232)  at org.apache.hadoop.hbase.backup.impl.backupadminimpl.backuptables(backupadminimpl.java:601)  at org.apache.hadoop.hbase.backup.impl.backupcommands$createcommand.execute(backupcommands.java:336)  at org.apache.hadoop.hbase.backup.backupdriver.parseandrun(backupdriver.java:137)  at org.apache.hadoop.hbase.backup.backupdriver.dowork(backupdriver.java:170)  at org.apache.hadoop.hbase.backup.backupdriver.run(backupdriver.java:203)  at org.apache.hadoop.util.toolrunner.run(toolrunner.java:70)  at org.apache.hadoop.hbase.backup.backupdriver.main(backupdriver.java:178)  caused by: java.lang.illegalargumentexception: can not create a path from an empty string  at org.apache.hadoop.fs.path.checkpatharg(path.java:126)  at org.apache.hadoop.fs.path.<init>(path.java:134)  at org.apache.hadoop.util.stringutils.stringtopath(stringutils.java:245)  at org.apache.hadoop.hbase.mapreduce.walinputformat.getinputpaths(walinputformat.java:301)  at org.apache.hadoop.hbase.mapreduce.walinputformat.getsplits(walinputformat.java:274)  at org.apache.hadoop.hbase.mapreduce.walinputformat.getsplits(walinputformat.java:264)  at org.apache.hadoop.mapreduce.jobsubmitter.writenewsplits(jobsubmitter.java:301)  at org.apache.hadoop.mapreduce.jobsubmitter.writesplits(jobsubmitter.java:318)  at org.apache.hadoop.mapreduce.jobsubmitter.submitjobinternal(jobsubmitter.java:196)  at org.apache.hadoop.mapreduce.job$10.run(job.java:1290)  at org.apache.hadoop.mapreduce.job$10.run(job.java:1287)  at java.security.accesscontroller.doprivileged(native method)  at javax.security.auth.subject.doas(subject.java:422)  at org.apache.hadoop.security.usergroupinformation.doas(usergroupinformation.java:1657)  at org.apache.hadoop.mapreduce.job.submit(job.java:1287)  at org.apache.hadoop.mapreduce.job.waitforcompletion(job.java:1308)  at org.apache.hadoop.hbase.mapreduce.walplayer.run(walplayer.java:380)  at org.apache.hadoop.hbase.backup.impl.incrementaltablebackupclient.waltohfiles(incrementaltablebackupclient.java:354)  ... 9 more  2017-09-27 10:20:48,216 error [main] impl.tablebackupclient: backupid=backup_1506487845361,startts=1506487846725,failedts=1506487848216,failedphase=prepare_incremental,failedmessage=can not convert from directory (check hadoop, hbase and walplayer m/r job logs)   2017-09-27 10:20:49,919 error [main] impl.tablebackupclient: backup backup_1506487845361 failed.  backup session backup_1506487845361 finished. status: success    >>  vkhandelwal@vishalk-wsl:~/desktop/backup-open-source/hbase-2.0.0-alpha3$ ./bin/hbase backup delete backup_150648776638  please make sure that backup is enabled on the cluster. to enable backup, in hbase-site.xml, set:  hbase.backup.enable=true  hbase.master.logcleaner.plugins=your_plugins,org.apache.hadoop.hbase.backup.master.backuplogcleaner  hbase.procedure.master.classes=your_classes,org.apache.hadoop.hbase.backup.master.logrollmasterproceduremanager  hbase.procedure.regionserver.classes=your_classes,org.apache.hadoop.hbase.backup.regionserver.logrollregionserverproceduremanager  and restart the cluster  2017-09-27 10:22:37,043 info [main] metrics.metricregistries: loaded metricregistries class org.apache.hadoop.hbase.metrics.impl.metricregistriesimpl  deleted 0 backups. total requested: 2    >>  vkhandelwal@vishalk-wsl:~/desktop/backup-open-source/hbase-2.0.0-alpha3$ ./bin/hbase backup history | grep backup_150648776638  2017-09-27 10:22:18,600 info [main] metrics.metricregistries: loaded metricregistries class org.apache.hadoop.hbase.metrics.impl.metricregistriesimpl  {id=backup_1506487766386,type=full,tables={test1} ,state=complete,start time=wed sep 27 10:19:27 ist 2017,end time=wed sep 27 10:19:38 ist 2017,progress=100%} so we should have 2 fixes here #1 backup on root should not be allowed at all either full or incremental  #2 delete should work for any incorrect backup, as backup structure might be abstracted from user. ",
        "label": 478
    },
    {
        "text": "document security config requirements from hbase  running secure hbase has always effectively required setting both hbase.security.authentication and hadoop.security.authentication, but internal usage was inconsistent. hbase-7357 cleaned up the internal code usage. we should update the ref guide security docs to explicitly call out the requirement the hadoop.security.authentication be set as well. ",
        "label": 330
    },
    {
        "text": "memstore usemslab default is false  hbase default xml says it's true  someone not familiar with the memstore code might find it confusing that memstore.usemslab_default's value is \"false\" whereas hbase.hregion.memstore.mslab.enabled is true in hbase-default.xml (and in the end hbase-default.xml is the one used). this should be harmonized to true. ",
        "label": 46
    },
    {
        "text": "reconstruction log playback has no bounds on memory used  makes a treemap and just keeps adding edits without regard for size of edits applied; could cause oome (i've not seen a definitive case though have seen an oome around time of a reconstructionlog replay \u2013 perhaps this the straw that broke the fleas antlers?) ",
        "label": 314
    },
    {
        "text": "maven archetype  client application  ",
        "label": 123
    },
    {
        "text": "improve rsgroupinfo constructors  hbase-common/src/main/java/org/apache/hadoop/hbase/rsgroup/rsgroupinfo.java rsgroupinfo(string name, sortedset<address> servers, sortedset<tablename> tables) {     this.name = name;     this.servers = servers == null? new treeset<>(): servers;     this.servers.addall(servers);     this.tables = new treeset<>(tables); } 2 improvements could be made: when servers is not null, addall(servers) tries to add all items in servers again. seems not needed new treeset<>(tables) has no null check on tables. the constructor of treeset does not do the null check either. it leads to nullpointerexception if tables is null ",
        "label": 490
    },
    {
        "text": "datatype  provide extensible type api  ",
        "label": 339
    },
    {
        "text": "store the rsgroup of a table in table configuration  ",
        "label": 149
    },
    {
        "text": "add support for java serialization to hbaseobjectwritable  it is convenient in some situations to have hbaseobjectwritable write serializable java objects, for instance when prototyping new code where you don't want to take the time to implement a writable. adding this support requires no overhead compared the current implementation. ",
        "label": 150
    },
    {
        "text": "make cpenv getconnection return a facade that throws unsupported if cp calls  close  follows from hbase-19301, a suggestion by [~zghaobac]. to prevent a cp accidentally closing the connection returned by cpenv#getconnection \u2013 which returns the hosting servers connection \u2013 we should throw unsupportedexception if the cp calls #close.... do it. ",
        "label": 187
    },
    {
        "text": "hbase doesn't work going against  its packaged hadoop  see this mikhail thread up on the list: http://search-hadoop.com/m/wmuzr24eaj1/%2522sequencefilelogreader+uses+a+reflection+hack+resulting+in+runtime+failures%2522&subj=re+sequencefilelogreader+uses+a+reflection+hack+resulting+in+runtime+failures dig into it. ",
        "label": 314
    },
    {
        "text": "master coprocessor rpcs don't propagate exceptions  i was working on some coprocessor tests, and was wondering why exceptions weren't bubbling up while calling checkfailed on my rpccontroller. turns out, that hmaster's execmasterservice seems to be sending the wrong rpccontroller (that happens to be null in my case) to the methods. i have a fix that appears to work, but i am not familiar enough with the code to know that it's the write one. version i am working on has the git sha 9a322b0 ",
        "label": 321
    },
    {
        "text": "occasional testdistributedlogsplitting failure  looks this link:  https://builds.apache.org/job/precommit-hbase-build/253//testreport/org.apache.hadoop.hbase.master/testdistributedlogsplitting/testrecoverededits/ // it said that regions is 0.  2011-11-15 03:53:11,215 info [thread-2335] master.testdistributedlogsplitting(211): #regions = 0  2011-11-15 03:53:11,215 debug [regionserver:0;asf001.sp2.ygridcore.net,36721,1321329179789.logsyncer] wal.hlog$logsyncer(1192): regionserver:0;asf001.sp2.ygridcore.net,36721,1321329179789.logsyncer interrupted while waiting for sync requests  2011-11-15 03:53:11,215 info [regionserver:0;asf001.sp2.ygridcore.net,36721,1321329179789.logsyncer] wal.hlog$logsyncer(1194): regionserver:0;asf001.sp2.ygridcore.net,36721,1321329179789.logsyncer exiting  2011-11-15 03:53:11,215 debug [thread-2335] wal.hlog(967): closing hlog writer in hdfs://localhost:46229/user/jenkins/.logs/asf001.sp2.ygridcore.net,36721,1321329179789  2011-11-15 03:53:11,637 debug [thread-2335] master.splitlogmanager(233): scheduling batch of logs to split ",
        "label": 529
    },
    {
        "text": "hlog  found logs to remove out of total  oldest outstanding seqnum is fr om region  root  above was in tim sell log just before it oome'd. 1450 log files are going to mess us up. need to clear them. catalog tables should probably keep up the old optional flush or, if n commit logs, schedule a flush on the region with the oldest sequent number. bringing into 0.19.0. gets in the way of our scaling. ",
        "label": 314
    },
    {
        "text": " findbugs  address dodgy bugs  see https://builds.apache.org/job/precommit-hbase-build/1313//artifact/trunk/patchprocess/newpatchfindbugswarnings.html#warnings_style this may be broken down further. ",
        "label": 56
    },
    {
        "text": " hbase  method to get a list of a row's timestamps accompanied by the columns at that version  it would be handy in some situations to be able to get a list of the timestamps and matching columns for a row without returning the data in the cells. /**  * get all the timestamps for a row along with which cells exist at that timestamp.  */ map<long, text[]> getrowtimestampswithcolumns(text row); ",
        "label": 241
    },
    {
        "text": "recovered log files are not inserted into the storefile map  after a log recovery, the resulting flushed file is not introduced into the store.storefiles map. the new data isnt available until the region is closed or compacted. ",
        "label": 547
    },
    {
        "text": "democlient java is outdated   similar to hbase-3593. this patch upgrades democlient.java to thrift 0.5/0.6, fixes the check for allowing non-utf8 in row names, and eliminates the hard-coded host/port. ",
        "label": 331
    },
    {
        "text": "testblockreorder testblocklocationreorder fails  http://54.241.6.143/job/hbase-0.95/669/org.apache.hbase$hbase-server/testreport/junit/org.apache.hadoop.hbase.fs/testblockreorder/testblocklocationreorder/ java.net.bindexception: address already in use  at java.net.plainsocketimpl.socketbind(native method)  at java.net.plainsocketimpl.bind(plainsocketimpl.java:383)  at java.net.serversocket.bind(serversocket.java:328)  at java.net.serversocket.<init>(serversocket.java:194)  at java.net.serversocket.<init>(serversocket.java:106)  at org.apache.hadoop.hbase.fs.testblockreorder.testblocklocationreorder(testblockreorder.java:182) ",
        "label": 340
    },
    {
        "text": "hregion equals is broken  it's currently implemented by comparing the hashcode, which is not unique! currently it only appears to be depended upon by hregionserver#getregionstocheck, which is as best i can tell unused. ",
        "label": 441
    },
    {
        "text": "remove the hooks in regionobserver which are designed to construct a storescanner which is marked as ia private  there are three methods here keyvaluescanner prestorescanneropen(observercontext<regioncoprocessorenvironment> c,       store store, scan scan, navigableset<byte[]> targetcols, keyvaluescanner s, long readpt)       throws ioexception; internalscanner preflushscanneropen(observercontext<regioncoprocessorenvironment> c,       store store, list<keyvaluescanner> scanners, internalscanner s, long readpoint)       throws ioexception; internalscanner precompactscanneropen(observercontext<regioncoprocessorenvironment> c,       store store, list<? extends keyvaluescanner> scanners, scantype scantype, long earliestputts,       internalscanner s, compactionlifecycletracker tracker, compactionrequest request,       long readpoint) throws ioexception; for the flush and compact ones, we've discussed many times, it is not safe to let user inject a filter or even implement their own internalscanner using the store file scanners, as our correctness highly depends on the complicated logic in sqm and storescanner. cp users are expected to wrap the original internalscanner(it is a storescanner anyway) in preflush/precompact methods to do filtering or something else. for prestorescanneropen it even returns a keyvaluescanner which is marked as ia.private... this is less hurt but still, we've decided to not expose storescanner to cp users so here this method is useless. cp users can use pregetop and prescanneropen method to modify the get/scan object passed in to inject into the scan operation. ",
        "label": 149
    },
    {
        "text": "tableinputformatbase npe  spot the bug in this code: public list<inputsplit> getsplits(jobcontext context) throws ioexception {  byte [][] startkeys = table.getstartkeys();  if (startkeys == null || startkeys.length == 0) { throw new ioexception(\"expecting at least one region.\"); } if (table == null) { throw new ioexception(\"no table was provided.\"); } ...  } should check if the table is null before calling a method on it. admittedly, this isn't the worst bug in the world, it's really just more of a nuisance in that the \"no table was provided\" message becomes an npe this bug is in both org.apache.hadoop.hbase.mapred.tableinputformatbase  org.apache.hadoop.hbase.mapreduce.tableinputformatbase ",
        "label": 314
    },
    {
        "text": "region jsp returns npe when provided encoded region name is not online  noticed while testing for hbase-23653. a link off to a region that is closed or otherwise not in the region server's online region map results in a 500. ",
        "label": 555
    },
    {
        "text": "add remaining per table region   store   flush   compaction related metrics  continuing on the work for per-table metrics, hbase-15518 and hbase-15671. we need to add some remaining metrics at the per-table level, so that we will have the same metrics reported at the per-regionserver, per-region and per-table levels. after this patch, most of the metrics at the rs and all of the per-region level are also reported at the per-table level. ",
        "label": 494
    },
    {
        "text": "make mapper function in importtsv plug able  it would be really useful to allow the ability to specify a different mapper for the importtsv class to use than the current tsvimporter. this would allow transformations to be made on the input data before being added to hbase. one suggestion is to add a new command line option to specify a user defined mapper (udm?). or maybe instead we just refactor it to be extended where a subclass can specify a new mapper. the mapper is statically defined and bound to the job though, so i'm not sure of the best way to make it dynamically plug-able. suggestions welcome. ",
        "label": 489
    },
    {
        "text": "incorrect javadoc for atomicity guarantee of increment and append  at the front of increment.java file, there is comment about read atomicity:  * this operation does not appear atomic to readers.  increments are done  * under a single row lock, so write operations to a row are synchronized, but  * readers do not take row locks so get and scan operations can see this  * operation partially completed. it seems this comment is not true after mvcc integrated hbase-4583. currently, the readers can be guaranteed to read the whole result of increment if i am not wrong. similar comments also exist in append.java, table#append(...) and table#increment(...) ",
        "label": 238
    },
    {
        "text": "regex filters are at least an order of magnitude slower since  i found this issue after debugging a performance problem on an opentsdb cluster, it was basically unusable after an upgrade from 0.94.2 to 0.94.6. it was caused by hbase-7279 (ping [~lhofhansl]). the easiest way to see it is to run a simple 1 client pe: $ ./bin/hbase org.apache.hadoop.hbase.performanceevaluation sequentialwrite 1 then in the shell do a filter scan (flush the table first and make sure if fits in your blockcache if you want stable numbers). pre hbase-7279: hbase(main):028:0> scan 'testtable', {filter => \"(rowfilter (=, 'regexstring:0000055872') )\"} row                                                 column+cell                                                                                                                                           0000055872                                         column=info:data, timestamp=1378248850191, value=(blanked)                                                                                                                                     1 row(s) in 1.2780 seconds post hbase-7279 hbase(main):037:0* scan 'testtable', {filter => \"(rowfilter (=, 'regexstring:0000055872') )\"} row                                                 column+cell                                                                                                                                           0000055872                                         column=info:data, timestamp=1378248850191, value=(blanked)                                                                                                                                       1 row(s) in 24.2940 seconds i tried a bunch of 0.94, up to 0.94.11, and the tip of 0.96. they are all slow like this. it seems that since that jira went in we do a lot more row matching, and running the regex gets super expensive. ",
        "label": 286
    },
    {
        "text": "close zookeeper when done with it  hcm  master  and rs   we're not closing down zk properly, mostly in hcm. makes for spew in zk logs and it also causes shutdown to run longer. ",
        "label": 314
    },
    {
        "text": "group multiple block cache clear requests per server  during the review of hbase-18624, i brought up the following: there would be multiple regions on the same server whose block cache is to be cleared.  multiple block cache clear requests should be grouped per server to reduce the number of rpc calls. ",
        "label": 188
    },
    {
        "text": " scan internal  in table rb should accept argument that specifies reverse scan  reversed scan usage on shell:  hbase> scan 't1', {reversed => true}  other parameter could also be added with 'reversed', like limit,columns.    examples:    hbase(main):019:0* scan 't1'  row column+cell   001 column=f1:q1, timestamp=1386644670350, value=v1   002 column=f1:q2, timestamp=1386644675585, value=v1   003 column=f1:q1, timestamp=1386644680090, value=v1   003 column=f1:q2, timestamp=1386644682749, value=v1   004 column=f1:q1, timestamp=1386644692589, value=v1   4 row(s) in 0.0130 seconds      hbase(main):022:0> scan 't1',{reversed => true} row column+cell   004 column=f1:q1, timestamp=1386644692589, value=v1   003 column=f1:q1, timestamp=1386644680090, value=v1   003 column=f1:q2, timestamp=1386644682749, value=v1   002 column=f1:q2, timestamp=1386644675585, value=v1   001 column=f1:q1, timestamp=1386644670350, value=v1 hbase(main):023:0> scan 't1', {reversed => true,columns=>'f1:q2'} row column+cell   003 column=f1:q2, timestamp=1386644682749, value=v1   002 column=f1:q2, timestamp=1386644675585, value=v1   2 row(s) in 0.0100 seconds here is how boolean argument is accepted:         cache_blocks = args[\"cache_blocks\"] || true flag for reverse scan should be supported in similar manner ",
        "label": 107
    },
    {
        "text": "fix log line in stochasticloadbalancer when balancer is an ill fit for cluster size  hbase-21338 added log lines regarding load balancer warnings. there is a bug in log that uses wrong parameter.  'maxrunningtime' is used , should be maxsteps. ",
        "label": 494
    },
    {
        "text": "support passing multiple qops to saslclient server via hbase rpc protection  currently, we can set the value of hbase.rpc.protection to one of authentication/integrity/privacy. it is the used to set javax.security.sasl.qop in saslutil.java.  the problem is, if a cluster wants to switch from one qop to another, it'll have to take a downtime. rolling upgrade will create a situation where some nodes have old value and some have new, which'll prevent any communication between them. there will be similar issue when clients will try to connect. javax.security.sasl.qop can take in a list of qop in preferences order. so a transition from qop1 to qop2 can be easily done like this  \"qop1\" --> \"qop2,qop1\" --> rolling restart --> \"qop2\" --> rolling restart need to change hbase.rpc.protection to accept a list too. ",
        "label": 48
    },
    {
        "text": "move core to use hbase thirdparty  hbase-thirdparty was just released. have core move to use the lib. ",
        "label": 314
    },
    {
        "text": "hanging unit tests  we have hanging tests. here's a few from this morning's review: durruti:0.95 stack$ ./dev-support/findhangingtest.sh  https://builds.apache.org/job/hbase-0.95-on-hadoop2/176/consoletext   % total    % received % xferd  average speed   time    time     time  current                                  dload  upload   total   spent    left  speed 100 3300k    0 3300k    0     0   508k      0 --:--:--  0:00:06 --:--:--  621k hanging test: running org.apache.hadoop.hbase.testiofencing hanging test: running org.apache.hadoop.hbase.regionserver.wal.testlogrolling and... durruti:0.95 stack$ ./dev-support/findhangingtest.sh http://54.241.6.143/job/hbase-trunk-hadoop-2/396/consoletext   % total    % received % xferd  average speed   time    time     time  current                                  dload  upload   total   spent    left  speed 100  779k    0  779k    0     0   538k      0 --:--:--  0:00:01 --:--:--  559k hanging test: running org.apache.hadoop.hbase.testiofencing hanging test: running org.apache.hadoop.hbase.coprocessor.testregionservercoprocessorexceptionwithabort hanging test: running org.apache.hadoop.hbase.client.testfromclientside3 and.... durruti:0.95 stack$ ./dev-support/findhangingtest.sh  http://54.241.6.143/job/hbase-0.95/607/consoletext   % total    % received % xferd  average speed   time    time     time  current                                  dload  upload   total   spent    left  speed 100  445k    0  445k    0     0   490k      0 --:--:-- --:--:-- --:--:--  522k hanging test: running org.apache.hadoop.hbase.replication.testreplicationdisableinactivepeer hanging test: running org.apache.hadoop.hbase.master.testassignmentmanager hanging test: running org.apache.hadoop.hbase.util.testhbasefsck hanging test: running org.apache.hadoop.hbase.regionserver.teststorefileblockcachesummary hanging test: running org.apache.hadoop.hbase.integrationtestdataingestslowdeterministic and... durruti:0.95 stack$ ./dev-support/findhangingtest.sh  http://54.241.6.143/job/hbase-0.95-hadoop-2/607/consoletext   % total    % received % xferd  average speed   time    time     time  current                                  dload  upload   total   spent    left  speed 100  781k    0  781k    0     0   240k      0 --:--:--  0:00:03 --:--:--  244k hanging test: running org.apache.hadoop.hbase.coprocessor.testcoprocessorendpoint hanging test: running org.apache.hadoop.hbase.client.testfromclientside hanging test: running org.apache.hadoop.hbase.testiofencing hanging test: running org.apache.hadoop.hbase.master.testmasterfailoverbalancerpersistence hanging test: running org.apache.hadoop.hbase.master.testdistributedlogsplitting ",
        "label": 314
    },
    {
        "text": "leaseexception in scan should be retired  we should retry leaseexception just like other exceptions like outoforderscannernextexception and unknownscannerexception  code in clientscanner\uff1a if ((cause != null && cause instanceof notservingregionexception) ||         (cause != null && cause instanceof regionserverstoppedexception) ||         e instanceof outoforderscannernextexception || e instanceof unknownscannerexception ||         e instanceof scannerresetexception) {       // pass. it is easier writing the if loop test as list of what is allowed rather than       // as a list of what is not allowed... so if in here, it means we do not throw.       if (retriesleft <= 0) {         throw e; // no more retries       } ",
        "label": 211
    },
    {
        "text": " transactional contrib  correctly handle or avoid cases where writes occur in same millisecond  this patch fixes a few issues where puts/deletes occur with the same timestamp. in the indexing layer, we avoid a delete followed by a put to the same row for the index update. when the row is the same, we can just do the put. in the transactional layer, we correctly handled put, put, scan. this way the scan will see the last put, even if they have the same timestamp. remove the sleep to fix the putputscan transactional test, and run it many times to be sure we hit the case where they are in the same millisecond. also some small cleanup, null handling, and fail-fast changes. ",
        "label": 110
    },
    {
        "text": "testforcecacheimportantblocks ooms occasionally in  this trace: caused by: java.lang.outofmemoryerror at java.util.zip.deflater.init(native method) at java.util.zip.deflater.<init>(deflater.java:169) at java.util.zip.gzipoutputstream.<init>(gzipoutputstream.java:91) at java.util.zip.gzipoutputstream.<init>(gzipoutputstream.java:110) at org.apache.hadoop.hbase.io.hfile.reusablestreamgzipcodec$reusablegzipoutputstream$resetablegzipoutputstream.<init>(reusablestreamgzipcodec.java:79) at org.apache.hadoop.hbase.io.hfile.reusablestreamgzipcodec$reusablegzipoutputstream.<init>(reusablestreamgzipcodec.java:90) at org.apache.hadoop.hbase.io.hfile.reusablestreamgzipcodec.createoutputstream(reusablestreamgzipcodec.java:130) at org.apache.hadoop.io.compress.gzipcodec.createoutputstream(gzipcodec.java:101) at org.apache.hadoop.hbase.io.hfile.compression$algorithm.createplaincompressionstream(compression.java:299) at org.apache.hadoop.hbase.io.hfile.compression$algorithm.createcompressionstream(compression.java:283) at org.apache.hadoop.hbase.io.hfile.hfilewriterv1.getcompressingstream(hfilewriterv1.java:207) at org.apache.hadoop.hbase.io.hfile.hfilewriterv1.close(hfilewriterv1.java:356) at org.apache.hadoop.hbase.regionserver.storefile$writer.close(storefile.java:1330) at org.apache.hadoop.hbase.regionserver.store.internalflushcache(store.java:913) note that is caused specifically by hfilewritev1 when using compression. it looks like the compression resources are not released. not sure it's worth fixing this at this point. the test can be fixed by either not using compression (why are we using compression anyway), or by not testing for hfilev1. michael stack it seems you know the the code in hfilewriterv1. do you want to have a look? maybe there is a quick fix in hfilewriterv1. ",
        "label": 286
    },
    {
        "text": "metascanner throws tablenotfoundexception when specifying empty start row of a table  getting errors like this:  org.apache.hadoop.hbase.tablenotfoundexception: cannot find row in .meta. for table: verifiableeditor, row=verifiableeditor,,00000000000000  at org.apache.hadoop.hbase.client.metascanner.metascan(metascanner.java:104)  at org.apache.hadoop.hbase.client.hconnectionmanager$tableservers.prefetchregioncache(hconnectionmanager.java:733)  meta contains: hbase(main):001:0> scan '.meta.' row                                                      column+cell                                                                                                                                                          verifiableeditor,,1277097543936.6a2992842d685f48213bc33 column=info:regioninfo, timestamp=1277097544071, value=region => {name => 'verifiableeditor,,1277097543936.6a2992842d685f48213bc33afa85ac94.', startkey => '', endk  afa85ac94.                                              ey => '', encoded => 6a2992842d685f48213bc33afa85ac94, table => {{name => 'verifiableeditor', families => [{name => 'info', bloomfilter => 'none', replication_scop                                                          e => '0', compression => 'none', versions => '3', ttl => '2147483647', blocksize => '65536', in_memory => 'false', blockcache => 'true'}]}}                          verifiableeditor,,1277097543936.6a2992842d685f48213bc33 column=info:server, timestamp=1277097544317, value=monster04.sf.cloudera.com:60020                                                                                   afa85ac94.                                                                                                                                                                                                                   verifiableeditor,,1277097543936.6a2992842d685f48213bc33 column=info:serverstartcode, timestamp=1277097544317, value=1277097337799                                                                                            afa85ac94.                                                                                                                                                                                                                  1 row(s) in 0.2660 seconds ",
        "label": 453
    },
    {
        "text": "build with hadoop profile  building trunk with hadoop.profile=3.0 gives exceptions (see [1]) due to change in the hadoop maven modules naming (and also usage of 3.0-snapshot instead of 3.0.0-snapshot in hbase-common). i can provide a patch that would move most of hadoop dependencies in their respective profiles and will define the correct hadoop deps in the 3.0 profile. please tell me if that's ok to go this way. thx, eric [1]  $ mvn clean install -dhadoop.profile=3.0  [info] scanning for projects...  [error] the build could not read 3 projects -> [help 1]  [error]   [error] the project org.apache.hbase:hbase-server:0.95-snapshot (/d/hbase.svn/hbase-server/pom.xml) has 3 errors  [error] 'dependencies.dependency.version' for org.apache.hadoop:hadoop-common:jar is missing. @ line 655, column 21  [error] 'dependencies.dependency.version' for org.apache.hadoop:hadoop-annotations:jar is missing. @ line 659, column 21  [error] 'dependencies.dependency.version' for org.apache.hadoop:hadoop-minicluster:jar is missing. @ line 663, column 21  [error]   [error] the project org.apache.hbase:hbase-common:0.95-snapshot (/d/hbase.svn/hbase-common/pom.xml) has 3 errors  [error] 'dependencies.dependency.version' for org.apache.hadoop:hadoop-common:jar is missing. @ line 170, column 21  [error] 'dependencies.dependency.version' for org.apache.hadoop:hadoop-annotations:jar is missing. @ line 174, column 21  [error] 'dependencies.dependency.version' for org.apache.hadoop:hadoop-minicluster:jar is missing. @ line 178, column 21  [error]   [error] the project org.apache.hbase:hbase-it:0.95-snapshot (/d/hbase.svn/hbase-it/pom.xml) has 3 errors  [error] 'dependencies.dependency.version' for org.apache.hadoop:hadoop-common:jar is missing. @ line 220, column 18  [error] 'dependencies.dependency.version' for org.apache.hadoop:hadoop-annotations:jar is missing. @ line 224, column 21  [error] 'dependencies.dependency.version' for org.apache.hadoop:hadoop-minicluster:jar is missing. @ line 228, column 21  [error] ",
        "label": 158
    },
    {
        "text": "replication handling of changes to peer clusters is inefficient  the current handling of changes to the region servers in a replication peer cluster is currently quite inefficient. the list of region servers that are being replicated to is only updated if there are a large number of issues encountered while replicating. this can cause it to take quite a while to recognize that a number of the regionserver in a peer cluster are no longer available. a potentially bigger problem is that if a replication peer cluster is started with a small number of regionservers, and then more region servers are added after replication has started, the additional region servers will never be used for replication (unless there are failures on the in-use regionservers). part of the current issue is that the retry code in replicationsource#shipedits checks a randomly-chosen replication peer regionserver (in replicationsource#isslavedown) to see if it is up after a replication write has failed on a different randonly-chosen replication peer. if the peer is seen as not down, another randomly-chosen peer is used for writing. a second part of the issue is that changes to the list of region servers in a peer cluster are not detected at all, and are only picked up if a certain number of failures have occurred when trying to ship edits. ",
        "label": 178
    },
    {
        "text": "application x www form urlencoded is incorrectly handled in the rest interface  currently if application/x-www-form-urlencoded form data is posted to the rest interface it does not appear in the query map. attached to this issue is a patch that fixes this and allows data posted with a form as application/x-www-form-urlencoded data to be read into the query map and used to complete the request. i first noticed this while trying to create a scanner and i was unable to specify the start date/end date/columns if the query parameters were passed in as application/x-www-form-urlencoded. ",
        "label": 79
    },
    {
        "text": "documet use scan snapshot feature  add the design doc in dev-support/design-docs{{ and describe }}the feature in the reference guide. ",
        "label": 500
    },
    {
        "text": "heap usage and limit reporting doesn't work as expected when using g1 gc  getting some early experience with the g1 gc. running with -xmx1000m and hbase_opts set to \"-xx:+unlockexperimentalvmopts -xx:+useg1gc\". regionserver heap use reports are not of much use: hbase(main):001:0> status 'simple' 3 live servers     test3:60020 1247389283042         requests=0, regions=1, usedheap=0, maxheap=41     test2:60020 1247389219994         requests=0, regions=1, usedheap=0, maxheap=41     test4:60020 1247389324563         requests=0, regions=2, usedheap=0, maxheap=41 0 dead servers top is about right:   pid user      pr  ni  virt  res  shr s %cpu %mem    time+  command 23988 hadoop    24   0 1492m  98m  10m s  0.0  2.5   0:02.65 java incidentally, don't try -xx:+useg1gc and -xx:+doescapeanalysis together or the jvm will rapidly segfault. ",
        "label": 290
    },
    {
        "text": "some tests do not use ephemeral ports  for example, seems like most of the tests bind the master to port 60000. this doesn't work on shared build machines where multiple hbase test targets might run concurrently. ",
        "label": 247
    },
    {
        "text": "alow more than one log splitter per rs  iirc, this is an idea that came from the lads at xiaomi. i have a small cluster of 6 rss and one went down. it had a few wals. i see this in logs: 2013-10-09 05:47:27,890 debug org.apache.hadoop.hbase.master.splitlogmanager: total tasks = 25 unassigned = 21 wal splitting is held up for want of slots out on the cluster to split wals. we need to be careful we don't overwhelm the foreground regionservers but more splitters should help get all back online faster. ",
        "label": 233
    },
    {
        "text": "validate compile protobuf profile in test patch sh  compile-protobuf profile sometimes doesn't compile - latest issue being hbase-11373 test-patch.sh should validate that compile-protobuf profile compiles. this would discover such issue sooner. ",
        "label": 441
    },
    {
        "text": "scan copy constructor doesn't copy reversed member variable  the scan copy constructor doesn't copy reversed member variable. ",
        "label": 544
    },
    {
        "text": "support cyclic replication  we need to support cyclic replication by using the cluster id of each hlogkey and stop replicating when it goes back to the original cluster. ",
        "label": 286
    },
    {
        "text": "concurrentmodificationexception in notifychangedreadersobservers  org.apache.hadoop.hbase.droppedsnapshotexception: region: .meta.,,1         at org.apache.hadoop.hbase.regionserver.hregion.internalflushcache(hregion.java:876)         at org.apache.hadoop.hbase.regionserver.hregion.flushcache(hregion.java:772)         at org.apache.hadoop.hbase.regionserver.memcacheflusher.flushregion(memcacheflusher.java:220)         at org.apache.hadoop.hbase.regionserver.memcacheflusher.run(memcacheflusher.java:130) caused by: java.util.concurrentmodificationexception         at java.util.hashmap$hashiterator.nextentry(hashmap.java:793)         at java.util.hashmap$keyiterator.next(hashmap.java:828)         at org.apache.hadoop.hbase.regionserver.hstore.notifychangedreadersobservers(hstore.java:734)         at org.apache.hadoop.hbase.regionserver.hstore.updatereaders(hstore.java:722)         at org.apache.hadoop.hbase.regionserver.hstore.internalflushcache(hstore.java:691)         at org.apache.hadoop.hbase.regionserver.hstore.flushcache(hstore.java:627)         at org.apache.hadoop.hbase.regionserver.hregion.internalflushcache(hregion.java:863)         ... 3 more ",
        "label": 314
    },
    {
        "text": "high scale lib's counter depends on oracle  sun  jre  and also has some bug  cliff's high-scale-lib's counter is used in important classes (for example, hregion) in hbase, but counter uses sun.misc.unsafe, that is implementation detail of the java standard library and belongs to oracle (sun). that consequently makes hbase depend on the specific jre implementation. to make matters worse, counter has a bug and you may get wrong result if you mix a reading method into your logic calling writing methods. in more detail, i think the bug is caused by reading an internal array field without resolving memory caching, which is intentional the comment says, but storing the read result into a volatile field. that field may be not changed after you can see the true values of the array field, and also may be not changed after updating the \"next\" cat instance's values in some race condition when extending cat instance chain. anyway, it is possible that you create a new alternative class which only depends on the standard library. i know java8 provides its alternative, but hbase should support java6 and java7 for some time. ",
        "label": 200
    },
    {
        "text": "autorestart option is not working because of stale znode  shutdown   in hbase-daemon.sh autorestart option the znode used is \"shutdown\" zshutdown=`$bin/hbase org.apache.hadoop.hbase.util.hbaseconftool zookeeper.znode.state`         if [ \"$zshutdown\" == \"null\" ]; then zshutdown=\"shutdown\"; fi         zfullshutdown=$zparent/$zshutdown the node shutdown is not available now and is changed to running. since this node is not available, script does not restart the node and it exists. so autorestart scripts needs to be changed to make use of \"running\" znode. ",
        "label": 539
    },
    {
        "text": "speedup loadincrementalhfiles  from adam phelps:  from the logs it looks like <1% of the hfiles we're loading have to be split. looking at the code for loadincrementhfiles (hbase v0.90.1), i'm actually thinking our problem is that this code loads the hfiles sequentially. our largest table has over 2500 regions and the data being loaded is fairly well distributed across them, so there end up being around 2500 hfiles for each load period. at 1-2 seconds per hfile that means the loading process is very time consuming. currently server.bulkloadhfile() is a blocking call.  we can utilize executorservice to achieve better parallelism on multi-core computer. new configuration parameter \"hbase.loadincremental.threads.max\" is introduced which sets the maximum number of threads for parallel bulk load. ",
        "label": 441
    },
    {
        "text": "log splitting slowed by repeated attempts at connecting to downed datanode  testing if i kill rs and dn on a node, log splitting takes longer as we doggedly try connecting to the downed dn to get wal blocks. here's the cycle i see: 2010-12-21 17:34:48,239 warn org.apache.hadoop.hdfs.dfsclient: error recovery for block blk_900551257176291912_1203821 failed  because recovery from primary datanode 10.20.20.182:10010 failed 5 times.    pipeline was 10.20.20.184:10010, 10.20.20.186:10010, 10.20.20.182:10010. will retry... 2010-12-21 17:34:50,240 info org.apache.hadoop.ipc.client: retrying connect to server: /10.20.20.182:10020. already tried 0 time(s). 2010-12-21 17:34:51,241 info org.apache.hadoop.ipc.client: retrying connect to server: /10.20.20.182:10020. already tried 1 time(s). 2010-12-21 17:34:52,241 info org.apache.hadoop.ipc.client: retrying connect to server: /10.20.20.182:10020. already tried 2 time(s). 2010-12-21 17:34:53,242 info org.apache.hadoop.ipc.client: retrying connect to server: /10.20.20.182:10020. already tried 3 time(s). 2010-12-21 17:34:54,243 info org.apache.hadoop.ipc.client: retrying connect to server: /10.20.20.182:10020. already tried 4 time(s). 2010-12-21 17:34:55,243 info org.apache.hadoop.ipc.client: retrying connect to server: /10.20.20.182:10020. already tried 5 time(s). 2010-12-21 17:34:56,244 info org.apache.hadoop.ipc.client: retrying connect to server: /10.20.20.182:10020. already tried 6 time(s). 2010-12-21 17:34:57,245 info org.apache.hadoop.ipc.client: retrying connect to server: /10.20.20.182:10020. already tried 7 time(s). 2010-12-21 17:34:58,245 info org.apache.hadoop.ipc.client: retrying connect to server: /10.20.20.182:10020. already tried 8 time(s). 2010-12-21 17:34:59,246 info org.apache.hadoop.ipc.client: retrying connect to server: /10.20.20.182:10020. already tried 9 time(s). 2010-12-21 17:34:59,246 warn org.apache.hadoop.hdfs.dfsclient: failed recovery attempt #5 from primary datanode 10.20.20.182:10010 java.net.connectexception: call to /10.20.20.182:10020 failed on connection exception: java.net.connectexception: connection refused     at org.apache.hadoop.ipc.client.wrapexception(client.java:767)     at org.apache.hadoop.ipc.client.call(client.java:743)     at org.apache.hadoop.ipc.rpc$invoker.invoke(rpc.java:220)     at $proxy8.getprotocolversion(unknown source)     at org.apache.hadoop.ipc.rpc.getproxy(rpc.java:359)     at org.apache.hadoop.ipc.rpc.getproxy(rpc.java:346)     at org.apache.hadoop.ipc.rpc.getproxy(rpc.java:383) ... \"because recovery from primary datanode\" is done 5 times (hardcoded). within these retries we'll do this.maxretries = conf.getint(\"ipc.client.connect.max.retries\", 10); the hardcoding of 5 attempts we should get fixed and we should doc the ipc.client.connect.max.retries as important config. we should recommend bringing it down from default. ",
        "label": 314
    },
    {
        "text": "memory leak in monitoredrpchandlerimpl  i got a pretty reliable way of oome'ing my region servers. using a big payload (64mb in my case), a default heap and default number of handlers, it's not too long that all the monitoredrpchandlerimpl hold on a 64mb reference and once a compaction kicks in it kills everything. the issue is that even after the rpc call is done, the packet still lives in monitoredrpchandlerimpl. will attach a screen shot of jprofiler's analysis in a moment. this is a blocker for 0.92.0, anyone using a high number of handlers and bigish values will kill themselves. ",
        "label": 229
    },
    {
        "text": "rename recovered edits file from oldlogfile log to recovered edits  i can't stand the name we have for the file of edits per region that is written by the wal log splitting code. its oldlogfile.log. how dumb is that? ",
        "label": 314
    },
    {
        "text": " stargate  fix json handling of meta and root  while working on the hbase explorer front end in hue i found a few inconsistencies between the plain text version of values versus the json representation. from an email conversation: plain text  --------------- $ curl -h \"curl -h \"accept: text/plain\" localhost:8888/status/cluster  1 live servers, 0 dead servers, 5.0000 average load 1 live servers  de1-app-mbp-2.fritz.box:62884 1280924907616  requests=0, regions=5  heapsizemb=27  maxheapsizemb=995  t2,,1280917558997  stores=3  storefiless=0  storefilesizemb=0  memstoresizemb=0  storefileindexsizemb=0  usertable,,1280917566604  stores=3  storefiless=2  storefilesizemb=224  memstoresizemb=0  storefileindexsizemb=0  .meta.,,1  stores=2  storefiless=1  storefilesizemb=0  memstoresizemb=0  storefileindexsizemb=0  t1,,1280917554475  stores=3  storefiless=0  storefilesizemb=0  memstoresizemb=0  storefileindexsizemb=0  -root-,,0  stores=1  storefiless=1  storefilesizemb=0  memstoresizemb=0  storefileindexsizemb=0 json  --------- and curling the json yields: $ curl -h \"accept: application/json\" localhost:8888/status/cluster  {\"requests\":0,\"regions\":5,\"averageload\":5.0,\"deadnodes\":[null],\"livenodes\":[{\"node\":{\"startcode\":1280924907616,\"requests\":0,\"name\":\"de1-app-mbp-2.fritz.box:62884\",\"maxheapsizemb\":995,\"heapsizemb\":27,\"region\":[ {\"stores\":3,\"storefiles\":0,\"storefilesizemb\":0,\"storefileindexsizemb\":0,\"name\":\"ddisldeyoda5mtc1ntg5otc=\",\"memstoresizemb\":0} , {\"stores\":3,\"storefiles\":2,\"storefilesizemb\":224,\"storefileindexsizemb\":0,\"name\":\"dxnlcnrhymxllcwxmjgwote3nty2nja0\",\"memstoresizemb\":0} , {\"stores\":2,\"storefiles\":1,\"storefilesizemb\":0,\"storefileindexsizemb\":0,\"name\":\"lk1fveeulcwx\",\"memstoresizemb\":0} , {\"stores\":3,\"storefiles\":0,\"storefilesizemb\":0,\"storefileindexsizemb\":0,\"name\":\"ddesldeyoda5mtc1ntq0nzu=\",\"memstoresizemb\":0} , {\"stores\":1,\"storefiles\":1,\"storefilesizemb\":0,\"storefileindexsizemb\":0,\"name\":\"lvjpt1qtlcww\",\"memstoresizemb\":0} ]}}]} and another one: i have another one with .meta. and -root-, in my small sample setup (all local, /tmp etc.) i see this in the master ui: name region server encoded name start key end key  .meta.,,1 10.0.0.43:60030 - but running the same against stargate i get: $ curl -h \"accept: application/json\" http://localhost:8888/.meta./regions {\"name\":\".meta.\"} while a \"normal\" user table with a single row has name region server encoded name start key end key  t1,,1281111615489 10.0.0.43:60030 1127696125 and through stargate: $ curl -h \"accept: application/json\" http://localhost:8888/t1/regions  {\"name\":\"t1\",\"region\":[ {\"location\":\"10.0.0.43:54988\",\"endkey\":\"\",\"startkey\":\"\",\"id\":1281111615489,\"name\":\"t1,,1281111615489\"} ]} so the internal tables are not reported right. ",
        "label": 38
    },
    {
        "text": "replace deprecated methods in filesystem with their replacements  filestatus#isdir() is deprecated. filestatus#isdirectory() should be called instead. here is the list of deprecated methods in filesystem : public string getname() public static filesystem getnamed(string name, configuration conf)   public fsdataoutputstream createnonrecursive(path f,       boolean overwrite,       int buffersize, short replication, long blocksize,       progressable progress) throws ioexception {    public fsdataoutputstream createnonrecursive(path f, fspermission permission,        boolean overwrite, int buffersize, short replication, long blocksize,        progressable progress) throws ioexception {   public short getreplication(path src) throws ioexception {   public boolean delete(path f) throws ioexception {   public long getlength(path f) throws ioexception {   public long getblocksize(path f) throws ioexception {   public long getdefaultblocksize() { public short getdefaultreplication() except for createnonrecursive() which doesn't have non-deprecated equivalent in distributedfilesystem, deprecated methods are replaced with their non-deprecated counterparts. ",
        "label": 191
    },
    {
        "text": "offlinemetarepair doesn't support hadoop 20's fs default name property  i want to use \"offlinemetarepair\" tools and found onbody fix this bugs. i will make a patch. > 12/01/05 23:23:30 error util.hbasefsck: bailed out due to:  > java.lang.illegalargumentexception: wrong fs: hdfs://   > us01-ciqps1-name01.carrieriq.com:9000/hbase/m2m-integration-mm_tion-13  > 25190318714/0003d2ede27668737e192d8430dbe5d0/.regioninfo,  > expected: file:///  > at org.apache.hadoop.fs.filesystem.checkpath(filesystem.java:352)  > at  > org.apache.hadoop.fs.rawlocalfilesystem.pathtofile(rawlocalfilesystem.java:47)  > at  > org.apache.hadoop.fs.rawlocalfilesystem.getfilestatus(rawlocalfilesystem.java:368)  > at  > org.apache.hadoop.fs.filterfilesystem.getfilestatus(filterfilesystem.java:251)  > at  > org.apache.hadoop.fs.checksumfilesystem$checksumfsinputchecker.<init>(checksumfilesystem.java:126)  > at  > org.apache.hadoop.fs.checksumfilesystem.open(checksumfilesystem.java:284)  > at org.apache.hadoop.fs.filesystem.open(filesystem.java:398)  > at  > org.apache.hadoop.hbase.util.hbasefsck.loadmetaentry(hbasefsck.java:256)  > at  > org.apache.hadoop.hbase.util.hbasefsck.loadtableinfo(hbasefsck.java:284)  > at  > org.apache.hadoop.hbase.util.hbasefsck.rebuildmeta(hbasefsck.java:402)  > at  > org.apache.hadoop.hbase.util.hbck.offlinemetarepair.main(offlinemetare ",
        "label": 529
    },
    {
        "text": "testacidguarantees should cover adaptive in memory compaction  currently testacidguarantees populates 3 policies of (in-memory) compaction. adaptive in-memory compaction is new and should be added as 4th compaction policy. ",
        "label": 98
    },
    {
        "text": "fix the  meta  fixer in hbasefsck  i tried writing a few unit tests in the scope of hbase-3216 since the previous one was only testing a best case scenario but it's at least currently not able to fix the case where .meta. says the assignment is on server a when in fact it's on server b (the region gets closed but never reopened). stack says the breakage probably happened with the new master. ",
        "label": 453
    },
    {
        "text": "bring recent rpc changes down from hadoop  add hadoop-4797 \"rpc server can leave a lot of direct buffers\" and hadoop-4802 \"rpc server send buffer retains size of largest response ever sent\" to our rpc. these are 0.20.0 improvements. bring them down so for first we have benefit of the improvement and the second, so we can undo our bringing rpc server local when we move to 0.20.0 (having the two rpcservers look the same will make it easier undoing it). ",
        "label": 314
    },
    {
        "text": "hcd setcompressiontype should use enum support for storing compression types as strings  let's not require an update to hcd every time the hfile compression enum is changed. ",
        "label": 38
    },
    {
        "text": "add uts to test retry on update zk failure  ",
        "label": 149
    },
    {
        "text": "hbase exporter should compress output files by default  or at least allow this as an option   the hbase exporter puts (key, result) pairs as keys and values into an output sequence file. there could be significant savings at low cost if at least default compression was enabled on this output sequence file. in createsubmittablejob(), this might be as simple as adding the following:  sequencefileoutputformat.setoutputcompressiontype(job, sequencefile.compressiontype.block);  sequencefileoutputformat.setcompressoutput(job, true);  fileoutputformat.setoutputcompressorclass(job, defaultcodec.class); ",
        "label": 263
    },
    {
        "text": "upgrade hadoop dependency to hadoop  hadoop 1.1.2 release fixes a critical bug: https://issues.apache.org/jira/browse/hadoop-9115 ",
        "label": 441
    },
    {
        "text": "reenable testshell and teststochasticloadbalancer  parent disabled these tests when test runs were flakier than they are now. try reenabling them. ",
        "label": 314
    },
    {
        "text": "make maven skip module test properties consistent  ",
        "label": 154
    },
    {
        "text": "tablemapreduceutil inittablereducerjob broken due to setconf method in tableoutputformat  setconf() method in tableoutputformat gets called and it replaces the hbase.zookeeper.quorum address in the job conf xml when you run a copytable job from one cluster to another. the conf gets set to the peer.addr that is specified, which makes the job read and write from/to the peer cluster instead of reading from the original cluster and writing to the peer. possibly caused due to the change in https://issues.apache.org/jira/browse/hbase-3111 ",
        "label": 229
    },
    {
        "text": "testdrainingserver is an integration test  it should be a unit test instead  testdrainingserver tests the function that allows to say that a regionserver should not get new regions. as it is written today, it's an integration test: it starts & stops a cluster. the test would be more efficient if it would just check that the assignmentmanager does not use the drained region server; whatever the circumstances (bulk assign or not for example). ",
        "label": 191
    },
    {
        "text": "log message about cleanerchore delegate initialization should be at info  right now we log a debug message as we initialize the delegates that decide on cleaner decisions: 2019-10-30 07:30:01,594 debug org.apache.hadoop.hbase.master.cleaner.cleanerchore: initialize cleaner=org.apache.hadoop.hbase.replication.master.replicationlogcleaner 2019-10-30 07:30:01,597 debug org.apache.hadoop.hbase.master.cleaner.cleanerchore: initialize cleaner=org.apache.hadoop.hbase.master.snapshot.snapshotlogcleaner 2019-10-30 07:30:01,600 debug org.apache.hadoop.hbase.master.cleaner.cleanerchore: initialize cleaner=org.apache.hadoop.hbase.master.cleaner.hfilelinkcleaner 2019-10-30 07:30:01,601 debug org.apache.hadoop.hbase.master.cleaner.cleanerchore: initialize cleaner=org.apache.hadoop.hbase.master.snapshot.snapshothfilecleaner 2019-10-30 07:30:01,602 debug org.apache.hadoop.hbase.master.cleaner.cleanerchore: initialize cleaner=org.apache.hadoop.hbase.master.cleaner.timetolivehfilecleaner done here in cleanerchore.java:  private void initcleanerchain(string confkey) {     this.cleanerschain = new linkedlist<>();     string[] logcleaners = conf.getstrings(confkey);     if (logcleaners != null) {       for (string classname : logcleaners) {         t logcleaner = newfilecleaner(classname, conf);         if (logcleaner != null) {           log.debug(\"initialize cleaner={}\", classname);           this.cleanerschain.add(logcleaner);         }       }     }   } this message should be at info. it doesn't happen often and knowing what plugins decide about file deletions is important all the time. ",
        "label": 363
    },
    {
        "text": "move external servers to metrics2  thrift thrift2 rest   implement metrics2 for all the external servers: thrift thrift2 rest ",
        "label": 154
    },
    {
        "text": "integrationtestingestwithacl should allow user to be passed as parameter  the integrationtestingestwithacl needs to be modified to allow the user to be passed in as an argument at run time. currently, the test is using a fixed set of user names which cannot be authenticated via kerberos, causing the test to fail. allowing the username to be passed at run time will allow a user that is already authenticated by kerberos to be used, and resolve the failure. 2014-02-06 02:58:25,315|beaver.machine|info|running: /usr/bin/kinit -c /hbase.kerberos.ticket -k -t /home/hadoopqa/keytabs/hbase.headless.keytab hbase 2014-02-06 02:58:25,325|beaver.machine|info|running: /usr/lib/hbase/bin/hbase --config /tmp/hbaseconf org.apache.hadoop.hbase.integrationtestsdriver -regex integrationtestingestwithacl 2014-02-06 02:58:34,489|beaver.machine|info|2014-02-06 02:58:34,489 debug hbasewriterthreadwithacl_1 token.authenticationtokenselector: no matching token found 2014-02-06 02:58:34,493|beaver.machine|info|2014-02-06 02:58:34,489 debug hbasewriterthreadwithacl_1 security.hbasesaslrpcclient: creating sasl gssapi client. server's kerberos principal name is hbase/h2-ubuntu12-sec-1391405488-hbase-7.cs1cloud.internal@example.com 2014-02-06 02:58:34,493|beaver.machine|info|2014-02-06 02:58:34,491 warn hbasewriterthreadwithacl_1 security.usergroupinformation: priviledgedactionexception as:owner (auth:simple) cause:javax.security.sasl.saslexception: gss initiate failed caused by gssexception: no valid credentials provided (mechanism level: failed to find any kerberos tgt) 2014-02-06 02:58:34,493|beaver.machine|info|2014-02-06 02:58:34,492 warn hbasewriterthreadwithacl_1 ipc.rpcclient: exception encountered while connecting to the server : javax.security.sasl.saslexception: gss initiate failed caused by gssexception: no valid credentials provided (mechanism level: failed to find any kerberos tgt) 2014-02-06 02:58:34,498|beaver.machine|info|2014-02-06 02:58:34,493 fatal hbasewriterthreadwithacl_1 ipc.rpcclient: sasl authentication failed. the most likely cause is missing or invalid credentials. consider 'kinit'. 2014-02-06 02:58:34,499|beaver.machine|info|javax.security.sasl.saslexception: gss initiate failed caused by gssexception: no valid credentials provided (mechanism level: failed to find any kerberos tgt) 2014-02-06 02:58:34,499|beaver.machine|info|at com.sun.security.sasl.gsskerb.gsskrb5client.evaluatechallenge(gsskrb5client.java:194) 2014-02-06 02:58:34,499|beaver.machine|info|at org.apache.hadoop.hbase.security.hbasesaslrpcclient.saslconnect(hbasesaslrpcclient.java:152) 2014-02-06 02:58:34,500|beaver.machine|info|at org.apache.hadoop.hbase.ipc.rpcclient$connection.setupsaslconnection(rpcclient.java:762) 2014-02-06 02:58:34,500|beaver.machine|info|at org.apache.hadoop.hbase.ipc.rpcclient$connection.access$600(rpcclient.java:354) 2014-02-06 02:58:34,500|beaver.machine|info|at org.apache.hadoop.hbase.ipc.rpcclient$connection$2.run(rpcclient.java:883) 2014-02-06 02:58:34,501|beaver.machine|info|at org.apache.hadoop.hbase.ipc.rpcclient$connection$2.run(rpcclient.java:880) 2014-02-06 02:58:34,501|beaver.machine|info|at java.security.accesscontroller.doprivileged(native method) 2014-02-06 02:58:34,501|beaver.machine|info|at javax.security.auth.subject.doas(subject.java:396) 2014-02-06 02:58:34,501|beaver.machine|info|at org.apache.hadoop.security.usergroupinformation.doas(usergroupinformation.java:1548) 2014-02-06 02:58:34,502|beaver.machine|info|at org.apache.hadoop.hbase.ipc.rpcclient$connection.setupiostreams(rpcclient.java:880) 2014-02-06 02:58:34,502|beaver.machine|info|at org.apache.hadoop.hbase.ipc.rpcclient.getconnection(rpcclient.java:1536) 2014-02-06 02:58:34,502|beaver.machine|info|at org.apache.hadoop.hbase.ipc.rpcclient.call(rpcclient.java:1425) 2014-02-06 02:58:34,502|beaver.machine|info|at org.apache.hadoop.hbase.ipc.rpcclient.callblockingmethod(rpcclient.java:1654) 2014-02-06 02:58:34,503|beaver.machine|info|at org.apache.hadoop.hbase.ipc.rpcclient$blockingrpcchannelimplementation.callblockingmethod(rpcclient.java:1712) 2014-02-06 02:58:34,503|beaver.machine|info|at org.apache.hadoop.hbase.protobuf.generated.clientprotos$clientservice$blockingstub.get(clientprotos.java:28833) 2014-02-06 02:58:34,503|beaver.machine|info|at org.apache.hadoop.hbase.protobuf.protobufutil.getroworbefore(protobufutil.java:1466) 2014-02-06 02:58:34,503|beaver.machine|info|at org.apache.hadoop.hbase.client.htable$2.call(htable.java:701) 2014-02-06 02:58:34,504|beaver.machine|info|at org.apache.hadoop.hbase.client.htable$2.call(htable.java:699) 2014-02-06 02:58:34,504|beaver.machine|info|at org.apache.hadoop.hbase.client.rpcretryingcaller.callwithretries(rpcretryingcaller.java:120) 2014-02-06 02:58:34,504|beaver.machine|info|at org.apache.hadoop.hbase.client.htable.getroworbefore(htable.java:705) 2014-02-06 02:58:34,504|beaver.machine|info|at org.apache.hadoop.hbase.client.metascanner.metascan(metascanner.java:144) thanks to huned who discovered this issue. ",
        "label": 544
    },
    {
        "text": "splitregionhandler doesn't care if it deletes the znode or not  leaves the parent region stuck offline  saw this on a little test cluster, really easy to trigger. first the master log: 2011-11-15 22:28:57,900 debug org.apache.hadoop.hbase.master.handler.splitregionhandler: handling split event for e5be6551c8584a6a1065466e520faf4e; deleting node  2011-11-15 22:28:57,900 debug org.apache.hadoop.hbase.zookeeper.zkassign: master:62003-0x132f043bbde08c1 deleting existing unassigned node for e5be6551c8584a6a1065466e520faf4e that is in expected state rs_zk_region_split  2011-11-15 22:28:57,975 warn org.apache.hadoop.hbase.zookeeper.zkassign: master:62003-0x132f043bbde08c1 attempting to delete unassigned node in rs_zk_region_split state but after verifying state, we got a version mismatch  2011-11-15 22:28:57,975 info org.apache.hadoop.hbase.master.handler.splitregionhandler: handled split report); parent=testtable,0001355346,1321396080924.e5be6551c8584a6a1065466e520faf4e. daughter a=testtable,0001355346,1321396132414.df9b549eb594a1f8728608a2a431224a.daughter b=testtable,0001368082,1321396132414.de861596db4337dc341138f26b9c8bc2.  ...  2011-11-15 22:28:58,052 debug org.apache.hadoop.hbase.master.assignmentmanager: handling transition=rs_zk_region_split, server=sv4r28s44,62023,1321395865619, region=e5be6551c8584a6a1065466e520faf4e  2011-11-15 22:28:58,052 warn org.apache.hadoop.hbase.master.assignmentmanager: region e5be6551c8584a6a1065466e520faf4e not found on server sv4r28s44,62023,1321395865619; failed processing  2011-11-15 22:28:58,052 warn org.apache.hadoop.hbase.master.assignmentmanager: received split for region e5be6551c8584a6a1065466e520faf4e from server sv4r28s44,62023,1321395865619 but it doesn't exist anymore, probably already processed its split  (repeated forever) the master processes the split but when it calls zkassign.deletenode it doesn't check the boolean that's returned. in this case it was false. so for the master the split was completed, but for the region server it's another story: 2011-11-15 22:28:57,661 debug org.apache.hadoop.hbase.zookeeper.zkassign: regionserver:62023-0x132f043bbde08d3 attempting to transition node e5be6551c8584a6a1065466e520faf4e from rs_zk_region_splitting to rs_zk_region_split  2011-11-15 22:28:57,775 debug org.apache.hadoop.hbase.zookeeper.zkassign: regionserver:62023-0x132f043bbde08d3 successfully transitioned node e5be6551c8584a6a1065466e520faf4e from rs_zk_region_splitting to rs_zk_region_split  2011-11-15 22:28:57,775 info org.apache.hadoop.hbase.regionserver.splittransaction: still waiting on the master to process the split for e5be6551c8584a6a1065466e520faf4e  2011-11-15 22:28:57,876 debug org.apache.hadoop.hbase.zookeeper.zkassign: regionserver:62023-0x132f043bbde08d3 attempting to transition node e5be6551c8584a6a1065466e520faf4e from rs_zk_region_split to rs_zk_region_split  2011-11-15 22:28:57,967 debug org.apache.hadoop.hbase.zookeeper.zkassign: regionserver:62023-0x132f043bbde08d3 successfully transitioned node e5be6551c8584a6a1065466e520faf4e from rs_zk_region_split to rs_zk_region_split  2011-11-15 22:28:58,067 debug org.apache.hadoop.hbase.zookeeper.zkassign: regionserver:62023-0x132f043bbde08d3 attempting to transition node e5be6551c8584a6a1065466e520faf4e from rs_zk_region_split to rs_zk_region_split  2011-11-15 22:28:58,108 debug org.apache.hadoop.hbase.zookeeper.zkassign: regionserver:62023-0x132f043bbde08d3 successfully transitioned node e5be6551c8584a6a1065466e520faf4e from rs_zk_region_split to rs_zk_region_split  (printed forever) since the znode isn't really deleted, it thinks the master just haven't got to process its region thus waits which leaves the region unavailable. we need to just retry the delete master-side asap since the rs will wait 100ms between retries. at the same time, it would be nice if zkassign.deletenode always printed out the name of the region in its messages because it took me a while to see that the delete didn't take affect while looking at a grep. ",
        "label": 229
    },
    {
        "text": "make global flusher check work with percentages rather than hard code memory sizes   currently defaults are 512m for upperbound and 256 for the lowerbound. comes of hbase-1023. ",
        "label": 314
    },
    {
        "text": "base hbase on hadoop  hadoop-0.17.1 is in the process of being released. it should become the base version of hbase 0.2.0 based on the inclusion of the patch hadoop-3472 ",
        "label": 241
    },
    {
        "text": "alternate indexed hbase implementation  speeds scans by adding indexes to regions rather secondary tables  purpose the goal of the indexed hbase contrib is to speed up scans by indexing hbase columns. indexed hbase (ihbase) is different from the indexed tables in transactional hbase (ithbase): while the indexes in ithbase are, in fact, hbase tables using the indexed column's values as row keys, ihbase creates indexes at the region level. the differences are summarized in below. + global ordering  ithbase: yes  ihbase: no  comment: ihbase has an index for each region. the flip side of not having global ordering is compatibility with the good old hregion: results are coming back in row order (and not value order as in thbase) + full table scan?  ithbase: no  ihbase: no  comment: ithbase does a partial scan on the index table. ihbase supports specifying start/end rows to limit the number of scanned regions + multiple index usage  ithbase: no  ihbase: yes  comment: ihbase can take advantage of multiple indexes in the same scan. ihbase idxscan object accepts an expression which allows intersection/ unison of several indexed   column criteria + extra disk storage  ithbase: yes  ihbase: no  comment: ihbase indexes are created when the region starts/flushes and do not require any extra storage + extra ram  ithbase: yes  ihbase: yes  comment: ihbase indexes are in memory and hence increase the memory overhead. thbase indexes increase the number of regions each region server has to support thus costing memory too + parallel scanning support  ithbase: no  ihbase: yes  in ithbase the index table needs to be consulted and then gets are issued for each matching row. the behavior of ihbase (as perceived by the client) is no different than a regular scan and hence supports parallel scanning seamlessly. parallel get can be implemented to speedup ithbase scans why ihbase should outperform ithbase  1. more flexible: a. supports range queries and multi-index queries b. supports different types - not only byte arrays  2. less overhead: ithbase pays at least two 'table roundtrips' - one for the index table and the other for the main table  3. quicker index expression evaluation: ihbase is using dedicated index data structures while ithbase is using the regular hregion scan facilities implementation notes  \u2022 only index storefiles.every index scan performs a full memstore scan. indexing the memstore will be implemented only if scanning the memstore will prove to be a performance bottleneck  \u2022 index expression evaluation is performed using bit sets.there are two types of bitsets: compressed and expanded. an index will typically store a compressed bitset while an expression evaluator will most probably use an expanded bitset  + todo this patch changes some some of hbase core so can instantiate other than default hregion. fixes bugs in filter too. would like to add this as a contrib. package on 0.20 branch in time for 0.20.3 if possible. ",
        "label": 314
    },
    {
        "text": "revisit default condition added to switch cases in trunk  we found that in some cases the default case in switch block was just throwing illegalarg exception. there are cases where we may get some other state for which we should not throw illegalargexception. ",
        "label": 544
    },
    {
        "text": "replicationsink should create connection instances lazily  over on hbase-12911 i have a patch that registers connection instances with the metrics system. in both standalone server and tll client applications, i was surprised to see multiple connection objects showing up that are unused. these are pretty heavy objects, including lots of client threads for the batch pool. we should track these down and remove them \u2013 if they're not some kind of phantom artifacts of my wip patch over there. ",
        "label": 198
    },
    {
        "text": "regionserver can't start when replication tries to replicate to an unknown host  just ran into this: 13/10/11 00:37:02 [regionserver60020] warn  zookeeper.zkconfig(204): java.net.unknownhostexception: <old-host>: name or service not known at java.net.inet6addressimpl.lookupallhostaddr(native method) at java.net.inetaddress$1.lookupallhostaddr(inetaddress.java:894) at java.net.inetaddress.getaddressesfromnameservice(inetaddress.java:1286) at java.net.inetaddress.getallbyname0(inetaddress.java:1239) at java.net.inetaddress.getallbyname(inetaddress.java:1155) at java.net.inetaddress.getallbyname(inetaddress.java:1091) at java.net.inetaddress.getbyname(inetaddress.java:1041) at org.apache.hadoop.hbase.zookeeper.zkconfig.getzkquorumserversstring(zkconfig.java:201) at org.apache.hadoop.hbase.zookeeper.zkconfig.getzkquorumserversstring(zkconfig.java:245) at org.apache.hadoop.hbase.zookeeper.zookeeperwatcher.<init>(zookeeperwatcher.java:147) at org.apache.hadoop.hbase.zookeeper.zookeeperwatcher.<init>(zookeeperwatcher.java:127) at org.apache.hadoop.hbase.replication.replicationpeer.reloadzkwatcher(replicationpeer.java:170) at org.apache.hadoop.hbase.replication.replicationpeer.<init>(replicationpeer.java:69) at org.apache.hadoop.hbase.replication.replicationzookeeper.getpeer(replicationzookeeper.java:343) at org.apache.hadoop.hbase.replication.replicationzookeeper.connecttopeer(replicationzookeeper.java:308) at org.apache.hadoop.hbase.replication.replicationzookeeper.connectexistingpeers(replicationzookeeper.java:189) at org.apache.hadoop.hbase.replication.replicationzookeeper.<init>(replicationzookeeper.java:156) at org.apache.hadoop.hbase.replication.regionserver.replication.initialize(replication.java:89) at org.apache.hadoop.hbase.regionserver.hregionserver.newreplicationinstance(hregionserver.java:3986) at org.apache.hadoop.hbase.regionserver.hregionserver.createnewreplicationinstance(hregionserver.java:3955) at org.apache.hadoop.hbase.regionserver.hregionserver.setupwalandreplication(hregionserver.java:1412) at org.apache.hadoop.hbase.regionserver.hregionserver.handlereportfordutyresponse(hregionserver.java:1096) at org.apache.hadoop.hbase.regionserver.hregionserver.run(hregionserver.java:749) at java.lang.thread.run(thread.java:722) 13/10/11 00:37:02 [regionserver60020] error zookeeper.zkconfig(210): no valid quorum servers found in zoo.cfg 13/10/11 00:37:02 [regionserver60020] warn  regionserver.hregionserver(1108): exception in region server :  java.io.ioexception: unable to determine zookeeper ensemble at org.apache.hadoop.hbase.zookeeper.zkutil.connect(zkutil.java:116) at org.apache.hadoop.hbase.zookeeper.zookeeperwatcher.<init>(zookeeperwatcher.java:153) at org.apache.hadoop.hbase.zookeeper.zookeeperwatcher.<init>(zookeeperwatcher.java:127) at org.apache.hadoop.hbase.replication.replicationpeer.reloadzkwatcher(replicationpeer.java:170) at org.apache.hadoop.hbase.replication.replicationpeer.<init>(replicationpeer.java:69) at org.apache.hadoop.hbase.replication.replicationzookeeper.getpeer(replicationzookeeper.java:343) at org.apache.hadoop.hbase.replication.replicationzookeeper.connecttopeer(replicationzookeeper.java:308) at org.apache.hadoop.hbase.replication.replicationzookeeper.connectexistingpeers(replicationzookeeper.java:189) at org.apache.hadoop.hbase.replication.replicationzookeeper.<init>(replicationzookeeper.java:156) at org.apache.hadoop.hbase.replication.regionserver.replication.initialize(replication.java:89) at org.apache.hadoop.hbase.regionserver.hregionserver.newreplicationinstance(hregionserver.java:3986) at org.apache.hadoop.hbase.regionserver.hregionserver.createnewreplicationinstance(hregionserver.java:3955) at org.apache.hadoop.hbase.regionserver.hregionserver.setupwalandreplication(hregionserver.java:1412) at org.apache.hadoop.hbase.regionserver.hregionserver.handlereportfordutyresponse(hregionserver.java:1096) at org.apache.hadoop.hbase.regionserver.hregionserver.run(hregionserver.java:749) at java.lang.thread.run(thread.java:722) 13/10/11 00:37:02 [regionserver60020] info  regionserver.hregionserver(1823): stopped: failed initialization 13/10/11 00:37:02 [regionserver60020] error regionserver.hregionserver(1228): failed init java.io.ioexception: unable to determine zookeeper ensemble at org.apache.hadoop.hbase.zookeeper.zkutil.connect(zkutil.java:116) at org.apache.hadoop.hbase.zookeeper.zookeeperwatcher.<init>(zookeeperwatcher.java:153) at org.apache.hadoop.hbase.zookeeper.zookeeperwatcher.<init>(zookeeperwatcher.java:127) at org.apache.hadoop.hbase.replication.replicationpeer.reloadzkwatcher(replicationpeer.java:170) at org.apache.hadoop.hbase.replication.replicationpeer.<init>(replicationpeer.java:69) at org.apache.hadoop.hbase.replication.replicationzookeeper.getpeer(replicationzookeeper.java:343) at org.apache.hadoop.hbase.replication.replicationzookeeper.connecttopeer(replicationzookeeper.java:308) at org.apache.hadoop.hbase.replication.replicationzookeeper.connectexistingpeers(replicationzookeeper.java:189) at org.apache.hadoop.hbase.replication.replicationzookeeper.<init>(replicationzookeeper.java:156) at org.apache.hadoop.hbase.replication.regionserver.replication.initialize(replication.java:89) at org.apache.hadoop.hbase.regionserver.hregionserver.newreplicationinstance(hregionserver.java:3986) at org.apache.hadoop.hbase.regionserver.hregionserver.createnewreplicationinstance(hregionserver.java:3955) at org.apache.hadoop.hbase.regionserver.hregionserver.setupwalandreplication(hregionserver.java:1412) at org.apache.hadoop.hbase.regionserver.hregionserver.handlereportfordutyresponse(hregionserver.java:1096) at org.apache.hadoop.hbase.regionserver.hregionserver.run(hregionserver.java:749) at java.lang.thread.run(thread.java:722) 13/10/11 00:37:02 [regionserver60020] fatal regionserver.hregionserver(1898): aborting region server xxxxxxxx,60020,1381451821216: unhandled exception: unable to determine zookeeper ensemble java.io.ioexception: unable to determine zookeeper ensemble at org.apache.hadoop.hbase.zookeeper.zkutil.connect(zkutil.java:116) at org.apache.hadoop.hbase.zookeeper.zookeeperwatcher.<init>(zookeeperwatcher.java:153) at org.apache.hadoop.hbase.zookeeper.zookeeperwatcher.<init>(zookeeperwatcher.java:127) at org.apache.hadoop.hbase.replication.replicationpeer.reloadzkwatcher(replicationpeer.java:170) at org.apache.hadoop.hbase.replication.replicationpeer.<init>(replicationpeer.java:69) at org.apache.hadoop.hbase.replication.replicationzookeeper.getpeer(replicationzookeeper.java:343) at org.apache.hadoop.hbase.replication.replicationzookeeper.connecttopeer(replicationzookeeper.java:308) at org.apache.hadoop.hbase.replication.replicationzookeeper.connectexistingpeers(replicationzookeeper.java:189) at org.apache.hadoop.hbase.replication.replicationzookeeper.<init>(replicationzookeeper.java:156) at org.apache.hadoop.hbase.replication.regionserver.replication.initialize(replication.java:89) at org.apache.hadoop.hbase.regionserver.hregionserver.newreplicationinstance(hregionserver.java:3986) at org.apache.hadoop.hbase.regionserver.hregionserver.createnewreplicationinstance(hregionserver.java:3955) at org.apache.hadoop.hbase.regionserver.hregionserver.setupwalandreplication(hregionserver.java:1412) at org.apache.hadoop.hbase.regionserver.hregionserver.handlereportfordutyresponse(hregionserver.java:1096) at org.apache.hadoop.hbase.regionserver.hregionserver.run(hregionserver.java:749) at java.lang.thread.run(thread.java:722) ",
        "label": 286
    },
    {
        "text": "allow  meta  table to be exported  i tried to export .meta. table in 0.20.6 and got: [hadoop@us01-ciqps1-name01 hbase]$ bin/hbase org.apache.hadoop.hbase.mapreduce.export .meta. h-meta 1 0 0  10/11/23 20:59:05 info jvm.jvmmetrics: initializing jvm metrics with processname=jobtracker, sessionid=  2010-11-23 20:59:05.255::info: logging to stderr via org.mortbay.log.stderrlog  2010-11-23 20:59:05.255::info: verisons=1, starttime=0, endtime=9223372036854775807  10/11/23 20:59:05 info zookeeper.zookeeper: client environment:zookeeper.version=3.2.2-888565, built on 12/08/2009 21:51 gmt  10/11/23 20:59:05 info zookeeper.zookeeper: client environment:host.name=us01-ciqps1-name01.carrieriq.com  10/11/23 20:59:05 info zookeeper.zookeeper: client environment:java.version=1.6.0_21  10/11/23 20:59:05 info zookeeper.zookeeper: client environment:java.vendor=sun microsystems inc.  ...  10/11/23 20:59:05 info zookeeper.clientcnxn: server connection successful  10/11/23 20:59:05 debug zookeeper.zookeeperwrapper: read znode /hbase/root-region-server got 10.202.50.112:60020  10/11/23 20:59:05 debug client.hconnectionmanager$tableservers: found root at 10.202.50.112:60020  10/11/23 20:59:05 debug client.hconnectionmanager$tableservers: cached location for .meta.,,1 is us01-ciqps1-grid02.carrieriq.com:60020  exception in thread \"main\" java.io.ioexception: expecting at least one region.  at org.apache.hadoop.hbase.mapreduce.tableinputformatbase.getsplits(tableinputformatbase.java:281)  at org.apache.hadoop.mapred.jobclient.writenewsplits(jobclient.java:885)  at org.apache.hadoop.mapred.jobclient.submitjobinternal(jobclient.java:779)  at org.apache.hadoop.mapreduce.job.submit(job.java:432)  at org.apache.hadoop.mapreduce.job.waitforcompletion(job.java:447)  at org.apache.hadoop.hbase.mapreduce.export.main(export.java:146) related code is:  if (keys == null || keys.getfirst() == null ||  keys.getfirst().length == 0) { throw new ioexception(\"expecting at least one region.\"); } my intention was to save the dangling rows in .meta. (for future investigation) which prevented a table from being created. ",
        "label": 290
    },
    {
        "text": "filter with filterrow  returning true is incompatible with scan with limit  currently if we scan with bot limit and a filter with filterrow(list<keyvalue>) implemented, an incompatiblefilterexception will be thrown. the same exception should also be thrown if the filer has its filterrow() implemented. ",
        "label": 239
    },
    {
        "text": "internal error when using hbase rest api to create namespace   when trying to the following url to create namespace: secured cluster: curl --negotiate -u : -i -k -vi -x post \"http://hbase_rest_api_host:20550/namespaces/datasparktest\"  unsecured cluster: curl -vi -x post \"http://hbase_rest_api_host:20550/namespaces/datasparktest\" the following is returned on the console:  http/1.1 500 request failed. the error in hbase rest server log is: 2019-08-13 15:44:55,080 warn org.eclipse.jetty.servlet.servlethandler:   javax.servlet.servletexception: java.lang.nullpointerexception  at org.glassfish.jersey.servlet.webcomponent.serviceimpl(webcomponent.java:489)  at org.glassfish.jersey.servlet.webcomponent.service(webcomponent.java:427)  ...  caused by: java.lang.nullpointerexception  at org.apache.hadoop.hbase.rest.namespacesinstanceresource.createorupdate(namespacesinstanceresource.java:250)  at org.apache.hadoop.hbase.rest.namespacesinstanceresource.processupdate(namespacesinstanceresource.java:243)  at org.apache.hadoop.hbase.rest.namespacesinstanceresource.post(namespacesinstanceresource.java:183)  at sun.reflect.nativemethodaccessorimpl.invoke0(native method)  at sun.reflect.nativemethodaccessorimpl.invoke(nativemethodaccessorimpl.java:62)  at sun.reflect.delegatingmethodaccessorimpl.invoke(delegatingmethodaccessorimpl.java:43)  at java.lang.reflect.method.invoke(method.java:498)  at org.glassfish.jersey.server.model.internal.resourcemethodinvocationhandlerfactory$1.invoke(resourcemethodinvocationhandlerfactory.java:81)  at org.glassfish.jersey.server.model.internal.abstractjavaresourcemethoddispatcher$1.run(abstractjavaresourcemethoddispatcher.java:144)  at org.glassfish.jersey.server.model.internal.abstractjavaresourcemethoddispatcher.invoke(abstractjavaresourcemethoddispatcher.java:161)   ",
        "label": 486
    },
    {
        "text": "htable incrementcolumnvalue does not take negative 'amount'  ",
        "label": 167
    },
    {
        "text": "testhfileoutputformat intermittent diff  loadincrementalhfiles should put expected data in table expected  but was   tests run: 5, failures: 2, errors: 0, skipped: 0, time elapsed: 160.582 sec <<< failure! testmrincrementalload(org.apache.hadoop.hbase.mapreduce.testhfileoutputformat)  time elapsed: 85.676 sec  <<< failure! java.lang.assertionerror: loadincrementalhfiles should put expected data in table expected:<2048> but was:<1024>         at org.junit.assert.fail(assert.java:91)         at org.junit.assert.failnotequals(assert.java:645)         at org.junit.assert.assertequals(assert.java:126)         at org.junit.assert.assertequals(assert.java:470)         at org.apache.hadoop.hbase.mapreduce.testhfileoutputformat.doincrementalloadtest(testhfileoutputformat.java:300)         at org.apache.hadoop.hbase.mapreduce.testhfileoutputformat.testmrincrementalload(testhfileoutputformat.java:248)         at sun.reflect.nativemethodaccessorimpl.invoke0(native method) will upload full test output shortly. ",
        "label": 453
    },
    {
        "text": "filterlist of prefix and columnvalue not working properly with deletes and multiple values  attached are some unit tests from client and region that demonstrate the failing issues. ",
        "label": 314
    },
    {
        "text": "add log about average execution time for scheduledchore  so far, there is no information about the exact execution time for a chore, we can provide log information about it. it also brings other benefits, like discovering inefficient chores which show rooms for improvement. ",
        "label": 370
    },
    {
        "text": "investigate ipc performance  turning off all file i/o, and running the performanceevaluation test, of 1,048,576 sequential writes to hbase managed to achieve only 7,285 ipcs per second. running performanceevaluation sequential write test modified to do an abort instead of a commit, it was possible to do 68,337 operations per second. we are obviously spending a lot of time doing ipcs. we need to investigate to find the bottleneck. marshalling and unmarshalling? socket setup and teardown? ",
        "label": 314
    },
    {
        "text": "org apache hadoop hbase master procedure testwalprocedurestoreonhdfs is super duper flaky  as seen in jenkins, this test has been super flaky and we should probably address it. ",
        "label": 198
    },
    {
        "text": "implementation of mutation getwritetowal  is backwards  the implementation of the deprecated getwritetowal is backwards. it should return true if this.durability == durability.sync_wal: /**    * @deprecated use {@link #getdurability()} instead.    * @return true if edits should be applied to wal, false if not    */   @deprecated   public boolean getwritetowal() {     return this.durability == durability.skip_wal;   } for example, if mutation.durability is durability.sync_wal and the following code is called clonedmutation.setwritetowal(mutation.getwritetowal()), it will disable writing to the wal for clonedmutation. ",
        "label": 155
    },
    {
        "text": "move hbase nightly source artifact creation test from jenkinsfile to a script in dev support  ref: https://issues.apache.org/jira/browse/hbase-19089?focusedcommentid=16221551&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-16221551 moving that jenkins test to script will make it easier to test changes to hbase-assembly. ",
        "label": 402
    },
    {
        "text": "oome in master splitting logs  in testing a rs failure under heavy increment workload i ran into an oome when the master was splitting the logs. in this test case, i have exactly 136 bytes per log entry in all the logs, and the logs are all around 66-74mb). with a batch size of 3 logs, this means the master is loading about 500k-600k edits per log file. each edit ends up creating 3 byte[] objects, the references for which are each 8 bytes of ram, so we have 160 (136+8*3) bytes per edit used by the byte[]. for each edit we also allocate a bunch of other objects: one hlog$entry, one waledit, one arraylist, one linkedlist$entry, one hlogkey, and one keyvalue. overall this works out to 400 bytes of overhead per edit. so, with the default settings on this fairly average workload, the 1.5m log entries takes about 770mb of ram. since i had a few log files that were a bit larger (around 90mb) it exceeded 1gb of ram and i got an oome. for one, the 400 bytes per edit overhead is pretty bad, and we could probably be a lot more efficient. for two, we should actually account this rather than simply having a configurable \"batch size\" in the master. i think this is a blocker because i'm running with fairly default configs here and just killing one rs made the cluster fall over due to master oome. ",
        "label": 453
    },
    {
        "text": "hfileoutputformat2 split a lot of hfile by roll once per rowkey  when i use hfileoutputformat2 in mr job to build hfiles\uff0cin reducer it creates lots of files. here is the log: 2019-08-16 14:42:51,988 info [main] org.apache.hadoop.hbase.mapreduce.hfileoutputformat2: writer=hdfs://hfile/_temporary/1/_temporary/attempt_1558444096078_519332_r_000016_0/f1/06f3b0e9f0644ee782b7cf4469f44a70, wrote=893827310 writer=hdfs://hfile/_temporary/1/_temporary/attempt_1558444096078_519332_r_000016_0/f1/1454ea148f1547499209a266ad25387f, wrote=61 writer=hdfs://hfile/_temporary/1/_temporary/attempt_1558444096078_519332_r_000016_0/f1/9d35446634154b4ca4be56f361b57c8b, wrote=55  ...   it keep writing a new file every rowkey comes.  then i output more logs for detail and found the problem. code heregithub if (wl != null && wl.written + length >= maxsize) {   this.rollrequested = true; } // this can only happen once a row is finished though if (rollrequested && bytes.compareto(this.previousrow, rowkey) != 0) {   rollwriters(wl); } in my case\uff0ci have two fimaly f1 & f2\uff0cand writer of f2 arrives the maxsize  ,so rollrequested becomes true, but it's rowkey was the same with previousrow so writer won't be roll. when next rowkey comes with fimaly f1, both of rollrequested && bytes.compareto(this.previousrow, rowkey) != 0 is true\uff0cand writter of f1 will be roll , new hfile create. and then same rowkey with fimaly f2 comes set rollrequested  true, and next rowkey with fimaly f1 comes writter of f1 rolled.   so, it will create a new hfile for every rowkey with fimaly f1, and f2 will never be roll until job ends.     here is my questions and part of solutions:  q1. first whether hbase 2.0.0 support different family of same hbasetable has different rowkey cut\uff1fwhich means rowkeya writes in the first hfile of f1\uff0cbut may be the second hfile of f2. for hbase 1.x.x it doesn't support so we roll all the writter and won't get this problem. i guess the answer is \"yes,support\" , we goes to q2.  q2. do we allow same rowkey with same family, comes to hfileoutputformat2.write?  if not, can we fix it this way, cause this rowkey will never be the same with previouserow  if (wl != null && wl.written + length >= maxsize) {        rollwriters(wl);  } if yes, should we need map to record previouserow private final map<byte[], byte[]> previousrows =         new treemap<>(bytes.bytes_comparator); if (wl != null && wl.written + length >= maxsize && bytes.compareto(this.previousrows.get(family), rowkey) != 0) {       rollwriters(wl);  } ",
        "label": 535
    },
    {
        "text": "hbase added bug where we'd tight loop if no root available   ",
        "label": 70
    },
    {
        "text": "provide administrative limits around bulkloads of files into a single region  given the current mechanism, it is possible for users to flood a single region with 1k+ store files via the bulkload api and basically cause the region to become a flying dutchman - never getting assigned successfully again. ideally, an administrative limit could solve this. if the bulkload rpc call can check if the region already has x store files, then it can reject the request to add another and throw a failure at the client with an appropriate message. this may be an intrusive change, but seems necessary in perfecting the gap between devs and ops in managing a hbase clusters. this would especially prevent abuse in form of unaware devs not pre-splitting tables before bulkloading things in. currently, this leads to ops pain, as the devs think hbase has gone non-functional and begin complaining. ",
        "label": 242
    },
    {
        "text": "testhregion testwriteswhilegetting flaky on trunk  saw this failure on my internal hudson: junit.framework.assertionfailederror: expected:<\\x00\\x00\\x00\\x96> but was:<\\x00\\x00\\x01\\x00>  at org.apache.hadoop.hbase.hbasetestcase.assertequals(hbasetestcase.java:684)  at org.apache.hadoop.hbase.regionserver.testhregion.testwriteswhilegetting(testhregion.java:2334) ",
        "label": 547
    }
]